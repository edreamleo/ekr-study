<?xml version="1.0" encoding="utf-8"?>
<!-- Created by Leo: https://leo-editor.github.io/leo-editor/leo_toc.html -->
<leo_file xmlns:leo="https://leo-editor.github.io/leo-editor/namespaces/leo-python-editor/1.1" >
<leo_header file_format="2"/>
<globals/>
<preferences/>
<find_panel_settings/>
<vnodes>
<v t="ekr.20131030071311.17125" descendentVnodeUnknownAttributes="7d7100285803000000302e3071017d7102580b0000005f5f626f6f6b6d61726b7371037d7104580700000069735f6475706571054930300a7373580a000000302e302e31302e362e3071067d7107580b0000005f5f626f6f6b6d61726b7371087d7109580700000069735f64757065710a4930300a7373580b000000302e302e31302e362e3234710b7d710c5808000000616e6e6f74617465710d7d710e2858080000007072696f72697479710f4d0f27580a000000707269736574646174657110580a000000323032302d31312d313171117573752e"><vh>Startup</vh>
<v t="ekr.20250131013029.1" descendentVnodeUnknownAttributes="7d71002858010000003071017d7102580b0000005f5f626f6f6b6d61726b7371037d7104580700000069735f6475706571054930300a73735808000000302e31302e362e3071067d7107580b0000005f5f626f6f6b6d61726b7371087d7109580700000069735f64757065710a4930300a73735809000000302e31302e362e3234710b7d710c5808000000616e6e6f74617465710d7d710e2858080000007072696f72697479710f4d0f27580a000000707269736574646174657110580a000000323032302d31312d313171117573752e"><vh>@settings</vh>
<v t="ekr.20250131013029.2"><vh>@bool allow-text-zoom = True</vh></v>
<v t="ekr.20250131014711.1"><vh>@bool beautify-python-code-on-write = False</vh></v>
<v t="ekr.20250131013029.3"><vh>@bool check-python-code-on-write = True</vh></v>
<v t="ekr.20250131013029.4"><vh>@bool use-german-keyboard = False</vh></v>
<v t="ekr.20250131013029.5"><vh>@bool use-mouse-expand-gestures = False</vh></v>
<v t="ekr.20250131013029.6"><vh>@data exec-script-commands</vh></v>
<v t="ekr.20250131013029.7"><vh>@data exec-script-patterns</vh></v>
<v t="ekr.20250131013029.8"><vh>@data history-list</vh></v>
<v t="ekr.20250131013029.9"><vh>@rclick say-hi @args=say hi</vh></v>
<v t="ekr.20250131013029.10"><vh>@string qt-layout-name = legacy</vh></v>
<v t="ekr.20250131013029.11" descendentVnodeUnknownAttributes="7d7100285805000000302e362e3071017d7102580b0000005f5f626f6f6b6d61726b7371037d7104580700000069735f6475706571054930300a73735806000000302e362e323471067d71075808000000616e6e6f7461746571087d71092858080000007072696f72697479710a4d0f27580a00000070726973657464617465710b580a000000323032302d31312d3131710c7573752e"><vh>Buttons &amp; commands</vh>
<v t="ekr.20250131013029.12"><vh>#@button count-children</vh></v>
<v t="ekr.20250131013029.13"><vh>#@button print-gnx @key=f6</vh></v>
<v t="ekr.20250131013029.14"><vh>#@button show-uas</vh></v>
<v t="ekr.20250131013029.15"><vh>#@button take-screen-shot</vh></v>
<v t="ekr.20250131013029.16"><vh>#@command test @key=f5</vh></v>
<v t="ekr.20250131013029.17"><vh>@button backup</vh></v>
<v t="ekr.20250131013029.18" descendentVnodeUnknownAttributes="7d7100285803000000302e3071017d7102580b0000005f5f626f6f6b6d61726b7371037d7104580700000069735f6475706571054930300a73735804000000302e323471067d71075808000000616e6e6f7461746571087d71092858080000007072696f72697479710a4d0f27580a00000070726973657464617465710b580a000000323032302d31312d3131710c7573752e"><vh>@ignore Disabled buttons</vh>
<v t="ekr.20250131013029.19" descendentVnodeUnknownAttributes="7d710058010000003071017d7102580b0000005f5f626f6f6b6d61726b7371037d7104580700000069735f6475706571054930300a7373732e"><vh>@button adoc</vh></v>
<v t="ekr.20250131013029.20"><vh>@button clean-text</vh></v>
<v t="ekr.20250131013029.21"><vh>@button create decorators</vh>
<v t="ekr.20250131013029.22"><vh>create_d</vh></v>
<v t="ekr.20250131013029.23"><vh>create_decorator</vh></v>
<v t="ekr.20250131013029.24"><vh>create_decorators</vh></v>
<v t="ekr.20250131013029.25"><vh>create_fixups</vh></v>
<v t="ekr.20250131013029.26"><vh>find_class</vh></v>
<v t="ekr.20250131013029.27"><vh>find_next_clone</vh></v>
<v t="ekr.20250131013029.28"><vh>munge_lines</vh></v>
<v t="ekr.20250131013029.29"><vh>run</vh></v>
</v>
<v t="ekr.20250131013029.30"><vh>@button cycling syntax coloring</vh></v>
<v t="ekr.20250131013029.31"><vh>@button dump uA</vh></v>
<v t="ekr.20250131013029.32"><vh>@button dump-state-dict</vh></v>
<v t="ekr.20250131013029.33"><vh>@button expand-section</vh></v>
<v t="ekr.20250131013029.34"><vh>@button graalvm</vh></v>
<v t="ekr.20250131013029.35"><vh>@button introspect</vh></v>
<v t="ekr.20250131013029.36"><vh>@button join-path</vh></v>
<v t="ekr.20250131013029.37"><vh>@button load-readme</vh></v>
<v t="ekr.20250131013029.38"><vh>@button make-decorators2</vh>
<v t="ekr.20250131013029.39"><vh>create_d</vh></v>
<v t="ekr.20250131013029.40"><vh>create_decorator</vh></v>
<v t="ekr.20250131013029.41"><vh>create_decorators V2</vh></v>
<v t="ekr.20250131013029.42"><vh>define_s</vh></v>
<v t="ekr.20250131013029.43"><vh>munge_lines</vh></v>
<v t="ekr.20250131013029.44"><vh>run V2</vh></v>
</v>
<v t="ekr.20250131013029.45"><vh>@button munge</vh></v>
<v t="ekr.20250131013029.46"><vh>@button print-gnx</vh></v>
<v t="ekr.20250131013029.47"><vh>@button print-ss</vh></v>
<v t="ekr.20250131013029.48"><vh>@button print-ua</vh></v>
<v t="ekr.20250131013029.49"><vh>@button proto</vh></v>
<v t="ekr.20250131013029.50"><vh>@button qt-demo</vh></v>
<v t="ekr.20250131013029.51"><vh>@button rclick-test</vh>
<v t="ekr.20250131013029.52"><vh>@rclick hi</vh></v>
</v>
<v t="ekr.20250131013029.53"><vh>@button reload-leowapp</vh></v>
<v t="ekr.20250131013029.54"><vh>@button save-clipboard</vh></v>
<v t="ekr.20250131013029.55"><vh>@button screen-shot @key=ctrl-1</vh></v>
<v t="ekr.20250131013029.56"><vh>@button set-ua</vh></v>
<v t="ekr.20250131013029.57"><vh>@button split-path</vh></v>
<v t="ekr.20250131013029.58" descendentVnodeUnknownAttributes="7d710058010000003071017d71025808000000616e6e6f7461746571037d71042858080000007072696f7269747971054d0f27580a000000707269736574646174657106580a000000323032302d31312d313171077573732e"><vh>@button test-undo-body</vh></v>
<v t="ekr.20250131013029.59"><vh>@button test-undo-head</vh></v>
<v t="ekr.20250131013029.60"><vh>@button timeit</vh></v>
<v t="ekr.20250131013029.61"><vh>@button toggle-debug-app</vh></v>
<v t="ekr.20250131013029.62"><vh>@button unit-tests</vh></v>
<v t="ekr.20250131013029.63"><vh>@command test @key=Ctrl-F7</vh></v>
</v>
</v>
</v>
<v t="ekr.20250131013112.1"><vh> Recursive import script</vh></v>
</v>
<v t="ekr.20250131013112.1"></v>
<v t="ekr.20250131014444.1"><vh>crash</vh></v>
<v t="ekr.20250131013559.238"><vh>pylint</vh>
<v t="ekr.20250131013559.239"><vh>@clean __init__.py</vh>
<v t="ekr.20250131013559.240"><vh>function: run_pylint</vh></v>
<v t="ekr.20250131013559.241"><vh>function: _run_pylint_config</vh></v>
<v t="ekr.20250131013559.242"><vh>function: run_pyreverse</vh></v>
<v t="ekr.20250131013559.243"><vh>function: run_symilar</vh></v>
<v t="ekr.20250131013559.244"><vh>function: modify_sys_path</vh></v>
<v t="ekr.20250131013559.245"><vh>function: _catch_valueerror</vh></v>
</v>
<v t="ekr.20250131013559.246"><vh>@clean __main__.py</vh></v>
<v t="ekr.20250131013559.247"><vh>@clean __pkginfo__.py</vh>
<v t="ekr.20250131013559.248"><vh>function: get_numversion_from_version</vh></v>
</v>
<v t="ekr.20250131013559.249"><vh>@clean constants.py</vh>
<v t="ekr.20250131013559.250"><vh>class WarningScope</vh></v>
<v t="ekr.20250131013559.251"><vh>function: _get_pylint_home</vh></v>
</v>
<v t="ekr.20250131013559.252"><vh>@clean exceptions.py</vh>
<v t="ekr.20250131013559.253"><vh>class InvalidMessageError</vh></v>
<v t="ekr.20250131013559.254"><vh>class UnknownMessageError</vh></v>
<v t="ekr.20250131013559.255"><vh>class DeletedMessageError</vh>
<v t="ekr.20250131013559.261"><vh>DeletedMessageError.__init__</vh></v>
</v>
<v t="ekr.20250131013559.256"><vh>class MessageBecameExtensionError</vh>
<v t="ekr.20250131013559.262"><vh>MessageBecameExtensionError.__init__</vh></v>
</v>
<v t="ekr.20250131013559.257"><vh>class EmptyReportError</vh></v>
<v t="ekr.20250131013559.258"><vh>class InvalidReporterError</vh></v>
<v t="ekr.20250131013559.259"><vh>class InvalidArgsError</vh></v>
<v t="ekr.20250131013559.260"><vh>class NoLineSuppliedError</vh></v>
</v>
<v t="ekr.20250131013559.263"><vh>@clean graph.py</vh>
<v t="ekr.20250131013559.264"><vh>function: target_info_from_filename</vh></v>
<v t="ekr.20250131013559.265"><vh>class DotBackend</vh>
<v t="ekr.20250131013559.269"><vh>DotBackend.__init__</vh></v>
<v t="ekr.20250131013559.270"><vh>DotBackend.get_source</vh></v>
<v t="ekr.20250131013559.271"><vh>DotBackend.generate</vh></v>
<v t="ekr.20250131013559.272"><vh>DotBackend.emit</vh></v>
<v t="ekr.20250131013559.273"><vh>DotBackend.emit_edge</vh></v>
<v t="ekr.20250131013559.274"><vh>DotBackend.emit_node</vh></v>
</v>
<v t="ekr.20250131013559.266"><vh>function: normalize_node_id</vh></v>
<v t="ekr.20250131013559.267"><vh>function: get_cycles</vh></v>
<v t="ekr.20250131013559.268"><vh>function: _get_cycles</vh></v>
</v>
<v t="ekr.20250131013559.275"><vh>@clean interfaces.py</vh>
<v t="ekr.20250131013559.276"><vh>class Confidence</vh></v>
</v>
<v t="ekr.20250131013559.277"><vh>@clean typing.py</vh>
<v t="ekr.20250131013559.278"><vh>class FileItem</vh></v>
<v t="ekr.20250131013559.279"><vh>class ModuleDescriptionDict</vh></v>
<v t="ekr.20250131013559.280"><vh>class ErrorDescriptionDict</vh></v>
<v t="ekr.20250131013559.281"><vh>class MessageLocationTuple</vh></v>
<v t="ekr.20250131013559.282"><vh>class ManagedMessage</vh></v>
<v t="ekr.20250131013559.283"><vh>class ExtraMessageOptions</vh></v>
<v t="ekr.20250131013559.284"><vh>class GetProjectCallable</vh>
<v t="ekr.20250131013559.285"><vh>GetProjectCallable.__call__</vh></v>
</v>
</v>
<v t="ekr.20250131013559.286"><vh>path: pylint/checkers</vh>
<v t="ekr.20250131013559.287"><vh>@clean __init__.py</vh>
<v t="ekr.20250131013559.288"><vh>function: table_lines_from_stats</vh></v>
<v t="ekr.20250131013559.289"><vh>function: initialize</vh></v>
</v>
<v t="ekr.20250131013559.290"><vh>@clean async_checker.py</vh>
<v t="ekr.20250131013559.291"><vh>class AsyncChecker</vh>
<v t="ekr.20250131013559.293"><vh>AsyncChecker.open</vh></v>
<v t="ekr.20250131013559.294"><vh>AsyncChecker.visit_asyncfunctiondef</vh></v>
<v t="ekr.20250131013559.295"><vh>AsyncChecker.visit_asyncwith</vh></v>
</v>
<v t="ekr.20250131013559.292"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013559.296"><vh>@clean bad_chained_comparison.py</vh>
<v t="ekr.20250131013559.297"><vh>class BadChainedComparisonChecker</vh>
<v t="ekr.20250131013559.299"><vh>BadChainedComparisonChecker._has_diff_semantic_groups</vh></v>
<v t="ekr.20250131013559.300"><vh>BadChainedComparisonChecker.visit_compare</vh></v>
</v>
<v t="ekr.20250131013559.298"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013559.301"><vh>@clean base_checker.py</vh>
<v t="ekr.20250131013559.302"><vh>class BaseChecker</vh>
<v t="ekr.20250131013559.305"><vh>BaseChecker.__init__</vh></v>
<v t="ekr.20250131013559.306"><vh>BaseChecker.__gt__</vh></v>
<v t="ekr.20250131013559.307"><vh>BaseChecker.__eq__</vh></v>
<v t="ekr.20250131013559.308"><vh>BaseChecker.__hash__</vh></v>
<v t="ekr.20250131013559.309"><vh>BaseChecker.__repr__</vh></v>
<v t="ekr.20250131013559.310"><vh>BaseChecker.__str__</vh></v>
<v t="ekr.20250131013559.311"><vh>BaseChecker.get_full_documentation</vh></v>
<v t="ekr.20250131013559.312"><vh>BaseChecker.add_message</vh></v>
<v t="ekr.20250131013559.313"><vh>BaseChecker.check_consistency</vh></v>
<v t="ekr.20250131013559.314"><vh>BaseChecker.create_message_definition_from_tuple</vh></v>
<v t="ekr.20250131013559.315"><vh>BaseChecker.messages</vh></v>
<v t="ekr.20250131013559.316"><vh>BaseChecker.open</vh></v>
<v t="ekr.20250131013559.317"><vh>BaseChecker.close</vh></v>
<v t="ekr.20250131013559.318"><vh>BaseChecker.get_map_data</vh></v>
<v t="ekr.20250131013559.319"><vh>BaseChecker.reduce_map_data</vh></v>
</v>
<v t="ekr.20250131013559.303"><vh>class BaseTokenChecker</vh>
<v t="ekr.20250131013559.320"><vh>BaseTokenChecker.process_tokens</vh></v>
</v>
<v t="ekr.20250131013559.304"><vh>class BaseRawFileChecker</vh>
<v t="ekr.20250131013559.321"><vh>BaseRawFileChecker.process_module</vh></v>
</v>
</v>
<v t="ekr.20250131013559.322"><vh>@clean dataclass_checker.py</vh>
<v t="ekr.20250131013559.323"><vh>function: _is_dataclasses_module</vh></v>
<v t="ekr.20250131013559.324"><vh>function: _check_name_or_attrname_eq_to</vh></v>
<v t="ekr.20250131013559.325"><vh>class DataclassChecker</vh>
<v t="ekr.20250131013559.327"><vh>DataclassChecker.visit_call</vh></v>
<v t="ekr.20250131013559.328"><vh>DataclassChecker._check_invalid_field_call</vh></v>
<v t="ekr.20250131013559.329"><vh>DataclassChecker._check_invalid_field_call_within_call</vh></v>
</v>
<v t="ekr.20250131013559.326"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013559.330"><vh>@clean deprecated.py</vh>
<v t="ekr.20250131013559.331"><vh>class DeprecatedMixin</vh>
<v t="ekr.20250131013559.332"><vh>DeprecatedMixin.visit_attribute</vh></v>
<v t="ekr.20250131013559.333"><vh>DeprecatedMixin.visit_call</vh></v>
<v t="ekr.20250131013559.334"><vh>DeprecatedMixin.visit_import</vh></v>
<v t="ekr.20250131013559.335"><vh>DeprecatedMixin.deprecated_decorators</vh></v>
<v t="ekr.20250131013559.336"><vh>DeprecatedMixin.visit_decorators</vh></v>
<v t="ekr.20250131013559.337"><vh>DeprecatedMixin.visit_importfrom</vh></v>
<v t="ekr.20250131013559.338"><vh>DeprecatedMixin.deprecated_methods</vh></v>
<v t="ekr.20250131013559.339"><vh>DeprecatedMixin.deprecated_arguments</vh></v>
<v t="ekr.20250131013559.340"><vh>DeprecatedMixin.deprecated_modules</vh></v>
<v t="ekr.20250131013559.341"><vh>DeprecatedMixin.deprecated_classes</vh></v>
<v t="ekr.20250131013559.342"><vh>DeprecatedMixin.deprecated_attributes</vh></v>
<v t="ekr.20250131013559.343"><vh>DeprecatedMixin.check_deprecated_attribute</vh></v>
<v t="ekr.20250131013559.344"><vh>DeprecatedMixin.check_deprecated_module</vh></v>
<v t="ekr.20250131013559.345"><vh>DeprecatedMixin.check_deprecated_method</vh></v>
<v t="ekr.20250131013559.346"><vh>DeprecatedMixin.check_deprecated_class</vh></v>
<v t="ekr.20250131013559.347"><vh>DeprecatedMixin.check_deprecated_class_in_call</vh></v>
</v>
</v>
<v t="ekr.20250131013559.348"><vh>@clean design_analysis.py</vh>
<v t="ekr.20250131013559.349"><vh>function: _is_exempt_from_public_methods</vh></v>
<v t="ekr.20250131013559.350"><vh>function: _count_boolean_expressions</vh></v>
<v t="ekr.20250131013559.351"><vh>function: _count_methods_in_class</vh></v>
<v t="ekr.20250131013559.352"><vh>function: _get_parents_iter</vh></v>
<v t="ekr.20250131013559.353"><vh>function: _get_parents</vh></v>
<v t="ekr.20250131013559.354"><vh>class MisdesignChecker</vh>
<v t="ekr.20250131013559.356"><vh>MisdesignChecker.__init__</vh></v>
<v t="ekr.20250131013559.357"><vh>MisdesignChecker.open</vh></v>
<v t="ekr.20250131013559.358"><vh>MisdesignChecker._inc_all_stmts</vh></v>
<v t="ekr.20250131013559.359"><vh>MisdesignChecker.visit_classdef</vh></v>
<v t="ekr.20250131013559.360"><vh>MisdesignChecker.leave_classdef</vh></v>
<v t="ekr.20250131013559.361"><vh>MisdesignChecker.visit_functiondef</vh></v>
<v t="ekr.20250131013559.362"><vh>MisdesignChecker.leave_functiondef</vh></v>
<v t="ekr.20250131013559.363"><vh>MisdesignChecker.visit_return</vh></v>
<v t="ekr.20250131013559.364"><vh>MisdesignChecker.visit_default</vh></v>
<v t="ekr.20250131013559.365"><vh>MisdesignChecker.visit_try</vh></v>
<v t="ekr.20250131013559.366"><vh>MisdesignChecker.visit_if</vh></v>
<v t="ekr.20250131013559.367"><vh>MisdesignChecker._check_boolean_expressions</vh></v>
<v t="ekr.20250131013559.368"><vh>MisdesignChecker.visit_while</vh></v>
<v t="ekr.20250131013559.369"><vh>MisdesignChecker._inc_branch</vh></v>
</v>
<v t="ekr.20250131013559.355"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013559.370"><vh>@clean dunder_methods.py</vh>
<v t="ekr.20250131013559.371"><vh>class DunderCallChecker</vh>
<v t="ekr.20250131013559.373"><vh>DunderCallChecker.open</vh></v>
<v t="ekr.20250131013559.374"><vh>DunderCallChecker.within_dunder_or_lambda_def</vh></v>
<v t="ekr.20250131013559.375"><vh>DunderCallChecker.is_lambda_rule_exception</vh></v>
<v t="ekr.20250131013559.376"><vh>DunderCallChecker.visit_call</vh></v>
</v>
<v t="ekr.20250131013559.372"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013559.377"><vh>@clean ellipsis_checker.py</vh>
<v t="ekr.20250131013559.378"><vh>class EllipsisChecker</vh>
<v t="ekr.20250131013559.380"><vh>EllipsisChecker.visit_const</vh></v>
</v>
<v t="ekr.20250131013559.379"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013559.381"><vh>@clean exceptions.py</vh>
<v t="ekr.20250131013559.382"><vh>function: _builtin_exceptions</vh></v>
<v t="ekr.20250131013559.383"><vh>function: _annotated_unpack_infer</vh></v>
<v t="ekr.20250131013559.384"><vh>function: _is_raising</vh></v>
<v t="ekr.20250131013559.385"><vh>class BaseVisitor</vh>
<v t="ekr.20250131013559.390"><vh>BaseVisitor.__init__</vh></v>
<v t="ekr.20250131013559.391"><vh>BaseVisitor.visit</vh></v>
<v t="ekr.20250131013559.392"><vh>BaseVisitor.visit_default</vh></v>
</v>
<v t="ekr.20250131013559.386"><vh>class ExceptionRaiseRefVisitor</vh>
<v t="ekr.20250131013559.393"><vh>ExceptionRaiseRefVisitor.visit_name</vh></v>
<v t="ekr.20250131013559.394"><vh>ExceptionRaiseRefVisitor.visit_call</vh></v>
</v>
<v t="ekr.20250131013559.387"><vh>class ExceptionRaiseLeafVisitor</vh>
<v t="ekr.20250131013559.395"><vh>ExceptionRaiseLeafVisitor.visit_const</vh></v>
<v t="ekr.20250131013559.396"><vh>ExceptionRaiseLeafVisitor.visit_instance</vh></v>
<v t="ekr.20250131013559.397"><vh>ExceptionRaiseLeafVisitor.visit_classdef</vh></v>
<v t="ekr.20250131013559.398"><vh>ExceptionRaiseLeafVisitor.visit_tuple</vh></v>
<v t="ekr.20250131013559.399"><vh>ExceptionRaiseLeafVisitor.visit_default</vh></v>
</v>
<v t="ekr.20250131013559.388"><vh>class ExceptionsChecker</vh>
<v t="ekr.20250131013559.400"><vh>ExceptionsChecker.open</vh></v>
<v t="ekr.20250131013559.401"><vh>ExceptionsChecker.visit_raise</vh></v>
<v t="ekr.20250131013559.402"><vh>ExceptionsChecker._check_misplaced_bare_raise</vh></v>
<v t="ekr.20250131013559.403"><vh>ExceptionsChecker._check_bad_exception_cause</vh></v>
<v t="ekr.20250131013559.404"><vh>ExceptionsChecker._check_raise_missing_from</vh></v>
<v t="ekr.20250131013559.405"><vh>ExceptionsChecker._check_catching_non_exception</vh></v>
<v t="ekr.20250131013559.406"><vh>ExceptionsChecker._check_try_except_raise</vh></v>
<v t="ekr.20250131013559.407"><vh>ExceptionsChecker.visit_binop</vh></v>
<v t="ekr.20250131013559.408"><vh>ExceptionsChecker.visit_compare</vh></v>
<v t="ekr.20250131013559.409"><vh>ExceptionsChecker.visit_trystar</vh></v>
<v t="ekr.20250131013559.410"><vh>ExceptionsChecker.visit_try</vh></v>
<v t="ekr.20250131013559.411"><vh>ExceptionsChecker._is_overgeneral_exception</vh></v>
</v>
<v t="ekr.20250131013559.389"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013559.412"><vh>@clean format.py</vh>
<v t="ekr.20250131013559.413"><vh>function: _last_token_on_line_is</vh></v>
<v t="ekr.20250131013559.414"><vh>class TokenWrapper</vh>
<v t="ekr.20250131013559.417"><vh>TokenWrapper.__init__</vh></v>
<v t="ekr.20250131013559.418"><vh>TokenWrapper.token</vh></v>
<v t="ekr.20250131013559.419"><vh>TokenWrapper.type</vh></v>
<v t="ekr.20250131013559.420"><vh>TokenWrapper.start_line</vh></v>
<v t="ekr.20250131013559.421"><vh>TokenWrapper.start_col</vh></v>
<v t="ekr.20250131013559.422"><vh>TokenWrapper.line</vh></v>
</v>
<v t="ekr.20250131013559.415"><vh>class FormatChecker</vh>
<v t="ekr.20250131013559.423"><vh>FormatChecker.__init__</vh></v>
<v t="ekr.20250131013559.424"><vh>FormatChecker.new_line</vh></v>
<v t="ekr.20250131013559.425"><vh>FormatChecker.process_module</vh></v>
<v t="ekr.20250131013559.426"><vh>FormatChecker._check_keyword_parentheses</vh></v>
<v t="ekr.20250131013559.427"><vh>FormatChecker.process_tokens</vh></v>
<v t="ekr.20250131013559.428"><vh>FormatChecker._check_line_ending</vh></v>
<v t="ekr.20250131013559.429"><vh>FormatChecker.visit_default</vh></v>
<v t="ekr.20250131013559.430"><vh>FormatChecker._is_first_node_in_else_finally_body</vh></v>
<v t="ekr.20250131013559.431"><vh>FormatChecker._infer_else_finally_line_number</vh></v>
<v t="ekr.20250131013559.432"><vh>FormatChecker._check_multi_statement_line</vh></v>
<v t="ekr.20250131013559.433"><vh>FormatChecker.check_trailing_whitespace_ending</vh></v>
<v t="ekr.20250131013559.434"><vh>FormatChecker.check_line_length</vh></v>
<v t="ekr.20250131013559.435"><vh>FormatChecker.remove_pylint_option_from_lines</vh></v>
<v t="ekr.20250131013559.436"><vh>FormatChecker.is_line_length_check_activated</vh></v>
<v t="ekr.20250131013559.437"><vh>FormatChecker.specific_splitlines</vh></v>
<v t="ekr.20250131013559.438"><vh>FormatChecker.check_lines</vh></v>
<v t="ekr.20250131013559.439"><vh>FormatChecker.check_indent_level</vh></v>
</v>
<v t="ekr.20250131013559.416"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013559.440"><vh>@clean imports.py</vh>
<v t="ekr.20250131013559.441"><vh>function: _get_first_import</vh></v>
<v t="ekr.20250131013559.442"><vh>function: _ignore_import_failure</vh></v>
<v t="ekr.20250131013559.443"><vh>function: _make_tree_defs</vh></v>
<v t="ekr.20250131013559.444"><vh>function: _repr_tree_defs</vh></v>
<v t="ekr.20250131013559.445"><vh>function: _dependencies_graph</vh></v>
<v t="ekr.20250131013559.446"><vh>function: _make_graph</vh></v>
<v t="ekr.20250131013559.447"><vh>class ImportsChecker</vh>
<v t="ekr.20250131013559.449"><vh>ImportsChecker.__init__</vh></v>
<v t="ekr.20250131013559.450"><vh>ImportsChecker.open</vh></v>
<v t="ekr.20250131013559.451"><vh>ImportsChecker._import_graph_without_ignored_edges</vh></v>
<v t="ekr.20250131013559.452"><vh>ImportsChecker.close</vh></v>
<v t="ekr.20250131013559.453"><vh>ImportsChecker.get_map_data</vh></v>
<v t="ekr.20250131013559.454"><vh>ImportsChecker.reduce_map_data</vh></v>
<v t="ekr.20250131013559.455"><vh>ImportsChecker.deprecated_modules</vh></v>
<v t="ekr.20250131013559.456"><vh>ImportsChecker.visit_module</vh></v>
<v t="ekr.20250131013559.457"><vh>ImportsChecker.visit_import</vh></v>
<v t="ekr.20250131013559.458"><vh>ImportsChecker.visit_importfrom</vh></v>
<v t="ekr.20250131013559.459"><vh>ImportsChecker.leave_module</vh></v>
<v t="ekr.20250131013559.460"><vh>ImportsChecker.compute_first_non_import_node</vh></v>
<v t="ekr.20250131013559.461"><vh>ImportsChecker.visit_functiondef</vh></v>
<v t="ekr.20250131013559.462"><vh>ImportsChecker._check_misplaced_future</vh></v>
<v t="ekr.20250131013559.463"><vh>ImportsChecker._check_same_line_imports</vh></v>
<v t="ekr.20250131013559.464"><vh>ImportsChecker._check_position</vh></v>
<v t="ekr.20250131013559.465"><vh>ImportsChecker._record_import</vh></v>
<v t="ekr.20250131013559.466"><vh>ImportsChecker._is_fallback_import</vh></v>
<v t="ekr.20250131013559.467"><vh>ImportsChecker._check_imports_order</vh></v>
<v t="ekr.20250131013559.468"><vh>ImportsChecker._get_out_of_order_string</vh></v>
<v t="ekr.20250131013559.469"><vh>ImportsChecker._get_full_import_name</vh></v>
<v t="ekr.20250131013559.470"><vh>ImportsChecker._get_imported_module</vh></v>
<v t="ekr.20250131013559.471"><vh>ImportsChecker._add_imported_module</vh></v>
<v t="ekr.20250131013559.472"><vh>ImportsChecker._check_preferred_module</vh></v>
<v t="ekr.20250131013559.473"><vh>ImportsChecker._check_import_as_rename</vh></v>
<v t="ekr.20250131013559.474"><vh>ImportsChecker._check_reimport</vh></v>
<v t="ekr.20250131013559.475"><vh>ImportsChecker._report_external_dependencies</vh></v>
<v t="ekr.20250131013559.476"><vh>ImportsChecker._report_dependencies_graph</vh></v>
<v t="ekr.20250131013559.477"><vh>ImportsChecker._filter_dependencies_graph</vh></v>
<v t="ekr.20250131013559.478"><vh>ImportsChecker._external_dependencies_info</vh></v>
<v t="ekr.20250131013559.479"><vh>ImportsChecker._internal_dependencies_info</vh></v>
<v t="ekr.20250131013559.480"><vh>ImportsChecker._check_wildcard_imports</vh></v>
<v t="ekr.20250131013559.481"><vh>ImportsChecker._wildcard_import_is_allowed</vh></v>
<v t="ekr.20250131013559.482"><vh>ImportsChecker._check_toplevel</vh></v>
</v>
<v t="ekr.20250131013559.448"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013559.483"><vh>@clean lambda_expressions.py</vh>
<v t="ekr.20250131013559.484"><vh>class LambdaExpressionChecker</vh>
<v t="ekr.20250131013559.486"><vh>LambdaExpressionChecker.visit_assign</vh></v>
<v t="ekr.20250131013559.487"><vh>LambdaExpressionChecker.visit_namedexpr</vh></v>
<v t="ekr.20250131013559.488"><vh>LambdaExpressionChecker.visit_call</vh></v>
</v>
<v t="ekr.20250131013559.485"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013559.489"><vh>@clean logging.py</vh>
<v t="ekr.20250131013559.490"><vh>function: is_method_call</vh></v>
<v t="ekr.20250131013559.491"><vh>class LoggingChecker</vh>
<v t="ekr.20250131013559.496"><vh>LoggingChecker.visit_module</vh></v>
<v t="ekr.20250131013559.497"><vh>LoggingChecker.visit_importfrom</vh></v>
<v t="ekr.20250131013559.498"><vh>LoggingChecker.visit_import</vh></v>
<v t="ekr.20250131013559.499"><vh>LoggingChecker.visit_call</vh></v>
<v t="ekr.20250131013559.500"><vh>LoggingChecker._check_log_method</vh></v>
<v t="ekr.20250131013559.501"><vh>LoggingChecker._helper_string</vh></v>
<v t="ekr.20250131013559.502"><vh>LoggingChecker._is_operand_literal_str</vh></v>
<v t="ekr.20250131013559.503"><vh>LoggingChecker._is_node_explicit_str_concatenation</vh></v>
<v t="ekr.20250131013559.504"><vh>LoggingChecker._check_call_func</vh></v>
<v t="ekr.20250131013559.505"><vh>LoggingChecker._check_format_string</vh></v>
</v>
<v t="ekr.20250131013559.492"><vh>function: is_complex_format_str</vh></v>
<v t="ekr.20250131013559.493"><vh>function: _count_supplied_tokens</vh></v>
<v t="ekr.20250131013559.494"><vh>function: str_formatting_in_f_string</vh></v>
<v t="ekr.20250131013559.495"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013559.506"><vh>@clean method_args.py</vh>
<v t="ekr.20250131013559.507"><vh>class MethodArgsChecker</vh>
<v t="ekr.20250131013559.509"><vh>MethodArgsChecker.visit_call</vh></v>
<v t="ekr.20250131013559.510"><vh>MethodArgsChecker._check_missing_timeout</vh></v>
<v t="ekr.20250131013559.511"><vh>MethodArgsChecker._check_positional_only_arguments_expected</vh></v>
</v>
<v t="ekr.20250131013559.508"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013559.512"><vh>@clean misc.py</vh>
<v t="ekr.20250131013559.513"><vh>class ByIdManagedMessagesChecker</vh>
<v t="ekr.20250131013559.516"><vh>ByIdManagedMessagesChecker._clear_by_id_managed_msgs</vh></v>
<v t="ekr.20250131013559.517"><vh>ByIdManagedMessagesChecker._get_by_id_managed_msgs</vh></v>
<v t="ekr.20250131013559.518"><vh>ByIdManagedMessagesChecker.process_module</vh></v>
</v>
<v t="ekr.20250131013559.514"><vh>class EncodingChecker</vh>
<v t="ekr.20250131013559.519"><vh>EncodingChecker.open</vh></v>
<v t="ekr.20250131013559.520"><vh>EncodingChecker._check_encoding</vh></v>
<v t="ekr.20250131013559.521"><vh>EncodingChecker.process_module</vh></v>
<v t="ekr.20250131013559.522"><vh>EncodingChecker.process_tokens</vh></v>
<v t="ekr.20250131013559.523"><vh>EncodingChecker._is_multiline_docstring</vh></v>
</v>
<v t="ekr.20250131013559.515"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013559.524"><vh>@clean modified_iterating_checker.py</vh>
<v t="ekr.20250131013559.525"><vh>class ModifiedIterationChecker</vh>
<v t="ekr.20250131013559.527"><vh>ModifiedIterationChecker.visit_for</vh></v>
<v t="ekr.20250131013559.528"><vh>ModifiedIterationChecker._modified_iterating_check_on_node_and_children</vh></v>
<v t="ekr.20250131013559.529"><vh>ModifiedIterationChecker._modified_iterating_check</vh></v>
<v t="ekr.20250131013559.530"><vh>ModifiedIterationChecker._is_node_expr_that_calls_attribute_name</vh></v>
<v t="ekr.20250131013559.531"><vh>ModifiedIterationChecker._common_cond_list_set</vh></v>
<v t="ekr.20250131013559.532"><vh>ModifiedIterationChecker._is_node_assigns_subscript_name</vh></v>
<v t="ekr.20250131013559.533"><vh>ModifiedIterationChecker._modified_iterating_list_cond</vh></v>
<v t="ekr.20250131013559.534"><vh>ModifiedIterationChecker._modified_iterating_dict_cond</vh></v>
<v t="ekr.20250131013559.535"><vh>ModifiedIterationChecker._modified_iterating_set_cond</vh></v>
<v t="ekr.20250131013559.536"><vh>ModifiedIterationChecker._deleted_iteration_target_cond</vh></v>
</v>
<v t="ekr.20250131013559.526"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013559.537"><vh>@clean nested_min_max.py</vh>
<v t="ekr.20250131013559.538"><vh>class NestedMinMaxChecker</vh>
<v t="ekr.20250131013559.540"><vh>NestedMinMaxChecker.is_min_max_call</vh></v>
<v t="ekr.20250131013559.541"><vh>NestedMinMaxChecker.get_redundant_calls</vh></v>
<v t="ekr.20250131013559.542"><vh>NestedMinMaxChecker.visit_call</vh></v>
<v t="ekr.20250131013559.543"><vh>NestedMinMaxChecker._is_splattable_expression</vh></v>
</v>
<v t="ekr.20250131013559.539"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013559.544"><vh>@clean newstyle.py</vh>
<v t="ekr.20250131013559.545"><vh>class NewStyleConflictChecker</vh>
<v t="ekr.20250131013559.547"><vh>NewStyleConflictChecker.visit_functiondef</vh></v>
</v>
<v t="ekr.20250131013559.546"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013559.548"><vh>@clean non_ascii_names.py</vh>
<v t="ekr.20250131013559.549"><vh>class NonAsciiNameChecker</vh>
<v t="ekr.20250131013559.551"><vh>NonAsciiNameChecker._check_name</vh></v>
<v t="ekr.20250131013559.552"><vh>NonAsciiNameChecker.visit_module</vh></v>
<v t="ekr.20250131013559.553"><vh>NonAsciiNameChecker.visit_functiondef</vh></v>
<v t="ekr.20250131013559.554"><vh>NonAsciiNameChecker.visit_global</vh></v>
<v t="ekr.20250131013559.555"><vh>NonAsciiNameChecker.visit_assignname</vh></v>
<v t="ekr.20250131013559.556"><vh>NonAsciiNameChecker.visit_classdef</vh></v>
<v t="ekr.20250131013559.557"><vh>NonAsciiNameChecker._check_module_import</vh></v>
<v t="ekr.20250131013559.558"><vh>NonAsciiNameChecker.visit_import</vh></v>
<v t="ekr.20250131013559.559"><vh>NonAsciiNameChecker.visit_importfrom</vh></v>
<v t="ekr.20250131013559.560"><vh>NonAsciiNameChecker.visit_call</vh></v>
</v>
<v t="ekr.20250131013559.550"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013559.561"><vh>@clean raw_metrics.py</vh>
<v t="ekr.20250131013559.562"><vh>function: report_raw_stats</vh></v>
<v t="ekr.20250131013559.563"><vh>class RawMetricsChecker</vh>
<v t="ekr.20250131013559.566"><vh>RawMetricsChecker.open</vh></v>
<v t="ekr.20250131013559.567"><vh>RawMetricsChecker.process_tokens</vh></v>
</v>
<v t="ekr.20250131013559.564"><vh>function: get_type</vh></v>
<v t="ekr.20250131013559.565"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013559.568"><vh>@clean spelling.py</vh>
<v t="ekr.20250131013559.569"><vh>class EmailFilter</vh></v>
<v t="ekr.20250131013559.570"><vh>class URLFilter</vh></v>
<v t="ekr.20250131013559.571"><vh>class WikiWordFilter</vh></v>
<v t="ekr.20250131013559.572"><vh>class Filter</vh>
<v t="ekr.20250131013559.587"><vh>Filter._skip</vh></v>
</v>
<v t="ekr.20250131013559.573"><vh>class Chunker</vh></v>
<v t="ekr.20250131013559.574"><vh>function: get_tokenizer</vh></v>
<v t="ekr.20250131013559.575"><vh>function: _get_enchant_dicts</vh></v>
<v t="ekr.20250131013559.576"><vh>function: _get_enchant_dict_choices</vh></v>
<v t="ekr.20250131013559.577"><vh>function: _get_enchant_dict_help</vh></v>
<v t="ekr.20250131013559.578"><vh>class WordsWithDigitsFilter</vh>
<v t="ekr.20250131013559.588"><vh>WordsWithDigitsFilter._skip</vh></v>
</v>
<v t="ekr.20250131013559.579"><vh>class WordsWithUnderscores</vh>
<v t="ekr.20250131013559.589"><vh>WordsWithUnderscores._skip</vh></v>
</v>
<v t="ekr.20250131013559.580"><vh>class RegExFilter</vh>
<v t="ekr.20250131013559.590"><vh>RegExFilter._skip</vh></v>
</v>
<v t="ekr.20250131013559.581"><vh>class CamelCasedWord</vh></v>
<v t="ekr.20250131013559.582"><vh>class SphinxDirectives</vh></v>
<v t="ekr.20250131013559.583"><vh>class ForwardSlashChunker</vh>
<v t="ekr.20250131013559.591"><vh>ForwardSlashChunker.next</vh></v>
<v t="ekr.20250131013559.592"><vh>ForwardSlashChunker._next</vh></v>
</v>
<v t="ekr.20250131013559.584"><vh>function: _strip_code_flanked_in_backticks</vh></v>
<v t="ekr.20250131013559.585"><vh>class SpellingChecker</vh>
<v t="ekr.20250131013559.593"><vh>SpellingChecker.open</vh></v>
<v t="ekr.20250131013559.594"><vh>SpellingChecker._check_spelling</vh></v>
<v t="ekr.20250131013559.595"><vh>SpellingChecker.process_tokens</vh></v>
<v t="ekr.20250131013559.596"><vh>SpellingChecker.visit_module</vh></v>
<v t="ekr.20250131013559.597"><vh>SpellingChecker.visit_classdef</vh></v>
<v t="ekr.20250131013559.598"><vh>SpellingChecker.visit_functiondef</vh></v>
<v t="ekr.20250131013559.599"><vh>SpellingChecker._check_docstring</vh></v>
</v>
<v t="ekr.20250131013559.586"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013559.600"><vh>@clean stdlib.py</vh>
<v t="ekr.20250131013559.601"><vh>function: _check_mode_str</vh></v>
<v t="ekr.20250131013559.602"><vh>class StdlibChecker</vh>
<v t="ekr.20250131013559.604"><vh>StdlibChecker.__init__</vh></v>
<v t="ekr.20250131013559.605"><vh>StdlibChecker._check_bad_thread_instantiation</vh></v>
<v t="ekr.20250131013559.606"><vh>StdlibChecker._check_for_preexec_fn_in_popen</vh></v>
<v t="ekr.20250131013559.607"><vh>StdlibChecker._check_for_check_kw_in_run</vh></v>
<v t="ekr.20250131013559.608"><vh>StdlibChecker._check_shallow_copy_environ</vh></v>
<v t="ekr.20250131013559.609"><vh>StdlibChecker.visit_call</vh></v>
<v t="ekr.20250131013559.610"><vh>StdlibChecker.visit_unaryop</vh></v>
<v t="ekr.20250131013559.611"><vh>StdlibChecker.visit_if</vh></v>
<v t="ekr.20250131013559.612"><vh>StdlibChecker.visit_ifexp</vh></v>
<v t="ekr.20250131013559.613"><vh>StdlibChecker.visit_boolop</vh></v>
<v t="ekr.20250131013559.614"><vh>StdlibChecker.visit_functiondef</vh></v>
<v t="ekr.20250131013559.615"><vh>StdlibChecker._check_lru_cache_decorators</vh></v>
<v t="ekr.20250131013559.616"><vh>StdlibChecker._check_dispatch_decorators</vh></v>
<v t="ekr.20250131013559.617"><vh>StdlibChecker._check_redundant_assert</vh></v>
<v t="ekr.20250131013559.618"><vh>StdlibChecker._check_datetime</vh></v>
<v t="ekr.20250131013559.619"><vh>StdlibChecker._check_open_call</vh></v>
<v t="ekr.20250131013559.620"><vh>StdlibChecker._check_env_function</vh></v>
<v t="ekr.20250131013559.621"><vh>StdlibChecker._check_invalid_envvar_value</vh></v>
<v t="ekr.20250131013559.622"><vh>StdlibChecker.deprecated_methods</vh></v>
<v t="ekr.20250131013559.623"><vh>StdlibChecker.deprecated_arguments</vh></v>
<v t="ekr.20250131013559.624"><vh>StdlibChecker.deprecated_classes</vh></v>
<v t="ekr.20250131013559.625"><vh>StdlibChecker.deprecated_decorators</vh></v>
<v t="ekr.20250131013559.626"><vh>StdlibChecker.deprecated_attributes</vh></v>
</v>
<v t="ekr.20250131013559.603"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013559.627"><vh>@clean strings.py</vh>
<v t="ekr.20250131013559.628"><vh>function: get_access_path</vh></v>
<v t="ekr.20250131013559.629"><vh>function: arg_matches_format_type</vh></v>
<v t="ekr.20250131013559.630"><vh>class StringFormatChecker</vh>
<v t="ekr.20250131013559.637"><vh>StringFormatChecker.visit_binop</vh></v>
<v t="ekr.20250131013559.638"><vh>StringFormatChecker.visit_joinedstr</vh></v>
<v t="ekr.20250131013559.639"><vh>StringFormatChecker._check_interpolation</vh></v>
<v t="ekr.20250131013559.640"><vh>StringFormatChecker.visit_call</vh></v>
<v t="ekr.20250131013559.641"><vh>StringFormatChecker._detect_vacuous_formatting</vh></v>
<v t="ekr.20250131013559.642"><vh>StringFormatChecker._check_new_format</vh></v>
<v t="ekr.20250131013559.643"><vh>StringFormatChecker._check_new_format_specifiers</vh></v>
</v>
<v t="ekr.20250131013559.631"><vh>class StringConstantChecker</vh>
<v t="ekr.20250131013559.644"><vh>StringConstantChecker.__init__</vh></v>
<v t="ekr.20250131013559.645"><vh>StringConstantChecker.process_module</vh></v>
<v t="ekr.20250131013559.646"><vh>StringConstantChecker.process_tokens</vh></v>
<v t="ekr.20250131013559.647"><vh>StringConstantChecker._is_initial_string_token</vh></v>
<v t="ekr.20250131013559.648"><vh>StringConstantChecker._is_parenthesized</vh></v>
<v t="ekr.20250131013559.649"><vh>StringConstantChecker._find_prev_token</vh></v>
<v t="ekr.20250131013559.650"><vh>StringConstantChecker._find_next_token</vh></v>
<v t="ekr.20250131013559.651"><vh>StringConstantChecker.visit_call</vh></v>
<v t="ekr.20250131013559.652"><vh>StringConstantChecker.visit_list</vh></v>
<v t="ekr.20250131013559.653"><vh>StringConstantChecker.visit_set</vh></v>
<v t="ekr.20250131013559.654"><vh>StringConstantChecker.visit_tuple</vh></v>
<v t="ekr.20250131013559.655"><vh>StringConstantChecker.visit_assign</vh></v>
<v t="ekr.20250131013559.656"><vh>StringConstantChecker.check_for_consistent_string_delimiters</vh></v>
<v t="ekr.20250131013559.657"><vh>StringConstantChecker.check_for_concatenated_strings</vh></v>
<v t="ekr.20250131013559.658"><vh>StringConstantChecker.process_string_token</vh></v>
<v t="ekr.20250131013559.659"><vh>StringConstantChecker.process_non_raw_string_token</vh></v>
<v t="ekr.20250131013559.660"><vh>StringConstantChecker.visit_const</vh></v>
<v t="ekr.20250131013559.661"><vh>StringConstantChecker._detect_u_string_prefix</vh></v>
</v>
<v t="ekr.20250131013559.632"><vh>function: register</vh></v>
<v t="ekr.20250131013559.633"><vh>function: str_eval</vh></v>
<v t="ekr.20250131013559.634"><vh>function: _is_long_string</vh></v>
<v t="ekr.20250131013559.635"><vh>function: _get_quote_delimiter</vh></v>
<v t="ekr.20250131013559.636"><vh>function: _is_quote_delimiter_chosen_freely</vh></v>
</v>
<v t="ekr.20250131013559.662"><vh>@clean symilar.py</vh>
<v t="ekr.20250131013559.663"><vh>class LineSpecifs</vh></v>
<v t="ekr.20250131013559.664"><vh>class CplSuccessiveLinesLimits</vh>
<v t="ekr.20250131013559.679"><vh>CplSuccessiveLinesLimits.__init__</vh></v>
</v>
<v t="ekr.20250131013559.665"><vh>class LinesChunk</vh>
<v t="ekr.20250131013559.680"><vh>LinesChunk.__init__</vh></v>
<v t="ekr.20250131013559.681"><vh>LinesChunk.__eq__</vh></v>
<v t="ekr.20250131013559.682"><vh>LinesChunk.__hash__</vh></v>
<v t="ekr.20250131013559.683"><vh>LinesChunk.__repr__</vh></v>
<v t="ekr.20250131013559.684"><vh>LinesChunk.__str__</vh></v>
</v>
<v t="ekr.20250131013559.666"><vh>class SuccessiveLinesLimits</vh>
<v t="ekr.20250131013559.685"><vh>SuccessiveLinesLimits.__init__</vh></v>
<v t="ekr.20250131013559.686"><vh>SuccessiveLinesLimits.start</vh></v>
<v t="ekr.20250131013559.687"><vh>SuccessiveLinesLimits.end</vh></v>
<v t="ekr.20250131013559.688"><vh>SuccessiveLinesLimits.end</vh></v>
<v t="ekr.20250131013559.689"><vh>SuccessiveLinesLimits.__repr__</vh></v>
</v>
<v t="ekr.20250131013559.667"><vh>class LineSetStartCouple</vh>
<v t="ekr.20250131013559.690"><vh>LineSetStartCouple.__repr__</vh></v>
<v t="ekr.20250131013559.691"><vh>LineSetStartCouple.__eq__</vh></v>
<v t="ekr.20250131013559.692"><vh>LineSetStartCouple.__hash__</vh></v>
<v t="ekr.20250131013559.693"><vh>LineSetStartCouple.increment</vh></v>
</v>
<v t="ekr.20250131013559.668"><vh>function: hash_lineset</vh></v>
<v t="ekr.20250131013559.669"><vh>function: remove_successive</vh></v>
<v t="ekr.20250131013559.670"><vh>function: filter_noncode_lines</vh></v>
<v t="ekr.20250131013559.671"><vh>class Commonality</vh></v>
<v t="ekr.20250131013559.672"><vh>class Symilar</vh>
<v t="ekr.20250131013559.694"><vh>Symilar.__init__</vh></v>
<v t="ekr.20250131013559.695"><vh>Symilar.append_stream</vh></v>
<v t="ekr.20250131013559.696"><vh>Symilar.run</vh></v>
<v t="ekr.20250131013559.697"><vh>Symilar._compute_sims</vh></v>
<v t="ekr.20250131013559.698"><vh>Symilar._display_sims</vh></v>
<v t="ekr.20250131013559.699"><vh>Symilar._get_similarity_report</vh></v>
<v t="ekr.20250131013559.700"><vh>Symilar._find_common</vh></v>
<v t="ekr.20250131013559.701"><vh>Symilar._iter_sims</vh></v>
<v t="ekr.20250131013559.702"><vh>Symilar.get_map_data</vh></v>
<v t="ekr.20250131013559.703"><vh>Symilar.combine_mapreduce_data</vh></v>
</v>
<v t="ekr.20250131013559.673"><vh>function: stripped_lines</vh></v>
<v t="ekr.20250131013559.674"><vh>class LineSet</vh>
<v t="ekr.20250131013559.704"><vh>LineSet.__init__</vh></v>
<v t="ekr.20250131013559.705"><vh>LineSet.__str__</vh></v>
<v t="ekr.20250131013559.706"><vh>LineSet.__len__</vh></v>
<v t="ekr.20250131013559.707"><vh>LineSet.__getitem__</vh></v>
<v t="ekr.20250131013559.708"><vh>LineSet.__lt__</vh></v>
<v t="ekr.20250131013559.709"><vh>LineSet.__hash__</vh></v>
<v t="ekr.20250131013559.710"><vh>LineSet.__eq__</vh></v>
<v t="ekr.20250131013559.711"><vh>LineSet.stripped_lines</vh></v>
<v t="ekr.20250131013559.712"><vh>LineSet.real_lines</vh></v>
</v>
<v t="ekr.20250131013559.675"><vh>function: report_similarities</vh></v>
<v t="ekr.20250131013559.676"><vh>class SimilaritiesChecker</vh>
<v t="ekr.20250131013559.713"><vh>SimilaritiesChecker.__init__</vh></v>
<v t="ekr.20250131013559.714"><vh>SimilaritiesChecker.open</vh></v>
<v t="ekr.20250131013559.715"><vh>SimilaritiesChecker.process_module</vh></v>
<v t="ekr.20250131013559.716"><vh>SimilaritiesChecker.close</vh></v>
<v t="ekr.20250131013559.717"><vh>SimilaritiesChecker.get_map_data</vh></v>
<v t="ekr.20250131013559.718"><vh>SimilaritiesChecker.reduce_map_data</vh></v>
</v>
<v t="ekr.20250131013559.677"><vh>function: register</vh></v>
<v t="ekr.20250131013559.678"><vh>function: Run</vh></v>
</v>
<v t="ekr.20250131013559.719"><vh>@clean threading_checker.py</vh>
<v t="ekr.20250131013559.720"><vh>class ThreadingChecker</vh>
<v t="ekr.20250131013559.722"><vh>ThreadingChecker.visit_with</vh></v>
</v>
<v t="ekr.20250131013559.721"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013559.723"><vh>@clean typecheck.py</vh>
<v t="ekr.20250131013559.724"><vh>class VERSION_COMPATIBLE_OVERLOAD</vh></v>
<v t="ekr.20250131013559.725"><vh>function: _is_owner_ignored</vh></v>
<v t="ekr.20250131013559.726"><vh>function: _node_names</vh></v>
<v t="ekr.20250131013559.727"><vh>function: _</vh></v>
<v t="ekr.20250131013559.728"><vh>function: _string_distance</vh></v>
<v t="ekr.20250131013559.729"><vh>function: _similar_names</vh></v>
<v t="ekr.20250131013559.730"><vh>function: _missing_member_hint</vh></v>
<v t="ekr.20250131013559.731"><vh>function: _emit_no_member</vh></v>
<v t="ekr.20250131013559.732"><vh>function: _get_all_attribute_assignments</vh></v>
<v t="ekr.20250131013559.733"><vh>function: _enum_has_attribute</vh></v>
<v t="ekr.20250131013559.734"><vh>function: _determine_callable</vh></v>
<v t="ekr.20250131013559.735"><vh>function: _has_parent_of_type</vh></v>
<v t="ekr.20250131013559.736"><vh>function: _no_context_variadic_keywords</vh></v>
<v t="ekr.20250131013559.737"><vh>function: _no_context_variadic_positional</vh></v>
<v t="ekr.20250131013559.738"><vh>function: _no_context_variadic</vh></v>
<v t="ekr.20250131013559.739"><vh>function: _is_invalid_metaclass</vh></v>
<v t="ekr.20250131013559.740"><vh>function: _infer_from_metaclass_constructor</vh></v>
<v t="ekr.20250131013559.741"><vh>function: _is_c_extension</vh></v>
<v t="ekr.20250131013559.742"><vh>function: _is_invalid_isinstance_type</vh></v>
<v t="ekr.20250131013559.743"><vh>class TypeChecker</vh>
<v t="ekr.20250131013559.746"><vh>TypeChecker.open</vh></v>
<v t="ekr.20250131013559.747"><vh>TypeChecker._suggestion_mode</vh></v>
<v t="ekr.20250131013559.748"><vh>TypeChecker._compiled_generated_members</vh></v>
<v t="ekr.20250131013559.749"><vh>TypeChecker.visit_functiondef</vh></v>
<v t="ekr.20250131013559.750"><vh>TypeChecker.visit_classdef</vh></v>
<v t="ekr.20250131013559.751"><vh>TypeChecker.visit_assignattr</vh></v>
<v t="ekr.20250131013559.752"><vh>TypeChecker.visit_delattr</vh></v>
<v t="ekr.20250131013559.753"><vh>TypeChecker.visit_attribute</vh></v>
<v t="ekr.20250131013559.754"><vh>TypeChecker._get_nomember_msgid_hint</vh></v>
<v t="ekr.20250131013559.755"><vh>TypeChecker.visit_assign</vh></v>
<v t="ekr.20250131013559.756"><vh>TypeChecker._check_assignment_from_function_call</vh></v>
<v t="ekr.20250131013559.757"><vh>TypeChecker._is_ignored_function</vh></v>
<v t="ekr.20250131013559.758"><vh>TypeChecker._is_builtin_no_return</vh></v>
<v t="ekr.20250131013559.759"><vh>TypeChecker._check_dundername_is_string</vh></v>
<v t="ekr.20250131013559.760"><vh>TypeChecker._check_uninferable_call</vh></v>
<v t="ekr.20250131013559.761"><vh>TypeChecker._check_argument_order</vh></v>
<v t="ekr.20250131013559.762"><vh>TypeChecker._check_isinstance_args</vh></v>
<v t="ekr.20250131013559.763"><vh>TypeChecker.visit_call</vh></v>
<v t="ekr.20250131013559.764"><vh>TypeChecker._keyword_argument_is_in_all_decorator_returns</vh></v>
<v t="ekr.20250131013559.765"><vh>TypeChecker._check_invalid_sequence_index</vh></v>
<v t="ekr.20250131013559.766"><vh>TypeChecker._check_not_callable</vh></v>
<v t="ekr.20250131013559.767"><vh>TypeChecker._check_invalid_slice_index</vh></v>
<v t="ekr.20250131013559.768"><vh>TypeChecker.visit_with</vh></v>
<v t="ekr.20250131013559.769"><vh>TypeChecker.visit_unaryop</vh></v>
<v t="ekr.20250131013559.770"><vh>TypeChecker.visit_binop</vh></v>
<v t="ekr.20250131013559.771"><vh>TypeChecker._detect_unsupported_alternative_union_syntax</vh></v>
<v t="ekr.20250131013559.772"><vh>TypeChecker._includes_version_compatible_overload</vh></v>
<v t="ekr.20250131013559.773"><vh>TypeChecker._recursive_search_for_classdef_type</vh></v>
<v t="ekr.20250131013559.774"><vh>TypeChecker._check_unsupported_alternative_union_syntax</vh></v>
<v t="ekr.20250131013559.775"><vh>TypeChecker._visit_binop</vh></v>
<v t="ekr.20250131013559.776"><vh>TypeChecker._visit_augassign</vh></v>
<v t="ekr.20250131013559.777"><vh>TypeChecker._check_binop_errors</vh></v>
<v t="ekr.20250131013559.778"><vh>TypeChecker._check_membership_test</vh></v>
<v t="ekr.20250131013559.779"><vh>TypeChecker.visit_compare</vh></v>
<v t="ekr.20250131013559.780"><vh>TypeChecker.visit_dict</vh></v>
<v t="ekr.20250131013559.781"><vh>TypeChecker.visit_set</vh></v>
<v t="ekr.20250131013559.782"><vh>TypeChecker.visit_subscript</vh></v>
<v t="ekr.20250131013559.783"><vh>TypeChecker.visit_for</vh></v>
<v t="ekr.20250131013559.784"><vh>TypeChecker.visit_await</vh></v>
<v t="ekr.20250131013559.785"><vh>TypeChecker._check_await_outside_coroutine</vh></v>
</v>
<v t="ekr.20250131013559.744"><vh>class IterableChecker</vh>
<v t="ekr.20250131013559.786"><vh>IterableChecker._is_asyncio_coroutine</vh></v>
<v t="ekr.20250131013559.787"><vh>IterableChecker._check_iterable</vh></v>
<v t="ekr.20250131013559.788"><vh>IterableChecker._check_mapping</vh></v>
<v t="ekr.20250131013559.789"><vh>IterableChecker.visit_for</vh></v>
<v t="ekr.20250131013559.790"><vh>IterableChecker.visit_asyncfor</vh></v>
<v t="ekr.20250131013559.791"><vh>IterableChecker.visit_yieldfrom</vh></v>
<v t="ekr.20250131013559.792"><vh>IterableChecker.visit_call</vh></v>
<v t="ekr.20250131013559.793"><vh>IterableChecker.visit_listcomp</vh></v>
<v t="ekr.20250131013559.794"><vh>IterableChecker.visit_dictcomp</vh></v>
<v t="ekr.20250131013559.795"><vh>IterableChecker.visit_setcomp</vh></v>
<v t="ekr.20250131013559.796"><vh>IterableChecker.visit_generatorexp</vh></v>
</v>
<v t="ekr.20250131013559.745"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013559.797"><vh>@clean unicode.py</vh>
<v t="ekr.20250131013559.798"><vh>class _BadChar</vh>
<v t="ekr.20250131013559.810"><vh>_BadChar.description</vh></v>
<v t="ekr.20250131013559.811"><vh>_BadChar.human_code</vh></v>
</v>
<v t="ekr.20250131013559.799"><vh>function: _line_length</vh></v>
<v t="ekr.20250131013559.800"><vh>function: _map_positions_to_result</vh></v>
<v t="ekr.20250131013559.801"><vh>function: _normalize_codec_name</vh></v>
<v t="ekr.20250131013559.802"><vh>function: _remove_bom</vh></v>
<v t="ekr.20250131013559.803"><vh>function: _encode_without_bom</vh></v>
<v t="ekr.20250131013559.804"><vh>function: _byte_to_str_length</vh></v>
<v t="ekr.20250131013559.805"><vh>function: _cached_encode_search</vh></v>
<v t="ekr.20250131013559.806"><vh>function: _fix_utf16_32_line_stream</vh></v>
<v t="ekr.20250131013559.807"><vh>function: extract_codec_from_bom</vh></v>
<v t="ekr.20250131013559.808"><vh>class UnicodeChecker</vh>
<v t="ekr.20250131013559.812"><vh>UnicodeChecker._is_invalid_codec</vh></v>
<v t="ekr.20250131013559.813"><vh>UnicodeChecker._is_unicode</vh></v>
<v t="ekr.20250131013559.814"><vh>UnicodeChecker._find_line_matches</vh></v>
<v t="ekr.20250131013559.815"><vh>UnicodeChecker._determine_codec</vh></v>
<v t="ekr.20250131013559.816"><vh>UnicodeChecker._check_codec</vh></v>
<v t="ekr.20250131013559.817"><vh>UnicodeChecker._check_invalid_chars</vh></v>
<v t="ekr.20250131013559.818"><vh>UnicodeChecker._check_bidi_chars</vh></v>
<v t="ekr.20250131013559.819"><vh>UnicodeChecker.process_module</vh></v>
</v>
<v t="ekr.20250131013559.809"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013559.820"><vh>@clean unsupported_version.py</vh>
<v t="ekr.20250131013559.821"><vh>class UnsupportedVersionChecker</vh>
<v t="ekr.20250131013559.823"><vh>UnsupportedVersionChecker.open</vh></v>
<v t="ekr.20250131013559.824"><vh>UnsupportedVersionChecker.visit_joinedstr</vh></v>
<v t="ekr.20250131013559.825"><vh>UnsupportedVersionChecker.visit_namedexpr</vh></v>
<v t="ekr.20250131013559.826"><vh>UnsupportedVersionChecker.visit_arguments</vh></v>
<v t="ekr.20250131013559.827"><vh>UnsupportedVersionChecker.visit_decorators</vh></v>
<v t="ekr.20250131013559.828"><vh>UnsupportedVersionChecker._check_typing_final</vh></v>
<v t="ekr.20250131013559.829"><vh>UnsupportedVersionChecker.visit_trystar</vh></v>
<v t="ekr.20250131013559.830"><vh>UnsupportedVersionChecker.visit_excepthandler</vh></v>
<v t="ekr.20250131013559.831"><vh>UnsupportedVersionChecker.visit_raise</vh></v>
<v t="ekr.20250131013559.832"><vh>UnsupportedVersionChecker.visit_typealias</vh></v>
<v t="ekr.20250131013559.833"><vh>UnsupportedVersionChecker.visit_typevar</vh></v>
<v t="ekr.20250131013559.834"><vh>UnsupportedVersionChecker.visit_typevartuple</vh></v>
</v>
<v t="ekr.20250131013559.822"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013559.835"><vh>@clean utils.py</vh>
<v t="ekr.20250131013600.1"><vh>class NoSuchArgumentError</vh></v>
<v t="ekr.20250131013600.2"><vh>class InferredTypeError</vh></v>
<v t="ekr.20250131013600.3"><vh>function: get_all_elements</vh></v>
<v t="ekr.20250131013600.4"><vh>function: is_super</vh></v>
<v t="ekr.20250131013600.5"><vh>function: is_error</vh></v>
<v t="ekr.20250131013600.6"><vh>function: is_builtin_object</vh></v>
<v t="ekr.20250131013600.7"><vh>function: is_builtin</vh></v>
<v t="ekr.20250131013600.8"><vh>function: is_defined_in_scope</vh></v>
<v t="ekr.20250131013600.9"><vh>function: defnode_in_scope</vh></v>
<v t="ekr.20250131013600.10"><vh>function: is_defined_before</vh></v>
<v t="ekr.20250131013600.11"><vh>function: is_default_argument</vh></v>
<v t="ekr.20250131013600.12"><vh>function: is_func_decorator</vh></v>
<v t="ekr.20250131013600.13"><vh>function: is_ancestor_name</vh></v>
<v t="ekr.20250131013600.14"><vh>function: is_being_called</vh></v>
<v t="ekr.20250131013600.15"><vh>function: assign_parent</vh></v>
<v t="ekr.20250131013600.16"><vh>function: overrides_a_method</vh></v>
<v t="ekr.20250131013600.17"><vh>function: only_required_for_messages</vh></v>
<v t="ekr.20250131013600.18"><vh>function: store_messages</vh></v>
<v t="ekr.20250131013600.19"><vh>class IncompleteFormatString</vh></v>
<v t="ekr.20250131013600.20"><vh>class UnsupportedFormatCharacter</vh>
<v t="ekr.20250131013600.127"><vh>UnsupportedFormatCharacter.__init__</vh></v>
</v>
<v t="ekr.20250131013600.21"><vh>function: parse_format_string</vh></v>
<v t="ekr.20250131013600.22"><vh>function: split_format_field_names</vh></v>
<v t="ekr.20250131013600.23"><vh>function: collect_string_fields</vh></v>
<v t="ekr.20250131013600.24"><vh>function: parse_format_method_string</vh></v>
<v t="ekr.20250131013600.25"><vh>function: is_attr_protected</vh></v>
<v t="ekr.20250131013600.26"><vh>function: node_frame_class</vh></v>
<v t="ekr.20250131013600.27"><vh>function: get_outer_class</vh></v>
<v t="ekr.20250131013600.28"><vh>function: is_attr_private</vh></v>
<v t="ekr.20250131013600.29"><vh>function: get_argument_from_call</vh></v>
<v t="ekr.20250131013600.30"><vh>function: infer_kwarg_from_call</vh></v>
<v t="ekr.20250131013600.31"><vh>function: inherit_from_std_ex</vh></v>
<v t="ekr.20250131013600.32"><vh>function: error_of_type</vh></v>
<v t="ekr.20250131013600.33"><vh>function: decorated_with_property</vh></v>
<v t="ekr.20250131013600.34"><vh>function: _is_property_kind</vh></v>
<v t="ekr.20250131013600.35"><vh>function: is_property_setter</vh></v>
<v t="ekr.20250131013600.36"><vh>function: is_property_deleter</vh></v>
<v t="ekr.20250131013600.37"><vh>function: is_property_setter_or_deleter</vh></v>
<v t="ekr.20250131013600.38"><vh>function: _is_property_decorator</vh></v>
<v t="ekr.20250131013600.39"><vh>function: decorated_with</vh></v>
<v t="ekr.20250131013600.40"><vh>function: uninferable_final_decorators</vh></v>
<v t="ekr.20250131013600.41"><vh>function: unimplemented_abstract_methods</vh></v>
<v t="ekr.20250131013600.42"><vh>function: find_try_except_wrapper_node</vh></v>
<v t="ekr.20250131013600.43"><vh>function: find_except_wrapper_node_in_scope</vh></v>
<v t="ekr.20250131013600.44"><vh>function: is_from_fallback_block</vh></v>
<v t="ekr.20250131013600.45"><vh>function: _except_handlers_ignores_exceptions</vh></v>
<v t="ekr.20250131013600.46"><vh>function: get_exception_handlers</vh></v>
<v t="ekr.20250131013600.47"><vh>function: get_contextlib_with_statements</vh></v>
<v t="ekr.20250131013600.48"><vh>function: _suppresses_exception</vh></v>
<v t="ekr.20250131013600.49"><vh>function: get_contextlib_suppressors</vh></v>
<v t="ekr.20250131013600.50"><vh>function: is_node_inside_try_except</vh></v>
<v t="ekr.20250131013600.51"><vh>function: node_ignores_exception</vh></v>
<v t="ekr.20250131013600.52"><vh>function: class_is_abstract</vh></v>
<v t="ekr.20250131013600.53"><vh>function: _supports_protocol_method</vh></v>
<v t="ekr.20250131013600.54"><vh>function: is_comprehension</vh></v>
<v t="ekr.20250131013600.55"><vh>function: _supports_mapping_protocol</vh></v>
<v t="ekr.20250131013600.56"><vh>function: _supports_membership_test_protocol</vh></v>
<v t="ekr.20250131013600.57"><vh>function: _supports_iteration_protocol</vh></v>
<v t="ekr.20250131013600.58"><vh>function: _supports_async_iteration_protocol</vh></v>
<v t="ekr.20250131013600.59"><vh>function: _supports_getitem_protocol</vh></v>
<v t="ekr.20250131013600.60"><vh>function: _supports_setitem_protocol</vh></v>
<v t="ekr.20250131013600.61"><vh>function: _supports_delitem_protocol</vh></v>
<v t="ekr.20250131013600.62"><vh>function: _is_abstract_class_name</vh></v>
<v t="ekr.20250131013600.63"><vh>function: is_inside_abstract_class</vh></v>
<v t="ekr.20250131013600.64"><vh>function: _supports_protocol</vh></v>
<v t="ekr.20250131013600.65"><vh>function: is_iterable</vh></v>
<v t="ekr.20250131013600.66"><vh>function: is_mapping</vh></v>
<v t="ekr.20250131013600.67"><vh>function: supports_membership_test</vh></v>
<v t="ekr.20250131013600.68"><vh>function: supports_getitem</vh></v>
<v t="ekr.20250131013600.69"><vh>function: supports_setitem</vh></v>
<v t="ekr.20250131013600.70"><vh>function: supports_delitem</vh></v>
<v t="ekr.20250131013600.71"><vh>function: _get_python_type_of_node</vh></v>
<v t="ekr.20250131013600.72"><vh>function: safe_infer</vh></v>
<v t="ekr.20250131013600.73"><vh>function: infer_all</vh></v>
<v t="ekr.20250131013600.74"><vh>function: function_arguments_are_ambiguous</vh></v>
<v t="ekr.20250131013600.75"><vh>function: class_constructors_are_ambiguous</vh></v>
<v t="ekr.20250131013600.76"><vh>function: has_known_bases</vh></v>
<v t="ekr.20250131013600.77"><vh>function: is_none</vh></v>
<v t="ekr.20250131013600.78"><vh>function: node_type</vh></v>
<v t="ekr.20250131013600.79"><vh>function: is_registered_in_singledispatch_function</vh></v>
<v t="ekr.20250131013600.80"><vh>function: find_inferred_fn_from_register</vh></v>
<v t="ekr.20250131013600.81"><vh>function: is_registered_in_singledispatchmethod_function</vh></v>
<v t="ekr.20250131013600.82"><vh>function: get_node_last_lineno</vh></v>
<v t="ekr.20250131013600.83"><vh>function: is_postponed_evaluation_enabled</vh></v>
<v t="ekr.20250131013600.84"><vh>function: is_node_in_type_annotation_context</vh></v>
<v t="ekr.20250131013600.85"><vh>function: is_subclass_of</vh></v>
<v t="ekr.20250131013600.86"><vh>function: is_overload_stub</vh></v>
<v t="ekr.20250131013600.87"><vh>function: is_protocol_class</vh></v>
<v t="ekr.20250131013600.88"><vh>function: is_call_of_name</vh></v>
<v t="ekr.20250131013600.89"><vh>function: is_test_condition</vh></v>
<v t="ekr.20250131013600.90"><vh>function: is_classdef_type</vh></v>
<v t="ekr.20250131013600.91"><vh>function: is_attribute_typed_annotation</vh></v>
<v t="ekr.20250131013600.92"><vh>function: is_enum</vh></v>
<v t="ekr.20250131013600.93"><vh>function: is_assign_name_annotated_with</vh></v>
<v t="ekr.20250131013600.94"><vh>function: get_iterating_dictionary_name</vh></v>
<v t="ekr.20250131013600.95"><vh>function: get_subscript_const_value</vh></v>
<v t="ekr.20250131013600.96"><vh>function: get_import_name</vh></v>
<v t="ekr.20250131013600.97"><vh>function: is_sys_guard</vh></v>
<v t="ekr.20250131013600.98"><vh>function: is_reassigned_after_current</vh></v>
<v t="ekr.20250131013600.99"><vh>function: is_deleted_after_current</vh></v>
<v t="ekr.20250131013600.100"><vh>function: is_function_body_ellipsis</vh></v>
<v t="ekr.20250131013600.101"><vh>function: is_base_container</vh></v>
<v t="ekr.20250131013600.102"><vh>function: is_empty_dict_literal</vh></v>
<v t="ekr.20250131013600.103"><vh>function: is_empty_str_literal</vh></v>
<v t="ekr.20250131013600.104"><vh>function: returns_bool</vh></v>
<v t="ekr.20250131013600.105"><vh>function: assigned_bool</vh></v>
<v t="ekr.20250131013600.106"><vh>function: get_node_first_ancestor_of_type</vh></v>
<v t="ekr.20250131013600.107"><vh>function: get_node_first_ancestor_of_type_and_its_child</vh></v>
<v t="ekr.20250131013600.108"><vh>function: in_type_checking_block</vh></v>
<v t="ekr.20250131013600.109"><vh>function: is_typing_member</vh></v>
<v t="ekr.20250131013600.110"><vh>function: in_for_else_branch</vh></v>
<v t="ekr.20250131013600.111"><vh>function: find_assigned_names_recursive</vh></v>
<v t="ekr.20250131013600.112"><vh>function: has_starred_node_recursive</vh></v>
<v t="ekr.20250131013600.113"><vh>function: is_hashable</vh></v>
<v t="ekr.20250131013600.114"><vh>function: subscript_chain_is_equal</vh></v>
<v t="ekr.20250131013600.115"><vh>function: _is_target_name_in_binop_side</vh></v>
<v t="ekr.20250131013600.116"><vh>function: is_augmented_assign</vh></v>
<v t="ekr.20250131013600.117"><vh>function: _qualified_name_parts</vh></v>
<v t="ekr.20250131013600.118"><vh>function: is_module_ignored</vh></v>
<v t="ekr.20250131013600.119"><vh>function: is_singleton_const</vh></v>
<v t="ekr.20250131013600.120"><vh>function: is_terminating_func</vh></v>
<v t="ekr.20250131013600.121"><vh>function: is_class_attr</vh></v>
<v t="ekr.20250131013600.122"><vh>function: get_inverse_comparator</vh></v>
<v t="ekr.20250131013600.123"><vh>function: not_condition_as_string</vh></v>
<v t="ekr.20250131013600.124"><vh>function: overridden_method</vh></v>
<v t="ekr.20250131013600.125"><vh>function: clear_lru_caches</vh></v>
<v t="ekr.20250131013600.126"><vh>function: is_enum_member</vh></v>
</v>
<v t="ekr.20250131013600.128"><vh>@clean variables.py</vh>
<v t="ekr.20250131013600.129"><vh>class VariableVisitConsumerAction</vh></v>
<v t="ekr.20250131013600.130"><vh>function: _is_from_future_import</vh></v>
<v t="ekr.20250131013600.131"><vh>function: _get_unpacking_extra_info</vh></v>
<v t="ekr.20250131013600.132"><vh>function: _detect_global_scope</vh></v>
<v t="ekr.20250131013600.133"><vh>function: _infer_name_module</vh></v>
<v t="ekr.20250131013600.134"><vh>function: _fix_dot_imports</vh></v>
<v t="ekr.20250131013600.135"><vh>function: _find_frame_imports</vh></v>
<v t="ekr.20250131013600.136"><vh>function: _import_name_is_global</vh></v>
<v t="ekr.20250131013600.137"><vh>function: _flattened_scope_names</vh></v>
<v t="ekr.20250131013600.138"><vh>function: _assigned_locally</vh></v>
<v t="ekr.20250131013600.139"><vh>function: _is_before</vh></v>
<v t="ekr.20250131013600.140"><vh>function: _is_nonlocal_name</vh></v>
<v t="ekr.20250131013600.141"><vh>function: _has_locals_call_after_node</vh></v>
<v t="ekr.20250131013600.142"><vh>class NamesConsumer</vh>
<v t="ekr.20250131013600.145"><vh>NamesConsumer.__init__</vh></v>
<v t="ekr.20250131013600.146"><vh>NamesConsumer.__repr__</vh></v>
<v t="ekr.20250131013600.147"><vh>NamesConsumer.mark_as_consumed</vh></v>
<v t="ekr.20250131013600.148"><vh>NamesConsumer.get_next_to_consume</vh></v>
<v t="ekr.20250131013600.149"><vh>NamesConsumer._inferred_to_define_name_raise_or_return</vh></v>
<v t="ekr.20250131013600.150"><vh>NamesConsumer._branch_handles_name</vh></v>
<v t="ekr.20250131013600.151"><vh>NamesConsumer._uncertain_nodes_if_tests</vh></v>
<v t="ekr.20250131013600.152"><vh>NamesConsumer._node_guarded_by_same_test</vh></v>
<v t="ekr.20250131013600.153"><vh>NamesConsumer._uncertain_nodes_in_except_blocks</vh></v>
<v t="ekr.20250131013600.154"><vh>NamesConsumer._defines_name_raises_or_returns</vh></v>
<v t="ekr.20250131013600.155"><vh>NamesConsumer._defines_name_raises_or_returns_recursive</vh></v>
<v t="ekr.20250131013600.156"><vh>NamesConsumer._check_loop_finishes_via_except</vh></v>
<v t="ekr.20250131013600.157"><vh>NamesConsumer._recursive_search_for_continue_before_break</vh></v>
<v t="ekr.20250131013600.158"><vh>NamesConsumer._uncertain_nodes_in_try_blocks_when_evaluating_except_blocks</vh></v>
<v t="ekr.20250131013600.159"><vh>NamesConsumer._uncertain_nodes_in_try_blocks_when_evaluating_finally_blocks</vh></v>
</v>
<v t="ekr.20250131013600.143"><vh>class VariablesChecker</vh>
<v t="ekr.20250131013600.160"><vh>VariablesChecker.__init__</vh></v>
<v t="ekr.20250131013600.161"><vh>VariablesChecker.visit_for</vh></v>
<v t="ekr.20250131013600.162"><vh>VariablesChecker.leave_for</vh></v>
<v t="ekr.20250131013600.163"><vh>VariablesChecker.visit_module</vh></v>
<v t="ekr.20250131013600.164"><vh>VariablesChecker.leave_module</vh></v>
<v t="ekr.20250131013600.165"><vh>VariablesChecker.visit_classdef</vh></v>
<v t="ekr.20250131013600.166"><vh>VariablesChecker.leave_classdef</vh></v>
<v t="ekr.20250131013600.167"><vh>VariablesChecker.visit_lambda</vh></v>
<v t="ekr.20250131013600.168"><vh>VariablesChecker.leave_lambda</vh></v>
<v t="ekr.20250131013600.169"><vh>VariablesChecker.visit_generatorexp</vh></v>
<v t="ekr.20250131013600.170"><vh>VariablesChecker.leave_generatorexp</vh></v>
<v t="ekr.20250131013600.171"><vh>VariablesChecker.visit_dictcomp</vh></v>
<v t="ekr.20250131013600.172"><vh>VariablesChecker.leave_dictcomp</vh></v>
<v t="ekr.20250131013600.173"><vh>VariablesChecker.visit_setcomp</vh></v>
<v t="ekr.20250131013600.174"><vh>VariablesChecker.leave_setcomp</vh></v>
<v t="ekr.20250131013600.175"><vh>VariablesChecker.visit_functiondef</vh></v>
<v t="ekr.20250131013600.176"><vh>VariablesChecker.leave_functiondef</vh></v>
<v t="ekr.20250131013600.177"><vh>VariablesChecker.visit_global</vh></v>
<v t="ekr.20250131013600.178"><vh>VariablesChecker.visit_assignname</vh></v>
<v t="ekr.20250131013600.179"><vh>VariablesChecker.visit_delname</vh></v>
<v t="ekr.20250131013600.180"><vh>VariablesChecker.visit_name</vh></v>
<v t="ekr.20250131013600.181"><vh>VariablesChecker.visit_excepthandler</vh></v>
<v t="ekr.20250131013600.182"><vh>VariablesChecker.leave_excepthandler</vh></v>
<v t="ekr.20250131013600.183"><vh>VariablesChecker._undefined_and_used_before_checker</vh></v>
<v t="ekr.20250131013600.184"><vh>VariablesChecker._should_node_be_skipped</vh></v>
<v t="ekr.20250131013600.185"><vh>VariablesChecker._check_consumer</vh></v>
<v t="ekr.20250131013600.186"><vh>VariablesChecker._report_unfound_name_definition</vh></v>
<v t="ekr.20250131013600.187"><vh>VariablesChecker._filter_type_checking_definitions_from_consumption</vh></v>
<v t="ekr.20250131013600.188"><vh>VariablesChecker.visit_import</vh></v>
<v t="ekr.20250131013600.189"><vh>VariablesChecker.visit_importfrom</vh></v>
<v t="ekr.20250131013600.190"><vh>VariablesChecker.visit_assign</vh></v>
<v t="ekr.20250131013600.191"><vh>VariablesChecker.visit_listcomp</vh></v>
<v t="ekr.20250131013600.192"><vh>VariablesChecker.leave_listcomp</vh></v>
<v t="ekr.20250131013600.193"><vh>VariablesChecker.leave_assign</vh></v>
<v t="ekr.20250131013600.194"><vh>VariablesChecker.leave_with</vh></v>
<v t="ekr.20250131013600.195"><vh>VariablesChecker.visit_arguments</vh></v>
<v t="ekr.20250131013600.196"><vh>VariablesChecker._analyse_fallback_blocks</vh></v>
<v t="ekr.20250131013600.197"><vh>VariablesChecker._ignored_modules</vh></v>
<v t="ekr.20250131013600.198"><vh>VariablesChecker._allow_global_unused_variables</vh></v>
<v t="ekr.20250131013600.199"><vh>VariablesChecker._defined_in_function_definition</vh></v>
<v t="ekr.20250131013600.200"><vh>VariablesChecker._in_lambda_or_comprehension_body</vh></v>
<v t="ekr.20250131013600.201"><vh>VariablesChecker._is_variable_violation</vh></v>
<v t="ekr.20250131013600.202"><vh>VariablesChecker._maybe_used_and_assigned_at_once</vh></v>
<v t="ekr.20250131013600.203"><vh>VariablesChecker._is_builtin</vh></v>
<v t="ekr.20250131013600.204"><vh>VariablesChecker._has_nonlocal_in_enclosing_frame</vh></v>
<v t="ekr.20250131013600.205"><vh>VariablesChecker._is_only_type_assignment</vh></v>
<v t="ekr.20250131013600.206"><vh>VariablesChecker._is_first_level_self_reference</vh></v>
<v t="ekr.20250131013600.207"><vh>VariablesChecker._is_never_evaluated</vh></v>
<v t="ekr.20250131013600.208"><vh>VariablesChecker._is_variable_annotation_in_function</vh></v>
<v t="ekr.20250131013600.209"><vh>VariablesChecker._ignore_class_scope</vh></v>
<v t="ekr.20250131013600.210"><vh>VariablesChecker._loopvar_name</vh></v>
<v t="ekr.20250131013600.211"><vh>VariablesChecker._check_is_unused</vh></v>
<v t="ekr.20250131013600.212"><vh>VariablesChecker._is_name_ignored</vh></v>
<v t="ekr.20250131013600.213"><vh>VariablesChecker._check_unused_arguments</vh></v>
<v t="ekr.20250131013600.214"><vh>VariablesChecker._check_late_binding_closure</vh></v>
<v t="ekr.20250131013600.215"><vh>VariablesChecker._should_ignore_redefined_builtin</vh></v>
<v t="ekr.20250131013600.216"><vh>VariablesChecker._allowed_redefined_builtin</vh></v>
<v t="ekr.20250131013600.217"><vh>VariablesChecker._comprehension_between_frame_and_node</vh></v>
<v t="ekr.20250131013600.218"><vh>VariablesChecker._store_type_annotation_node</vh></v>
<v t="ekr.20250131013600.219"><vh>VariablesChecker._store_type_annotation_names</vh></v>
<v t="ekr.20250131013600.220"><vh>VariablesChecker._check_self_cls_assign</vh></v>
<v t="ekr.20250131013600.221"><vh>VariablesChecker._check_unpacking</vh></v>
<v t="ekr.20250131013600.222"><vh>VariablesChecker._get_value_length</vh></v>
<v t="ekr.20250131013600.223"><vh>VariablesChecker._nodes_to_unpack</vh></v>
<v t="ekr.20250131013600.224"><vh>VariablesChecker._report_unbalanced_unpacking</vh></v>
<v t="ekr.20250131013600.225"><vh>VariablesChecker._report_unpacking_non_sequence</vh></v>
<v t="ekr.20250131013600.226"><vh>VariablesChecker._check_module_attrs</vh></v>
<v t="ekr.20250131013600.227"><vh>VariablesChecker._check_all</vh></v>
<v t="ekr.20250131013600.228"><vh>VariablesChecker._check_globals</vh></v>
<v t="ekr.20250131013600.229"><vh>VariablesChecker._check_imports</vh></v>
<v t="ekr.20250131013600.230"><vh>VariablesChecker._check_metaclasses</vh></v>
<v t="ekr.20250131013600.231"><vh>VariablesChecker._check_classdef_metaclasses</vh></v>
<v t="ekr.20250131013600.232"><vh>VariablesChecker.visit_subscript</vh></v>
<v t="ekr.20250131013600.233"><vh>VariablesChecker._inferred_iterable_length</vh></v>
<v t="ekr.20250131013600.234"><vh>VariablesChecker._check_potential_index_error</vh></v>
<v t="ekr.20250131013600.235"><vh>VariablesChecker.visit_const</vh></v>
</v>
<v t="ekr.20250131013600.144"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013600.236"><vh>path: pylint/checkers/base</vh>
<v t="ekr.20250131013600.237"><vh>@clean __init__.py</vh>
<v t="ekr.20250131013600.238"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013600.239"><vh>@clean basic_checker.py</vh>
<v t="ekr.20250131013600.240"><vh>class _BasicChecker</vh></v>
<v t="ekr.20250131013600.241"><vh>function: report_by_type_stats</vh></v>
<v t="ekr.20250131013600.242"><vh>class BasicChecker</vh>
<v t="ekr.20250131013600.243"><vh>BasicChecker.__init__</vh></v>
<v t="ekr.20250131013600.244"><vh>BasicChecker.open</vh></v>
<v t="ekr.20250131013600.245"><vh>BasicChecker.visit_if</vh></v>
<v t="ekr.20250131013600.246"><vh>BasicChecker.visit_ifexp</vh></v>
<v t="ekr.20250131013600.247"><vh>BasicChecker.visit_comprehension</vh></v>
<v t="ekr.20250131013600.248"><vh>BasicChecker._check_using_constant_test</vh></v>
<v t="ekr.20250131013600.249"><vh>BasicChecker._name_holds_generator</vh></v>
<v t="ekr.20250131013600.250"><vh>BasicChecker.visit_module</vh></v>
<v t="ekr.20250131013600.251"><vh>BasicChecker.visit_classdef</vh></v>
<v t="ekr.20250131013600.252"><vh>BasicChecker.visit_expr</vh></v>
<v t="ekr.20250131013600.253"><vh>BasicChecker._filter_vararg</vh></v>
<v t="ekr.20250131013600.254"><vh>BasicChecker._has_variadic_argument</vh></v>
<v t="ekr.20250131013600.255"><vh>BasicChecker.visit_lambda</vh></v>
<v t="ekr.20250131013600.256"><vh>BasicChecker.visit_functiondef</vh></v>
<v t="ekr.20250131013600.257"><vh>BasicChecker._check_dangerous_default</vh></v>
<v t="ekr.20250131013600.258"><vh>BasicChecker.visit_return</vh></v>
<v t="ekr.20250131013600.259"><vh>BasicChecker.visit_continue</vh></v>
<v t="ekr.20250131013600.260"><vh>BasicChecker.visit_break</vh></v>
<v t="ekr.20250131013600.261"><vh>BasicChecker.visit_raise</vh></v>
<v t="ekr.20250131013600.262"><vh>BasicChecker._check_misplaced_format_function</vh></v>
<v t="ekr.20250131013600.263"><vh>BasicChecker.visit_call</vh></v>
<v t="ekr.20250131013600.264"><vh>BasicChecker.visit_assert</vh></v>
<v t="ekr.20250131013600.265"><vh>BasicChecker.visit_dict</vh></v>
<v t="ekr.20250131013600.266"><vh>BasicChecker.visit_set</vh></v>
<v t="ekr.20250131013600.267"><vh>BasicChecker.visit_try</vh></v>
<v t="ekr.20250131013600.268"><vh>BasicChecker.leave_try</vh></v>
<v t="ekr.20250131013600.269"><vh>BasicChecker._check_unreachable</vh></v>
<v t="ekr.20250131013600.270"><vh>BasicChecker._check_not_in_finally</vh></v>
<v t="ekr.20250131013600.271"><vh>BasicChecker._check_reversed</vh></v>
<v t="ekr.20250131013600.272"><vh>BasicChecker.visit_with</vh></v>
<v t="ekr.20250131013600.273"><vh>BasicChecker._check_self_assigning_variable</vh></v>
<v t="ekr.20250131013600.274"><vh>BasicChecker._check_redeclared_assign_name</vh></v>
<v t="ekr.20250131013600.275"><vh>BasicChecker.visit_assign</vh></v>
<v t="ekr.20250131013600.276"><vh>BasicChecker.visit_for</vh></v>
</v>
</v>
<v t="ekr.20250131013600.277"><vh>@clean basic_error_checker.py</vh>
<v t="ekr.20250131013600.278"><vh>function: _get_break_loop_node</vh></v>
<v t="ekr.20250131013600.279"><vh>function: _loop_exits_early</vh></v>
<v t="ekr.20250131013600.280"><vh>function: _has_abstract_methods</vh></v>
<v t="ekr.20250131013600.281"><vh>function: redefined_by_decorator</vh></v>
<v t="ekr.20250131013600.282"><vh>class BasicErrorChecker</vh>
<v t="ekr.20250131013600.283"><vh>BasicErrorChecker.open</vh></v>
<v t="ekr.20250131013600.284"><vh>BasicErrorChecker.visit_classdef</vh></v>
<v t="ekr.20250131013600.285"><vh>BasicErrorChecker._too_many_starred_for_tuple</vh></v>
<v t="ekr.20250131013600.286"><vh>BasicErrorChecker.visit_assign</vh></v>
<v t="ekr.20250131013600.287"><vh>BasicErrorChecker.visit_starred</vh></v>
<v t="ekr.20250131013600.288"><vh>BasicErrorChecker.visit_functiondef</vh></v>
<v t="ekr.20250131013600.289"><vh>BasicErrorChecker._check_name_used_prior_global</vh></v>
<v t="ekr.20250131013600.290"><vh>BasicErrorChecker._check_nonlocal_and_global</vh></v>
<v t="ekr.20250131013600.291"><vh>BasicErrorChecker.visit_return</vh></v>
<v t="ekr.20250131013600.292"><vh>BasicErrorChecker.visit_yield</vh></v>
<v t="ekr.20250131013600.293"><vh>BasicErrorChecker.visit_yieldfrom</vh></v>
<v t="ekr.20250131013600.294"><vh>BasicErrorChecker.visit_continue</vh></v>
<v t="ekr.20250131013600.295"><vh>BasicErrorChecker.visit_break</vh></v>
<v t="ekr.20250131013600.296"><vh>BasicErrorChecker.visit_for</vh></v>
<v t="ekr.20250131013600.297"><vh>BasicErrorChecker.visit_while</vh></v>
<v t="ekr.20250131013600.298"><vh>BasicErrorChecker.visit_unaryop</vh></v>
<v t="ekr.20250131013600.299"><vh>BasicErrorChecker._check_nonlocal_without_binding</vh></v>
<v t="ekr.20250131013600.300"><vh>BasicErrorChecker.visit_nonlocal</vh></v>
<v t="ekr.20250131013600.301"><vh>BasicErrorChecker.visit_call</vh></v>
<v t="ekr.20250131013600.302"><vh>BasicErrorChecker._check_inferred_class_is_abstract</vh></v>
<v t="ekr.20250131013600.303"><vh>BasicErrorChecker._check_yield_outside_func</vh></v>
<v t="ekr.20250131013600.304"><vh>BasicErrorChecker._check_else_on_loop</vh></v>
<v t="ekr.20250131013600.305"><vh>BasicErrorChecker._check_in_loop</vh></v>
<v t="ekr.20250131013600.306"><vh>BasicErrorChecker._check_redefinition</vh></v>
</v>
</v>
<v t="ekr.20250131013600.307"><vh>@clean comparison_checker.py</vh>
<v t="ekr.20250131013600.308"><vh>function: _is_one_arg_pos_call</vh></v>
<v t="ekr.20250131013600.309"><vh>class ComparisonChecker</vh>
<v t="ekr.20250131013600.310"><vh>ComparisonChecker._check_singleton_comparison</vh></v>
<v t="ekr.20250131013600.311"><vh>ComparisonChecker._check_nan_comparison</vh></v>
<v t="ekr.20250131013600.312"><vh>ComparisonChecker._check_literal_comparison</vh></v>
<v t="ekr.20250131013600.313"><vh>ComparisonChecker._check_logical_tautology</vh></v>
<v t="ekr.20250131013600.314"><vh>ComparisonChecker._check_constants_comparison</vh></v>
<v t="ekr.20250131013600.315"><vh>ComparisonChecker._check_callable_comparison</vh></v>
<v t="ekr.20250131013600.316"><vh>ComparisonChecker.visit_compare</vh></v>
<v t="ekr.20250131013600.317"><vh>ComparisonChecker._check_unidiomatic_typecheck</vh></v>
<v t="ekr.20250131013600.318"><vh>ComparisonChecker._check_type_x_is_y</vh></v>
</v>
</v>
<v t="ekr.20250131013600.319"><vh>@clean docstring_checker.py</vh>
<v t="ekr.20250131013600.320"><vh>function: _infer_dunder_doc_attribute</vh></v>
<v t="ekr.20250131013600.321"><vh>class DocStringChecker</vh>
<v t="ekr.20250131013600.322"><vh>DocStringChecker.open</vh></v>
<v t="ekr.20250131013600.323"><vh>DocStringChecker.visit_module</vh></v>
<v t="ekr.20250131013600.324"><vh>DocStringChecker.visit_classdef</vh></v>
<v t="ekr.20250131013600.325"><vh>DocStringChecker.visit_functiondef</vh></v>
<v t="ekr.20250131013600.326"><vh>DocStringChecker._check_docstring</vh></v>
</v>
</v>
<v t="ekr.20250131013600.327"><vh>@clean function_checker.py</vh>
<v t="ekr.20250131013600.328"><vh>class FunctionChecker</vh>
<v t="ekr.20250131013600.329"><vh>FunctionChecker.visit_functiondef</vh></v>
<v t="ekr.20250131013600.330"><vh>FunctionChecker.visit_asyncfunctiondef</vh></v>
<v t="ekr.20250131013600.331"><vh>FunctionChecker._check_contextmanager_generator_missing_cleanup</vh></v>
<v t="ekr.20250131013600.332"><vh>FunctionChecker._node_fails_contextmanager_cleanup</vh></v>
</v>
</v>
<v t="ekr.20250131013600.333"><vh>@clean pass_checker.py</vh>
<v t="ekr.20250131013600.334"><vh>class PassChecker</vh>
<v t="ekr.20250131013600.335"><vh>PassChecker.visit_pass</vh></v>
</v>
</v>
<v t="ekr.20250131013600.336"><vh>path: pylint/checkers/base/name_checker</vh>
<v t="ekr.20250131013600.337"><vh>@clean __init__.py</vh></v>
<v t="ekr.20250131013600.338"><vh>@clean checker.py</vh>
<v t="ekr.20250131013600.339"><vh>class TypeVarVariance</vh></v>
<v t="ekr.20250131013600.340"><vh>function: _get_properties</vh></v>
<v t="ekr.20250131013600.341"><vh>function: _redefines_import</vh></v>
<v t="ekr.20250131013600.342"><vh>function: _determine_function_name_type</vh></v>
<v t="ekr.20250131013600.343"><vh>function: _is_multi_naming_match</vh></v>
<v t="ekr.20250131013600.344"><vh>class NameChecker</vh>
<v t="ekr.20250131013600.345"><vh>NameChecker.__init__</vh></v>
<v t="ekr.20250131013600.346"><vh>NameChecker.open</vh></v>
<v t="ekr.20250131013600.347"><vh>NameChecker._create_naming_rules</vh></v>
<v t="ekr.20250131013600.348"><vh>NameChecker.visit_module</vh></v>
<v t="ekr.20250131013600.349"><vh>NameChecker.leave_module</vh></v>
<v t="ekr.20250131013600.350"><vh>NameChecker.visit_classdef</vh></v>
<v t="ekr.20250131013600.351"><vh>NameChecker.visit_functiondef</vh></v>
<v t="ekr.20250131013600.352"><vh>NameChecker.visit_assignname</vh></v>
<v t="ekr.20250131013600.353"><vh>NameChecker._recursive_check_names</vh></v>
<v t="ekr.20250131013600.354"><vh>NameChecker._find_name_group</vh></v>
<v t="ekr.20250131013600.355"><vh>NameChecker._raise_name_warning</vh></v>
<v t="ekr.20250131013600.356"><vh>NameChecker._name_allowed_by_regex</vh></v>
<v t="ekr.20250131013600.357"><vh>NameChecker._name_disallowed_by_regex</vh></v>
<v t="ekr.20250131013600.358"><vh>NameChecker._check_name</vh></v>
<v t="ekr.20250131013600.359"><vh>NameChecker._assigns_typevar</vh></v>
<v t="ekr.20250131013600.360"><vh>NameChecker._assigns_typealias</vh></v>
<v t="ekr.20250131013600.361"><vh>NameChecker._check_typevar</vh></v>
</v>
</v>
<v t="ekr.20250131013600.362"><vh>@clean naming_style.py</vh>
<v t="ekr.20250131013600.363"><vh>class NamingStyle</vh>
<v t="ekr.20250131013600.370"><vh>NamingStyle.get_regex</vh></v>
</v>
<v t="ekr.20250131013600.364"><vh>class SnakeCaseStyle</vh></v>
<v t="ekr.20250131013600.365"><vh>class CamelCaseStyle</vh></v>
<v t="ekr.20250131013600.366"><vh>class PascalCaseStyle</vh></v>
<v t="ekr.20250131013600.367"><vh>class UpperCaseStyle</vh></v>
<v t="ekr.20250131013600.368"><vh>class AnyStyle</vh></v>
<v t="ekr.20250131013600.369"><vh>function: _create_naming_options</vh></v>
</v>
</v>
</v>
<v t="ekr.20250131013600.371"><vh>path: pylint/checkers/classes</vh>
<v t="ekr.20250131013600.372"><vh>@clean __init__.py</vh>
<v t="ekr.20250131013600.373"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013600.374"><vh>@clean class_checker.py</vh>
<v t="ekr.20250131013600.375"><vh>class _CallSignature</vh></v>
<v t="ekr.20250131013600.376"><vh>class _ParameterSignature</vh></v>
<v t="ekr.20250131013600.377"><vh>function: _signature_from_call</vh></v>
<v t="ekr.20250131013600.378"><vh>function: _signature_from_arguments</vh></v>
<v t="ekr.20250131013600.379"><vh>function: _definition_equivalent_to_call</vh></v>
<v t="ekr.20250131013600.380"><vh>function: _is_trivial_super_delegation</vh></v>
<v t="ekr.20250131013600.381"><vh>function: _positional_parameters</vh></v>
<v t="ekr.20250131013600.382"><vh>class _DefaultMissing</vh></v>
<v t="ekr.20250131013600.383"><vh>function: _has_different_parameters_default_value</vh></v>
<v t="ekr.20250131013600.384"><vh>function: _has_different_parameters</vh></v>
<v t="ekr.20250131013600.385"><vh>function: _has_different_keyword_only_parameters</vh></v>
<v t="ekr.20250131013600.386"><vh>function: _different_parameters</vh></v>
<v t="ekr.20250131013600.387"><vh>function: _is_invalid_base_class</vh></v>
<v t="ekr.20250131013600.388"><vh>function: _has_data_descriptor</vh></v>
<v t="ekr.20250131013600.389"><vh>function: _called_in_methods</vh></v>
<v t="ekr.20250131013600.390"><vh>function: _is_attribute_property</vh></v>
<v t="ekr.20250131013600.391"><vh>function: _has_same_layout_slots</vh></v>
<v t="ekr.20250131013600.392"><vh>function: _scope_default</vh></v>
<v t="ekr.20250131013600.393"><vh>class ScopeAccessMap</vh>
<v t="ekr.20250131013600.396"><vh>ScopeAccessMap.__init__</vh></v>
<v t="ekr.20250131013600.397"><vh>ScopeAccessMap.set_accessed</vh></v>
<v t="ekr.20250131013600.398"><vh>ScopeAccessMap.accessed</vh></v>
</v>
<v t="ekr.20250131013600.394"><vh>class ClassChecker</vh>
<v t="ekr.20250131013600.399"><vh>ClassChecker.__init__</vh></v>
<v t="ekr.20250131013600.400"><vh>ClassChecker.open</vh></v>
<v t="ekr.20250131013600.401"><vh>ClassChecker._dummy_rgx</vh></v>
<v t="ekr.20250131013600.402"><vh>ClassChecker.visit_classdef</vh></v>
<v t="ekr.20250131013600.403"><vh>ClassChecker._check_declare_non_slot</vh></v>
<v t="ekr.20250131013600.404"><vh>ClassChecker._check_consistent_mro</vh></v>
<v t="ekr.20250131013600.405"><vh>ClassChecker._check_enum_base</vh></v>
<v t="ekr.20250131013600.406"><vh>ClassChecker._check_proper_bases</vh></v>
<v t="ekr.20250131013600.407"><vh>ClassChecker._check_typing_final</vh></v>
<v t="ekr.20250131013600.408"><vh>ClassChecker.leave_classdef</vh></v>
<v t="ekr.20250131013600.409"><vh>ClassChecker._check_unused_private_functions</vh></v>
<v t="ekr.20250131013600.410"><vh>ClassChecker._check_unused_private_variables</vh></v>
<v t="ekr.20250131013600.411"><vh>ClassChecker._check_unused_private_attributes</vh></v>
<v t="ekr.20250131013600.412"><vh>ClassChecker._check_attribute_defined_outside_init</vh></v>
<v t="ekr.20250131013600.413"><vh>ClassChecker.visit_functiondef</vh></v>
<v t="ekr.20250131013600.414"><vh>ClassChecker._check_useless_super_delegation</vh></v>
<v t="ekr.20250131013600.415"><vh>ClassChecker._check_property_with_parameters</vh></v>
<v t="ekr.20250131013600.416"><vh>ClassChecker._check_invalid_overridden_method</vh></v>
<v t="ekr.20250131013600.417"><vh>ClassChecker._check_functools_or_not</vh></v>
<v t="ekr.20250131013600.418"><vh>ClassChecker._has_valid_slots</vh></v>
<v t="ekr.20250131013600.419"><vh>ClassChecker._check_slots</vh></v>
<v t="ekr.20250131013600.420"><vh>ClassChecker._get_classdef_slots_names</vh></v>
<v t="ekr.20250131013600.421"><vh>ClassChecker._get_slots_names</vh></v>
<v t="ekr.20250131013600.422"><vh>ClassChecker._check_redefined_slots</vh></v>
<v t="ekr.20250131013600.423"><vh>ClassChecker._check_slots_elt</vh></v>
<v t="ekr.20250131013600.424"><vh>ClassChecker.leave_functiondef</vh></v>
<v t="ekr.20250131013600.425"><vh>ClassChecker.visit_attribute</vh></v>
<v t="ekr.20250131013600.426"><vh>ClassChecker._check_super_without_brackets</vh></v>
<v t="ekr.20250131013600.427"><vh>ClassChecker.visit_assignattr</vh></v>
<v t="ekr.20250131013600.428"><vh>ClassChecker._check_invalid_class_object</vh></v>
<v t="ekr.20250131013600.429"><vh>ClassChecker._check_in_slots</vh></v>
<v t="ekr.20250131013600.430"><vh>ClassChecker.visit_assign</vh></v>
<v t="ekr.20250131013600.431"><vh>ClassChecker._check_classmethod_declaration</vh></v>
<v t="ekr.20250131013600.432"><vh>ClassChecker._check_protected_attribute_access</vh></v>
<v t="ekr.20250131013600.433"><vh>ClassChecker._is_called_inside_special_method</vh></v>
<v t="ekr.20250131013600.434"><vh>ClassChecker._is_type_self_call</vh></v>
<v t="ekr.20250131013600.435"><vh>ClassChecker._is_classmethod</vh></v>
<v t="ekr.20250131013600.436"><vh>ClassChecker._is_inferred_instance</vh></v>
<v t="ekr.20250131013600.437"><vh>ClassChecker._is_class_or_instance_attribute</vh></v>
<v t="ekr.20250131013600.438"><vh>ClassChecker._check_accessed_members</vh></v>
<v t="ekr.20250131013600.439"><vh>ClassChecker._check_first_arg_for_type</vh></v>
<v t="ekr.20250131013600.440"><vh>ClassChecker._check_first_arg_config</vh></v>
<v t="ekr.20250131013600.441"><vh>ClassChecker._check_bases_classes</vh></v>
<v t="ekr.20250131013600.442"><vh>ClassChecker._check_init</vh></v>
<v t="ekr.20250131013600.443"><vh>ClassChecker._check_signature</vh></v>
<v t="ekr.20250131013600.444"><vh>ClassChecker._uses_mandatory_method_param</vh></v>
<v t="ekr.20250131013600.445"><vh>ClassChecker._is_mandatory_method_param</vh></v>
</v>
<v t="ekr.20250131013600.395"><vh>function: _ancestors_to_call</vh></v>
</v>
<v t="ekr.20250131013600.446"><vh>@clean special_methods_checker.py</vh>
<v t="ekr.20250131013600.447"><vh>function: _safe_infer_call_result</vh></v>
<v t="ekr.20250131013600.448"><vh>class SpecialMethodsChecker</vh>
<v t="ekr.20250131013600.449"><vh>SpecialMethodsChecker.__init__</vh></v>
<v t="ekr.20250131013600.450"><vh>SpecialMethodsChecker.visit_functiondef</vh></v>
<v t="ekr.20250131013600.451"><vh>SpecialMethodsChecker._check_unexpected_method_signature</vh></v>
<v t="ekr.20250131013600.452"><vh>SpecialMethodsChecker._is_wrapped_type</vh></v>
<v t="ekr.20250131013600.453"><vh>SpecialMethodsChecker._is_int</vh></v>
<v t="ekr.20250131013600.454"><vh>SpecialMethodsChecker._is_str</vh></v>
<v t="ekr.20250131013600.455"><vh>SpecialMethodsChecker._is_bool</vh></v>
<v t="ekr.20250131013600.456"><vh>SpecialMethodsChecker._is_bytes</vh></v>
<v t="ekr.20250131013600.457"><vh>SpecialMethodsChecker._is_tuple</vh></v>
<v t="ekr.20250131013600.458"><vh>SpecialMethodsChecker._is_dict</vh></v>
<v t="ekr.20250131013600.459"><vh>SpecialMethodsChecker._is_iterator</vh></v>
<v t="ekr.20250131013600.460"><vh>SpecialMethodsChecker._check_iter</vh></v>
<v t="ekr.20250131013600.461"><vh>SpecialMethodsChecker._check_len</vh></v>
<v t="ekr.20250131013600.462"><vh>SpecialMethodsChecker._check_bool</vh></v>
<v t="ekr.20250131013600.463"><vh>SpecialMethodsChecker._check_index</vh></v>
<v t="ekr.20250131013600.464"><vh>SpecialMethodsChecker._check_repr</vh></v>
<v t="ekr.20250131013600.465"><vh>SpecialMethodsChecker._check_str</vh></v>
<v t="ekr.20250131013600.466"><vh>SpecialMethodsChecker._check_bytes</vh></v>
<v t="ekr.20250131013600.467"><vh>SpecialMethodsChecker._check_hash</vh></v>
<v t="ekr.20250131013600.468"><vh>SpecialMethodsChecker._check_length_hint</vh></v>
<v t="ekr.20250131013600.469"><vh>SpecialMethodsChecker._check_format</vh></v>
<v t="ekr.20250131013600.470"><vh>SpecialMethodsChecker._check_getnewargs</vh></v>
<v t="ekr.20250131013600.471"><vh>SpecialMethodsChecker._check_getnewargs_ex</vh></v>
</v>
</v>
</v>
<v t="ekr.20250131013600.472"><vh>path: pylint/checkers/refactoring</vh>
<v t="ekr.20250131013600.473"><vh>@clean __init__.py</vh>
<v t="ekr.20250131013600.474"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013600.475"><vh>@clean implicit_booleaness_checker.py</vh>
<v t="ekr.20250131013600.476"><vh>function: _is_constant_zero</vh></v>
<v t="ekr.20250131013600.477"><vh>class ImplicitBooleanessChecker</vh>
<v t="ekr.20250131013600.478"><vh>ImplicitBooleanessChecker.visit_call</vh></v>
<v t="ekr.20250131013600.479"><vh>ImplicitBooleanessChecker.instance_has_bool</vh></v>
<v t="ekr.20250131013600.480"><vh>ImplicitBooleanessChecker.visit_unaryop</vh></v>
<v t="ekr.20250131013600.481"><vh>ImplicitBooleanessChecker.visit_compare</vh></v>
<v t="ekr.20250131013600.482"><vh>ImplicitBooleanessChecker._check_compare_to_str_or_zero</vh></v>
<v t="ekr.20250131013600.483"><vh>ImplicitBooleanessChecker._check_use_implicit_booleaness_not_comparison</vh></v>
<v t="ekr.20250131013600.484"><vh>ImplicitBooleanessChecker._get_node_description</vh></v>
<v t="ekr.20250131013600.485"><vh>ImplicitBooleanessChecker._implicit_booleaness_message_args</vh></v>
<v t="ekr.20250131013600.486"><vh>ImplicitBooleanessChecker.base_names_of_instance</vh></v>
</v>
</v>
<v t="ekr.20250131013600.487"><vh>@clean not_checker.py</vh>
<v t="ekr.20250131013600.488"><vh>class NotChecker</vh>
<v t="ekr.20250131013600.489"><vh>NotChecker.visit_unaryop</vh></v>
</v>
</v>
<v t="ekr.20250131013600.490"><vh>@clean recommendation_checker.py</vh>
<v t="ekr.20250131013600.491"><vh>class RecommendationChecker</vh>
<v t="ekr.20250131013600.492"><vh>RecommendationChecker.open</vh></v>
<v t="ekr.20250131013600.493"><vh>RecommendationChecker._is_builtin</vh></v>
<v t="ekr.20250131013600.494"><vh>RecommendationChecker.visit_call</vh></v>
<v t="ekr.20250131013600.495"><vh>RecommendationChecker._check_consider_iterating_dictionary</vh></v>
<v t="ekr.20250131013600.496"><vh>RecommendationChecker._check_use_maxsplit_arg</vh></v>
<v t="ekr.20250131013600.497"><vh>RecommendationChecker.visit_for</vh></v>
<v t="ekr.20250131013600.498"><vh>RecommendationChecker._check_consider_using_enumerate</vh></v>
<v t="ekr.20250131013600.499"><vh>RecommendationChecker._check_consider_using_dict_items</vh></v>
<v t="ekr.20250131013600.500"><vh>RecommendationChecker.visit_comprehension</vh></v>
<v t="ekr.20250131013600.501"><vh>RecommendationChecker._check_consider_using_dict_items_comprehension</vh></v>
<v t="ekr.20250131013600.502"><vh>RecommendationChecker._check_use_sequence_for_iteration</vh></v>
<v t="ekr.20250131013600.503"><vh>RecommendationChecker.visit_const</vh></v>
<v t="ekr.20250131013600.504"><vh>RecommendationChecker._detect_replacable_format_call</vh></v>
</v>
</v>
<v t="ekr.20250131013600.505"><vh>@clean refactoring_checker.py</vh>
<v t="ekr.20250131013600.506"><vh>function: _if_statement_is_always_returning</vh></v>
<v t="ekr.20250131013600.507"><vh>function: _except_statement_is_always_returning</vh></v>
<v t="ekr.20250131013600.508"><vh>function: _is_trailing_comma</vh></v>
<v t="ekr.20250131013600.509"><vh>function: _is_inside_context_manager</vh></v>
<v t="ekr.20250131013600.510"><vh>function: _is_a_return_statement</vh></v>
<v t="ekr.20250131013600.511"><vh>function: _is_part_of_with_items</vh></v>
<v t="ekr.20250131013600.512"><vh>function: _will_be_released_automatically</vh></v>
<v t="ekr.20250131013600.513"><vh>function: _is_part_of_assignment_target</vh></v>
<v t="ekr.20250131013600.514"><vh>class ConsiderUsingWithStack</vh>
<v t="ekr.20250131013600.516"><vh>ConsiderUsingWithStack.__iter__</vh></v>
<v t="ekr.20250131013600.517"><vh>ConsiderUsingWithStack.get_stack_for_frame</vh></v>
<v t="ekr.20250131013600.518"><vh>ConsiderUsingWithStack.clear_all</vh></v>
</v>
<v t="ekr.20250131013600.515"><vh>class RefactoringChecker</vh>
<v t="ekr.20250131013600.519"><vh>RefactoringChecker.__init__</vh></v>
<v t="ekr.20250131013600.520"><vh>RefactoringChecker._init</vh></v>
<v t="ekr.20250131013600.521"><vh>RefactoringChecker.open</vh></v>
<v t="ekr.20250131013600.522"><vh>RefactoringChecker._dummy_rgx</vh></v>
<v t="ekr.20250131013600.523"><vh>RefactoringChecker._is_bool_const</vh></v>
<v t="ekr.20250131013600.524"><vh>RefactoringChecker._is_actual_elif</vh></v>
<v t="ekr.20250131013600.525"><vh>RefactoringChecker._check_simplifiable_if</vh></v>
<v t="ekr.20250131013600.526"><vh>RefactoringChecker.process_tokens</vh></v>
<v t="ekr.20250131013600.527"><vh>RefactoringChecker.leave_module</vh></v>
<v t="ekr.20250131013600.528"><vh>RefactoringChecker.visit_try</vh></v>
<v t="ekr.20250131013600.529"><vh>RefactoringChecker._check_redefined_argument_from_local</vh></v>
<v t="ekr.20250131013600.530"><vh>RefactoringChecker.visit_for</vh></v>
<v t="ekr.20250131013600.531"><vh>RefactoringChecker.visit_excepthandler</vh></v>
<v t="ekr.20250131013600.532"><vh>RefactoringChecker.visit_with</vh></v>
<v t="ekr.20250131013600.533"><vh>RefactoringChecker._check_superfluous_else</vh></v>
<v t="ekr.20250131013600.534"><vh>RefactoringChecker._check_superfluous_else_return</vh></v>
<v t="ekr.20250131013600.535"><vh>RefactoringChecker._check_superfluous_else_raise</vh></v>
<v t="ekr.20250131013600.536"><vh>RefactoringChecker._check_superfluous_else_break</vh></v>
<v t="ekr.20250131013600.537"><vh>RefactoringChecker._check_superfluous_else_continue</vh></v>
<v t="ekr.20250131013600.538"><vh>RefactoringChecker._type_and_name_are_equal</vh></v>
<v t="ekr.20250131013600.539"><vh>RefactoringChecker._is_dict_get_block</vh></v>
<v t="ekr.20250131013600.540"><vh>RefactoringChecker._check_consider_get</vh></v>
<v t="ekr.20250131013600.541"><vh>RefactoringChecker.visit_if</vh></v>
<v t="ekr.20250131013600.542"><vh>RefactoringChecker._check_consider_using_min_max_builtin</vh></v>
<v t="ekr.20250131013600.543"><vh>RefactoringChecker.visit_ifexp</vh></v>
<v t="ekr.20250131013600.544"><vh>RefactoringChecker._check_simplifiable_ifexp</vh></v>
<v t="ekr.20250131013600.545"><vh>RefactoringChecker.leave_functiondef</vh></v>
<v t="ekr.20250131013600.546"><vh>RefactoringChecker.leave_classdef</vh></v>
<v t="ekr.20250131013600.547"><vh>RefactoringChecker.visit_raise</vh></v>
<v t="ekr.20250131013600.548"><vh>RefactoringChecker._check_stop_iteration_inside_generator</vh></v>
<v t="ekr.20250131013600.549"><vh>RefactoringChecker._check_exception_inherit_from_stopiteration</vh></v>
<v t="ekr.20250131013600.550"><vh>RefactoringChecker._check_consider_using_comprehension_constructor</vh></v>
<v t="ekr.20250131013600.551"><vh>RefactoringChecker._check_consider_using_generator</vh></v>
<v t="ekr.20250131013600.552"><vh>RefactoringChecker.visit_call</vh></v>
<v t="ekr.20250131013600.553"><vh>RefactoringChecker.visit_yield</vh></v>
<v t="ekr.20250131013600.554"><vh>RefactoringChecker._has_exit_in_scope</vh></v>
<v t="ekr.20250131013600.555"><vh>RefactoringChecker._check_quit_exit_call</vh></v>
<v t="ekr.20250131013600.556"><vh>RefactoringChecker._check_super_with_arguments</vh></v>
<v t="ekr.20250131013600.557"><vh>RefactoringChecker._check_raising_stopiteration_in_generator_next_call</vh></v>
<v t="ekr.20250131013600.558"><vh>RefactoringChecker._check_nested_blocks</vh></v>
<v t="ekr.20250131013600.559"><vh>RefactoringChecker._emit_nested_blocks_message_if_needed</vh></v>
<v t="ekr.20250131013600.560"><vh>RefactoringChecker._emit_consider_using_with_if_needed</vh></v>
<v t="ekr.20250131013600.561"><vh>RefactoringChecker._duplicated_isinstance_types</vh></v>
<v t="ekr.20250131013600.562"><vh>RefactoringChecker._check_consider_merging_isinstance</vh></v>
<v t="ekr.20250131013600.563"><vh>RefactoringChecker._check_consider_using_in</vh></v>
<v t="ekr.20250131013600.564"><vh>RefactoringChecker._check_chained_comparison</vh></v>
<v t="ekr.20250131013600.565"><vh>RefactoringChecker._apply_boolean_simplification_rules</vh></v>
<v t="ekr.20250131013600.566"><vh>RefactoringChecker._simplify_boolean_operation</vh></v>
<v t="ekr.20250131013600.567"><vh>RefactoringChecker._check_simplifiable_condition</vh></v>
<v t="ekr.20250131013600.568"><vh>RefactoringChecker.visit_boolop</vh></v>
<v t="ekr.20250131013600.569"><vh>RefactoringChecker._is_simple_assignment</vh></v>
<v t="ekr.20250131013600.570"><vh>RefactoringChecker._check_swap_variables</vh></v>
<v t="ekr.20250131013600.571"><vh>RefactoringChecker.visit_assign</vh></v>
<v t="ekr.20250131013600.572"><vh>RefactoringChecker.visit_return</vh></v>
<v t="ekr.20250131013600.573"><vh>RefactoringChecker._append_context_managers_to_stack</vh></v>
<v t="ekr.20250131013600.574"><vh>RefactoringChecker._check_consider_using_with</vh></v>
<v t="ekr.20250131013600.575"><vh>RefactoringChecker._check_use_list_literal</vh></v>
<v t="ekr.20250131013600.576"><vh>RefactoringChecker._check_use_dict_literal</vh></v>
<v t="ekr.20250131013600.577"><vh>RefactoringChecker._dict_literal_suggestion</vh></v>
<v t="ekr.20250131013600.578"><vh>RefactoringChecker._name_to_concatenate</vh></v>
<v t="ekr.20250131013600.579"><vh>RefactoringChecker._check_consider_using_join</vh></v>
<v t="ekr.20250131013600.580"><vh>RefactoringChecker.visit_augassign</vh></v>
<v t="ekr.20250131013600.581"><vh>RefactoringChecker.visit_comprehension</vh></v>
<v t="ekr.20250131013600.582"><vh>RefactoringChecker._check_unnecessary_comprehension</vh></v>
<v t="ekr.20250131013600.583"><vh>RefactoringChecker._is_and_or_ternary</vh></v>
<v t="ekr.20250131013600.584"><vh>RefactoringChecker._and_or_ternary_arguments</vh></v>
<v t="ekr.20250131013600.585"><vh>RefactoringChecker.visit_functiondef</vh></v>
<v t="ekr.20250131013600.586"><vh>RefactoringChecker._check_consistent_returns</vh></v>
<v t="ekr.20250131013600.587"><vh>RefactoringChecker._is_if_node_return_ended</vh></v>
<v t="ekr.20250131013600.588"><vh>RefactoringChecker._is_raise_node_return_ended</vh></v>
<v t="ekr.20250131013600.589"><vh>RefactoringChecker._is_node_return_ended</vh></v>
<v t="ekr.20250131013600.590"><vh>RefactoringChecker._has_return_in_siblings</vh></v>
<v t="ekr.20250131013600.591"><vh>RefactoringChecker._is_function_def_never_returning</vh></v>
<v t="ekr.20250131013600.592"><vh>RefactoringChecker._check_return_at_the_end</vh></v>
<v t="ekr.20250131013600.593"><vh>RefactoringChecker._check_unnecessary_dict_index_lookup</vh></v>
<v t="ekr.20250131013600.594"><vh>RefactoringChecker._check_unnecessary_list_index_lookup</vh></v>
<v t="ekr.20250131013600.595"><vh>RefactoringChecker._enumerate_with_start</vh></v>
<v t="ekr.20250131013600.596"><vh>RefactoringChecker._get_start_value</vh></v>
</v>
</v>
</v>
</v>
<v t="ekr.20250131013600.597"><vh>path: pylint/config</vh>
<v t="ekr.20250131013600.598"><vh>@clean __init__.py</vh></v>
<v t="ekr.20250131013600.599"><vh>@clean _breaking_changes.py</vh>
<v t="ekr.20250131013600.600"><vh>class BreakingChange</vh></v>
<v t="ekr.20250131013600.601"><vh>class Condition</vh></v>
<v t="ekr.20250131013600.602"><vh>class Information</vh></v>
<v t="ekr.20250131013600.603"><vh>class Solution</vh></v>
</v>
<v t="ekr.20250131013600.604"><vh>@clean argument.py</vh>
<v t="ekr.20250131013600.605"><vh>function: _confidence_transformer</vh></v>
<v t="ekr.20250131013600.606"><vh>function: _csv_transformer</vh></v>
<v t="ekr.20250131013600.607"><vh>function: _yn_transformer</vh></v>
<v t="ekr.20250131013600.608"><vh>function: _non_empty_string_transformer</vh></v>
<v t="ekr.20250131013600.609"><vh>function: _path_transformer</vh></v>
<v t="ekr.20250131013600.610"><vh>function: _glob_paths_csv_transformer</vh></v>
<v t="ekr.20250131013600.611"><vh>function: _py_version_transformer</vh></v>
<v t="ekr.20250131013600.612"><vh>function: _regex_transformer</vh></v>
<v t="ekr.20250131013600.613"><vh>function: _regexp_csv_transfomer</vh></v>
<v t="ekr.20250131013600.614"><vh>function: _regexp_paths_csv_transfomer</vh></v>
<v t="ekr.20250131013600.615"><vh>class _Argument</vh>
<v t="ekr.20250131013600.624"><vh>_Argument.__init__</vh></v>
</v>
<v t="ekr.20250131013600.616"><vh>class _BaseStoreArgument</vh>
<v t="ekr.20250131013600.625"><vh>_BaseStoreArgument.__init__</vh></v>
</v>
<v t="ekr.20250131013600.617"><vh>class _StoreArgument</vh>
<v t="ekr.20250131013600.626"><vh>_StoreArgument.__init__</vh></v>
</v>
<v t="ekr.20250131013600.618"><vh>class _StoreTrueArgument</vh>
<v t="ekr.20250131013600.627"><vh>_StoreTrueArgument.__init__</vh></v>
</v>
<v t="ekr.20250131013600.619"><vh>class _DeprecationArgument</vh>
<v t="ekr.20250131013600.628"><vh>_DeprecationArgument.__init__</vh></v>
</v>
<v t="ekr.20250131013600.620"><vh>class _ExtendArgument</vh>
<v t="ekr.20250131013600.629"><vh>_ExtendArgument.__init__</vh></v>
</v>
<v t="ekr.20250131013600.621"><vh>class _StoreOldNamesArgument</vh>
<v t="ekr.20250131013600.630"><vh>_StoreOldNamesArgument.__init__</vh></v>
</v>
<v t="ekr.20250131013600.622"><vh>class _StoreNewNamesArgument</vh>
<v t="ekr.20250131013600.631"><vh>_StoreNewNamesArgument.__init__</vh></v>
</v>
<v t="ekr.20250131013600.623"><vh>class _CallableArgument</vh>
<v t="ekr.20250131013600.632"><vh>_CallableArgument.__init__</vh></v>
</v>
</v>
<v t="ekr.20250131013600.633"><vh>@clean arguments_manager.py</vh>
<v t="ekr.20250131013600.634"><vh>class _ArgumentsManager</vh>
<v t="ekr.20250131013600.635"><vh>_ArgumentsManager.__init__</vh></v>
<v t="ekr.20250131013600.636"><vh>_ArgumentsManager.config</vh></v>
<v t="ekr.20250131013600.637"><vh>_ArgumentsManager.config</vh></v>
<v t="ekr.20250131013600.638"><vh>_ArgumentsManager._register_options_provider</vh></v>
<v t="ekr.20250131013600.639"><vh>_ArgumentsManager._add_arguments_to_parser</vh></v>
<v t="ekr.20250131013600.640"><vh>_ArgumentsManager._add_parser_option</vh></v>
<v t="ekr.20250131013600.641"><vh>_ArgumentsManager._load_default_argument_values</vh></v>
<v t="ekr.20250131013600.642"><vh>_ArgumentsManager._parse_configuration_file</vh></v>
<v t="ekr.20250131013600.643"><vh>_ArgumentsManager._parse_command_line_configuration</vh></v>
<v t="ekr.20250131013600.644"><vh>_ArgumentsManager._generate_config</vh></v>
<v t="ekr.20250131013600.645"><vh>_ArgumentsManager.help</vh></v>
<v t="ekr.20250131013600.646"><vh>_ArgumentsManager._generate_config_file</vh></v>
<v t="ekr.20250131013600.647"><vh>_ArgumentsManager.set_option</vh></v>
</v>
</v>
<v t="ekr.20250131013600.648"><vh>@clean arguments_provider.py</vh>
<v t="ekr.20250131013600.649"><vh>class _ArgumentsProvider</vh>
<v t="ekr.20250131013600.650"><vh>_ArgumentsProvider.__init__</vh></v>
<v t="ekr.20250131013600.651"><vh>_ArgumentsProvider._option_value</vh></v>
<v t="ekr.20250131013600.652"><vh>_ArgumentsProvider._options_by_section</vh></v>
<v t="ekr.20250131013600.653"><vh>_ArgumentsProvider._options_and_values</vh></v>
</v>
</v>
<v t="ekr.20250131013600.654"><vh>@clean callback_actions.py</vh>
<v t="ekr.20250131013600.655"><vh>class _CallbackAction</vh>
<v t="ekr.20250131013600.675"><vh>_CallbackAction.__call__</vh></v>
</v>
<v t="ekr.20250131013600.656"><vh>class _DoNothingAction</vh>
<v t="ekr.20250131013600.676"><vh>_DoNothingAction.__call__</vh></v>
</v>
<v t="ekr.20250131013600.657"><vh>class _AccessRunObjectAction</vh>
<v t="ekr.20250131013600.677"><vh>_AccessRunObjectAction.__init__</vh></v>
<v t="ekr.20250131013600.678"><vh>_AccessRunObjectAction.__call__</vh></v>
</v>
<v t="ekr.20250131013600.658"><vh>class _MessageHelpAction</vh>
<v t="ekr.20250131013600.679"><vh>_MessageHelpAction.__init__</vh></v>
<v t="ekr.20250131013600.680"><vh>_MessageHelpAction.__call__</vh></v>
</v>
<v t="ekr.20250131013600.659"><vh>class _ListMessagesAction</vh>
<v t="ekr.20250131013600.681"><vh>_ListMessagesAction.__call__</vh></v>
</v>
<v t="ekr.20250131013600.660"><vh>class _ListMessagesEnabledAction</vh>
<v t="ekr.20250131013600.682"><vh>_ListMessagesEnabledAction.__call__</vh></v>
</v>
<v t="ekr.20250131013600.661"><vh>class _ListCheckGroupsAction</vh>
<v t="ekr.20250131013600.683"><vh>_ListCheckGroupsAction.__call__</vh></v>
</v>
<v t="ekr.20250131013600.662"><vh>class _ListConfidenceLevelsAction</vh>
<v t="ekr.20250131013600.684"><vh>_ListConfidenceLevelsAction.__call__</vh></v>
</v>
<v t="ekr.20250131013600.663"><vh>class _ListExtensionsAction</vh>
<v t="ekr.20250131013600.685"><vh>_ListExtensionsAction.__call__</vh></v>
</v>
<v t="ekr.20250131013600.664"><vh>class _FullDocumentationAction</vh>
<v t="ekr.20250131013600.686"><vh>_FullDocumentationAction.__call__</vh></v>
</v>
<v t="ekr.20250131013600.665"><vh>class _GenerateRCFileAction</vh>
<v t="ekr.20250131013600.687"><vh>_GenerateRCFileAction.__call__</vh></v>
</v>
<v t="ekr.20250131013600.666"><vh>class _GenerateConfigFileAction</vh>
<v t="ekr.20250131013600.688"><vh>_GenerateConfigFileAction.__call__</vh></v>
</v>
<v t="ekr.20250131013600.667"><vh>class _ErrorsOnlyModeAction</vh>
<v t="ekr.20250131013600.689"><vh>_ErrorsOnlyModeAction.__call__</vh></v>
</v>
<v t="ekr.20250131013600.668"><vh>class _LongHelpAction</vh>
<v t="ekr.20250131013600.690"><vh>_LongHelpAction.__call__</vh></v>
</v>
<v t="ekr.20250131013600.669"><vh>class _AccessLinterObjectAction</vh>
<v t="ekr.20250131013600.691"><vh>_AccessLinterObjectAction.__init__</vh></v>
<v t="ekr.20250131013600.692"><vh>_AccessLinterObjectAction.__call__</vh></v>
</v>
<v t="ekr.20250131013600.670"><vh>class _XableAction</vh>
<v t="ekr.20250131013600.693"><vh>_XableAction._call</vh></v>
<v t="ekr.20250131013600.694"><vh>_XableAction.__call__</vh></v>
</v>
<v t="ekr.20250131013600.671"><vh>class _DisableAction</vh>
<v t="ekr.20250131013600.695"><vh>_DisableAction.__call__</vh></v>
</v>
<v t="ekr.20250131013600.672"><vh>class _EnableAction</vh>
<v t="ekr.20250131013600.696"><vh>_EnableAction.__call__</vh></v>
</v>
<v t="ekr.20250131013600.673"><vh>class _OutputFormatAction</vh>
<v t="ekr.20250131013600.697"><vh>_OutputFormatAction.__call__</vh></v>
</v>
<v t="ekr.20250131013600.674"><vh>class _AccessParserAction</vh>
<v t="ekr.20250131013600.698"><vh>_AccessParserAction.__init__</vh></v>
<v t="ekr.20250131013600.699"><vh>_AccessParserAction.__call__</vh></v>
</v>
</v>
<v t="ekr.20250131013600.700"><vh>@clean config_file_parser.py</vh>
<v t="ekr.20250131013600.701"><vh>class _RawConfParser</vh>
<v t="ekr.20250131013600.703"><vh>_RawConfParser.parse_ini_file</vh></v>
<v t="ekr.20250131013600.704"><vh>_RawConfParser._ini_file_with_sections</vh></v>
<v t="ekr.20250131013600.705"><vh>_RawConfParser.parse_toml_file</vh></v>
<v t="ekr.20250131013600.706"><vh>_RawConfParser.parse_config_file</vh></v>
</v>
<v t="ekr.20250131013600.702"><vh>class _ConfigurationFileParser</vh>
<v t="ekr.20250131013600.707"><vh>_ConfigurationFileParser.__init__</vh></v>
<v t="ekr.20250131013600.708"><vh>_ConfigurationFileParser.parse_config_file</vh></v>
</v>
</v>
<v t="ekr.20250131013600.709"><vh>@clean config_initialization.py</vh>
<v t="ekr.20250131013600.710"><vh>function: _config_initialization</vh></v>
<v t="ekr.20250131013600.711"><vh>function: _order_all_first</vh></v>
</v>
<v t="ekr.20250131013600.712"><vh>@clean deprecation_actions.py</vh>
<v t="ekr.20250131013600.713"><vh>class _OldNamesAction</vh>
<v t="ekr.20250131013600.715"><vh>_OldNamesAction.__init__</vh></v>
<v t="ekr.20250131013600.716"><vh>_OldNamesAction.__call__</vh></v>
</v>
<v t="ekr.20250131013600.714"><vh>class _NewNamesAction</vh>
<v t="ekr.20250131013600.717"><vh>_NewNamesAction.__init__</vh></v>
<v t="ekr.20250131013600.718"><vh>_NewNamesAction.__call__</vh></v>
</v>
</v>
<v t="ekr.20250131013600.719"><vh>@clean exceptions.py</vh>
<v t="ekr.20250131013600.720"><vh>class UnrecognizedArgumentAction</vh></v>
<v t="ekr.20250131013600.721"><vh>class _UnrecognizedOptionError</vh>
<v t="ekr.20250131013600.723"><vh>_UnrecognizedOptionError.__init__</vh></v>
</v>
<v t="ekr.20250131013600.722"><vh>class ArgumentPreprocessingError</vh></v>
</v>
<v t="ekr.20250131013600.724"><vh>@clean find_default_config_files.py</vh>
<v t="ekr.20250131013600.725"><vh>function: _find_pyproject</vh></v>
<v t="ekr.20250131013600.726"><vh>function: _toml_has_config</vh></v>
<v t="ekr.20250131013600.727"><vh>function: _cfg_or_ini_has_config</vh></v>
<v t="ekr.20250131013600.728"><vh>function: _yield_default_files</vh></v>
<v t="ekr.20250131013600.729"><vh>function: _find_project_config</vh></v>
<v t="ekr.20250131013600.730"><vh>function: _find_config_in_home_or_environment</vh></v>
<v t="ekr.20250131013600.731"><vh>function: find_default_config_files</vh></v>
</v>
<v t="ekr.20250131013600.732"><vh>@clean help_formatter.py</vh>
<v t="ekr.20250131013600.733"><vh>class _HelpFormatter</vh>
<v t="ekr.20250131013600.734"><vh>_HelpFormatter._get_help_string</vh></v>
<v t="ekr.20250131013600.735"><vh>_HelpFormatter.get_long_description</vh></v>
</v>
</v>
<v t="ekr.20250131013600.736"><vh>@clean utils.py</vh>
<v t="ekr.20250131013600.737"><vh>function: _convert_option_to_argument</vh></v>
<v t="ekr.20250131013600.738"><vh>function: _parse_rich_type_value</vh></v>
<v t="ekr.20250131013600.739"><vh>function: _init_hook</vh></v>
<v t="ekr.20250131013600.740"><vh>function: _set_rcfile</vh></v>
<v t="ekr.20250131013600.741"><vh>function: _set_output</vh></v>
<v t="ekr.20250131013600.742"><vh>function: _add_plugins</vh></v>
<v t="ekr.20250131013600.743"><vh>function: _set_verbose_mode</vh></v>
<v t="ekr.20250131013600.744"><vh>function: _enable_all_extensions</vh></v>
<v t="ekr.20250131013600.745"><vh>function: _preprocess_options</vh></v>
</v>
<v t="ekr.20250131013600.746"><vh>path: pylint/config/_pylint_config</vh>
<v t="ekr.20250131013600.747"><vh>@clean __init__.py</vh></v>
<v t="ekr.20250131013600.748"><vh>@clean generate_command.py</vh>
<v t="ekr.20250131013600.749"><vh>function: generate_interactive_config</vh></v>
<v t="ekr.20250131013600.750"><vh>function: handle_generate_command</vh></v>
</v>
<v t="ekr.20250131013600.751"><vh>@clean help_message.py</vh>
<v t="ekr.20250131013600.752"><vh>function: get_subparser_help</vh></v>
<v t="ekr.20250131013600.753"><vh>function: get_help</vh></v>
</v>
<v t="ekr.20250131013600.754"><vh>@clean main.py</vh>
<v t="ekr.20250131013600.755"><vh>function: _handle_pylint_config_commands</vh></v>
</v>
<v t="ekr.20250131013600.756"><vh>@clean setup.py</vh>
<v t="ekr.20250131013600.757"><vh>class _HelpAction</vh>
<v t="ekr.20250131013600.759"><vh>_HelpAction.__call__</vh></v>
</v>
<v t="ekr.20250131013600.758"><vh>function: _register_generate_config_options</vh></v>
</v>
<v t="ekr.20250131013600.760"><vh>@clean utils.py</vh>
<v t="ekr.20250131013600.761"><vh>class InvalidUserInput</vh>
<v t="ekr.20250131013600.767"><vh>InvalidUserInput.__init__</vh></v>
</v>
<v t="ekr.20250131013600.762"><vh>function: should_retry_after_invalid_input</vh></v>
<v t="ekr.20250131013600.763"><vh>function: get_and_validate_format</vh></v>
<v t="ekr.20250131013600.764"><vh>function: validate_yes_no</vh></v>
<v t="ekr.20250131013600.765"><vh>function: get_minimal_setting</vh></v>
<v t="ekr.20250131013600.766"><vh>function: get_and_validate_output_file</vh></v>
</v>
</v>
</v>
<v t="ekr.20250131013600.768"><vh>path: pylint/extensions</vh>
<v t="ekr.20250131013600.769"><vh>@clean __init__.py</vh>
<v t="ekr.20250131013600.770"><vh>function: initialize</vh></v>
</v>
<v t="ekr.20250131013600.771"><vh>@clean _check_docs_utils.py</vh>
<v t="ekr.20250131013600.772"><vh>function: space_indentation</vh></v>
<v t="ekr.20250131013600.773"><vh>function: get_setters_property_name</vh></v>
<v t="ekr.20250131013600.774"><vh>function: get_setters_property</vh></v>
<v t="ekr.20250131013600.775"><vh>function: returns_something</vh></v>
<v t="ekr.20250131013600.776"><vh>function: _get_raise_target</vh></v>
<v t="ekr.20250131013600.777"><vh>function: _split_multiple_exc_types</vh></v>
<v t="ekr.20250131013600.778"><vh>function: possible_exc_types</vh></v>
<v t="ekr.20250131013600.779"><vh>function: _is_ellipsis</vh></v>
<v t="ekr.20250131013600.780"><vh>function: _merge_annotations</vh></v>
<v t="ekr.20250131013600.781"><vh>function: _annotations_list</vh></v>
<v t="ekr.20250131013600.782"><vh>function: args_with_annotation</vh></v>
<v t="ekr.20250131013600.783"><vh>function: docstringify</vh></v>
<v t="ekr.20250131013600.784"><vh>class Docstring</vh>
<v t="ekr.20250131013600.789"><vh>Docstring.__init__</vh></v>
<v t="ekr.20250131013600.790"><vh>Docstring.__repr__</vh></v>
<v t="ekr.20250131013600.791"><vh>Docstring.matching_sections</vh></v>
<v t="ekr.20250131013600.792"><vh>Docstring.exceptions</vh></v>
<v t="ekr.20250131013600.793"><vh>Docstring.has_params</vh></v>
<v t="ekr.20250131013600.794"><vh>Docstring.has_returns</vh></v>
<v t="ekr.20250131013600.795"><vh>Docstring.has_rtype</vh></v>
<v t="ekr.20250131013600.796"><vh>Docstring.has_property_returns</vh></v>
<v t="ekr.20250131013600.797"><vh>Docstring.has_property_type</vh></v>
<v t="ekr.20250131013600.798"><vh>Docstring.has_yields</vh></v>
<v t="ekr.20250131013600.799"><vh>Docstring.has_yields_type</vh></v>
<v t="ekr.20250131013600.800"><vh>Docstring.match_param_docs</vh></v>
<v t="ekr.20250131013600.801"><vh>Docstring.params_documented_elsewhere</vh></v>
</v>
<v t="ekr.20250131013600.785"><vh>class SphinxDocstring</vh>
<v t="ekr.20250131013600.802"><vh>SphinxDocstring.matching_sections</vh></v>
<v t="ekr.20250131013600.803"><vh>SphinxDocstring.exceptions</vh></v>
<v t="ekr.20250131013600.804"><vh>SphinxDocstring.has_params</vh></v>
<v t="ekr.20250131013600.805"><vh>SphinxDocstring.has_returns</vh></v>
<v t="ekr.20250131013600.806"><vh>SphinxDocstring.has_rtype</vh></v>
<v t="ekr.20250131013600.807"><vh>SphinxDocstring.has_property_returns</vh></v>
<v t="ekr.20250131013600.808"><vh>SphinxDocstring.has_property_type</vh></v>
<v t="ekr.20250131013600.809"><vh>SphinxDocstring.match_param_docs</vh></v>
</v>
<v t="ekr.20250131013600.786"><vh>class EpytextDocstring</vh>
<v t="ekr.20250131013600.810"><vh>EpytextDocstring.has_property_returns</vh></v>
</v>
<v t="ekr.20250131013600.787"><vh>class GoogleDocstring</vh>
<v t="ekr.20250131013600.811"><vh>GoogleDocstring.matching_sections</vh></v>
<v t="ekr.20250131013600.812"><vh>GoogleDocstring.has_params</vh></v>
<v t="ekr.20250131013600.813"><vh>GoogleDocstring.has_returns</vh></v>
<v t="ekr.20250131013600.814"><vh>GoogleDocstring.has_rtype</vh></v>
<v t="ekr.20250131013600.815"><vh>GoogleDocstring.has_property_returns</vh></v>
<v t="ekr.20250131013600.816"><vh>GoogleDocstring.has_property_type</vh></v>
<v t="ekr.20250131013600.817"><vh>GoogleDocstring.has_yields</vh></v>
<v t="ekr.20250131013600.818"><vh>GoogleDocstring.has_yields_type</vh></v>
<v t="ekr.20250131013600.819"><vh>GoogleDocstring.exceptions</vh></v>
<v t="ekr.20250131013600.820"><vh>GoogleDocstring.match_param_docs</vh></v>
<v t="ekr.20250131013600.821"><vh>GoogleDocstring._first_line</vh></v>
<v t="ekr.20250131013600.822"><vh>GoogleDocstring.min_section_indent</vh></v>
<v t="ekr.20250131013600.823"><vh>GoogleDocstring._is_section_header</vh></v>
<v t="ekr.20250131013600.824"><vh>GoogleDocstring._parse_section</vh></v>
</v>
<v t="ekr.20250131013600.788"><vh>class NumpyDocstring</vh>
<v t="ekr.20250131013600.825"><vh>NumpyDocstring.match_param_docs</vh></v>
<v t="ekr.20250131013600.826"><vh>NumpyDocstring.min_section_indent</vh></v>
<v t="ekr.20250131013600.827"><vh>NumpyDocstring._is_section_header</vh></v>
</v>
</v>
<v t="ekr.20250131013600.828"><vh>@clean bad_builtin.py</vh>
<v t="ekr.20250131013600.829"><vh>class BadBuiltinChecker</vh>
<v t="ekr.20250131013600.831"><vh>BadBuiltinChecker.visit_call</vh></v>
</v>
<v t="ekr.20250131013600.830"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013600.832"><vh>@clean broad_try_clause.py</vh>
<v t="ekr.20250131013600.833"><vh>class BroadTryClauseChecker</vh>
<v t="ekr.20250131013600.835"><vh>BroadTryClauseChecker._count_statements</vh></v>
<v t="ekr.20250131013600.836"><vh>BroadTryClauseChecker.visit_try</vh></v>
</v>
<v t="ekr.20250131013600.834"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013600.837"><vh>@clean check_elif.py</vh>
<v t="ekr.20250131013600.838"><vh>class ElseifUsedChecker</vh>
<v t="ekr.20250131013600.840"><vh>ElseifUsedChecker.__init__</vh></v>
<v t="ekr.20250131013600.841"><vh>ElseifUsedChecker._init</vh></v>
<v t="ekr.20250131013600.842"><vh>ElseifUsedChecker.process_tokens</vh></v>
<v t="ekr.20250131013600.843"><vh>ElseifUsedChecker.leave_module</vh></v>
<v t="ekr.20250131013600.844"><vh>ElseifUsedChecker.visit_if</vh></v>
</v>
<v t="ekr.20250131013600.839"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013600.845"><vh>@clean code_style.py</vh>
<v t="ekr.20250131013600.846"><vh>class CodeStyleChecker</vh>
<v t="ekr.20250131013600.848"><vh>CodeStyleChecker.open</vh></v>
<v t="ekr.20250131013600.849"><vh>CodeStyleChecker.visit_call</vh></v>
<v t="ekr.20250131013600.850"><vh>CodeStyleChecker.visit_dict</vh></v>
<v t="ekr.20250131013600.851"><vh>CodeStyleChecker.visit_for</vh></v>
<v t="ekr.20250131013600.852"><vh>CodeStyleChecker.visit_comprehension</vh></v>
<v t="ekr.20250131013600.853"><vh>CodeStyleChecker.visit_if</vh></v>
<v t="ekr.20250131013600.854"><vh>CodeStyleChecker._check_dict_consider_namedtuple_dataclass</vh></v>
<v t="ekr.20250131013600.855"><vh>CodeStyleChecker._check_consider_using_assignment_expr</vh></v>
<v t="ekr.20250131013600.856"><vh>CodeStyleChecker._check_prev_sibling_to_if_stmt</vh></v>
<v t="ekr.20250131013600.857"><vh>CodeStyleChecker._check_ignore_assignment_expr_suggestion</vh></v>
<v t="ekr.20250131013600.858"><vh>CodeStyleChecker.visit_assign</vh></v>
</v>
<v t="ekr.20250131013600.847"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013600.859"><vh>@clean comparison_placement.py</vh>
<v t="ekr.20250131013600.860"><vh>class MisplacedComparisonConstantChecker</vh>
<v t="ekr.20250131013600.862"><vh>MisplacedComparisonConstantChecker._check_misplaced_constant</vh></v>
<v t="ekr.20250131013600.863"><vh>MisplacedComparisonConstantChecker.visit_compare</vh></v>
</v>
<v t="ekr.20250131013600.861"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013600.864"><vh>@clean confusing_elif.py</vh>
<v t="ekr.20250131013600.865"><vh>class ConfusingConsecutiveElifChecker</vh>
<v t="ekr.20250131013600.867"><vh>ConfusingConsecutiveElifChecker.visit_if</vh></v>
<v t="ekr.20250131013600.868"><vh>ConfusingConsecutiveElifChecker._has_no_else_clause</vh></v>
</v>
<v t="ekr.20250131013600.866"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013600.869"><vh>@clean consider_refactoring_into_while_condition.py</vh>
<v t="ekr.20250131013600.870"><vh>class ConsiderRefactorIntoWhileConditionChecker</vh>
<v t="ekr.20250131013600.872"><vh>ConsiderRefactorIntoWhileConditionChecker.visit_while</vh></v>
<v t="ekr.20250131013600.873"><vh>ConsiderRefactorIntoWhileConditionChecker._check_breaking_after_while_true</vh></v>
</v>
<v t="ekr.20250131013600.871"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013600.874"><vh>@clean consider_ternary_expression.py</vh>
<v t="ekr.20250131013600.875"><vh>class ConsiderTernaryExpressionChecker</vh>
<v t="ekr.20250131013600.877"><vh>ConsiderTernaryExpressionChecker.visit_if</vh></v>
</v>
<v t="ekr.20250131013600.876"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013600.878"><vh>@clean dict_init_mutate.py</vh>
<v t="ekr.20250131013600.879"><vh>class DictInitMutateChecker</vh>
<v t="ekr.20250131013600.881"><vh>DictInitMutateChecker.visit_assign</vh></v>
</v>
<v t="ekr.20250131013600.880"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013600.882"><vh>@clean docparams.py</vh>
<v t="ekr.20250131013600.883"><vh>class DocstringParameterChecker</vh>
<v t="ekr.20250131013600.885"><vh>DocstringParameterChecker.visit_functiondef</vh></v>
<v t="ekr.20250131013600.886"><vh>DocstringParameterChecker.check_functiondef_params</vh></v>
<v t="ekr.20250131013600.887"><vh>DocstringParameterChecker.check_functiondef_returns</vh></v>
<v t="ekr.20250131013600.888"><vh>DocstringParameterChecker.check_functiondef_yields</vh></v>
<v t="ekr.20250131013600.889"><vh>DocstringParameterChecker.visit_raise</vh></v>
<v t="ekr.20250131013600.890"><vh>DocstringParameterChecker.visit_return</vh></v>
<v t="ekr.20250131013600.891"><vh>DocstringParameterChecker.visit_yield</vh></v>
<v t="ekr.20250131013600.892"><vh>DocstringParameterChecker._compare_missing_args</vh></v>
<v t="ekr.20250131013600.893"><vh>DocstringParameterChecker._compare_different_args</vh></v>
<v t="ekr.20250131013600.894"><vh>DocstringParameterChecker._compare_ignored_args</vh></v>
<v t="ekr.20250131013600.895"><vh>DocstringParameterChecker.check_arguments_in_docstring</vh></v>
<v t="ekr.20250131013600.896"><vh>DocstringParameterChecker.check_single_constructor_params</vh></v>
<v t="ekr.20250131013600.897"><vh>DocstringParameterChecker._add_raise_message</vh></v>
</v>
<v t="ekr.20250131013600.884"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013600.898"><vh>@clean docstyle.py</vh>
<v t="ekr.20250131013600.899"><vh>class DocStringStyleChecker</vh>
<v t="ekr.20250131013600.901"><vh>DocStringStyleChecker.visit_module</vh></v>
<v t="ekr.20250131013600.902"><vh>DocStringStyleChecker.visit_classdef</vh></v>
<v t="ekr.20250131013600.903"><vh>DocStringStyleChecker.visit_functiondef</vh></v>
<v t="ekr.20250131013600.904"><vh>DocStringStyleChecker._check_docstring</vh></v>
</v>
<v t="ekr.20250131013600.900"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013600.905"><vh>@clean dunder.py</vh>
<v t="ekr.20250131013600.906"><vh>class DunderChecker</vh>
<v t="ekr.20250131013600.908"><vh>DunderChecker.open</vh></v>
<v t="ekr.20250131013600.909"><vh>DunderChecker.visit_functiondef</vh></v>
</v>
<v t="ekr.20250131013600.907"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013600.910"><vh>@clean empty_comment.py</vh>
<v t="ekr.20250131013600.911"><vh>function: is_line_commented</vh></v>
<v t="ekr.20250131013600.912"><vh>function: comment_part_of_string</vh></v>
<v t="ekr.20250131013600.913"><vh>class CommentChecker</vh>
<v t="ekr.20250131013600.915"><vh>CommentChecker.process_module</vh></v>
</v>
<v t="ekr.20250131013600.914"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013600.916"><vh>@clean eq_without_hash.py</vh>
<v t="ekr.20250131013600.917"><vh>class EqWithoutHash</vh>
<v t="ekr.20250131013600.919"><vh>EqWithoutHash.visit_classdef</vh></v>
</v>
<v t="ekr.20250131013600.918"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013600.920"><vh>@clean for_any_all.py</vh>
<v t="ekr.20250131013600.921"><vh>class ConsiderUsingAnyOrAllChecker</vh>
<v t="ekr.20250131013600.923"><vh>ConsiderUsingAnyOrAllChecker.visit_for</vh></v>
<v t="ekr.20250131013600.924"><vh>ConsiderUsingAnyOrAllChecker._if_statement_returns_bool</vh></v>
<v t="ekr.20250131013600.925"><vh>ConsiderUsingAnyOrAllChecker._assigned_reassigned_returned</vh></v>
<v t="ekr.20250131013600.926"><vh>ConsiderUsingAnyOrAllChecker._build_suggested_string</vh></v>
</v>
<v t="ekr.20250131013600.922"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013600.927"><vh>@clean magic_value.py</vh>
<v t="ekr.20250131013600.928"><vh>class MagicValueChecker</vh>
<v t="ekr.20250131013600.930"><vh>MagicValueChecker.__init__</vh></v>
<v t="ekr.20250131013600.931"><vh>MagicValueChecker.open</vh></v>
<v t="ekr.20250131013600.932"><vh>MagicValueChecker._magic_vals_ext_configured</vh></v>
<v t="ekr.20250131013600.933"><vh>MagicValueChecker._check_constants_comparison</vh></v>
<v t="ekr.20250131013600.934"><vh>MagicValueChecker._is_magic_value</vh></v>
<v t="ekr.20250131013600.935"><vh>MagicValueChecker._parse_rcfile_magic_numbers</vh></v>
<v t="ekr.20250131013600.936"><vh>MagicValueChecker.visit_compare</vh></v>
</v>
<v t="ekr.20250131013600.929"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013600.937"><vh>@clean mccabe.py</vh>
<v t="ekr.20250131013600.938"><vh>class PathGraph</vh>
<v t="ekr.20250131013600.942"><vh>PathGraph.__init__</vh></v>
</v>
<v t="ekr.20250131013600.939"><vh>class PathGraphingAstVisitor</vh>
<v t="ekr.20250131013600.943"><vh>PathGraphingAstVisitor.__init__</vh></v>
<v t="ekr.20250131013600.944"><vh>PathGraphingAstVisitor.default</vh></v>
<v t="ekr.20250131013600.945"><vh>PathGraphingAstVisitor.dispatch</vh></v>
<v t="ekr.20250131013600.946"><vh>PathGraphingAstVisitor.visitFunctionDef</vh></v>
<v t="ekr.20250131013600.947"><vh>PathGraphingAstVisitor.visitSimpleStatement</vh></v>
<v t="ekr.20250131013600.948"><vh>PathGraphingAstVisitor.visitWith</vh></v>
<v t="ekr.20250131013600.949"><vh>PathGraphingAstVisitor._append_node</vh></v>
<v t="ekr.20250131013600.950"><vh>PathGraphingAstVisitor._subgraph</vh></v>
<v t="ekr.20250131013600.951"><vh>PathGraphingAstVisitor._subgraph_parse</vh></v>
</v>
<v t="ekr.20250131013600.940"><vh>class McCabeMethodChecker</vh>
<v t="ekr.20250131013600.952"><vh>McCabeMethodChecker.visit_module</vh></v>
</v>
<v t="ekr.20250131013600.941"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013600.953"><vh>@clean no_self_use.py</vh>
<v t="ekr.20250131013600.954"><vh>class NoSelfUseChecker</vh>
<v t="ekr.20250131013600.957"><vh>NoSelfUseChecker.__init__</vh></v>
<v t="ekr.20250131013600.958"><vh>NoSelfUseChecker.visit_name</vh></v>
<v t="ekr.20250131013600.959"><vh>NoSelfUseChecker.visit_functiondef</vh></v>
<v t="ekr.20250131013600.960"><vh>NoSelfUseChecker._check_first_arg_for_type</vh></v>
<v t="ekr.20250131013600.961"><vh>NoSelfUseChecker.leave_functiondef</vh></v>
</v>
<v t="ekr.20250131013600.955"><vh>function: _has_bare_super_call</vh></v>
<v t="ekr.20250131013600.956"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013600.962"><vh>@clean overlapping_exceptions.py</vh>
<v t="ekr.20250131013600.963"><vh>class OverlappingExceptionsChecker</vh>
<v t="ekr.20250131013600.965"><vh>OverlappingExceptionsChecker.visit_try</vh></v>
</v>
<v t="ekr.20250131013600.964"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013600.966"><vh>@clean private_import.py</vh>
<v t="ekr.20250131013600.967"><vh>class PrivateImportChecker</vh>
<v t="ekr.20250131013600.969"><vh>PrivateImportChecker.__init__</vh></v>
<v t="ekr.20250131013600.970"><vh>PrivateImportChecker.visit_import</vh></v>
<v t="ekr.20250131013600.971"><vh>PrivateImportChecker.visit_importfrom</vh></v>
<v t="ekr.20250131013600.972"><vh>PrivateImportChecker._get_private_imports</vh></v>
<v t="ekr.20250131013600.973"><vh>PrivateImportChecker._name_is_private</vh></v>
<v t="ekr.20250131013600.974"><vh>PrivateImportChecker._get_type_annotation_names</vh></v>
<v t="ekr.20250131013600.975"><vh>PrivateImportChecker._populate_type_annotations</vh></v>
<v t="ekr.20250131013600.976"><vh>PrivateImportChecker._populate_type_annotations_function</vh></v>
<v t="ekr.20250131013600.977"><vh>PrivateImportChecker._populate_type_annotations_annotation</vh></v>
<v t="ekr.20250131013600.978"><vh>PrivateImportChecker._assignments_call_private_name</vh></v>
<v t="ekr.20250131013600.979"><vh>PrivateImportChecker.same_root_dir</vh></v>
</v>
<v t="ekr.20250131013600.968"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013600.980"><vh>@clean redefined_loop_name.py</vh>
<v t="ekr.20250131013600.981"><vh>class RedefinedLoopNameChecker</vh>
<v t="ekr.20250131013600.983"><vh>RedefinedLoopNameChecker.__init__</vh></v>
<v t="ekr.20250131013600.984"><vh>RedefinedLoopNameChecker.visit_assignname</vh></v>
<v t="ekr.20250131013600.985"><vh>RedefinedLoopNameChecker.visit_for</vh></v>
<v t="ekr.20250131013600.986"><vh>RedefinedLoopNameChecker.leave_for</vh></v>
</v>
<v t="ekr.20250131013600.982"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013600.987"><vh>@clean redefined_variable_type.py</vh>
<v t="ekr.20250131013600.988"><vh>class MultipleTypesChecker</vh>
<v t="ekr.20250131013600.990"><vh>MultipleTypesChecker.visit_classdef</vh></v>
<v t="ekr.20250131013600.991"><vh>MultipleTypesChecker.leave_classdef</vh></v>
<v t="ekr.20250131013600.992"><vh>MultipleTypesChecker.visit_module</vh></v>
<v t="ekr.20250131013600.993"><vh>MultipleTypesChecker._check_and_add_messages</vh></v>
<v t="ekr.20250131013600.994"><vh>MultipleTypesChecker.visit_assign</vh></v>
</v>
<v t="ekr.20250131013600.989"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013600.995"><vh>@clean set_membership.py</vh>
<v t="ekr.20250131013600.996"><vh>class SetMembershipChecker</vh>
<v t="ekr.20250131013600.998"><vh>SetMembershipChecker.__init__</vh></v>
<v t="ekr.20250131013600.999"><vh>SetMembershipChecker.visit_compare</vh></v>
<v t="ekr.20250131013600.1000"><vh>SetMembershipChecker._check_in_comparison</vh></v>
</v>
<v t="ekr.20250131013600.997"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013600.1001"><vh>@clean typing.py</vh>
<v t="ekr.20250131013600.1002"><vh>class TypingAlias</vh></v>
<v t="ekr.20250131013600.1003"><vh>class DeprecatedTypingAliasMsg</vh></v>
<v t="ekr.20250131013600.1004"><vh>class TypingChecker</vh>
<v t="ekr.20250131013600.1006"><vh>TypingChecker.__init__</vh></v>
<v t="ekr.20250131013600.1007"><vh>TypingChecker.open</vh></v>
<v t="ekr.20250131013600.1008"><vh>TypingChecker._msg_postponed_eval_hint</vh></v>
<v t="ekr.20250131013600.1009"><vh>TypingChecker.visit_name</vh></v>
<v t="ekr.20250131013600.1010"><vh>TypingChecker.visit_attribute</vh></v>
<v t="ekr.20250131013600.1011"><vh>TypingChecker.visit_annassign</vh></v>
<v t="ekr.20250131013600.1012"><vh>TypingChecker.visit_subscript</vh></v>
<v t="ekr.20250131013600.1013"><vh>TypingChecker._is_deprecated_union_annotation</vh></v>
<v t="ekr.20250131013600.1014"><vh>TypingChecker._is_binop_union_annotation</vh></v>
<v t="ekr.20250131013600.1015"><vh>TypingChecker._is_optional_none_annotation</vh></v>
<v t="ekr.20250131013600.1016"><vh>TypingChecker._parse_binops_typehints</vh></v>
<v t="ekr.20250131013600.1017"><vh>TypingChecker._check_union_types</vh></v>
<v t="ekr.20250131013600.1018"><vh>TypingChecker._check_for_alternative_union_syntax</vh></v>
<v t="ekr.20250131013600.1019"><vh>TypingChecker._check_for_typing_alias</vh></v>
<v t="ekr.20250131013600.1020"><vh>TypingChecker.leave_module</vh></v>
<v t="ekr.20250131013600.1021"><vh>TypingChecker._check_broken_noreturn</vh></v>
<v t="ekr.20250131013600.1022"><vh>TypingChecker._check_broken_callable</vh></v>
<v t="ekr.20250131013600.1023"><vh>TypingChecker._broken_callable_location</vh></v>
</v>
<v t="ekr.20250131013600.1005"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013600.1024"><vh>@clean while_used.py</vh>
<v t="ekr.20250131013600.1025"><vh>class WhileChecker</vh>
<v t="ekr.20250131013600.1027"><vh>WhileChecker.visit_while</vh></v>
</v>
<v t="ekr.20250131013600.1026"><vh>function: register</vh></v>
</v>
</v>
<v t="ekr.20250131013600.1028"><vh>path: pylint/lint</vh>
<v t="ekr.20250131013600.1029"><vh>@clean __init__.py</vh></v>
<v t="ekr.20250131013600.1030"><vh>@clean base_options.py</vh>
<v t="ekr.20250131013600.1031"><vh>function: _make_linter_options</vh></v>
<v t="ekr.20250131013600.1032"><vh>function: _make_run_options</vh></v>
</v>
<v t="ekr.20250131013600.1033"><vh>@clean caching.py</vh>
<v t="ekr.20250131013600.1034"><vh>function: _get_pdata_path</vh></v>
<v t="ekr.20250131013600.1035"><vh>function: load_results</vh></v>
<v t="ekr.20250131013600.1036"><vh>function: save_results</vh></v>
</v>
<v t="ekr.20250131013600.1037"><vh>@clean expand_modules.py</vh>
<v t="ekr.20250131013600.1038"><vh>function: _modpath_from_file</vh></v>
<v t="ekr.20250131013600.1039"><vh>function: discover_package_path</vh></v>
<v t="ekr.20250131013600.1040"><vh>function: _is_in_ignore_list_re</vh></v>
<v t="ekr.20250131013600.1041"><vh>function: _is_ignored_file</vh></v>
<v t="ekr.20250131013600.1042"><vh>function: expand_modules</vh></v>
</v>
<v t="ekr.20250131013600.1043"><vh>@clean message_state_handler.py</vh>
<v t="ekr.20250131013600.1044"><vh>class _MessageStateHandler</vh>
<v t="ekr.20250131013600.1045"><vh>_MessageStateHandler.__init__</vh></v>
<v t="ekr.20250131013600.1046"><vh>_MessageStateHandler._set_one_msg_status</vh></v>
<v t="ekr.20250131013600.1047"><vh>_MessageStateHandler._get_messages_to_set</vh></v>
<v t="ekr.20250131013600.1048"><vh>_MessageStateHandler._set_msg_status</vh></v>
<v t="ekr.20250131013600.1049"><vh>_MessageStateHandler._register_by_id_managed_msg</vh></v>
<v t="ekr.20250131013600.1050"><vh>_MessageStateHandler.disable</vh></v>
<v t="ekr.20250131013600.1051"><vh>_MessageStateHandler.disable_next</vh></v>
<v t="ekr.20250131013600.1052"><vh>_MessageStateHandler.enable</vh></v>
<v t="ekr.20250131013600.1053"><vh>_MessageStateHandler.disable_noerror_messages</vh></v>
<v t="ekr.20250131013600.1054"><vh>_MessageStateHandler.list_messages_enabled</vh></v>
<v t="ekr.20250131013600.1055"><vh>_MessageStateHandler._get_message_state_scope</vh></v>
<v t="ekr.20250131013600.1056"><vh>_MessageStateHandler._is_one_message_enabled</vh></v>
<v t="ekr.20250131013600.1057"><vh>_MessageStateHandler.is_message_enabled</vh></v>
<v t="ekr.20250131013600.1058"><vh>_MessageStateHandler.process_tokens</vh></v>
</v>
</v>
<v t="ekr.20250131013600.1059"><vh>@clean parallel.py</vh>
<v t="ekr.20250131013600.1060"><vh>function: _worker_initialize</vh></v>
<v t="ekr.20250131013600.1061"><vh>function: _worker_check_single_file</vh></v>
<v t="ekr.20250131013600.1062"><vh>function: _merge_mapreduce_data</vh></v>
<v t="ekr.20250131013600.1063"><vh>function: check_parallel</vh></v>
</v>
<v t="ekr.20250131013600.1064"><vh>@clean pylinter.py</vh>
<v t="ekr.20250131013601.1"><vh>class GetAstProtocol</vh>
<v t="ekr.20250131013601.47"><vh>GetAstProtocol.__call__</vh></v>
</v>
<v t="ekr.20250131013601.2"><vh>function: _read_stdin</vh></v>
<v t="ekr.20250131013601.3"><vh>function: _load_reporter_by_class</vh></v>
<v t="ekr.20250131013601.4"><vh>class PyLinter</vh></v>
<v t="ekr.20250131013601.5"><vh>function: __init__</vh></v>
<v t="ekr.20250131013601.6"><vh>function: load_default_plugins</vh></v>
<v t="ekr.20250131013601.7"><vh>function: load_plugin_modules</vh></v>
<v t="ekr.20250131013601.8"><vh>function: load_plugin_configuration</vh></v>
<v t="ekr.20250131013601.9"><vh>function: _load_reporters</vh></v>
<v t="ekr.20250131013601.10"><vh>function: _load_reporter_by_name</vh></v>
<v t="ekr.20250131013601.11"><vh>function: set_reporter</vh></v>
<v t="ekr.20250131013601.12"><vh>function: register_reporter</vh></v>
<v t="ekr.20250131013601.13"><vh>function: report_order</vh></v>
<v t="ekr.20250131013601.14"><vh>function: register_checker</vh></v>
<v t="ekr.20250131013601.15"><vh>function: enable_fail_on_messages</vh></v>
<v t="ekr.20250131013601.16"><vh>function: any_fail_on_issues</vh></v>
<v t="ekr.20250131013601.17"><vh>function: disable_reporters</vh></v>
<v t="ekr.20250131013601.18"><vh>function: _parse_error_mode</vh></v>
<v t="ekr.20250131013601.19"><vh>function: get_checkers</vh></v>
<v t="ekr.20250131013601.20"><vh>function: get_checker_names</vh></v>
<v t="ekr.20250131013601.21"><vh>function: prepare_checkers</vh></v>
<v t="ekr.20250131013601.22"><vh>function: should_analyze_file</vh></v>
<v t="ekr.20250131013601.23"><vh>function: initialize</vh></v>
<v t="ekr.20250131013601.24"><vh>function: _discover_files</vh></v>
<v t="ekr.20250131013601.25"><vh>function: check</vh></v>
<v t="ekr.20250131013601.26"><vh>function: _get_asts</vh></v>
<v t="ekr.20250131013601.27"><vh>function: check_single_file_item</vh></v>
<v t="ekr.20250131013601.28"><vh>function: _lint_files</vh></v>
<v t="ekr.20250131013601.29"><vh>function: _lint_file</vh></v>
<v t="ekr.20250131013601.30"><vh>function: _check_file</vh></v>
<v t="ekr.20250131013601.31"><vh>function: _get_file_descr_from_stdin</vh></v>
<v t="ekr.20250131013601.32"><vh>function: _iterate_file_descrs</vh></v>
<v t="ekr.20250131013601.33"><vh>function: _expand_files</vh></v>
<v t="ekr.20250131013601.34"><vh>function: set_current_module</vh></v>
<v t="ekr.20250131013601.35"><vh>function: _get_namespace_for_file</vh></v>
<v t="ekr.20250131013601.36"><vh>function: _astroid_module_checker</vh></v>
<v t="ekr.20250131013601.37"><vh>function: get_ast</vh></v>
<v t="ekr.20250131013601.38"><vh>function: check_astroid_module</vh></v>
<v t="ekr.20250131013601.39"><vh>function: _check_astroid_module</vh></v>
<v t="ekr.20250131013601.40"><vh>function: open</vh></v>
<v t="ekr.20250131013601.41"><vh>function: generate_reports</vh></v>
<v t="ekr.20250131013601.42"><vh>function: _report_evaluation</vh></v>
<v t="ekr.20250131013601.43"><vh>function: _add_one_message</vh></v>
<v t="ekr.20250131013601.44"><vh>function: add_message</vh></v>
<v t="ekr.20250131013601.45"><vh>function: add_ignored_message</vh></v>
<v t="ekr.20250131013601.46"><vh>function: _emit_stashed_messages</vh></v>
</v>
<v t="ekr.20250131013601.48"><vh>@clean report_functions.py</vh>
<v t="ekr.20250131013601.49"><vh>function: report_total_messages_stats</vh></v>
<v t="ekr.20250131013601.50"><vh>function: report_messages_stats</vh></v>
<v t="ekr.20250131013601.51"><vh>function: report_messages_by_module_stats</vh></v>
</v>
<v t="ekr.20250131013601.52"><vh>@clean run.py</vh>
<v t="ekr.20250131013601.53"><vh>function: _query_cpu</vh></v>
<v t="ekr.20250131013601.54"><vh>function: _query_cpu_cgroupv2</vh></v>
<v t="ekr.20250131013601.55"><vh>function: _query_cpu_cgroupsv1</vh></v>
<v t="ekr.20250131013601.56"><vh>function: _query_cpu_handle_k8s_pods</vh></v>
<v t="ekr.20250131013601.57"><vh>function: _cpu_count</vh></v>
<v t="ekr.20250131013601.58"><vh>class Run</vh>
<v t="ekr.20250131013601.60"><vh>Run.__init__</vh></v>
</v>
<v t="ekr.20250131013601.59"><vh>class _PylintConfigRun</vh></v>
</v>
<v t="ekr.20250131013601.61"><vh>@clean utils.py</vh>
<v t="ekr.20250131013601.62"><vh>function: prepare_crash_report</vh></v>
<v t="ekr.20250131013601.63"><vh>function: get_fatal_error_message</vh></v>
<v t="ekr.20250131013601.64"><vh>function: _augment_sys_path</vh></v>
<v t="ekr.20250131013601.65"><vh>function: augmented_sys_path</vh></v>
</v>
</v>
<v t="ekr.20250131013601.66"><vh>path: pylint/message</vh>
<v t="ekr.20250131013601.67"><vh>@clean __init__.py</vh></v>
<v t="ekr.20250131013601.68"><vh>@clean _deleted_message_ids.py</vh>
<v t="ekr.20250131013601.69"><vh>class DeletedMessage</vh></v>
<v t="ekr.20250131013601.70"><vh>function: is_deleted_symbol</vh></v>
<v t="ekr.20250131013601.71"><vh>function: is_deleted_msgid</vh></v>
<v t="ekr.20250131013601.72"><vh>function: is_moved_symbol</vh></v>
<v t="ekr.20250131013601.73"><vh>function: is_moved_msgid</vh></v>
</v>
<v t="ekr.20250131013601.74"><vh>@clean message.py</vh>
<v t="ekr.20250131013601.75"><vh>class Message</vh>
<v t="ekr.20250131013601.76"><vh>Message.__init__</vh></v>
<v t="ekr.20250131013601.77"><vh>Message.format</vh></v>
<v t="ekr.20250131013601.78"><vh>Message.location</vh></v>
</v>
</v>
<v t="ekr.20250131013601.79"><vh>@clean message_definition.py</vh>
<v t="ekr.20250131013601.80"><vh>class MessageDefinition</vh>
<v t="ekr.20250131013601.81"><vh>MessageDefinition.__init__</vh></v>
<v t="ekr.20250131013601.82"><vh>MessageDefinition.check_msgid</vh></v>
<v t="ekr.20250131013601.83"><vh>MessageDefinition.__eq__</vh></v>
<v t="ekr.20250131013601.84"><vh>MessageDefinition.__repr__</vh></v>
<v t="ekr.20250131013601.85"><vh>MessageDefinition.__str__</vh></v>
<v t="ekr.20250131013601.86"><vh>MessageDefinition.may_be_emitted</vh></v>
<v t="ekr.20250131013601.87"><vh>MessageDefinition.format_help</vh></v>
<v t="ekr.20250131013601.88"><vh>MessageDefinition.check_message_definition</vh></v>
</v>
</v>
<v t="ekr.20250131013601.89"><vh>@clean message_definition_store.py</vh>
<v t="ekr.20250131013601.90"><vh>class MessageDefinitionStore</vh>
<v t="ekr.20250131013601.91"><vh>MessageDefinitionStore.__init__</vh></v>
<v t="ekr.20250131013601.92"><vh>MessageDefinitionStore.messages</vh></v>
<v t="ekr.20250131013601.93"><vh>MessageDefinitionStore.register_messages_from_checker</vh></v>
<v t="ekr.20250131013601.94"><vh>MessageDefinitionStore.register_message</vh></v>
<v t="ekr.20250131013601.95"><vh>MessageDefinitionStore.get_message_definitions</vh></v>
<v t="ekr.20250131013601.96"><vh>MessageDefinitionStore.get_msg_display_string</vh></v>
<v t="ekr.20250131013601.97"><vh>MessageDefinitionStore.help_message</vh></v>
<v t="ekr.20250131013601.98"><vh>MessageDefinitionStore.list_messages</vh></v>
<v t="ekr.20250131013601.99"><vh>MessageDefinitionStore.find_emittable_messages</vh></v>
</v>
</v>
<v t="ekr.20250131013601.100"><vh>@clean message_id_store.py</vh>
<v t="ekr.20250131013601.101"><vh>class MessageIdStore</vh>
<v t="ekr.20250131013601.102"><vh>MessageIdStore.__init__</vh></v>
<v t="ekr.20250131013601.103"><vh>MessageIdStore.__len__</vh></v>
<v t="ekr.20250131013601.104"><vh>MessageIdStore.__repr__</vh></v>
<v t="ekr.20250131013601.105"><vh>MessageIdStore.get_symbol</vh></v>
<v t="ekr.20250131013601.106"><vh>MessageIdStore.get_msgid</vh></v>
<v t="ekr.20250131013601.107"><vh>MessageIdStore.register_message_definition</vh></v>
<v t="ekr.20250131013601.108"><vh>MessageIdStore.add_msgid_and_symbol</vh></v>
<v t="ekr.20250131013601.109"><vh>MessageIdStore.add_legacy_msgid_and_symbol</vh></v>
<v t="ekr.20250131013601.110"><vh>MessageIdStore.check_msgid_and_symbol</vh></v>
<v t="ekr.20250131013601.111"><vh>MessageIdStore._raise_duplicate_symbol</vh></v>
<v t="ekr.20250131013601.112"><vh>MessageIdStore._raise_duplicate_msgid</vh></v>
<v t="ekr.20250131013601.113"><vh>MessageIdStore.get_active_msgids</vh></v>
</v>
</v>
</v>
<v t="ekr.20250131013601.114"><vh>path: pylint/pyreverse</vh>
<v t="ekr.20250131013601.115"><vh>@clean __init__.py</vh></v>
<v t="ekr.20250131013601.116"><vh>@clean diadefslib.py</vh>
<v t="ekr.20250131013601.117"><vh>class DiaDefGenerator</vh>
<v t="ekr.20250131013601.121"><vh>DiaDefGenerator.__init__</vh></v>
<v t="ekr.20250131013601.122"><vh>DiaDefGenerator.get_title</vh></v>
<v t="ekr.20250131013601.123"><vh>DiaDefGenerator._set_option</vh></v>
<v t="ekr.20250131013601.124"><vh>DiaDefGenerator._set_default_options</vh></v>
<v t="ekr.20250131013601.125"><vh>DiaDefGenerator._get_levels</vh></v>
<v t="ekr.20250131013601.126"><vh>DiaDefGenerator.show_node</vh></v>
<v t="ekr.20250131013601.127"><vh>DiaDefGenerator.add_class</vh></v>
<v t="ekr.20250131013601.128"><vh>DiaDefGenerator.get_ancestors</vh></v>
<v t="ekr.20250131013601.129"><vh>DiaDefGenerator.get_associated</vh></v>
<v t="ekr.20250131013601.130"><vh>DiaDefGenerator.extract_classes</vh></v>
</v>
<v t="ekr.20250131013601.118"><vh>class DefaultDiadefGenerator</vh>
<v t="ekr.20250131013601.131"><vh>DefaultDiadefGenerator.__init__</vh></v>
<v t="ekr.20250131013601.132"><vh>DefaultDiadefGenerator.visit_project</vh></v>
<v t="ekr.20250131013601.133"><vh>DefaultDiadefGenerator.leave_project</vh></v>
<v t="ekr.20250131013601.134"><vh>DefaultDiadefGenerator.visit_module</vh></v>
<v t="ekr.20250131013601.135"><vh>DefaultDiadefGenerator.visit_classdef</vh></v>
<v t="ekr.20250131013601.136"><vh>DefaultDiadefGenerator.visit_importfrom</vh></v>
</v>
<v t="ekr.20250131013601.119"><vh>class ClassDiadefGenerator</vh>
<v t="ekr.20250131013601.137"><vh>ClassDiadefGenerator.class_diagram</vh></v>
</v>
<v t="ekr.20250131013601.120"><vh>class DiadefsHandler</vh>
<v t="ekr.20250131013601.138"><vh>DiadefsHandler.__init__</vh></v>
<v t="ekr.20250131013601.139"><vh>DiadefsHandler.get_diadefs</vh></v>
</v>
</v>
<v t="ekr.20250131013601.140"><vh>@clean diagrams.py</vh>
<v t="ekr.20250131013601.141"><vh>class Figure</vh>
<v t="ekr.20250131013601.148"><vh>Figure.__init__</vh></v>
</v>
<v t="ekr.20250131013601.142"><vh>class Relationship</vh>
<v t="ekr.20250131013601.149"><vh>Relationship.__init__</vh></v>
</v>
<v t="ekr.20250131013601.143"><vh>class DiagramEntity</vh>
<v t="ekr.20250131013601.150"><vh>DiagramEntity.__init__</vh></v>
</v>
<v t="ekr.20250131013601.144"><vh>class PackageEntity</vh></v>
<v t="ekr.20250131013601.145"><vh>class ClassEntity</vh>
<v t="ekr.20250131013601.151"><vh>ClassEntity.__init__</vh></v>
</v>
<v t="ekr.20250131013601.146"><vh>class ClassDiagram</vh>
<v t="ekr.20250131013601.152"><vh>ClassDiagram.__init__</vh></v>
<v t="ekr.20250131013601.153"><vh>ClassDiagram.get_relationships</vh></v>
<v t="ekr.20250131013601.154"><vh>ClassDiagram.add_relationship</vh></v>
<v t="ekr.20250131013601.155"><vh>ClassDiagram.get_relationship</vh></v>
<v t="ekr.20250131013601.156"><vh>ClassDiagram.get_attrs</vh></v>
<v t="ekr.20250131013601.157"><vh>ClassDiagram.get_methods</vh></v>
<v t="ekr.20250131013601.158"><vh>ClassDiagram.add_object</vh></v>
<v t="ekr.20250131013601.159"><vh>ClassDiagram.class_names</vh></v>
<v t="ekr.20250131013601.160"><vh>ClassDiagram.has_node</vh></v>
<v t="ekr.20250131013601.161"><vh>ClassDiagram.object_from_node</vh></v>
<v t="ekr.20250131013601.162"><vh>ClassDiagram.classes</vh></v>
<v t="ekr.20250131013601.163"><vh>ClassDiagram.classe</vh></v>
<v t="ekr.20250131013601.164"><vh>ClassDiagram.extract_relationships</vh></v>
<v t="ekr.20250131013601.165"><vh>ClassDiagram.assign_association_relationship</vh></v>
</v>
<v t="ekr.20250131013601.147"><vh>class PackageDiagram</vh>
<v t="ekr.20250131013601.166"><vh>PackageDiagram.modules</vh></v>
<v t="ekr.20250131013601.167"><vh>PackageDiagram.module</vh></v>
<v t="ekr.20250131013601.168"><vh>PackageDiagram.add_object</vh></v>
<v t="ekr.20250131013601.169"><vh>PackageDiagram.get_module</vh></v>
<v t="ekr.20250131013601.170"><vh>PackageDiagram.add_from_depend</vh></v>
<v t="ekr.20250131013601.171"><vh>PackageDiagram.extract_relationships</vh></v>
</v>
</v>
<v t="ekr.20250131013601.172"><vh>@clean dot_printer.py</vh>
<v t="ekr.20250131013601.173"><vh>class HTMLLabels</vh></v>
<v t="ekr.20250131013601.174"><vh>class DotPrinter</vh>
<v t="ekr.20250131013601.175"><vh>DotPrinter.__init__</vh></v>
<v t="ekr.20250131013601.176"><vh>DotPrinter._open_graph</vh></v>
<v t="ekr.20250131013601.177"><vh>DotPrinter.emit_node</vh></v>
<v t="ekr.20250131013601.178"><vh>DotPrinter._build_label_for_node</vh></v>
<v t="ekr.20250131013601.179"><vh>DotPrinter._escape_annotation_label</vh></v>
<v t="ekr.20250131013601.180"><vh>DotPrinter.emit_edge</vh></v>
<v t="ekr.20250131013601.181"><vh>DotPrinter.generate</vh></v>
<v t="ekr.20250131013601.182"><vh>DotPrinter._close_graph</vh></v>
</v>
</v>
<v t="ekr.20250131013601.183"><vh>@clean inspector.py</vh>
<v t="ekr.20250131013601.184"><vh>function: _astroid_wrapper</vh></v>
<v t="ekr.20250131013601.185"><vh>class IdGeneratorMixIn</vh>
<v t="ekr.20250131013601.193"><vh>IdGeneratorMixIn.__init__</vh></v>
<v t="ekr.20250131013601.194"><vh>IdGeneratorMixIn.init_counter</vh></v>
<v t="ekr.20250131013601.195"><vh>IdGeneratorMixIn.generate_id</vh></v>
</v>
<v t="ekr.20250131013601.186"><vh>class Project</vh>
<v t="ekr.20250131013601.196"><vh>Project.__init__</vh></v>
<v t="ekr.20250131013601.197"><vh>Project.add_module</vh></v>
<v t="ekr.20250131013601.198"><vh>Project.get_module</vh></v>
<v t="ekr.20250131013601.199"><vh>Project.get_children</vh></v>
<v t="ekr.20250131013601.200"><vh>Project.__repr__</vh></v>
</v>
<v t="ekr.20250131013601.187"><vh>class Linker</vh>
<v t="ekr.20250131013601.201"><vh>Linker.__init__</vh></v>
<v t="ekr.20250131013601.202"><vh>Linker.visit_project</vh></v>
<v t="ekr.20250131013601.203"><vh>Linker.visit_module</vh></v>
<v t="ekr.20250131013601.204"><vh>Linker.visit_classdef</vh></v>
<v t="ekr.20250131013601.205"><vh>Linker.visit_functiondef</vh></v>
<v t="ekr.20250131013601.206"><vh>Linker.visit_assignname</vh></v>
<v t="ekr.20250131013601.207"><vh>Linker.handle_assignattr_type</vh></v>
<v t="ekr.20250131013601.208"><vh>Linker.visit_import</vh></v>
<v t="ekr.20250131013601.209"><vh>Linker.visit_importfrom</vh></v>
<v t="ekr.20250131013601.210"><vh>Linker.compute_module</vh></v>
<v t="ekr.20250131013601.211"><vh>Linker._imported_module</vh></v>
</v>
<v t="ekr.20250131013601.188"><vh>class AssociationHandlerInterface</vh>
<v t="ekr.20250131013601.212"><vh>AssociationHandlerInterface.set_next</vh></v>
<v t="ekr.20250131013601.213"><vh>AssociationHandlerInterface.handle</vh></v>
</v>
<v t="ekr.20250131013601.189"><vh>class AbstractAssociationHandler</vh>
<v t="ekr.20250131013601.214"><vh>AbstractAssociationHandler.set_next</vh></v>
<v t="ekr.20250131013601.215"><vh>AbstractAssociationHandler.handle</vh></v>
</v>
<v t="ekr.20250131013601.190"><vh>class AggregationsHandler</vh>
<v t="ekr.20250131013601.216"><vh>AggregationsHandler.handle</vh></v>
</v>
<v t="ekr.20250131013601.191"><vh>class OtherAssociationsHandler</vh>
<v t="ekr.20250131013601.217"><vh>OtherAssociationsHandler.handle</vh></v>
</v>
<v t="ekr.20250131013601.192"><vh>function: project_from_files</vh></v>
</v>
<v t="ekr.20250131013601.218"><vh>@clean main.py</vh>
<v t="ekr.20250131013601.219"><vh>class Run</vh>
<v t="ekr.20250131013601.220"><vh>Run.__init__</vh></v>
<v t="ekr.20250131013601.221"><vh>Run.run</vh></v>
</v>
</v>
<v t="ekr.20250131013601.222"><vh>@clean mermaidjs_printer.py</vh>
<v t="ekr.20250131013601.223"><vh>class MermaidJSPrinter</vh>
<v t="ekr.20250131013601.225"><vh>MermaidJSPrinter._open_graph</vh></v>
<v t="ekr.20250131013601.226"><vh>MermaidJSPrinter.emit_node</vh></v>
<v t="ekr.20250131013601.227"><vh>MermaidJSPrinter.emit_edge</vh></v>
<v t="ekr.20250131013601.228"><vh>MermaidJSPrinter._close_graph</vh></v>
</v>
<v t="ekr.20250131013601.224"><vh>class HTMLMermaidJSPrinter</vh>
<v t="ekr.20250131013601.229"><vh>HTMLMermaidJSPrinter._open_graph</vh></v>
<v t="ekr.20250131013601.230"><vh>HTMLMermaidJSPrinter._close_graph</vh></v>
</v>
</v>
<v t="ekr.20250131013601.231"><vh>@clean plantuml_printer.py</vh>
<v t="ekr.20250131013601.232"><vh>class PlantUmlPrinter</vh>
<v t="ekr.20250131013601.233"><vh>PlantUmlPrinter._open_graph</vh></v>
<v t="ekr.20250131013601.234"><vh>PlantUmlPrinter.emit_node</vh></v>
<v t="ekr.20250131013601.235"><vh>PlantUmlPrinter.emit_edge</vh></v>
<v t="ekr.20250131013601.236"><vh>PlantUmlPrinter._close_graph</vh></v>
</v>
</v>
<v t="ekr.20250131013601.237"><vh>@clean printer.py</vh>
<v t="ekr.20250131013601.238"><vh>class NodeType</vh></v>
<v t="ekr.20250131013601.239"><vh>class EdgeType</vh></v>
<v t="ekr.20250131013601.240"><vh>class Layout</vh></v>
<v t="ekr.20250131013601.241"><vh>class NodeProperties</vh></v>
<v t="ekr.20250131013601.242"><vh>class Printer</vh>
<v t="ekr.20250131013601.243"><vh>Printer.__init__</vh></v>
<v t="ekr.20250131013601.244"><vh>Printer._inc_indent</vh></v>
<v t="ekr.20250131013601.245"><vh>Printer._dec_indent</vh></v>
<v t="ekr.20250131013601.246"><vh>Printer._open_graph</vh></v>
<v t="ekr.20250131013601.247"><vh>Printer.emit</vh></v>
<v t="ekr.20250131013601.248"><vh>Printer.emit_node</vh></v>
<v t="ekr.20250131013601.249"><vh>Printer.emit_edge</vh></v>
<v t="ekr.20250131013601.250"><vh>Printer._get_method_arguments</vh></v>
<v t="ekr.20250131013601.251"><vh>Printer.generate</vh></v>
<v t="ekr.20250131013601.252"><vh>Printer._close_graph</vh></v>
</v>
</v>
<v t="ekr.20250131013601.253"><vh>@clean printer_factory.py</vh>
<v t="ekr.20250131013601.254"><vh>function: get_printer_for_filetype</vh></v>
</v>
<v t="ekr.20250131013601.255"><vh>@clean utils.py</vh>
<v t="ekr.20250131013601.256"><vh>function: get_default_options</vh></v>
<v t="ekr.20250131013601.257"><vh>function: insert_default_options</vh></v>
<v t="ekr.20250131013601.258"><vh>function: get_visibility</vh></v>
<v t="ekr.20250131013601.259"><vh>function: is_exception</vh></v>
<v t="ekr.20250131013601.260"><vh>class FilterMixIn</vh>
<v t="ekr.20250131013601.267"><vh>FilterMixIn.__init__</vh></v>
<v t="ekr.20250131013601.268"><vh>FilterMixIn.show_attr</vh></v>
</v>
<v t="ekr.20250131013601.261"><vh>class LocalsVisitor</vh>
<v t="ekr.20250131013601.269"><vh>LocalsVisitor.__init__</vh></v>
<v t="ekr.20250131013601.270"><vh>LocalsVisitor.get_callbacks</vh></v>
<v t="ekr.20250131013601.271"><vh>LocalsVisitor.visit</vh></v>
</v>
<v t="ekr.20250131013601.262"><vh>function: get_annotation_label</vh></v>
<v t="ekr.20250131013601.263"><vh>function: get_annotation</vh></v>
<v t="ekr.20250131013601.264"><vh>function: infer_node</vh></v>
<v t="ekr.20250131013601.265"><vh>function: check_graphviz_availability</vh></v>
<v t="ekr.20250131013601.266"><vh>function: check_if_graphviz_supports_format</vh></v>
</v>
<v t="ekr.20250131013601.272"><vh>@clean writer.py</vh>
<v t="ekr.20250131013601.273"><vh>class DiagramWriter</vh>
<v t="ekr.20250131013601.274"><vh>DiagramWriter.__init__</vh></v>
<v t="ekr.20250131013601.275"><vh>DiagramWriter.write</vh></v>
<v t="ekr.20250131013601.276"><vh>DiagramWriter.should_show_node</vh></v>
<v t="ekr.20250131013601.277"><vh>DiagramWriter.write_packages</vh></v>
<v t="ekr.20250131013601.278"><vh>DiagramWriter.write_classes</vh></v>
<v t="ekr.20250131013601.279"><vh>DiagramWriter.set_printer</vh></v>
<v t="ekr.20250131013601.280"><vh>DiagramWriter.get_package_properties</vh></v>
<v t="ekr.20250131013601.281"><vh>DiagramWriter.get_class_properties</vh></v>
<v t="ekr.20250131013601.282"><vh>DiagramWriter.get_shape_color</vh></v>
<v t="ekr.20250131013601.283"><vh>DiagramWriter.save</vh></v>
</v>
</v>
</v>
<v t="ekr.20250131013601.284"><vh>path: pylint/reporters</vh>
<v t="ekr.20250131013601.285"><vh>@clean __init__.py</vh>
<v t="ekr.20250131013601.286"><vh>function: initialize</vh></v>
</v>
<v t="ekr.20250131013601.287"><vh>@clean base_reporter.py</vh>
<v t="ekr.20250131013601.288"><vh>class BaseReporter</vh>
<v t="ekr.20250131013601.289"><vh>BaseReporter.__init__</vh></v>
<v t="ekr.20250131013601.290"><vh>BaseReporter.handle_message</vh></v>
<v t="ekr.20250131013601.291"><vh>BaseReporter.writeln</vh></v>
<v t="ekr.20250131013601.292"><vh>BaseReporter.display_reports</vh></v>
<v t="ekr.20250131013601.293"><vh>BaseReporter._display</vh></v>
<v t="ekr.20250131013601.294"><vh>BaseReporter.display_messages</vh></v>
<v t="ekr.20250131013601.295"><vh>BaseReporter.on_set_current_module</vh></v>
<v t="ekr.20250131013601.296"><vh>BaseReporter.on_close</vh></v>
</v>
</v>
<v t="ekr.20250131013601.297"><vh>@clean collecting_reporter.py</vh>
<v t="ekr.20250131013601.298"><vh>class CollectingReporter</vh>
<v t="ekr.20250131013601.299"><vh>CollectingReporter.__init__</vh></v>
<v t="ekr.20250131013601.300"><vh>CollectingReporter.reset</vh></v>
<v t="ekr.20250131013601.301"><vh>CollectingReporter._display</vh></v>
</v>
</v>
<v t="ekr.20250131013601.302"><vh>@clean json_reporter.py</vh>
<v t="ekr.20250131013601.303"><vh>class JSONReporter</vh>
<v t="ekr.20250131013601.307"><vh>JSONReporter.display_messages</vh></v>
<v t="ekr.20250131013601.308"><vh>JSONReporter.display_reports</vh></v>
<v t="ekr.20250131013601.309"><vh>JSONReporter._display</vh></v>
<v t="ekr.20250131013601.310"><vh>JSONReporter.serialize</vh></v>
<v t="ekr.20250131013601.311"><vh>JSONReporter.deserialize</vh></v>
</v>
<v t="ekr.20250131013601.304"><vh>class JSONMessage</vh></v>
<v t="ekr.20250131013601.305"><vh>class JSON2Reporter</vh>
<v t="ekr.20250131013601.312"><vh>JSON2Reporter.display_reports</vh></v>
<v t="ekr.20250131013601.313"><vh>JSON2Reporter._display</vh></v>
<v t="ekr.20250131013601.314"><vh>JSON2Reporter.display_messages</vh></v>
<v t="ekr.20250131013601.315"><vh>JSON2Reporter.serialize</vh></v>
<v t="ekr.20250131013601.316"><vh>JSON2Reporter.deserialize</vh></v>
<v t="ekr.20250131013601.317"><vh>JSON2Reporter.serialize_stats</vh></v>
</v>
<v t="ekr.20250131013601.306"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013601.318"><vh>@clean multi_reporter.py</vh>
<v t="ekr.20250131013601.319"><vh>class MultiReporter</vh>
<v t="ekr.20250131013601.320"><vh>MultiReporter.__init__</vh></v>
<v t="ekr.20250131013601.321"><vh>MultiReporter.out</vh></v>
<v t="ekr.20250131013601.322"><vh>MultiReporter.out</vh></v>
<v t="ekr.20250131013601.323"><vh>MultiReporter.__del__</vh></v>
<v t="ekr.20250131013601.324"><vh>MultiReporter.path_strip_prefix</vh></v>
<v t="ekr.20250131013601.325"><vh>MultiReporter.linter</vh></v>
<v t="ekr.20250131013601.326"><vh>MultiReporter.linter</vh></v>
<v t="ekr.20250131013601.327"><vh>MultiReporter.handle_message</vh></v>
<v t="ekr.20250131013601.328"><vh>MultiReporter.writeln</vh></v>
<v t="ekr.20250131013601.329"><vh>MultiReporter.display_reports</vh></v>
<v t="ekr.20250131013601.330"><vh>MultiReporter.display_messages</vh></v>
<v t="ekr.20250131013601.331"><vh>MultiReporter.on_set_current_module</vh></v>
<v t="ekr.20250131013601.332"><vh>MultiReporter.on_close</vh></v>
</v>
</v>
<v t="ekr.20250131013601.333"><vh>@clean progress_reporters.py</vh>
<v t="ekr.20250131013601.334"><vh>class ProgressReporter</vh>
<v t="ekr.20250131013601.335"><vh>ProgressReporter.__init__</vh></v>
<v t="ekr.20250131013601.336"><vh>ProgressReporter.start_get_asts</vh></v>
<v t="ekr.20250131013601.337"><vh>ProgressReporter.get_ast_for_file</vh></v>
<v t="ekr.20250131013601.338"><vh>ProgressReporter.start_linting</vh></v>
<v t="ekr.20250131013601.339"><vh>ProgressReporter.lint_file</vh></v>
<v t="ekr.20250131013601.340"><vh>ProgressReporter._print_message</vh></v>
</v>
</v>
<v t="ekr.20250131013601.341"><vh>@clean reports_handler_mix_in.py</vh>
<v t="ekr.20250131013601.342"><vh>class ReportsHandlerMixIn</vh>
<v t="ekr.20250131013601.343"><vh>ReportsHandlerMixIn.__init__</vh></v>
<v t="ekr.20250131013601.344"><vh>ReportsHandlerMixIn.report_order</vh></v>
<v t="ekr.20250131013601.345"><vh>ReportsHandlerMixIn.register_report</vh></v>
<v t="ekr.20250131013601.346"><vh>ReportsHandlerMixIn.enable_report</vh></v>
<v t="ekr.20250131013601.347"><vh>ReportsHandlerMixIn.disable_report</vh></v>
<v t="ekr.20250131013601.348"><vh>ReportsHandlerMixIn.report_is_enabled</vh></v>
<v t="ekr.20250131013601.349"><vh>ReportsHandlerMixIn.make_reports</vh></v>
</v>
</v>
<v t="ekr.20250131013601.350"><vh>@clean text.py</vh>
<v t="ekr.20250131013601.351"><vh>class MessageStyle</vh>
<v t="ekr.20250131013601.361"><vh>MessageStyle.__get_ansi_code</vh></v>
<v t="ekr.20250131013601.362"><vh>MessageStyle._colorize_ansi</vh></v>
</v>
<v t="ekr.20250131013601.352"><vh>function: colorize_ansi</vh></v>
<v t="ekr.20250131013601.353"><vh>function: make_header</vh></v>
<v t="ekr.20250131013601.354"><vh>class TextReporter</vh>
<v t="ekr.20250131013601.363"><vh>TextReporter.__init__</vh></v>
<v t="ekr.20250131013601.364"><vh>TextReporter.on_set_current_module</vh></v>
<v t="ekr.20250131013601.365"><vh>TextReporter.write_message</vh></v>
<v t="ekr.20250131013601.366"><vh>TextReporter.handle_message</vh></v>
<v t="ekr.20250131013601.367"><vh>TextReporter._display</vh></v>
</v>
<v t="ekr.20250131013601.355"><vh>class NoHeaderReporter</vh>
<v t="ekr.20250131013601.368"><vh>NoHeaderReporter.handle_message</vh></v>
</v>
<v t="ekr.20250131013601.356"><vh>class ParseableTextReporter</vh>
<v t="ekr.20250131013601.369"><vh>ParseableTextReporter.__init__</vh></v>
</v>
<v t="ekr.20250131013601.357"><vh>class VSTextReporter</vh></v>
<v t="ekr.20250131013601.358"><vh>class ColorizedTextReporter</vh>
<v t="ekr.20250131013601.370"><vh>ColorizedTextReporter.__init__</vh></v>
<v t="ekr.20250131013601.371"><vh>ColorizedTextReporter._get_decoration</vh></v>
<v t="ekr.20250131013601.372"><vh>ColorizedTextReporter.handle_message</vh></v>
</v>
<v t="ekr.20250131013601.359"><vh>class GithubReporter</vh>
<v t="ekr.20250131013601.373"><vh>GithubReporter.write_message</vh></v>
</v>
<v t="ekr.20250131013601.360"><vh>function: register</vh></v>
</v>
<v t="ekr.20250131013601.374"><vh>path: pylint/reporters/ureports</vh>
<v t="ekr.20250131013601.375"><vh>@clean __init__.py</vh></v>
<v t="ekr.20250131013601.376"><vh>@clean base_writer.py</vh>
<v t="ekr.20250131013601.377"><vh>class BaseWriter</vh>
<v t="ekr.20250131013601.378"><vh>BaseWriter.format</vh></v>
<v t="ekr.20250131013601.379"><vh>BaseWriter.format_children</vh></v>
<v t="ekr.20250131013601.380"><vh>BaseWriter.writeln</vh></v>
<v t="ekr.20250131013601.381"><vh>BaseWriter.write</vh></v>
<v t="ekr.20250131013601.382"><vh>BaseWriter.begin_format</vh></v>
<v t="ekr.20250131013601.383"><vh>BaseWriter.end_format</vh></v>
<v t="ekr.20250131013601.384"><vh>BaseWriter.get_table_content</vh></v>
<v t="ekr.20250131013601.385"><vh>BaseWriter.compute_content</vh></v>
</v>
</v>
<v t="ekr.20250131013601.386"><vh>@clean nodes.py</vh>
<v t="ekr.20250131013601.387"><vh>class VNode</vh>
<v t="ekr.20250131013601.396"><vh>VNode.__init__</vh></v>
<v t="ekr.20250131013601.397"><vh>VNode.__iter__</vh></v>
<v t="ekr.20250131013601.398"><vh>VNode.accept</vh></v>
<v t="ekr.20250131013601.399"><vh>VNode.leave</vh></v>
</v>
<v t="ekr.20250131013601.388"><vh>class BaseLayout</vh>
<v t="ekr.20250131013601.400"><vh>BaseLayout.__init__</vh></v>
<v t="ekr.20250131013601.401"><vh>BaseLayout.append</vh></v>
<v t="ekr.20250131013601.402"><vh>BaseLayout.insert</vh></v>
<v t="ekr.20250131013601.403"><vh>BaseLayout.parents</vh></v>
<v t="ekr.20250131013601.404"><vh>BaseLayout.add_text</vh></v>
</v>
<v t="ekr.20250131013601.389"><vh>class Text</vh>
<v t="ekr.20250131013601.405"><vh>Text.__init__</vh></v>
</v>
<v t="ekr.20250131013601.390"><vh>class VerbatimText</vh></v>
<v t="ekr.20250131013601.391"><vh>class Section</vh>
<v t="ekr.20250131013601.406"><vh>Section.__init__</vh></v>
</v>
<v t="ekr.20250131013601.392"><vh>class EvaluationSection</vh>
<v t="ekr.20250131013601.407"><vh>EvaluationSection.__init__</vh></v>
</v>
<v t="ekr.20250131013601.393"><vh>class Title</vh></v>
<v t="ekr.20250131013601.394"><vh>class Paragraph</vh></v>
<v t="ekr.20250131013601.395"><vh>class Table</vh>
<v t="ekr.20250131013601.408"><vh>Table.__init__</vh></v>
</v>
</v>
<v t="ekr.20250131013601.409"><vh>@clean text_writer.py</vh>
<v t="ekr.20250131013601.410"><vh>class TextWriter</vh>
<v t="ekr.20250131013601.411"><vh>TextWriter.__init__</vh></v>
<v t="ekr.20250131013601.412"><vh>TextWriter.visit_section</vh></v>
<v t="ekr.20250131013601.413"><vh>TextWriter.visit_evaluationsection</vh></v>
<v t="ekr.20250131013601.414"><vh>TextWriter.visit_title</vh></v>
<v t="ekr.20250131013601.415"><vh>TextWriter.visit_paragraph</vh></v>
<v t="ekr.20250131013601.416"><vh>TextWriter.visit_table</vh></v>
<v t="ekr.20250131013601.417"><vh>TextWriter.default_table</vh></v>
<v t="ekr.20250131013601.418"><vh>TextWriter.visit_verbatimtext</vh></v>
<v t="ekr.20250131013601.419"><vh>TextWriter.visit_text</vh></v>
</v>
</v>
</v>
</v>
<v t="ekr.20250131013601.420"><vh>path: pylint/testutils</vh>
<v t="ekr.20250131013601.421"><vh>@clean __init__.py</vh></v>
<v t="ekr.20250131013601.422"><vh>@clean _run.py</vh>
<v t="ekr.20250131013601.423"><vh>function: _add_rcfile_default_pylintrc</vh></v>
<v t="ekr.20250131013601.424"><vh>class _Run</vh>
<v t="ekr.20250131013601.425"><vh>_Run.__init__</vh></v>
</v>
</v>
<v t="ekr.20250131013601.426"><vh>@clean checker_test_case.py</vh>
<v t="ekr.20250131013601.427"><vh>class CheckerTestCase</vh>
<v t="ekr.20250131013601.428"><vh>CheckerTestCase.setup_method</vh></v>
<v t="ekr.20250131013601.429"><vh>CheckerTestCase.assertNoMessages</vh></v>
<v t="ekr.20250131013601.430"><vh>CheckerTestCase.assertAddsMessages</vh></v>
<v t="ekr.20250131013601.431"><vh>CheckerTestCase.walk</vh></v>
</v>
</v>
<v t="ekr.20250131013601.432"><vh>@clean configuration_test.py</vh>
<v t="ekr.20250131013601.433"><vh>function: get_expected_or_default</vh></v>
<v t="ekr.20250131013601.434"><vh>function: get_expected_configuration</vh></v>
<v t="ekr.20250131013601.435"><vh>function: get_related_files</vh></v>
<v t="ekr.20250131013601.436"><vh>function: get_expected_output</vh></v>
<v t="ekr.20250131013601.437"><vh>function: run_using_a_configuration_file</vh></v>
</v>
<v t="ekr.20250131013601.438"><vh>@clean constants.py</vh></v>
<v t="ekr.20250131013601.439"><vh>@clean decorator.py</vh>
<v t="ekr.20250131013601.440"><vh>function: set_config</vh></v>
</v>
<v t="ekr.20250131013601.441"><vh>@clean get_test_info.py</vh>
<v t="ekr.20250131013601.442"><vh>function: _get_tests_info</vh></v>
</v>
<v t="ekr.20250131013601.443"><vh>@clean global_test_linter.py</vh>
<v t="ekr.20250131013601.444"><vh>function: create_test_linter</vh></v>
</v>
<v t="ekr.20250131013601.445"><vh>@clean lint_module_test.py</vh>
<v t="ekr.20250131013601.446"><vh>class LintModuleTest</vh>
<v t="ekr.20250131013601.447"><vh>LintModuleTest.__init__</vh></v>
<v t="ekr.20250131013601.448"><vh>LintModuleTest.setUp</vh></v>
<v t="ekr.20250131013601.449"><vh>LintModuleTest.runTest</vh></v>
<v t="ekr.20250131013601.450"><vh>LintModuleTest._should_be_skipped_due_to_version</vh></v>
<v t="ekr.20250131013601.451"><vh>LintModuleTest.__str__</vh></v>
<v t="ekr.20250131013601.452"><vh>LintModuleTest.get_expected_messages</vh></v>
<v t="ekr.20250131013601.453"><vh>LintModuleTest.multiset_difference</vh></v>
<v t="ekr.20250131013601.454"><vh>LintModuleTest._open_expected_file</vh></v>
<v t="ekr.20250131013601.455"><vh>LintModuleTest._open_source_file</vh></v>
<v t="ekr.20250131013601.456"><vh>LintModuleTest._get_expected</vh></v>
<v t="ekr.20250131013601.457"><vh>LintModuleTest._get_actual</vh></v>
<v t="ekr.20250131013601.458"><vh>LintModuleTest._runTest</vh></v>
<v t="ekr.20250131013601.459"><vh>LintModuleTest.error_msg_for_unequal_messages</vh></v>
<v t="ekr.20250131013601.460"><vh>LintModuleTest.error_msg_for_unequal_output</vh></v>
<v t="ekr.20250131013601.461"><vh>LintModuleTest._check_output_text</vh></v>
</v>
</v>
<v t="ekr.20250131013601.462"><vh>@clean output_line.py</vh>
<v t="ekr.20250131013601.463"><vh>class MessageTest</vh></v>
<v t="ekr.20250131013601.464"><vh>class OutputLine</vh>
<v t="ekr.20250131013601.465"><vh>OutputLine.from_msg</vh></v>
<v t="ekr.20250131013601.466"><vh>OutputLine._get_column</vh></v>
<v t="ekr.20250131013601.467"><vh>OutputLine._get_end_line_and_end_col</vh></v>
<v t="ekr.20250131013601.468"><vh>OutputLine.from_csv</vh></v>
<v t="ekr.20250131013601.469"><vh>OutputLine.to_csv</vh></v>
<v t="ekr.20250131013601.470"><vh>OutputLine._value_to_optional_int</vh></v>
</v>
</v>
<v t="ekr.20250131013601.471"><vh>@clean pyreverse.py</vh>
<v t="ekr.20250131013601.472"><vh>class PyreverseConfig</vh></v>
<v t="ekr.20250131013601.473"><vh>function: __init__</vh></v>
<v t="ekr.20250131013601.474"><vh>class TestFileOptions</vh></v>
<v t="ekr.20250131013601.475"><vh>class FunctionalPyreverseTestfile</vh></v>
<v t="ekr.20250131013601.476"><vh>function: get_functional_test_files</vh></v>
<v t="ekr.20250131013601.477"><vh>function: _read_config</vh></v>
</v>
<v t="ekr.20250131013601.478"><vh>@clean reporter_for_tests.py</vh>
<v t="ekr.20250131013601.479"><vh>class GenericTestReporter</vh>
<v t="ekr.20250131013601.482"><vh>GenericTestReporter.__init__</vh></v>
<v t="ekr.20250131013601.483"><vh>GenericTestReporter.reset</vh></v>
<v t="ekr.20250131013601.484"><vh>GenericTestReporter.handle_message</vh></v>
<v t="ekr.20250131013601.485"><vh>GenericTestReporter.finalize</vh></v>
<v t="ekr.20250131013601.486"><vh>GenericTestReporter.on_set_current_module</vh></v>
<v t="ekr.20250131013601.487"><vh>GenericTestReporter.display_reports</vh></v>
<v t="ekr.20250131013601.488"><vh>GenericTestReporter._display</vh></v>
</v>
<v t="ekr.20250131013601.480"><vh>class MinimalTestReporter</vh>
<v t="ekr.20250131013601.489"><vh>MinimalTestReporter.on_set_current_module</vh></v>
<v t="ekr.20250131013601.490"><vh>MinimalTestReporter._display</vh></v>
</v>
<v t="ekr.20250131013601.481"><vh>class FunctionalTestReporter</vh>
<v t="ekr.20250131013601.491"><vh>FunctionalTestReporter.display_reports</vh></v>
<v t="ekr.20250131013601.492"><vh>FunctionalTestReporter._display</vh></v>
</v>
</v>
<v t="ekr.20250131013601.493"><vh>@clean tokenize_str.py</vh>
<v t="ekr.20250131013601.494"><vh>function: _tokenize_str</vh></v>
</v>
<v t="ekr.20250131013601.495"><vh>@clean unittest_linter.py</vh>
<v t="ekr.20250131013601.496"><vh>class UnittestLinter</vh>
<v t="ekr.20250131013601.497"><vh>UnittestLinter.__init__</vh></v>
<v t="ekr.20250131013601.498"><vh>UnittestLinter.release_messages</vh></v>
<v t="ekr.20250131013601.499"><vh>UnittestLinter.add_message</vh></v>
<v t="ekr.20250131013601.500"><vh>UnittestLinter.is_message_enabled</vh></v>
</v>
</v>
<v t="ekr.20250131013601.501"><vh>@clean utils.py</vh>
<v t="ekr.20250131013601.502"><vh>function: _patch_streams</vh></v>
<v t="ekr.20250131013601.503"><vh>function: _test_sys_path</vh></v>
<v t="ekr.20250131013601.504"><vh>function: _test_cwd</vh></v>
<v t="ekr.20250131013601.505"><vh>function: _test_environ_pythonpath</vh></v>
<v t="ekr.20250131013601.506"><vh>function: create_files</vh></v>
</v>
<v t="ekr.20250131013601.507"><vh>path: pylint/testutils/_primer</vh>
<v t="ekr.20250131013601.508"><vh>@clean __init__.py</vh></v>
<v t="ekr.20250131013601.509"><vh>@clean package_to_lint.py</vh>
<v t="ekr.20250131013601.510"><vh>class DirtyPrimerDirectoryException</vh>
<v t="ekr.20250131013601.512"><vh>DirtyPrimerDirectoryException.__init__</vh></v>
</v>
<v t="ekr.20250131013601.511"><vh>class PackageToLint</vh>
<v t="ekr.20250131013601.513"><vh>PackageToLint.__init__</vh></v>
<v t="ekr.20250131013601.514"><vh>PackageToLint.pylintrc</vh></v>
<v t="ekr.20250131013601.515"><vh>PackageToLint.clone_directory</vh></v>
<v t="ekr.20250131013601.516"><vh>PackageToLint.paths_to_lint</vh></v>
<v t="ekr.20250131013601.517"><vh>PackageToLint.pylint_args</vh></v>
<v t="ekr.20250131013601.518"><vh>PackageToLint.lazy_clone</vh></v>
<v t="ekr.20250131013601.519"><vh>PackageToLint._clone_repository</vh></v>
<v t="ekr.20250131013601.520"><vh>PackageToLint._pull_repository</vh></v>
</v>
</v>
<v t="ekr.20250131013601.521"><vh>@clean primer.py</vh>
<v t="ekr.20250131013601.522"><vh>class Primer</vh>
<v t="ekr.20250131013601.523"><vh>Primer.__init__</vh></v>
<v t="ekr.20250131013601.524"><vh>Primer.run</vh></v>
<v t="ekr.20250131013601.525"><vh>Primer._minimum_python_supported</vh></v>
<v t="ekr.20250131013601.526"><vh>Primer._get_packages_to_lint_from_json</vh></v>
</v>
</v>
<v t="ekr.20250131013601.527"><vh>@clean primer_command.py</vh>
<v t="ekr.20250131013601.528"><vh>class PackageData</vh></v>
<v t="ekr.20250131013601.529"><vh>class PrimerCommand</vh>
<v t="ekr.20250131013601.530"><vh>PrimerCommand.__init__</vh></v>
<v t="ekr.20250131013601.531"><vh>PrimerCommand.run</vh></v>
</v>
</v>
<v t="ekr.20250131013601.532"><vh>@clean primer_compare_command.py</vh>
<v t="ekr.20250131013601.533"><vh>class CompareCommand</vh>
<v t="ekr.20250131013601.534"><vh>CompareCommand.run</vh></v>
<v t="ekr.20250131013601.535"><vh>CompareCommand._cross_reference</vh></v>
<v t="ekr.20250131013601.536"><vh>CompareCommand._load_json</vh></v>
<v t="ekr.20250131013601.537"><vh>CompareCommand._create_comment</vh></v>
<v t="ekr.20250131013601.538"><vh>CompareCommand._create_comment_for_package</vh></v>
<v t="ekr.20250131013601.539"><vh>CompareCommand._truncate_comment</vh></v>
</v>
</v>
<v t="ekr.20250131013601.540"><vh>@clean primer_prepare_command.py</vh>
<v t="ekr.20250131013601.541"><vh>class PrepareCommand</vh>
<v t="ekr.20250131013601.542"><vh>PrepareCommand.run</vh></v>
</v>
</v>
<v t="ekr.20250131013601.543"><vh>@clean primer_run_command.py</vh>
<v t="ekr.20250131013601.544"><vh>class RunCommand</vh>
<v t="ekr.20250131013601.545"><vh>RunCommand.run</vh></v>
<v t="ekr.20250131013601.546"><vh>RunCommand._filter_fatal_errors</vh></v>
<v t="ekr.20250131013601.547"><vh>RunCommand._print_msgs</vh></v>
<v t="ekr.20250131013601.548"><vh>RunCommand._lint_package</vh></v>
</v>
</v>
</v>
<v t="ekr.20250131013601.549"><vh>path: pylint/testutils/functional</vh>
<v t="ekr.20250131013601.550"><vh>@clean __init__.py</vh></v>
<v t="ekr.20250131013601.551"><vh>@clean find_functional_tests.py</vh>
<v t="ekr.20250131013601.552"><vh>function: get_functional_test_files_from_directory</vh></v>
<v t="ekr.20250131013601.553"><vh>function: _check_functional_tests_structure</vh></v>
</v>
<v t="ekr.20250131013601.554"><vh>@clean lint_module_output_update.py</vh>
<v t="ekr.20250131013601.555"><vh>class LintModuleOutputUpdate</vh>
<v t="ekr.20250131013601.556"><vh>class TestDialect</vh></v>
<v t="ekr.20250131013601.557"><vh>LintModuleOutputUpdate._check_output_text</vh></v>
</v>
</v>
<v t="ekr.20250131013601.558"><vh>@clean test_file.py</vh>
<v t="ekr.20250131013601.559"><vh>function: parse_python_version</vh></v>
<v t="ekr.20250131013601.560"><vh>class NoFileError</vh></v>
<v t="ekr.20250131013601.561"><vh>class TestFileOptions</vh></v>
<v t="ekr.20250131013601.562"><vh>class FunctionalTestFile</vh>
<v t="ekr.20250131013601.563"><vh>FunctionalTestFile.__init__</vh></v>
<v t="ekr.20250131013601.564"><vh>FunctionalTestFile.__repr__</vh></v>
<v t="ekr.20250131013601.565"><vh>FunctionalTestFile._parse_options</vh></v>
<v t="ekr.20250131013601.566"><vh>FunctionalTestFile.option_file</vh></v>
<v t="ekr.20250131013601.567"><vh>FunctionalTestFile.module</vh></v>
<v t="ekr.20250131013601.568"><vh>FunctionalTestFile.expected_output</vh></v>
<v t="ekr.20250131013601.569"><vh>FunctionalTestFile.source</vh></v>
<v t="ekr.20250131013601.570"><vh>FunctionalTestFile._file_type</vh></v>
</v>
</v>
</v>
</v>
<v t="ekr.20250131013601.571"><vh>path: pylint/utils</vh>
<v t="ekr.20250131013601.572"><vh>@clean __init__.py</vh></v>
<v t="ekr.20250131013601.573"><vh>@clean ast_walker.py</vh>
<v t="ekr.20250131013601.574"><vh>class ASTWalker</vh>
<v t="ekr.20250131013601.575"><vh>ASTWalker.__init__</vh></v>
<v t="ekr.20250131013601.576"><vh>ASTWalker._is_method_enabled</vh></v>
<v t="ekr.20250131013601.577"><vh>ASTWalker.add_checker</vh></v>
<v t="ekr.20250131013601.578"><vh>ASTWalker.walk</vh></v>
</v>
</v>
<v t="ekr.20250131013601.579"><vh>@clean docs.py</vh>
<v t="ekr.20250131013601.580"><vh>function: _get_checkers_infos</vh></v>
<v t="ekr.20250131013601.581"><vh>function: _get_global_options_documentation</vh></v>
<v t="ekr.20250131013601.582"><vh>function: _get_checkers_documentation</vh></v>
<v t="ekr.20250131013601.583"><vh>function: print_full_documentation</vh></v>
</v>
<v t="ekr.20250131013601.584"><vh>@clean file_state.py</vh>
<v t="ekr.20250131013601.585"><vh>class FileState</vh>
<v t="ekr.20250131013601.586"><vh>FileState.__init__</vh></v>
<v t="ekr.20250131013601.587"><vh>FileState._set_state_on_block_lines</vh></v>
<v t="ekr.20250131013601.588"><vh>FileState._set_message_state_in_block</vh></v>
<v t="ekr.20250131013601.589"><vh>FileState._set_message_state_on_line</vh></v>
<v t="ekr.20250131013601.590"><vh>FileState.set_msg_status</vh></v>
<v t="ekr.20250131013601.591"><vh>FileState.handle_ignored_message</vh></v>
<v t="ekr.20250131013601.592"><vh>FileState.iter_spurious_suppression_messages</vh></v>
<v t="ekr.20250131013601.593"><vh>FileState.get_effective_max_line_number</vh></v>
</v>
</v>
<v t="ekr.20250131013601.594"><vh>@clean linterstats.py</vh>
<v t="ekr.20250131013601.595"><vh>class BadNames</vh></v>
<v t="ekr.20250131013601.596"><vh>class CodeTypeCount</vh></v>
<v t="ekr.20250131013601.597"><vh>class DuplicatedLines</vh></v>
<v t="ekr.20250131013601.598"><vh>class NodeCount</vh></v>
<v t="ekr.20250131013601.599"><vh>class UndocumentedNodes</vh></v>
<v t="ekr.20250131013601.600"><vh>class ModuleStats</vh></v>
<v t="ekr.20250131013601.601"><vh>class LinterStats</vh>
<v t="ekr.20250131013601.603"><vh>LinterStats.__init__</vh></v>
<v t="ekr.20250131013601.604"><vh>LinterStats.__repr__</vh></v>
<v t="ekr.20250131013601.605"><vh>LinterStats.__str__</vh></v>
<v t="ekr.20250131013601.606"><vh>LinterStats.init_single_module</vh></v>
<v t="ekr.20250131013601.607"><vh>LinterStats.get_bad_names</vh></v>
<v t="ekr.20250131013601.608"><vh>LinterStats.increase_bad_name</vh></v>
<v t="ekr.20250131013601.609"><vh>LinterStats.reset_bad_names</vh></v>
<v t="ekr.20250131013601.610"><vh>LinterStats.get_code_count</vh></v>
<v t="ekr.20250131013601.611"><vh>LinterStats.reset_code_count</vh></v>
<v t="ekr.20250131013601.612"><vh>LinterStats.reset_duplicated_lines</vh></v>
<v t="ekr.20250131013601.613"><vh>LinterStats.get_node_count</vh></v>
<v t="ekr.20250131013601.614"><vh>LinterStats.reset_node_count</vh></v>
<v t="ekr.20250131013601.615"><vh>LinterStats.get_undocumented</vh></v>
<v t="ekr.20250131013601.616"><vh>LinterStats.reset_undocumented</vh></v>
<v t="ekr.20250131013601.617"><vh>LinterStats.get_global_message_count</vh></v>
<v t="ekr.20250131013601.618"><vh>LinterStats.get_module_message_count</vh></v>
<v t="ekr.20250131013601.619"><vh>LinterStats.increase_single_message_count</vh></v>
<v t="ekr.20250131013601.620"><vh>LinterStats.increase_single_module_message_count</vh></v>
<v t="ekr.20250131013601.621"><vh>LinterStats.reset_message_count</vh></v>
</v>
<v t="ekr.20250131013601.602"><vh>function: merge_stats</vh></v>
</v>
<v t="ekr.20250131013601.622"><vh>@clean pragma_parser.py</vh>
<v t="ekr.20250131013601.623"><vh>class PragmaRepresenter</vh></v>
<v t="ekr.20250131013601.624"><vh>function: emit_pragma_representer</vh></v>
<v t="ekr.20250131013601.625"><vh>class PragmaParserError</vh>
<v t="ekr.20250131013601.629"><vh>PragmaParserError.__init__</vh></v>
</v>
<v t="ekr.20250131013601.626"><vh>class UnRecognizedOptionError</vh></v>
<v t="ekr.20250131013601.627"><vh>class InvalidPragmaError</vh></v>
<v t="ekr.20250131013601.628"><vh>function: parse_pragma</vh></v>
</v>
<v t="ekr.20250131013601.630"><vh>@clean utils.py</vh>
<v t="ekr.20250131013601.631"><vh>function: normalize_text</vh></v>
<v t="ekr.20250131013601.632"><vh>function: cmp</vh></v>
<v t="ekr.20250131013601.633"><vh>function: diff_string</vh></v>
<v t="ekr.20250131013601.634"><vh>function: get_module_and_frameid</vh></v>
<v t="ekr.20250131013601.635"><vh>function: get_rst_title</vh></v>
<v t="ekr.20250131013601.636"><vh>function: get_rst_section</vh></v>
<v t="ekr.20250131013601.637"><vh>function: decoding_stream</vh></v>
<v t="ekr.20250131013601.638"><vh>function: tokenize_module</vh></v>
<v t="ekr.20250131013601.639"><vh>function: register_plugins</vh></v>
<v t="ekr.20250131013601.640"><vh>function: _splitstrip</vh></v>
<v t="ekr.20250131013601.641"><vh>function: _unquote</vh></v>
<v t="ekr.20250131013601.642"><vh>function: _check_csv</vh></v>
<v t="ekr.20250131013601.643"><vh>function: _check_regexp_csv</vh></v>
<v t="ekr.20250131013601.644"><vh>function: _comment</vh></v>
<v t="ekr.20250131013601.645"><vh>function: _format_option_value</vh></v>
<v t="ekr.20250131013601.646"><vh>function: format_section</vh></v>
<v t="ekr.20250131013601.647"><vh>function: _ini_format</vh></v>
<v t="ekr.20250131013601.648"><vh>class IsortDriver</vh>
<v t="ekr.20250131013601.649"><vh>IsortDriver.__init__</vh></v>
<v t="ekr.20250131013601.650"><vh>IsortDriver.place_module</vh></v>
</v>
</v>
</v>
</v>
</vnodes>
<tnodes>
<t tx="ekr.20131030071311.17125">By convention, a Startup node contains settings, scripts, etc.
that mostly one wants to have hidden.
</t>
<t tx="ekr.20250131013029.1" __bookmarks="7d7100580700000069735f6475706571014930300a732e">@language rest
@wrap

The @settings tree contains all active settings. 

Settings outside this tree have no effect.</t>
<t tx="ekr.20250131013029.10"># legacy: (default) Leo's legacy layout
# big-tree: replaces @bool big-outline-pane
# horizontal-thirds: VR &amp; VR3 panes at bottom.</t>
<t tx="ekr.20250131013029.11">@language python
</t>
<t tx="ekr.20250131013029.12">print(c.p.numberOfChildren())</t>
<t tx="ekr.20250131013029.13">print(p.gnx)</t>
<t tx="ekr.20250131013029.14">d = {
'annotate': {'priority': 2, 'prisetdate': '2017-10-22'}
   'icons': [{'yoffset': 0,
              'where': 'beforeHeadline',
              'file': 'C:\\leo.repo\\leo-editor\\leo\\Icons\\cleo\\pri2.png',
              'type': 'file',
              'xoffset': 2,
              'relPath': 'cleo\\pri2.png',
              'on': 'vnode',
              'xpad': 1,
              'cleoIcon': '1'}]
}

g.printDict(p.u)
</t>
<t tx="ekr.20250131013029.15">@language python

"""Take a screenshot and save it in ~/.leo"""

g.app.pluginsController.loadOnePlugin('leo.plugins.screenshots', verbose=True)

c.k.simulateCommand('take-global-screen-shot')
</t>
<t tx="ekr.20250131013029.16">print('@command test')</t>
<t tx="ekr.20250131013029.17">"""
Back up this .leo file.

os.environ['LEO_BACKUP'] must be the path to an existing (writable) directory.
"""
c.backup_helper(sub_dir='ekr-study')
</t>
<t tx="ekr.20250131013029.18"></t>
<t tx="ekr.20250131013029.19" __bookmarks="7d7100580700000069735f6475706571014930300a732e">'''A prototype of running adoc and asciidoctor.'''
import os
p = g.findNodeAnywhere(c, r'@adoc ad_test.adoc')
assert p
paths = c.asciiDoctorCommands.adoc_command(event=g.Bunch(p=p),verbose=False)
paths = [os.path.abspath(os.path.normpath(z)) for z in paths]
input_paths = ' '.join(paths)
g.execute_shell_commands(['asciidoctor %s' % input_paths])
output_paths = ' '.join([z.replace('.adoc', '.html') for z in paths])
for path in paths:
    print(f"wrote: {path}\n")
if 0:
    # optional: open .html files in the default browser.
    g.execute_shell_commands([output_paths])
</t>
<t tx="ekr.20250131013029.2"></t>
<t tx="ekr.20250131013029.20">'''(ekr.leo) Clean newlines from EKR text.'''
s = p.b.replace('\n\n','\nPARA\n')
s = s.replace('\n',' ')
s = s.replace(' PARA ','\n\n')
s = s.replace('  ',' ')
p.b = s
</t>
<t tx="ekr.20250131013029.21">g.cls()

print('===== Start =====')

class CreateDecorators:
    '''
    A class to create decorators from tables in getPublicCommands.
    
    Note: the node "Found: getPublicCommands" must exist.
    '''
    def __init__(self,c,make_changes):
        self.c = c
        self.fixups = self.create_fixups()
        self.n = 0
        self.n_fail = 0
        self.make_changes=make_changes
        self.suppress = [
            'c.frame.body and c.frame.body.addEditor',
            'cls','cloneFindParents','cycleTabFocus',
            'k and k.keyboardQuit',
            'menuShortcutPlaceHolder','removeBlankLines',
            'saveBuffersKillLeo',
        ]
    @others

CreateDecorators(c,make_changes=False).run()
</t>
<t tx="ekr.20250131013029.22">def create_d(self,lines,publicCommands):
    '''Create a dict. keys are method names; values are command names.'''
    trace = False
    if trace:
        print('')
        g.trace(publicCommands.h)
    d = {}
    for s in lines:
        aList = s.split()
        if len(aList) &gt; 2:
            aList = [aList[0],' '.join(aList[1:])]
        c_name,f_name = aList[0].strip(),aList[1].strip()
        if ' ' not in f_name:
            f_name = f_name.split('.')[-1]
        # if '(' in f_name:
            # f_name = f_name[:f_name.find('(')]
        if trace: g.trace('%45s %s' % (c_name,f_name))
        d [f_name] = c_name
    return d
</t>
<t tx="ekr.20250131013029.23">def create_decorator(self,c_name,f_name,root):
    '''
    Search root for a definition of f_name.
    If found, insert @cmd(f_name) before the definition.
    '''
    # g.trace('%45s %s' % (c_name,f_name))
    trace = False
    found = False
    decorator = "@cmd('%s')\n" % (c_name)
    for p in root.self_and_subtree():
        changed,result = False,[]
        for s in g.splitLines(p.b):
            if g.match_word(s,0,'def ' + f_name):
                if found:
                    if f_name not in self.suppress:
                        g.trace('duplicate def',f_name)
                else:
                    changed,found = True,True
                    result.append(decorator)
                    # print('%s%s' % (decorator,s))
            result.append(s)
        # if changed and self.make_changes:
            # new_body = ''.join(result)
            # # use git as our undo :-)
            # p.b = new_body
    return found
</t>
<t tx="ekr.20250131013029.24">def create_decorators(self,d,root):
    '''Create decorators for all items in d in root's tree.'''
    # print('***** %s' % root.h)
    if root.h in self.fixups:
        roots = []
        aList = self.fixups.get(root.h)
        for root2_h in aList:
            root2 = g.findNodeAnywhere(self.c,root2_h)
            if root2:
                # g.trace(root.h,'=====&gt;',root2.h)
                roots.append(root2)
            else:
                g.trace('===== not found',root2_h)
    else:
        roots = [root]
    for f_name in sorted(d.keys()):
        found = False
        for root in roots:
            c_name = d.get(f_name)
            found = self.create_decorator(c_name,f_name,root)
            if found: break
        if not found and f_name not in self.suppress:
            print('===== not found: %30s %s' % (root.h,f_name))
            self.n_fail += 1
</t>
<t tx="ekr.20250131013029.25">def create_fixups(self):
    '''
    Return a fixup dict.
    Keys are headlines for classes.
    Values are new headlines of nodes containing the actual class.
    '''
    return {
        'ChapterCommandsClass': ['class ChapterController'],
        'EditCommandsClass': [
            'EditCommandsClass',
            'class Commands',
            'class LeoQtFrame',
            'class LeoBody',
        ],
        'class SearchCommandsClass': ['class LeoFind (LeoFind.py)'],
        'KeyHandlerCommandsClass (add docstrings)': [
            'class KeyHandlerClass',
            'class AutoCompleterClass',
        ]
    }
</t>
<t tx="ekr.20250131013029.26">def find_class(self,p):
    '''Return the position of the class enclosing p.'''
    for p2 in p.parents():
        if p2.h.lower().find('class') &gt; -1 and p2.b.find('class') &gt; -1:
            return p2
    else:
        g.trace('*** no class for p.h')
        return None
</t>
<t tx="ekr.20250131013029.27">def find_next_clone(self,p):
    v = p.v
    p = p.copy()
    p.moveToThreadNext()
    wrapped = False
    while 1:
        # g.trace(p.v,p.h)
        if p and p.v == v:
            break
        elif p:
            p.moveToThreadNext()
        elif wrapped:
            break
        else:
            wrapped = True
            p = c.rootPosition()
    return p
</t>
<t tx="ekr.20250131013029.28">def munge_lines(self,root,publicCommands):
    '''Return munged lines of '''
    # print('')
    # g.trace(root.h)
    s = publicCommands.b
    i,j = s.find('{'),s.find('}')
    s = s[i+1:j]
    # print(s)
    lines = sorted([z.strip() for z in g.splitLines(s) if z.strip()])
    lines = [z for z in lines if not z.startswith('#')]
    lines = [z[:z.find('#')] if z.find('#') &gt; -1 else z for z in lines]
    lines = [z.rstrip().rstrip(',') for z in lines]
    lines = [z[1:] for z in lines]
    lines = [z.replace("':",' ') for z in lines]
    # print('\n'.join(lines))
    self.n += len(lines)
    return lines
</t>
<t tx="ekr.20250131013029.29">def run(self):
    '''Top-level code.'''
    self.n = 0
    found = g.findNodeAnywhere(c,'Found: getPublicCommands')
    assert found
    for child in found.children():
        publicCommands = self.find_next_clone(child)
        root = self.find_class(publicCommands)
        if root:
            lines = self.munge_lines(root,publicCommands)
            d = self.create_d(lines,publicCommands)
            self.create_decorators(d,root)
    print('\n%s commands %s failed' % (self.n,self.n_fail))
</t>
<t tx="ekr.20250131013029.3"></t>
<t tx="ekr.20250131013029.30">@language python

'''Cycle syntax coloring when there are multiple @langauge directives in a node.'''
# Original by Terry Brown, Revised by EKR.
while not p.isRoot():
    if p.b.strip().startswith("@language "):
        lines = g.splitLines(p.b)
        words = lines[0].split()
        if len(words) &gt; 2 and words[2][0].isalpha():
            # Cycle the languages on line 1.
            line0 = '%s %s %s\n' % (words[0], ' '.join(words[2:]), words[1])
            p.b = line0 + ''.join(lines[1:])
            c.selectVisBack()
            c.selectVisNext()
            break
    p.moveToParent()
else:
    g.es("No ambiguous @language directive found")</t>
<t tx="ekr.20250131013029.31">g.cls()
d = p.v.u
print(p.h)
g.printDict(d)
</t>
<t tx="ekr.20250131013029.32">g.cls()
colorizer = c.frame.body.colorizer
g.printObj(colorizer.stateDict)</t>
<t tx="ekr.20250131013029.33">'''take a selected region,  convert each line to a section reference.'''
# For Eric S. Johansson
current = c.p
body = c.frame.body
u,undoType = c.undoer, 'expand sections'
last = c.lastTopLevel()
wrapper = c.frame.body.wrapper
sel_1, sel_2 = wrapper.getSelectionRange()
ins = wrapper.getInsertPoint()
tab_width = c.getTabWidth(c.p)
head, lines, tail, oldSel, oldYview = c.getBodyLines()
u.beforeChangeGroup(current, undoType)
lines_3 = []
for s in lines:
    start_of_line, width_of_line = g.skip_leading_ws_with_indent(s, 0, c.tab_width)
    new_section_heading = g.angleBrackets('{}')
    l2 = s[start_of_line:].strip()
    header = new_section_heading.format(l2)
    # calculate replacement line for source material
    lines_3.append((" "*start_of_line) + l2 + "\n")
    undo_data = u.beforeInsertNode(current)
    new_node = p.insertAsLastChild()
    new_node.h = header
    new_node.b = "'''\n'''"
    u.afterInsertNode(new_node, 'Insert-Node', undo_data)
        # New
    c.redraw(current) # Selects the old node.
preserveSel = sel_1 == sel_2
if preserveSel:
    ins += tab_width
    oldSel = ins, ins
c.updateBodyPane(head, ''.join(lines_3), tail, undoType, oldSel, oldYview, preserveSel)
u.afterChangeGroup(current, undoType)
</t>
<t tx="ekr.20250131013029.34">"""
Run the Javascripot code in the node selected in the outline.
"""
from subprocess import run
graal = r"C:\apps\graalvm-ce-java11-20.0.0\languages\js\bin\js.exe"
progfile = r"C:\test\grall_input.txt"
s = c.atFileCommands.stringToString(
    p, p.b, forcePythonSentinels=False, sentinels=False)
prog = s.replace("\r\n", "\n")  # Use brute force. 
with open(progfile, 'w') as f:
    f.write(s)
cmd = f'{graal} {progfile}'
result = run(cmd, capture_output=True, text=True, encoding='utf-8')
print(result.stdout or 'no output')
</t>
<t tx="ekr.20250131013029.35">@language python
"""Introspect"""

# By Terry Brown.  Requires Python 2.x.

# https://groups.google.com/forum/#!msg/leo-editor/Qu2HccpC_wc/_ee11jIvAQAJ

import types

sub_mode = 'instance'
# 'instance' or 'class' - controls which, instance or class names,
# are put it a subnode.  'instance class' sub-nodes both.
# '' appends classes after names, not useful.

def classname(thing):
    if hasattr(thing, '__class__'):
        return thing.__class__.__name__
    else:
        return thing.__name__

if not hasattr(c.p.v, '_introspection_target'):
    txt = g.app.gui.runAskOkCancelStringDialog(
        c, "Introspect what", "Introspect what")
    if txt is not None:
        o = eval(txt)
        c.p.v._introspection_target = o
        c.p.h = "%s %s" % (txt, classname(o))

# c.p.deletePositionsInList([i.copy() for i in p.children()])

obj = c.p.v._introspection_target
g.es(classname(obj))

def show_obj(c, obj):

    inames = sorted(dir(obj))
    
    things = {}
    instances = []
    for iname in inames:
        
        if iname.startswith('__'):
            continue
        
        o = getattr(obj, iname)
        cname = classname(o)
        instances.append((iname, o))
        things.setdefault(cname, []).append(instances[-1])

    if 'instance' in sub_mode:
        tnd = c.p.v.insertAsNthChild(0)
        tnd.h = "&lt;by name&gt;"
    else:
        tnd = c.p.v

    instances.sort()
    for iname, o in instances:
        
        if classname(o) == 'position':
            # apparently this collapses the space-time continuum?
            continue
        
        nd = tnd.insertAsLastChild()
        
        if not seen_already(tnd, nd, iname, o):
            nd.h = "%s %s" % (iname, format_type(nd, o))
            nd._introspection_target = o

    if 'class' in sub_mode:
        ttnd = c.p.v.insertAsNthChild(0)
        ttnd.h = "&lt;by class&gt;"
    else:
        ttnd = c.p.v

    for cname in sorted(things):
    
        if len(things[cname]) == 1:
            tnd = ttnd
        else:
            tnd = ttnd.insertAsLastChild()
            tnd.h = "&lt;%s&gt;"%cname
    
        for iname, o in sorted(things[cname]):
            
            if cname == 'position':
                # apparently this collapses the space-time continuum?
                continue
            
            nd = tnd.insertAsLastChild()
            if not seen_already(tnd, nd, iname, o):
                show_child(nd, iname, o)
                nd._introspection_target = o
         
def seen_already(tnd, nd, iname, o):
        
    up = tnd.parents
    while up:
        if (hasattr(up[0], '_introspection_target') and
            up[0]._introspection_target is o):
            break
        up = up[0].parents
    else:
        return False
        
    nd.h = "[%s %s]" % (classname(o), iname)
    pos = c.vnode2position(up[0])
    nd.b = pos.get_UNL(with_file=True, with_proto=True)
    
    return True
            
def show_child(nd, iname, o):
                
    nd._introspection_target = o
    nd.h = "%s %s" % (format_type(nd, o), iname)
    
docable = (
    types.ClassType, types.MethodType, types.UnboundMethodType, 
    types.BuiltinFunctionType, types.BuiltinMethodType,
)
    
def format_type(nd, o):
    
    if isinstance(o, docable):
        if hasattr(o, '__doc__'):
            nd.b = o.__doc__
    
    if isinstance(o, (str, unicode)):
        nd.b = o
        return "%s '%s'" % (classname(o), o[:20])
    elif isinstance(o, bool):
        return "%s %s" % (classname(o), 'T' if o else 'F')
    elif isinstance(o, (int, float)):
        return "%s %s" % (classname(o), o)
    elif isinstance(o, (tuple, list, dict)):
        return "%s %s" % (classname(o), len(o))
    else:
        return classname(o)
    
def show_list(c, list_):
    
    if len(list_) &gt; 100:
        nd = c.p.v.insertAsLastChild()
        nd.h = "&lt;%s of %d items truncated&gt;" % len(list_.__class__.__name__, list_)
        
    if len(list_) == 0:
        nd = c.p.v.insertAsLastChild()
        nd.h = "&lt;%s of 0 items&gt;" % list_.__class__.__name__
        
    for n, i in enumerate(list_[:100]):
        nd = c.p.v.insertAsLastChild()
        show_child(nd, '', i)
        nd.h = "%d: %s" % (n, nd.h)
        nd._introspection_target = i

def show_dict(c, dict_):
    
    if len(dict_) &gt; 100:
        nd = c.p.v.insertAsLastChild()
        nd.h = "&lt;dict of %d items truncated&gt;" % len(dict_)
        
    if len(dict_) == 0:
        nd = c.p.v.insertAsLastChild()
        nd.h = "&lt;dict of 0 items&gt;"
        
    keys = dict_.keys()
    keys.sort()
        
    for k in keys[:100]:
        nd = c.p.v.insertAsLastChild()
        i = dict_[k]
        show_child(nd, '', i)
        nd.h = "%s: %s" % (k, nd.h)
        nd._introspection_target = i

dispatch = {
    list: show_list,
    tuple: show_list,
    dict: show_dict,
}

func = dispatch.get(type(obj), show_obj)

func(c, obj)
   
c.p.expand()
c.redraw()
</t>
<t tx="ekr.20250131013029.36">'''@button (ekr.leo) Join the lines, with ; separators'''
# No longer needed on Windows 10
w = c.frame.body.widget
aList = [z.rstrip() for z in p.b.split('\n')]
p.b = ';'.join(aList)
c.bodyWantsFocusNow()
</t>
<t tx="ekr.20250131013029.37">g.cls()

import os

file_name = g.os_path_finalize_join(g.app.loadDir, '..', '..', 'README.md')
assert os.path.exists(file_name), file_name
g.openWithFileName(file_name, old_c = c)</t>
<t tx="ekr.20250131013029.38">g.cls()

# Changed files:
# leoApp.py
# leoAtFile.py
# leoCommands.py
# leoFileCommands.py
# leoFrame.py
# leoUndo.py
# qt_frame.py

make_changes = True
    # True, actually make the change

class CreateDecorators:
    '''
    A class to create decorators from tables in getPublicCommands.
    
    Note: the node "Found: getPublicCommands" must exist.
    '''
    def __init__(self):
        self.n = 0
        self.n_fail = 0
        self.s = self.define_s()
    @others

CreateDecorators().run()
</t>
<t tx="ekr.20250131013029.39">def create_d(self,lines):
    '''Create a dict. keys are method names; values are command names.'''
    trace = False
    d = {}
    for s in lines:
        aList = s.split()
        if len(aList) &gt; 2:
            aList = [aList[0],' '.join(aList[1:])]
        c_name,f_name = aList[0].strip(),aList[1].strip()
        if ' ' not in f_name:
            f_name = f_name.split('.')[-1]
        # if '(' in f_name:
            # f_name = f_name[:f_name.find('(')]
        if trace: g.trace('%45s %s' % (c_name,f_name))
        d [f_name] = c_name
    return d
</t>
<t tx="ekr.20250131013029.4">
</t>
<t tx="ekr.20250131013029.40">def create_decorator(self,c_name,f_name,root):
    '''
    Search root for a definition of f_name.
    If found, insert @cmd(f_name) before the definition.
    '''
    trace = True
    found = False
    decorator = "@cmd('%s')\n" % (c_name)
    for p in root.self_and_subtree():
        changed,result = False,[]
        for s in g.splitLines(p.b):
            if g.match_word(s,0,'def ' + f_name):
                if found:
                    if f_name not in self.suppress:
                        g.trace('duplicate def',f_name)
                else:
                    changed,found = True,True
                    result.append(decorator)
                    # print('%s%s' % (decorator,s))
            result.append(s)
        if changed and make_changes:
            new_body = ''.join(result)
            print('%40s %s' % (p.h[:40],decorator.rstrip()))
            # use git as our undo :-)
            # p.b = new_body
    return found
</t>
<t tx="ekr.20250131013029.41">def create_decorators(self,d): ### ,root):
    '''Create decorators for all items in d in root's tree.'''
    table = (
        'class Commands', # c.
        'class LeoQtFrame', # f.
        'class LeoFrame', # f.
        'class LeoApp', # g.app.
        '@file leoAtFile.py', # c.atFileCommands
        '@file leoFileCommands.py', # c.fileCommands
        'class Undoer', # c.undoer
    )
    roots = []
    for h in table:
        root = g.findNodeAnywhere(c,h)
        assert root,h
        roots.append(root)
    for f_name in sorted(d.keys()):
        found = False
        for root in roots:
            c_name = d.get(f_name)
            found = self.create_decorator(c_name,f_name,root)
            if found: break
        if not found and f_name not in self.suppress:
            print('===== not found: %s' % (f_name))
            self.n_fail += 1
</t>
<t tx="ekr.20250131013029.42"># 'check-all-python-code':      c.checkAllPythonCode,
# 'check-python-code':          c.checkPythonCode,
# 'extract-python-method':        c.extractPythonMethod,
# 'extract-section':              c.extractSection,
# 'import-at-file':               c.importAtFile,
# 'import-at-root':               c.importAtRoot,
# 'import-cweb-files':            c.importCWEBFiles,
# 'import-derived-file':          c.importDerivedFile,
# 'import-flattened-outline':     c.importFlattenedOutline,
# 'import-noweb-files':           c.importNowebFiles,
# 'mark-changed-roots':           c.markChangedRoots,
# 'mark-clones':                c.markClones,
# 'open-compare-window':        c.openCompareWindow,
# 'open-online-tutorial':       c.leoTutorial,
# 'reformat-body':              c.reformatBody, # 2013/10/02.
def define_s(self):
    return '''
'abort-edit-headline':          f.abortEditLabelCommand,
'about-leo':                    c.about,
'add-comments':                 c.addComments,     
'beautify':                     c.beautifyPythonCode,
'beautify-all':                 c.beautifyAllPythonCode,
'beautify-c':                   c.beautifyCCode,
'beautify-tree':                c.beautifyPythonTree,
'cascade-windows':              f.cascade,
'check-derived-file':           c.atFileCommands.checkDerivedFile,
'check-leo-file':               c.fileCommands.checkLeoFile,
'check-outline':                c.fullCheckOutline,
'clean-recent-files':           c.cleanRecentFiles,
'clear-recent-files':           c.clearRecentFiles,
'clone-node':                   c.clone,
'clone-node-to-last-node':      c.cloneToLastNode,
'close-window':                 c.close,
'contract-all':                 c.contractAllHeadlines,
'contract-all-other-nodes':     c.contractAllOtherNodes,
'contract-node':                c.contractNode,
'contract-or-go-left':          c.contractNodeOrGoToParent,
'contract-parent':              c.contractParent,
'convert-all-blanks':           c.convertAllBlanks,
'convert-all-tabs':             c.convertAllTabs,
'convert-blanks':               c.convertBlanks,
'convert-tabs':                 c.convertTabs,
'copy-node':                    c.copyOutline,
'copy-text':                    f.copyText,
'cut-node':                     c.cutOutline,
'cut-text':                     f.cutText,
'de-hoist':                     c.dehoist,
'delete-comments':              c.deleteComments,
'delete-node':                  c.deleteOutline,
'demote':                       c.demote,
'dump-outline':                 c.dumpOutline,
'edit-headline':                c.editHeadline,
'end-edit-headline':            f.endEditLabelCommand,
'equal-sized-panes':            f.equalSizedPanes,
'execute-script':               c.executeScript,
'exit-leo':                     g.app.onQuit,
'expand-all':                   c.expandAllHeadlines,
'expand-all-subheads':          c.expandAllSubheads,
'expand-ancestors-only':        c.expandOnlyAncestorsOfNode,
'expand-and-go-right':          c.expandNodeAndGoToFirstChild,
'expand-next-level':            c.expandNextLevel,
'expand-node':                  c.expandNode,
'expand-or-go-right':           c.expandNodeOrGoToFirstChild,
'expand-prev-level':            c.expandPrevLevel,
'expand-to-level-1':            c.expandLevel1,
'expand-to-level-2':            c.expandLevel2,
'expand-to-level-3':            c.expandLevel3,
'expand-to-level-4':            c.expandLevel4,
'expand-to-level-5':            c.expandLevel5,
'expand-to-level-6':            c.expandLevel6,
'expand-to-level-7':            c.expandLevel7,
'expand-to-level-8':            c.expandLevel8,
'expand-to-level-9':            c.expandLevel9,
'export-headlines':             c.exportHeadlines,
'extract':                      c.extract,
'extract-names':                c.extractSectionNames,
'find-next-clone':              c.findNextClone,
'flatten-outline':              c.flattenOutline,
'flatten-outline-to-node':      c.flattenOutlineToNode,
'go-back':                      c.goPrevVisitedNode,
'go-forward':                   c.goNextVisitedNode,
'goto-first-node':              c.goToFirstNode,
'goto-first-sibling':           c.goToFirstSibling,
'goto-first-visible-node':      c.goToFirstVisibleNode,
'goto-last-node':               c.goToLastNode,
'goto-last-sibling':            c.goToLastSibling,
'goto-last-visible-node':       c.goToLastVisibleNode,
'goto-next-changed':            c.goToNextDirtyHeadline,
'goto-next-clone':              c.goToNextClone,
'goto-next-history-node':       c.goToNextHistory,
'goto-next-marked':             c.goToNextMarkedHeadline,
'goto-next-node':               c.selectThreadNext,
'goto-next-sibling':            c.goToNextSibling,
'goto-next-visible':            c.selectVisNext,
'goto-parent':                  c.goToParent,
'goto-prev-history-node':       c.goToPrevHistory,
'goto-prev-node':               c.selectThreadBack,
'goto-prev-sibling':            c.goToPrevSibling,
'goto-prev-visible':            c.selectVisBack,
'hide-invisibles':              c.hideInvisibles,
'hoist':                        c.hoist,
'import-file':                  c.importAnyFile,
'indent-region':                c.indentBody,
'insert-body-time':             c.insertBodyTime,
'insert-child':                 c.insertChild,
'insert-node':                  c.insertHeadline,
'insert-node-before':           c.insertHeadlineBefore,
'mark':                         c.markHeadline,
'mark-changed-items':           c.markChangedHeadlines,
'mark-subheads':                c.markSubheads,
'match-brackets':               c.findMatchingBracket,
'minimize-all':                 f.minimizeAll,
'move-outline-down':            c.moveOutlineDown,
'move-outline-left':            c.moveOutlineLeft,
'move-outline-right':           c.moveOutlineRight,
'move-outline-up':              c.moveOutlineUp,
'new':                          c.new,
'open-cheat-sheet-leo':         c.openCheatSheet,
'open-leoDocs-leo':             c.leoDocumentation,
'open-leoPlugins-leo':          c.openLeoPlugins,
'open-leoSettings-leo':         c.openLeoSettings,
'open-local-settings':          c.selectAtSettingsNode,
'open-myLeoSettings-leo':       c.openMyLeoSettings,
'open-offline-tutorial':        f.leoHelp,
'open-online-home':             c.leoHome,
'open-online-toc':              c.openLeoTOC,
'open-online-tutorials':        c.openLeoTutorials,
'open-online-videos':           c.openLeoVideos,
'open-outline':                 c.open,
'open-python-window':           c.openPythonWindow,
'open-quickstart-leo':          c.leoQuickStart,
'open-scripts-leo':             c.openLeoScripts,
'open-users-guide':             c.openLeoUsersGuide,
'open-with':                    c.openWith,
'outline-to-cweb':              c.outlineToCWEB,
'outline-to-noweb':             c.outlineToNoweb,
'paste-node':                   c.pasteOutline,
'paste-retaining-clones':       c.pasteOutlineRetainingClones,
'paste-text':                   f.pasteText,
'pretty-print-all-python-code': c.prettyPrintAllPythonCode,
'pretty-print-python-code':     c.prettyPrintPythonCode,
'promote':                      c.promote,
'read-at-auto-nodes':           c.readAtAutoNodes,
'read-at-file-nodes':           c.readAtFileNodes,
'read-at-shadow-nodes':         c.readAtShadowNodes,
'read-file-into-node':          c.readFileIntoNode,
'read-outline-only':            c.readOutlineOnly,
'redo':                         c.undoer.redo,
'reformat-paragraph':           c.reformatParagraph,
'refresh-from-disk':            c.refreshFromDisk,
'remove-sentinels':             c.removeSentinels,
'resize-to-screen':             f.resizeToScreen,
'revert':                       c.revert,
'save-all':                     c.saveAll,
'save-file':                    c.save,
'save-file-as':                 c.saveAs,
'save-file-as-unzipped':        c.saveAsUnzipped,
'save-file-as-zipped':          c.saveAsZipped,
'save-file-to':                 c.saveTo,
'set-colors':                   c.colorPanel,
'set-font':                     c.fontPanel,
'settings':                     c.preferences,
'show-invisibles':              c.showInvisibles,
'sort-children':                c.sortChildren,
'sort-recent-files':            c.sortRecentFiles,
'sort-siblings':                c.sortSiblings,
'tangle':                       c.tangle,
'tangle-all':                   c.tangleAll,
'tangle-marked':                c.tangleMarked,
'toggle-active-pane':           f.toggleActivePane,
'toggle-angle-brackets':        c.toggleAngleBrackets,
'toggle-invisibles':            c.toggleShowInvisibles,
'toggle-sparse-move':           c.toggleSparseMove,
'toggle-split-direction':       f.toggleSplitDirection,
'undo':                         c.undoer.undo,
'unformat-paragraph':           c.unformatParagraph,
'unindent-region':              c.dedentBody,
'unmark-all':                   c.unmarkAll,
'untangle':                     c.untangle,
'untangle-all':                 c.untangleAll,
'untangle-marked':              c.untangleMarked,
'weave':                        c.weave,
'write-at-auto-nodes':          c.atFileCommands.writeAtAutoNodes,
'write-at-file-nodes':          c.fileCommands.writeAtFileNodes,
'write-at-shadow-nodes':        c.fileCommands.writeAtShadowNodes,
'write-dirty-at-auto-nodes':    c.atFileCommands.writeDirtyAtAutoNodes,
'write-dirty-at-file-nodes':    c.fileCommands.writeDirtyAtFileNodes,
'write-dirty-at-shadow-nodes':  c.fileCommands.writeDirtyAtShadowNodes,
'write-file-from-node':         c.writeFileFromNode,
'write-missing-at-file-nodes':  c.fileCommands.writeMissingAtFileNodes,
'write-outline-only':           c.fileCommands.writeOutlineOnly,
'''
</t>
<t tx="ekr.20250131013029.43">def munge_lines(self,s):
    '''Return munged lines of s. '''
    lines = sorted([z.strip() for z in g.splitLines(s) if z.strip()])
    lines = [z for z in lines if not z.startswith('#')]
    lines = [z[:z.find('#')] if z.find('#') &gt; -1 else z for z in lines]
    lines = [z.rstrip().rstrip(',') for z in lines]
    lines = [z[1:] for z in lines]
    lines = [z.replace("':",' ') for z in lines]
    self.n += len(lines)
    return lines
</t>
<t tx="ekr.20250131013029.44">def run(self):
    '''Top-level code.'''
    lines = self.munge_lines(self.s)
    d = self.create_d(lines)
    self.create_decorators(d)
    print('%s commands %s failed' % (self.n,self.n_fail))
</t>
<t tx="ekr.20250131013029.45"># Make sustitutions...
aList = [
    ('pandas', 'pd'),
    ('numpy', 'np'),
]
s = p.b
for pat1, pat2 in aList:
    s = s.replace(pat1, pat2)
# Create a new node, with the new text.
p2 = c.p.insertAfter()
p2.h = "Substitutions"
p2.b = s
c.selectPosition(p2)
c.redraw()
</t>
<t tx="ekr.20250131013029.46">'''@button (ekr.leo) print the gnx.'''
# g.cls()
print('timestamp: %s lastIndex: %s' % (g.app.nodeIndices.timeString,g.app.nodeIndices.lastIndex))
print('gnxs: -----')
for p in c.p.self_and_subtree():
    print('%s %s' % (p.v.gnx,p.h))
print('uAs: -----')
for p in c.p.self_and_subtree():
    if p.v.u:
        print('%s %s' % (p.v.u,p.h))
# print('done')
</t>
<t tx="ekr.20250131013029.47">c.k.simulateCommand('print-style-sheet')</t>
<t tx="ekr.20250131013029.48">d = p.v.u
if d:
    for key in sorted(d):
        print('%10s %s' % (key, d.get(key)))</t>
<t tx="ekr.20250131013029.49">demo = r"C:\test\qt_proto.py"
g.execute_shell_commands(rf'&amp;python {demo}')
</t>
<t tx="ekr.20250131013029.5"></t>
<t tx="ekr.20250131013029.50">demo = r"C:\leo.repo\qt-examples\src\pyqt-official/qtdemo/qtdemo.py"
g.execute_shell_commands(rf'&amp;python "{demo}"')
</t>
<t tx="ekr.20250131013029.51">print(p.h)
assert False</t>
<t tx="ekr.20250131013029.52">print('hi: %s' % p.h)</t>
<t tx="ekr.20250131013029.53"># g.cls()
if 1:
    print('----- restarting -----')
    c.k.simulateCommand('reload-all-settings')
    import imp
    import leo.plugins.leowapp as leowapp
    imp.reload(leowapp)
    pc = g.app.pluginsController
    pc.unloadOnePlugin('leoapp', verbose=True)
    pc.loadOnePlugin('leowapp', tag='open0', verbose=True)
g.execute_shell_commands('&amp;moz http://127.0.0.1:8100/ekr.leo')
</t>
<t tx="ekr.20250131013029.54">'''
Save an image on the clipboard to .leo/screen_captures.
Use Alt-PrintScn to copy the active window to the clipboard.
'''
import time
app = g.app.gui.qtApp
app.processEvents()
image = app.clipboard().image()
if not image.isNull():
    base = r'C:\Users\edreamleo\.leo\screen_captures'
    assert g.os_path_exists(base), repr(base)
    fn = '%s.png' % time.strftime('%Y-%m-%d-%H.%M.%S')
    path = g.os_path_finalize_join(base, fn)
    image.save(path, 'png')
    g.es_print('saved: %s' % path)
</t>
<t tx="ekr.20250131013029.55">'''Create a screenshot of the present Leo outline and save it to .leo/screen_captures.'''
#  --window-size=682x1264 is recommended.
from leo.core.leoQt import isQt5, QtGui
import time
base = r'C:\Users\edreamleo\.leo\screen_captures'
assert g.os_path_exists(base), repr(base)
window = g.app.gui.qtApp.activeWindow()
w = window.grab() if isQt5 else QtGui.QPixmap.grabWindow(window.winID())
fn = '%s.png' % time.strftime('%Y-%m-%d-%H-%M-%S')
path = g.os_path_finalize_join(base, fn)
w.save(path, 'png')
g.es_print('saved: %s' % path)
</t>
<t tx="ekr.20250131013029.56">'''@button (ekr.leo) set the ua to 'test-head' '''

p.v.u = {'test-head':p.h}
p.setDirty()
c.setChanged(True)
c.redraw()
</t>
<t tx="ekr.20250131013029.57">'''@button (ekr.leo) Split the body text at semicolons'''
# No longer needed on Windows 10
w = c.frame.body.widget
p.b = '\n'.join(p.b.split(';'))
c.bodyWantsFocusNow()
# w.selectAllText()
</t>
<t tx="ekr.20250131013029.58" annotate="7d71002858080000007072696f7269747971014d0f27580a000000707269736574646174657102580a000000323032302d31312d31317103752e">u = c.undoer
command = 'Uppercase Body'
bunch = u.beforeChangeBody(p)
p.b = p.b.upper()
c.setChanged()
p.setDirty()
u.afterChangeBody(p, command, bunch)
</t>
<t tx="ekr.20250131013029.59">u = c.undoer
command = 'Uppercase Head'
bunch = u.beforeChangeHead(p)
p.h = p.h.upper()
c.setChanged()
p.setDirty()
u.afterChangeHead(p, command, bunch)
</t>
<t tx="ekr.20250131013029.6"># This node contains the commands needed to execute a program in a particular language.

# Format: language-name: command

# Create a temporary file if c.p is not any kind of @&lt;file&gt; node.

# Compute the final command as follows:

# 1. If command contains &lt;FILE&gt;, replace &lt;FILE&gt; with the full path to the external file.
# 2. If command contains &lt;NO-FILE&gt;, just remove &lt;NO-FILE&gt;.
# 3. Otherwise, append the full path to the external file to the command.

go: go run . &lt;NO-FILE&gt;
python: python
rust: rustc
</t>
<t tx="ekr.20250131013029.60">c.testManager.runTimerOnNode(p,count=100000)
</t>
<t tx="ekr.20250131013029.61">g.app.debug_app = not g.app.debug_app
g.app.debug_widgets = not g.app.debug_widgets
print('g.app.debug_app: %s' % g.app.debug_app)
print('g.app.debug_widgets: %s' % g.app.debug_widgets)</t>
<t tx="ekr.20250131013029.62">g.cls()

import unittest
# import pyflakes
# print(pyflakes)
import os
import sys
path = g.os_path_finalize_join(os.curdir, '..')
print(path)
if 0:
    import importlib
    import importlib.util
    # importlib.invalidate_caches()
    pyflakes = importlib.util.spec_from_file_location("pyflakes", path)
    # importlib.import_module('pyflakes', path)

else:
    if 'pyflakes' in sys.modules:
        del sys.modules['pyflakes']
    if sys.path[0] != path:
        sys.path.insert(0, path)
    import pyflakes
print(pyflakes)
if 1:
    from pyflakes.test import test_api, test_doctests, test_imports, test_other
    from pyflakes.test import test_return_with_arguments_inside_generator
    from pyflakes.test import test_undefined_names
    tests = (
        test_api,
        test_doctests,
        test_imports, test_other,
        test_return_with_arguments_inside_generator,
        test_undefined_names,
    )
    loader = unittest.TestLoader()
    suite = unittest.TestSuite()
    for module in tests:
        suite.addTest(loader.loadTestsFromModule(module))
    unittest.TextTestRunner(verbosity=1).run(suite)</t>
<t tx="ekr.20250131013029.63">print('Test')</t>
<t tx="ekr.20250131013029.7"># This node contains the regex pattern to determine the line number in error messages.
# Format: language-name: regex pattern
#
# Patterns must define two groups, in either order:
# One group, containing only digits, defines the line number.
# The other group defines the file name.

go: ^\s*(.*):([0-9]+):([0-9]+):.+$
python: ^\s*File "(.+)", line ([0-9]+), in .+$
rust: ^\s*--&gt; (.+):([0-9]+):([0-9]+)\s*$</t>
<t tx="ekr.20250131013029.8">backup
execute-script
ctrl-click-at-cursor

# import-ipynb
# exec-py-file

# expand-body-pane
# expand-vr-pane
# contract-body-pane
# contract-vr-pane
# contract-vr3-pane
# contract-log-pane
# parse-ipynb
# test.ipynb
# vr-toggle
# vr3-toggle

# add-editor
# beautify-files
# clone-to-at-spot
# help-for-layouts
# import-any-file
# import-to-indented-c
# import-to-indented-lisp
# import-to-indented-typescript
# merge-node-with-next-node
# merge-node-with-prev-node
# pylint
# refresh-from-disk
# reload-outline
# reload-settings
# show-layouts
# show-plugin-handlers
# stickynote
</t>
<t tx="ekr.20250131013029.9">g.cls()
print('rclick hi: %s' % c.p.h)
print('dir()', dir())
print(script_args)
print(script_gnx)</t>
<t tx="ekr.20250131013112.1">@language python
@tabwidth -4 # For a better match.

"""Recursively import all python files in a directory and clean the result."""
g.cls()

dir_ = r'C:\Repos\ekr-study\ekr-pylint-study'

c.recursiveImport(
    dir_=dir_,
    kind = '@clean', # '@auto', '@clean', '@nosent','@file',
    recursive = True,
    safe_at_file = False,
    theTypes = ['.py',],
    verbose = True,
)
if 1:
    last = c.lastTopLevel()
    last.expand()
    if last.hasChildren():
        last.firstChild().expand()
    c.redraw(last)
print('Done')</t>
<t tx="ekr.20250131013559.238"># C:/Repos/ekr-study/ekr-pylint-study</t>
<t tx="ekr.20250131013559.239">@path pylint
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

__all__ = [
    "__version__",
    "modify_sys_path",
    "run_pylint",
    "run_pyreverse",
    "run_symilar",
    "version",
]

import os
import sys
from collections.abc import Sequence
from typing import NoReturn

from pylint.__pkginfo__ import __version__

# pylint: disable=import-outside-toplevel


@others
if (3, 12, 0) &lt;= sys.version_info[:3] &lt; (3, 12, 3):
    sys.unraisablehook = _catch_valueerror


version = __version__
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013559.240">def run_pylint(argv: Sequence[str] | None = None) -&gt; None:
    """Run pylint.

    argv can be a sequence of strings normally supplied as arguments on the command line
    """
    from pylint.lint import Run as PylintRun

    try:
        PylintRun(argv or sys.argv[1:])
    except KeyboardInterrupt:
        sys.exit(1)


</t>
<t tx="ekr.20250131013559.241">def _run_pylint_config(argv: Sequence[str] | None = None) -&gt; None:
    """Run pylint-config.

    argv can be a sequence of strings normally supplied as arguments on the command line
    """
    from pylint.lint.run import _PylintConfigRun

    _PylintConfigRun(argv or sys.argv[1:])


</t>
<t tx="ekr.20250131013559.242">def run_pyreverse(argv: Sequence[str] | None = None) -&gt; NoReturn:
    """Run pyreverse.

    argv can be a sequence of strings normally supplied as arguments on the command line
    """
    from pylint.pyreverse.main import Run as PyreverseRun

    sys.exit(PyreverseRun(argv or sys.argv[1:]).run())


</t>
<t tx="ekr.20250131013559.243">def run_symilar(argv: Sequence[str] | None = None) -&gt; NoReturn:
    """Run symilar.

    argv can be a sequence of strings normally supplied as arguments on the command line
    """
    from pylint.checkers.symilar import Run as SymilarRun

    SymilarRun(argv or sys.argv[1:])


</t>
<t tx="ekr.20250131013559.244">def modify_sys_path() -&gt; None:
    """Modify sys path for execution as Python module.

    Strip out the current working directory from sys.path.
    Having the working directory in `sys.path` means that `pylint` might
    inadvertently import user code from modules having the same name as
    stdlib or pylint's own modules.
    CPython issue: https://bugs.python.org/issue33053

    - Remove the first entry. This will always be either "" or the working directory
    - Remove the working directory from the second and third entries
      if PYTHONPATH includes a ":" at the beginning or the end.
      https://github.com/pylint-dev/pylint/issues/3636
      Don't remove it if PYTHONPATH contains the cwd or '.' as the entry will
      only be added once.
    - Don't remove the working directory from the rest. It will be included
      if pylint is installed in an editable configuration (as the last item).
      https://github.com/pylint-dev/pylint/issues/4161
    """
    cwd = os.getcwd()
    if sys.path[0] in ("", ".", cwd):
        sys.path.pop(0)
    env_pythonpath = os.environ.get("PYTHONPATH", "")
    if env_pythonpath.startswith(":") and env_pythonpath not in (f":{cwd}", ":."):
        sys.path.pop(0)
    elif env_pythonpath.endswith(":") and env_pythonpath not in (f"{cwd}:", ".:"):
        sys.path.pop(1)


</t>
<t tx="ekr.20250131013559.245">def _catch_valueerror(unraisable: sys.UnraisableHookArgs) -&gt; None:  # pragma: no cover
    """Overwrite sys.unraisablehook to catch incorrect ValueError.

    Python 3.12 introduced changes that sometimes cause astroid to emit ValueErrors
    with 'generator already executing'. Fixed in Python 3.12.3 and 3.13.

    https://github.com/pylint-dev/pylint/issues/9138
    """
    if (
        isinstance(unraisable.exc_value, ValueError)
        and unraisable.exc_value.args[0] == "generator already executing"
    ):
        return

    sys.__unraisablehook__(unraisable)


</t>
<t tx="ekr.20250131013559.246">@path pylint
#!/usr/bin/env python

# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

import pylint

pylint.modify_sys_path()
pylint.run_pylint()
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013559.247">@path pylint
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""This module exists for compatibility reasons.

It's updated via tbump, do not modify.
"""

from __future__ import annotations

__version__ = "4.0.0-dev0"


@others
numversion = get_numversion_from_version(__version__)
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013559.248">def get_numversion_from_version(v: str) -&gt; tuple[int, int, int]:
    """Kept for compatibility reason.

    See https://github.com/pylint-dev/pylint/issues/4399
    https://github.com/pylint-dev/pylint/issues/4420,
    """
    version = v.replace("pylint-", "")
    result_version = []
    for number in version.split(".")[0:3]:
        try:
            result_version.append(int(number))
        except ValueError:
            current_number = ""
            for char in number:
                if char.isdigit():
                    current_number += char
                else:
                    break
            try:
                result_version.append(int(current_number))
            except ValueError:
                result_version.append(0)
    while len(result_version) != 3:
        result_version.append(0)

    return tuple(result_version)  # type: ignore[return-value] # mypy can't infer the length


</t>
<t tx="ekr.20250131013559.249">@path pylint
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import os
import platform
import sys

import astroid
import platformdirs

from pylint.__pkginfo__ import __version__
from pylint.typing import MessageTypesFullName

PY310_PLUS = sys.version_info[:2] &gt;= (3, 10)
PY311_PLUS = sys.version_info[:2] &gt;= (3, 11)
PY312_PLUS = sys.version_info[:2] &gt;= (3, 12)

IS_PYPY = platform.python_implementation() == "PyPy"

PY_EXTS = (".py", ".pyc", ".pyo", ".pyw", ".so", ".dll")

MSG_STATE_CONFIDENCE = 2
_MSG_ORDER = "EWRCIF"
MSG_STATE_SCOPE_CONFIG = 0
MSG_STATE_SCOPE_MODULE = 1

# The line/node distinction does not apply to fatal errors and reports.
_SCOPE_EXEMPT = "FR"

MSG_TYPES: dict[str, MessageTypesFullName] = {
    "I": "info",
    "C": "convention",
    "R": "refactor",
    "W": "warning",
    "E": "error",
    "F": "fatal",
}
MSG_TYPES_LONG: dict[str, str] = {v: k for k, v in MSG_TYPES.items()}

MSG_TYPES_STATUS = {"I": 0, "C": 16, "R": 8, "W": 4, "E": 2, "F": 1}

# You probably don't want to change the MAIN_CHECKER_NAME
# This would affect rcfile generation and retro-compatibility
# on all project using [MAIN] in their rcfile.
MAIN_CHECKER_NAME = "main"

DEFAULT_PYLINT_HOME = platformdirs.user_cache_dir("pylint")

DEFAULT_IGNORE_LIST = ("CVS",)


@others
PYLINT_HOME = _get_pylint_home()

TYPING_NORETURN = frozenset(
    (
        "typing.NoReturn",
        "typing_extensions.NoReturn",
    )
)
TYPING_NEVER = frozenset(
    (
        "typing.Never",
        "typing_extensions.Never",
    )
)

DUNDER_METHODS: dict[tuple[int, int], dict[str, str]] = {
    (0, 0): {
        "__init__": "Instantiate class directly",
        "__del__": "Use del keyword",
        "__repr__": "Use repr built-in function",
        "__str__": "Use str built-in function",
        "__bytes__": "Use bytes built-in function",
        "__format__": "Use format built-in function, format string method, or f-string",
        "__lt__": "Use &lt; operator",
        "__le__": "Use &lt;= operator",
        "__eq__": "Use == operator",
        "__ne__": "Use != operator",
        "__gt__": "Use &gt; operator",
        "__ge__": "Use &gt;= operator",
        "__hash__": "Use hash built-in function",
        "__bool__": "Use bool built-in function",
        "__getattr__": "Access attribute directly or use getattr built-in function",
        "__getattribute__": "Access attribute directly or use getattr built-in function",
        "__setattr__": "Set attribute directly or use setattr built-in function",
        "__delattr__": "Use del keyword",
        "__dir__": "Use dir built-in function",
        "__get__": "Use get method",
        "__set__": "Use set method",
        "__delete__": "Use del keyword",
        "__instancecheck__": "Use isinstance built-in function",
        "__subclasscheck__": "Use issubclass built-in function",
        "__call__": "Invoke instance directly",
        "__len__": "Use len built-in function",
        "__length_hint__": "Use length_hint method",
        "__getitem__": "Access item via subscript",
        "__setitem__": "Set item via subscript",
        "__delitem__": "Use del keyword",
        "__iter__": "Use iter built-in function",
        "__next__": "Use next built-in function",
        "__reversed__": "Use reversed built-in function",
        "__contains__": "Use in keyword",
        "__add__": "Use + operator",
        "__sub__": "Use - operator",
        "__mul__": "Use * operator",
        "__matmul__": "Use @ operator",
        "__truediv__": "Use / operator",
        "__floordiv__": "Use // operator",
        "__mod__": "Use % operator",
        "__divmod__": "Use divmod built-in function",
        "__pow__": "Use ** operator or pow built-in function",
        "__lshift__": "Use &lt;&lt; operator",
        "__rshift__": "Use &gt;&gt; operator",
        "__and__": "Use &amp; operator",
        "__xor__": "Use ^ operator",
        "__or__": "Use | operator",
        "__radd__": "Use + operator",
        "__rsub__": "Use - operator",
        "__rmul__": "Use * operator",
        "__rmatmul__": "Use @ operator",
        "__rtruediv__": "Use / operator",
        "__rfloordiv__": "Use // operator",
        "__rmod__": "Use % operator",
        "__rdivmod__": "Use divmod built-in function",
        "__rpow__": "Use ** operator or pow built-in function",
        "__rlshift__": "Use &lt;&lt; operator",
        "__rrshift__": "Use &gt;&gt; operator",
        "__rand__": "Use &amp; operator",
        "__rxor__": "Use ^ operator",
        "__ror__": "Use | operator",
        "__iadd__": "Use += operator",
        "__isub__": "Use -= operator",
        "__imul__": "Use *= operator",
        "__imatmul__": "Use @= operator",
        "__itruediv__": "Use /= operator",
        "__ifloordiv__": "Use //= operator",
        "__imod__": "Use %= operator",
        "__ipow__": "Use **= operator",
        "__ilshift__": "Use &lt;&lt;= operator",
        "__irshift__": "Use &gt;&gt;= operator",
        "__iand__": "Use &amp;= operator",
        "__ixor__": "Use ^= operator",
        "__ior__": "Use |= operator",
        "__neg__": "Multiply by -1 instead",
        "__pos__": "Multiply by +1 instead",
        "__abs__": "Use abs built-in function",
        "__invert__": "Use ~ operator",
        "__complex__": "Use complex built-in function",
        "__int__": "Use int built-in function",
        "__float__": "Use float built-in function",
        "__round__": "Use round built-in function",
        "__trunc__": "Use math.trunc function",
        "__floor__": "Use math.floor function",
        "__ceil__": "Use math.ceil function",
        "__enter__": "Invoke context manager directly",
        "__aenter__": "Invoke context manager directly",
        "__copy__": "Use copy.copy function",
        "__deepcopy__": "Use copy.deepcopy function",
        "__fspath__": "Use os.fspath function instead",
    },
    (3, 10): {
        "__aiter__": "Use aiter built-in function",
        "__anext__": "Use anext built-in function",
    },
}

EXTRA_DUNDER_METHODS = [
    "__new__",
    "__subclasses__",
    "__init_subclass__",
    "__set_name__",
    "__class_getitem__",
    "__missing__",
    "__exit__",
    "__await__",
    "__aexit__",
    "__getnewargs_ex__",
    "__getnewargs__",
    "__getstate__",
    "__index__",
    "__setstate__",
    "__reduce__",
    "__reduce_ex__",
    "__post_init__",  # part of `dataclasses` module
]

DUNDER_PROPERTIES = [
    "__class__",
    "__dict__",
    "__doc__",
    "__format__",
    "__module__",
    "__sizeof__",
    "__subclasshook__",
    "__weakref__",
]

# C2801 rule exceptions as their corresponding function/method/operator
# is not valid python syntax in a lambda definition
UNNECESSARY_DUNDER_CALL_LAMBDA_EXCEPTIONS = [
    "__init__",
    "__del__",
    "__delattr__",
    "__set__",
    "__delete__",
    "__setitem__",
    "__delitem__",
    "__iadd__",
    "__isub__",
    "__imul__",
    "__imatmul__",
    "__itruediv__",
    "__ifloordiv__",
    "__imod__",
    "__ipow__",
    "__ilshift__",
    "__irshift__",
    "__iand__",
    "__ixor__",
    "__ior__",
]

MAX_NUMBER_OF_IMPORT_SHOWN = 6
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013559.250">class WarningScope:
    LINE = "line-based-msg"
    NODE = "node-based-msg"


</t>
<t tx="ekr.20250131013559.251">full_version = f"""pylint {__version__}
astroid {astroid.__version__}
Python {sys.version}"""

HUMAN_READABLE_TYPES = {
    "file": "file",
    "module": "module",
    "const": "constant",
    "class": "class",
    "function": "function",
    "method": "method",
    "attr": "attribute",
    "argument": "argument",
    "variable": "variable",
    "class_attribute": "class attribute",
    "class_const": "class constant",
    "inlinevar": "inline iteration",
    "typevar": "type variable",
    "typealias": "type alias",
}

# ignore some messages when emitting useless-suppression:
# - cyclic-import: can show false positives due to incomplete context
# - deprecated-{module, argument, class, method, decorator}:
#   can cause false positives for multi-interpreter projects
#   when linting with an interpreter on a lower python version
INCOMPATIBLE_WITH_USELESS_SUPPRESSION = frozenset(
    [
        "R0401",  # cyclic-import
        "W0402",  # deprecated-module
        "W1505",  # deprecated-method
        "W1511",  # deprecated-argument
        "W1512",  # deprecated-class
        "W1513",  # deprecated-decorator
        "R0801",  # duplicate-code
    ]
)


def _get_pylint_home() -&gt; str:
    """Return the pylint home."""
    if "PYLINTHOME" in os.environ:
        return os.environ["PYLINTHOME"]
    return DEFAULT_PYLINT_HOME


</t>
<t tx="ekr.20250131013559.252">@path pylint
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Exception classes raised by various operations within pylint."""


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013559.253">class InvalidMessageError(Exception):
    """Raised when a message creation, registration or addition is rejected."""


</t>
<t tx="ekr.20250131013559.254">class UnknownMessageError(Exception):
    """Raised when an unregistered message id is encountered."""


</t>
<t tx="ekr.20250131013559.255">class DeletedMessageError(UnknownMessageError):
    """Raised when a message id or symbol that was deleted from pylint is
    encountered.
    """

    @others
</t>
<t tx="ekr.20250131013559.256">class MessageBecameExtensionError(UnknownMessageError):
    """Raised when a message id or symbol that was moved to an optional
    extension is encountered.
    """

    @others
</t>
<t tx="ekr.20250131013559.257">class EmptyReportError(Exception):
    """Raised when a report is empty and so should not be displayed."""


</t>
<t tx="ekr.20250131013559.258">class InvalidReporterError(Exception):
    """Raised when selected reporter is invalid (e.g. not found)."""


</t>
<t tx="ekr.20250131013559.259">class InvalidArgsError(ValueError):
    """Raised when passed arguments are invalid, e.g., have the wrong length."""


</t>
<t tx="ekr.20250131013559.260">class NoLineSuppliedError(Exception):
    """Raised when trying to disable a message on a next line without supplying a line
    number.
    """
</t>
<t tx="ekr.20250131013559.261">def __init__(self, msgid_or_symbol: str, removal_explanation: str):
    super().__init__(
        f"'{msgid_or_symbol}' was removed from pylint, see {removal_explanation}."
    )


</t>
<t tx="ekr.20250131013559.262">def __init__(self, msgid_or_symbol: str, moved_explanation: str):
    super().__init__(
        f"'{msgid_or_symbol}' was moved to an optional extension, see {moved_explanation}."
    )


</t>
<t tx="ekr.20250131013559.263">@path pylint
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Graph manipulation utilities.

(dot generation adapted from pypy/translator/tool/make_dot.py)
"""

from __future__ import annotations

import codecs
import os
import shutil
import subprocess
import tempfile
from collections.abc import Sequence
from typing import Any


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013559.264">def target_info_from_filename(filename: str) -&gt; tuple[str, str, str]:
    """Transforms /some/path/foo.png into ('/some/path', 'foo.png', 'png')."""
    basename = os.path.basename(filename)
    storedir = os.path.dirname(os.path.abspath(filename))
    target = os.path.splitext(filename)[-1][1:]
    return storedir, basename, target


</t>
<t tx="ekr.20250131013559.265">class DotBackend:
    """Dot File back-end."""

    @others
</t>
<t tx="ekr.20250131013559.266">def normalize_node_id(nid: str) -&gt; str:
    """Returns a suitable DOT node id for `nid`."""
    return f'"{nid}"'


</t>
<t tx="ekr.20250131013559.267">def get_cycles(
    graph_dict: dict[str, set[str]], vertices: list[str] | None = None
) -&gt; Sequence[list[str]]:
    """Return a list of detected cycles based on an ordered graph (i.e. keys are
    vertices and values are lists of destination vertices representing edges).
    """
    if not graph_dict:
        return ()
    result: list[list[str]] = []
    if vertices is None:
        vertices = list(graph_dict.keys())
    for vertice in vertices:
        _get_cycles(graph_dict, [], set(), result, vertice)
    return result


</t>
<t tx="ekr.20250131013559.268">def _get_cycles(
    graph_dict: dict[str, set[str]],
    path: list[str],
    visited: set[str],
    result: list[list[str]],
    vertice: str,
) -&gt; None:
    """Recursive function doing the real work for get_cycles."""
    if vertice in path:
        cycle = [vertice]
        for node in path[::-1]:
            if node == vertice:
                break
            cycle.insert(0, node)
        # make a canonical representation
        start_from = min(cycle)
        index = cycle.index(start_from)
        cycle = cycle[index:] + cycle[0:index]
        # append it to result if not already in
        if cycle not in result:
            result.append(cycle)
        return
    path.append(vertice)
    try:
        for node in graph_dict[vertice]:
            # don't check already visited nodes again
            if node not in visited:
                _get_cycles(graph_dict, path, visited, result, node)
                visited.add(node)
    except KeyError:
        pass
    path.pop()
</t>
<t tx="ekr.20250131013559.269">def __init__(
    self,
    graphname: str,
    rankdir: str | None = None,
    size: Any = None,
    ratio: Any = None,
    charset: str = "utf-8",
    renderer: str = "dot",
    additional_param: dict[str, Any] | None = None,
) -&gt; None:
    if additional_param is None:
        additional_param = {}
    self.graphname = graphname
    self.renderer = renderer
    self.lines: list[str] = []
    self._source: str | None = None
    self.emit(f"digraph {normalize_node_id(graphname)} {{")
    if rankdir:
        self.emit(f"rankdir={rankdir}")
    if ratio:
        self.emit(f"ratio={ratio}")
    if size:
        self.emit(f'size="{size}"')
    if charset:
        assert charset.lower() in {
            "utf-8",
            "iso-8859-1",
            "latin1",
        }, f"unsupported charset {charset}"
        self.emit(f'charset="{charset}"')
    for param in additional_param.items():
        self.emit("=".join(param))

</t>
<t tx="ekr.20250131013559.270">def get_source(self) -&gt; str:
    """Returns self._source."""
    if self._source is None:
        self.emit("}\n")
        self._source = "\n".join(self.lines)
        del self.lines
    return self._source

</t>
<t tx="ekr.20250131013559.271">source = property(get_source)

def generate(
    self, outputfile: str | None = None, mapfile: str | None = None
) -&gt; str:
    """Generates a graph file.

    :param str outputfile: filename and path [defaults to graphname.png]
    :param str mapfile: filename and path

    :rtype: str
    :return: a path to the generated file
    :raises RuntimeError: if the executable for rendering was not found
    """
    # pylint: disable=duplicate-code
    graphviz_extensions = ("dot", "gv")
    name = self.graphname
    if outputfile is None:
        target = "png"
        pdot, dot_sourcepath = tempfile.mkstemp(".gv", name)
        ppng, outputfile = tempfile.mkstemp(".png", name)
        os.close(pdot)
        os.close(ppng)
    else:
        _, _, target = target_info_from_filename(outputfile)
        if not target:
            target = "png"
            outputfile = outputfile + "." + target
        if target not in graphviz_extensions:
            pdot, dot_sourcepath = tempfile.mkstemp(".gv", name)
            os.close(pdot)
        else:
            dot_sourcepath = outputfile
    with codecs.open(dot_sourcepath, "w", encoding="utf8") as file:
        file.write(self.source)
    if target not in graphviz_extensions:
        if shutil.which(self.renderer) is None:
            raise RuntimeError(
                f"Cannot generate `{outputfile}` because '{self.renderer}' "
                "executable not found. Install graphviz, or specify a `.gv` "
                "outputfile to produce the DOT source code."
            )
        if mapfile:
            subprocess.run(
                [
                    self.renderer,
                    "-Tcmapx",
                    "-o",
                    mapfile,
                    "-T",
                    target,
                    dot_sourcepath,
                    "-o",
                    outputfile,
                ],
                check=True,
            )
        else:
            subprocess.run(
                [self.renderer, "-T", target, dot_sourcepath, "-o", outputfile],
                check=True,
            )
        os.unlink(dot_sourcepath)
    return outputfile

</t>
<t tx="ekr.20250131013559.272">def emit(self, line: str) -&gt; None:
    """Adds &lt;line&gt; to final output."""
    self.lines.append(line)

</t>
<t tx="ekr.20250131013559.273">def emit_edge(self, name1: str, name2: str, **props: Any) -&gt; None:
    """Emit an edge from &lt;name1&gt; to &lt;name2&gt;.

    For edge properties: see https://www.graphviz.org/doc/info/attrs.html
    """
    attrs = [f'{prop}="{value}"' for prop, value in props.items()]
    n_from, n_to = normalize_node_id(name1), normalize_node_id(name2)
    self.emit(f"{n_from} -&gt; {n_to} [{', '.join(sorted(attrs))}];")

</t>
<t tx="ekr.20250131013559.274">def emit_node(self, name: str, **props: Any) -&gt; None:
    """Emit a node with given properties.

    For node properties: see https://www.graphviz.org/doc/info/attrs.html
    """
    attrs = [f'{prop}="{value}"' for prop, value in props.items()]
    self.emit(f"{normalize_node_id(name)} [{', '.join(sorted(attrs))}];")


</t>
<t tx="ekr.20250131013559.275">@path pylint
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

from typing import NamedTuple

__all__ = (
    "CONFIDENCE_LEVELS",
    "CONFIDENCE_LEVEL_NAMES",
    "CONTROL_FLOW",
    "HIGH",
    "INFERENCE",
    "INFERENCE_FAILURE",
    "UNDEFINED",
)


@others
# Warning Certainties
HIGH = Confidence("HIGH", "Warning that is not based on inference result.")
CONTROL_FLOW = Confidence(
    "CONTROL_FLOW", "Warning based on assumptions about control flow."
)
INFERENCE = Confidence("INFERENCE", "Warning based on inference result.")
INFERENCE_FAILURE = Confidence(
    "INFERENCE_FAILURE", "Warning based on inference with failures."
)
UNDEFINED = Confidence("UNDEFINED", "Warning without any associated confidence level.")

CONFIDENCE_LEVELS = [HIGH, CONTROL_FLOW, INFERENCE, INFERENCE_FAILURE, UNDEFINED]
CONFIDENCE_LEVEL_NAMES = [i.name for i in CONFIDENCE_LEVELS]
CONFIDENCE_MAP = {i.name: i for i in CONFIDENCE_LEVELS}
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013559.276">class Confidence(NamedTuple):
    name: str
    description: str


</t>
<t tx="ekr.20250131013559.277">@path pylint
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""A collection of typing utilities."""

from __future__ import annotations

import argparse
from collections.abc import Iterable
from pathlib import Path
from re import Pattern
from typing import (
    TYPE_CHECKING,
    Any,
    Callable,
    Literal,
    NamedTuple,
    Optional,
    Protocol,
    TypedDict,
    Union,
)

if TYPE_CHECKING:
    from pylint.config.callback_actions import _CallbackAction
    from pylint.pyreverse.inspector import Project
    from pylint.reporters.ureports.nodes import Section
    from pylint.utils import LinterStats


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013559.278">class FileItem(NamedTuple):
    """Represents data about a file handled by pylint.

    Each file item has:
    - name: full name of the module
    - filepath: path of the file
    - modname: module name
    """

    name: str
    filepath: str
    modpath: str


</t>
<t tx="ekr.20250131013559.279">class ModuleDescriptionDict(TypedDict):
    """Represents data about a checked module."""

    path: str
    name: str
    isarg: bool
    basepath: str
    basename: str
    isignored: bool


</t>
<t tx="ekr.20250131013559.280">class ErrorDescriptionDict(TypedDict):
    """Represents data about errors collected during checking of a module."""

    key: Literal["fatal"]
    mod: str
    ex: ImportError | SyntaxError


</t>
<t tx="ekr.20250131013559.281">class MessageLocationTuple(NamedTuple):
    """Tuple with information about the location of a to-be-displayed message."""

    abspath: str
    path: str
    module: str
    obj: str
    line: int
    column: int
    end_line: int | None = None
    end_column: int | None = None


</t>
<t tx="ekr.20250131013559.282">class ManagedMessage(NamedTuple):
    """Tuple with information about a managed message of the linter."""

    name: str | None
    msgid: str
    symbol: str
    line: int | None
    is_disabled: bool


</t>
<t tx="ekr.20250131013559.283">MessageTypesFullName = Literal[
    "convention", "error", "fatal", "info", "refactor", "statement", "warning"
]
"""All possible message categories."""


OptionDict = dict[
    str,
    Union[
        None,
        str,
        bool,
        int,
        Pattern[str],
        Iterable[Union[str, int, Pattern[str]]],
        type["_CallbackAction"],
        Callable[[Any], Any],
        Callable[[Any, Any, Any, Any], Any],
    ],
]
Options = tuple[tuple[str, OptionDict], ...]


ReportsCallable = Callable[["Section", "LinterStats", Optional["LinterStats"]], None]
"""Callable to create a report."""


class ExtraMessageOptions(TypedDict, total=False):
    """All allowed keys in the extra options for message definitions."""

    scope: str
    old_names: list[tuple[str, str]]
    maxversion: tuple[int, int]
    minversion: tuple[int, int]
    shared: bool
    default_enabled: bool


</t>
<t tx="ekr.20250131013559.284">MessageDefinitionTuple = Union[
    tuple[str, str, str],
    tuple[str, str, str, ExtraMessageOptions],
]
DirectoryNamespaceDict = dict[Path, tuple[argparse.Namespace, "DirectoryNamespaceDict"]]


class GetProjectCallable(Protocol):
    @others
</t>
<t tx="ekr.20250131013559.285">def __call__(
    self, module: str, name: str | None = "No Name"
) -&gt; Project: ...  # pragma: no cover
</t>
<t tx="ekr.20250131013559.286"></t>
<t tx="ekr.20250131013559.287">@path pylint/checkers
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Utilities methods and classes for checkers.

Base id of standard checkers (used in msg and report ids):
01: base
02: classes
03: format
04: import
05: misc
06: variables
07: exceptions
08: similar
09: design_analysis
10: newstyle
11: typecheck
12: logging
13: string_format
14: string_constant
15: stdlib
16: python3 (This one was deleted but needs to be reserved for consistency with old messages)
17: refactoring
.
.
.
24: non-ascii-names
25: unicode
26: unsupported_version
27: private-import
28-50: not yet used: reserved for future internal checkers.
This file is not updated. Use
   script/get_unused_message_id_category.py
to get the next free checker id.

51-99: perhaps used: reserved for external checkers

The raw_metrics checker has no number associated since it doesn't emit any
messages nor reports. XXX not true, emit a 07 report !
"""

from __future__ import annotations

from typing import TYPE_CHECKING, Literal

from pylint.checkers.base_checker import (
    BaseChecker,
    BaseRawFileChecker,
    BaseTokenChecker,
)
from pylint.checkers.deprecated import DeprecatedMixin
from pylint.utils import LinterStats, diff_string, register_plugins

if TYPE_CHECKING:
    from pylint.lint import PyLinter


@others
__all__ = [
    "BaseChecker",
    "BaseRawFileChecker",
    "BaseTokenChecker",
    "DeprecatedMixin",
    "initialize",
    "register_plugins",
]
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013559.288">def table_lines_from_stats(
    stats: LinterStats,
    old_stats: LinterStats | None,
    stat_type: Literal["duplicated_lines", "message_types"],
) -&gt; list[str]:
    """Get values listed in &lt;columns&gt; from &lt;stats&gt; and &lt;old_stats&gt;,
    and return a formatted list of values.

    The return value is designed to be given to a ureport.Table object
    """
    lines: list[str] = []
    if stat_type == "duplicated_lines":
        new: list[tuple[str, int | float]] = [
            ("nb_duplicated_lines", stats.duplicated_lines["nb_duplicated_lines"]),
            (
                "percent_duplicated_lines",
                stats.duplicated_lines["percent_duplicated_lines"],
            ),
        ]
        if old_stats:
            old: list[tuple[str, str | int | float]] = [
                (
                    "nb_duplicated_lines",
                    old_stats.duplicated_lines["nb_duplicated_lines"],
                ),
                (
                    "percent_duplicated_lines",
                    old_stats.duplicated_lines["percent_duplicated_lines"],
                ),
            ]
        else:
            old = [("nb_duplicated_lines", "NC"), ("percent_duplicated_lines", "NC")]
    elif stat_type == "message_types":
        new = [
            ("convention", stats.convention),
            ("refactor", stats.refactor),
            ("warning", stats.warning),
            ("error", stats.error),
        ]
        if old_stats:
            old = [
                ("convention", old_stats.convention),
                ("refactor", old_stats.refactor),
                ("warning", old_stats.warning),
                ("error", old_stats.error),
            ]
        else:
            old = [
                ("convention", "NC"),
                ("refactor", "NC"),
                ("warning", "NC"),
                ("error", "NC"),
            ]

    # pylint: disable=possibly-used-before-assignment
    for index, value in enumerate(new):
        new_value = value[1]
        old_value = old[index][1]
        diff_str = (
            diff_string(old_value, new_value)
            if isinstance(old_value, float)
            else old_value
        )
        new_str = f"{new_value:.3f}" if isinstance(new_value, float) else str(new_value)
        old_str = f"{old_value:.3f}" if isinstance(old_value, float) else str(old_value)
        lines.extend((value[0].replace("_", " "), new_str, old_str, diff_str))  # type: ignore[arg-type]
    return lines


</t>
<t tx="ekr.20250131013559.289">def initialize(linter: PyLinter) -&gt; None:
    """Initialize linter with checkers in this package."""
    register_plugins(linter, __path__[0])


</t>
<t tx="ekr.20250131013559.290">@path pylint/checkers
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Checker for anything related to the async protocol (PEP 492)."""

from __future__ import annotations

import sys
from typing import TYPE_CHECKING

import astroid
from astroid import nodes, util

from pylint import checkers
from pylint.checkers import utils as checker_utils
from pylint.checkers.utils import decorated_with

if TYPE_CHECKING:
    from pylint.lint import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013559.291">class AsyncChecker(checkers.BaseChecker):
    @others
</t>
<t tx="ekr.20250131013559.292">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(AsyncChecker(linter))
</t>
<t tx="ekr.20250131013559.293">name = "async"
msgs = {
    "E1700": (
        "Yield inside async function",
        "yield-inside-async-function",
        "Used when an `yield` or `yield from` statement is "
        "found inside an async function.",
        {"minversion": (3, 5)},
    ),
    "E1701": (
        "Async context manager '%s' doesn't implement __aenter__ and __aexit__.",
        "not-async-context-manager",
        "Used when an async context manager is used with an object "
        "that does not implement the async context management protocol.",
        {"minversion": (3, 5)},
    ),
}

def open(self) -&gt; None:
    self._mixin_class_rgx = self.linter.config.mixin_class_rgx
    self._async_generators = ["contextlib.asynccontextmanager"]

</t>
<t tx="ekr.20250131013559.294">@checker_utils.only_required_for_messages("yield-inside-async-function")
def visit_asyncfunctiondef(self, node: nodes.AsyncFunctionDef) -&gt; None:
    for child in node.nodes_of_class(nodes.Yield):
        if child.scope() is node and (
            sys.version_info[:2] == (3, 5) or isinstance(child, nodes.YieldFrom)
        ):
            self.add_message("yield-inside-async-function", node=child)

</t>
<t tx="ekr.20250131013559.295">@checker_utils.only_required_for_messages("not-async-context-manager")
def visit_asyncwith(self, node: nodes.AsyncWith) -&gt; None:
    for ctx_mgr, _ in node.items:
        inferred = checker_utils.safe_infer(ctx_mgr)
        if inferred is None or isinstance(inferred, util.UninferableBase):
            continue

        if isinstance(inferred, nodes.AsyncFunctionDef):
            # Check if we are dealing with a function decorated
            # with contextlib.asynccontextmanager.
            if decorated_with(inferred, self._async_generators):
                continue
        elif isinstance(inferred, astroid.bases.AsyncGenerator):
            # Check if we are dealing with a function decorated
            # with contextlib.asynccontextmanager.
            if decorated_with(inferred.parent, self._async_generators):
                continue
        else:
            try:
                inferred.getattr("__aenter__")
                inferred.getattr("__aexit__")
            except astroid.exceptions.NotFoundError:
                if isinstance(inferred, astroid.Instance):
                    # If we do not know the bases of this class,
                    # just skip it.
                    if not checker_utils.has_known_bases(inferred):
                        continue
                    # Ignore mixin classes if they match the rgx option.
                    if (
                        "not-async-context-manager"
                        in self.linter.config.ignored_checks_for_mixins
                        and self._mixin_class_rgx.match(inferred.name)
                    ):
                        continue
            else:
                continue
        self.add_message(
            "not-async-context-manager", node=node, args=(inferred.name,)
        )


</t>
<t tx="ekr.20250131013559.296">@path pylint/checkers
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

from typing import TYPE_CHECKING

from astroid import nodes

from pylint.checkers import BaseChecker
from pylint.interfaces import HIGH

if TYPE_CHECKING:
    from pylint.lint import PyLinter

COMPARISON_OP = frozenset(("&lt;", "&lt;=", "&gt;", "&gt;=", "!=", "=="))
IDENTITY_OP = frozenset(("is", "is not"))
MEMBERSHIP_OP = frozenset(("in", "not in"))


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013559.297">class BadChainedComparisonChecker(BaseChecker):
    """Checks for unintentional usage of chained comparison."""

    @others
</t>
<t tx="ekr.20250131013559.298">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(BadChainedComparisonChecker(linter))
</t>
<t tx="ekr.20250131013559.299">name = "bad-chained-comparison"
msgs = {
    "W3601": (
        "Suspicious %s-part chained comparison using semantically incompatible operators (%s)",
        "bad-chained-comparison",
        "Used when there is a chained comparison where one expression is part "
        "of two comparisons that belong to different semantic groups "
        '("&lt;" does not mean the same thing as "is", chaining them in '
        '"0 &lt; x is None" is probably a mistake).',
    )
}

def _has_diff_semantic_groups(self, operators: list[str]) -&gt; bool:
    # Check if comparison operators are in the same semantic group
    for semantic_group in (COMPARISON_OP, IDENTITY_OP, MEMBERSHIP_OP):
        if operators[0] in semantic_group:
            group = semantic_group
    return not all(o in group for o in operators)

</t>
<t tx="ekr.20250131013559.300">def visit_compare(self, node: nodes.Compare) -&gt; None:
    operators = sorted({op[0] for op in node.ops})
    if self._has_diff_semantic_groups(operators):
        num_parts = f"{len(node.ops)}"
        incompatibles = (
            ", ".join(f"'{o}'" for o in operators[:-1]) + f" and '{operators[-1]}'"
        )
        self.add_message(
            "bad-chained-comparison",
            node=node,
            args=(num_parts, incompatibles),
            confidence=HIGH,
        )


</t>
<t tx="ekr.20250131013559.301">@path pylint/checkers
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import abc
import functools
from collections.abc import Iterable, Sequence
from inspect import cleandoc
from tokenize import TokenInfo
from typing import TYPE_CHECKING, Any

from astroid import nodes

from pylint.config.arguments_provider import _ArgumentsProvider
from pylint.constants import _MSG_ORDER, MAIN_CHECKER_NAME, WarningScope
from pylint.exceptions import InvalidMessageError
from pylint.interfaces import Confidence
from pylint.message.message_definition import MessageDefinition
from pylint.typing import (
    ExtraMessageOptions,
    MessageDefinitionTuple,
    OptionDict,
    Options,
    ReportsCallable,
)
from pylint.utils import get_rst_section, get_rst_title

if TYPE_CHECKING:
    from pylint.lint import PyLinter


@functools.total_ordering
@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013559.302">class BaseChecker(_ArgumentsProvider):
@others
</t>
<t tx="ekr.20250131013559.303">class BaseTokenChecker(BaseChecker):
    """Base class for checkers that want to have access to the token stream."""

    @others
</t>
<t tx="ekr.20250131013559.304">class BaseRawFileChecker(BaseChecker):
    """Base class for checkers which need to parse the raw file."""

    @others
</t>
<t tx="ekr.20250131013559.305">    # checker name (you may reuse an existing one)
    name: str = ""
    # ordered list of options to control the checker behaviour
    options: Options = ()
    # messages issued by this checker
    msgs: dict[str, MessageDefinitionTuple] = {}
    # reports issued by this checker
    reports: tuple[tuple[str, str, ReportsCallable], ...] = ()
    # mark this checker as enabled or not.
    enabled: bool = True

    def __init__(self, linter: PyLinter) -&gt; None:
        """Checker instances should have the linter as argument."""
        if self.name is not None:
            self.name = self.name.lower()
        self.linter = linter
        _ArgumentsProvider.__init__(self, linter)

</t>
<t tx="ekr.20250131013559.306">    def __gt__(self, other: Any) -&gt; bool:
        """Permits sorting checkers for stable doc and tests.

        The main checker is always the first one, then builtin checkers in alphabetical
        order, then extension checkers in alphabetical order.
        """
        if not isinstance(other, BaseChecker):
            return False
        if self.name == MAIN_CHECKER_NAME:
            return False
        if other.name == MAIN_CHECKER_NAME:
            return True
        self_is_builtin = type(self).__module__.startswith("pylint.checkers")
        if self_is_builtin ^ type(other).__module__.startswith("pylint.checkers"):
            return not self_is_builtin
        return self.name &gt; other.name

</t>
<t tx="ekr.20250131013559.307">    def __eq__(self, other: object) -&gt; bool:
        """Permit to assert Checkers are equal."""
        if not isinstance(other, BaseChecker):
            return False
        return f"{self.name}{self.msgs}" == f"{other.name}{other.msgs}"

</t>
<t tx="ekr.20250131013559.308">    def __hash__(self) -&gt; int:
        """Make Checker hashable."""
        return hash(f"{self.name}{self.msgs}")

</t>
<t tx="ekr.20250131013559.309">    def __repr__(self) -&gt; str:
        status = "Checker" if self.enabled else "Disabled checker"
        msgs = "', '".join(self.msgs.keys())
        return f"{status} '{self.name}' (responsible for '{msgs}')"

</t>
<t tx="ekr.20250131013559.310">    def __str__(self) -&gt; str:
        """This might be incomplete because multiple classes inheriting BaseChecker
        can have the same name.

        See: MessageHandlerMixIn.get_full_documentation()
        """
        return self.get_full_documentation(
            msgs=self.msgs, options=self._options_and_values(), reports=self.reports
        )

</t>
<t tx="ekr.20250131013559.311">    def get_full_documentation(
        self,
        msgs: dict[str, MessageDefinitionTuple],
        options: Iterable[tuple[str, OptionDict, Any]],
        reports: Sequence[tuple[str, str, ReportsCallable]],
        doc: str | None = None,
        module: str | None = None,
        show_options: bool = True,
    ) -&gt; str:
        result = ""
        checker_title = f"{self.name.replace('_', ' ').title()} checker"
        if module:
            # Provide anchor to link against
            result += f".. _{module}:\n\n"
        result += f"{get_rst_title(checker_title, '~')}\n"
        if module:
            result += f"This checker is provided by ``{module}``.\n"
        result += f"Verbatim name of the checker is ``{self.name}``.\n\n"
        if doc:
            # Provide anchor to link against
            result += get_rst_title(f"{checker_title} Documentation", "^")
            result += f"{cleandoc(doc)}\n\n"
        # options might be an empty generator and not be False when cast to boolean
        options_list = list(options)
        if options_list:
            if show_options:
                result += get_rst_title(f"{checker_title} Options", "^")
                result += f"{get_rst_section(None, options_list)}\n"
            else:
                result += f"See also :ref:`{self.name} checker's options' documentation &lt;{self.name}-options&gt;`\n\n"
        if msgs:
            result += get_rst_title(f"{checker_title} Messages", "^")
            for msgid, msg in sorted(
                msgs.items(), key=lambda kv: (_MSG_ORDER.index(kv[0][0]), kv[1])
            ):
                msg_def = self.create_message_definition_from_tuple(msgid, msg)
                result += f"{msg_def.format_help(checkerref=False)}\n"
            result += "\n"
        if reports:
            result += get_rst_title(f"{checker_title} Reports", "^")
            for report in reports:
                result += f":{report[0]}: {report[1]}\n"
            result += "\n"
        result += "\n"
        return result

</t>
<t tx="ekr.20250131013559.312">    def add_message(
        self,
        msgid: str,
        line: int | None = None,
        node: nodes.NodeNG | None = None,
        args: Any = None,
        confidence: Confidence | None = None,
        col_offset: int | None = None,
        end_lineno: int | None = None,
        end_col_offset: int | None = None,
    ) -&gt; None:
        self.linter.add_message(
            msgid, line, node, args, confidence, col_offset, end_lineno, end_col_offset
        )

</t>
<t tx="ekr.20250131013559.313">    def check_consistency(self) -&gt; None:
        """Check the consistency of msgid.

        msg ids for a checker should be a string of len 4, where the two first
        characters are the checker id and the two last the msg id in this
        checker.

        :raises InvalidMessageError: If the checker id in the messages are not
        always the same.
        """
        checker_id = None
        existing_ids = []
        for message in self.messages:
            # Id's for shared messages such as the 'deprecated-*' messages
            # can be inconsistent with their checker id.
            if message.shared:
                continue
            if checker_id is not None and checker_id != message.msgid[1:3]:
                error_msg = "Inconsistent checker part in message id "
                error_msg += f"'{message.msgid}' (expected 'x{checker_id}xx' "
                error_msg += f"because we already had {existing_ids})."
                raise InvalidMessageError(error_msg)
            checker_id = message.msgid[1:3]
            existing_ids.append(message.msgid)

</t>
<t tx="ekr.20250131013559.314">    def create_message_definition_from_tuple(
        self, msgid: str, msg_tuple: MessageDefinitionTuple
    ) -&gt; MessageDefinition:
        if isinstance(self, (BaseTokenChecker, BaseRawFileChecker)):
            default_scope = WarningScope.LINE
        else:
            default_scope = WarningScope.NODE
        options: ExtraMessageOptions = {}
        if len(msg_tuple) == 4:
            (msg, symbol, descr, msg_options) = msg_tuple
            options = ExtraMessageOptions(**msg_options)
        elif len(msg_tuple) == 3:
            (msg, symbol, descr) = msg_tuple
        else:
            error_msg = """Messages should have a msgid, a symbol and a description. Something like this :

"W1234": (
    "message",
    "message-symbol",
    "Message description with detail.",
    ...
),
"""
            raise InvalidMessageError(error_msg)
        options.setdefault("scope", default_scope)
        return MessageDefinition(self, msgid, msg, descr, symbol, **options)

</t>
<t tx="ekr.20250131013559.315">    @property
    def messages(self) -&gt; list[MessageDefinition]:
        return [
            self.create_message_definition_from_tuple(msgid, msg_tuple)
            for msgid, msg_tuple in sorted(self.msgs.items())
        ]

</t>
<t tx="ekr.20250131013559.316">    def open(self) -&gt; None:
        """Called before visiting project (i.e. set of modules)."""

</t>
<t tx="ekr.20250131013559.317">    def close(self) -&gt; None:
        """Called after visiting project (i.e set of modules)."""

</t>
<t tx="ekr.20250131013559.318">    def get_map_data(self) -&gt; Any:
        return None

</t>
<t tx="ekr.20250131013559.319">    # pylint: disable-next=unused-argument
    def reduce_map_data(self, linter: PyLinter, data: list[Any]) -&gt; None:
        return None


</t>
<t tx="ekr.20250131013559.320">@abc.abstractmethod
def process_tokens(self, tokens: list[TokenInfo]) -&gt; None:
    """Should be overridden by subclasses."""
    raise NotImplementedError()


</t>
<t tx="ekr.20250131013559.321">@abc.abstractmethod
def process_module(self, node: nodes.Module) -&gt; None:
    """Process a module.

    The module's content is accessible via ``astroid.stream``
    """
    raise NotImplementedError()
</t>
<t tx="ekr.20250131013559.322">@path pylint/checkers
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Dataclass checkers for Python code."""

from __future__ import annotations

from typing import TYPE_CHECKING

from astroid import nodes
from astroid.brain.brain_dataclasses import DATACLASS_MODULES

from pylint.checkers import BaseChecker, utils
from pylint.interfaces import INFERENCE

if TYPE_CHECKING:
    from pylint.lint import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013559.323">def _is_dataclasses_module(node: nodes.Module) -&gt; bool:
    """Utility function to check if node is from dataclasses_module."""
    return node.name in DATACLASS_MODULES


</t>
<t tx="ekr.20250131013559.324">def _check_name_or_attrname_eq_to(
    node: nodes.Name | nodes.Attribute, check_with: str
) -&gt; bool:
    """Utility function to check either a Name/Attribute node's name/attrname with a
    given string.
    """
    if isinstance(node, nodes.Name):
        return str(node.name) == check_with
    return str(node.attrname) == check_with


</t>
<t tx="ekr.20250131013559.325">class DataclassChecker(BaseChecker):
    """Checker that detects invalid or problematic usage in dataclasses.

    Checks for
    * invalid-field-call
    """

    @others
</t>
<t tx="ekr.20250131013559.326">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(DataclassChecker(linter))
</t>
<t tx="ekr.20250131013559.327">name = "dataclass"
msgs = {
    "E3701": (
        "Invalid usage of field(), %s",
        "invalid-field-call",
        "The dataclasses.field() specifier should only be used as the value of "
        "an assignment within a dataclass, or within the make_dataclass() function.",
    ),
}

@utils.only_required_for_messages("invalid-field-call")
def visit_call(self, node: nodes.Call) -&gt; None:
    self._check_invalid_field_call(node)

</t>
<t tx="ekr.20250131013559.328">def _check_invalid_field_call(self, node: nodes.Call) -&gt; None:
    """Checks for correct usage of the dataclasses.field() specifier in
    dataclasses or within the make_dataclass() function.

    Emits message
    when field() is detected to be used outside a class decorated with
    @dataclass decorator and outside make_dataclass() function, or when it
    is used improperly within a dataclass.
    """
    if not isinstance(node.func, (nodes.Name, nodes.Attribute)):
        return
    if not _check_name_or_attrname_eq_to(node.func, "field"):
        return
    inferred_func = utils.safe_infer(node.func)
    if not (
        isinstance(inferred_func, nodes.FunctionDef)
        and _is_dataclasses_module(inferred_func.root())
    ):
        return
    scope_node = node.parent
    while scope_node and not isinstance(scope_node, (nodes.ClassDef, nodes.Call)):
        scope_node = scope_node.parent

    if isinstance(scope_node, nodes.Call):
        self._check_invalid_field_call_within_call(node, scope_node)
        return

    if not scope_node or not scope_node.is_dataclass:
        self.add_message(
            "invalid-field-call",
            node=node,
            args=(
                "it should be used within a dataclass or the make_dataclass() function.",
            ),
            confidence=INFERENCE,
        )
        return

    if not (isinstance(node.parent, nodes.AnnAssign) and node == node.parent.value):
        self.add_message(
            "invalid-field-call",
            node=node,
            args=("it should be the value of an assignment within a dataclass.",),
            confidence=INFERENCE,
        )

</t>
<t tx="ekr.20250131013559.329">def _check_invalid_field_call_within_call(
    self, node: nodes.Call, scope_node: nodes.Call
) -&gt; None:
    """Checks for special case where calling field is valid as an argument of the
    make_dataclass() function.
    """
    inferred_func = utils.safe_infer(scope_node.func)
    if (
        isinstance(scope_node.func, (nodes.Name, nodes.AssignName))
        and scope_node.func.name == "make_dataclass"
        and isinstance(inferred_func, nodes.FunctionDef)
        and _is_dataclasses_module(inferred_func.root())
    ):
        return
    self.add_message(
        "invalid-field-call",
        node=node,
        args=(
            "it should be used within a dataclass or the make_dataclass() function.",
        ),
        confidence=INFERENCE,
    )


</t>
<t tx="ekr.20250131013559.330">@path pylint/checkers
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Checker mixin for deprecated functionality."""

from __future__ import annotations

from collections.abc import Container, Iterable
from itertools import chain

import astroid
from astroid import nodes
from astroid.bases import Instance

from pylint.checkers import utils
from pylint.checkers.base_checker import BaseChecker
from pylint.checkers.utils import get_import_name, infer_all, safe_infer
from pylint.interfaces import INFERENCE
from pylint.typing import MessageDefinitionTuple

ACCEPTABLE_NODES = (
    astroid.BoundMethod,
    astroid.UnboundMethod,
    nodes.FunctionDef,
    nodes.ClassDef,
    astroid.Attribute,
)


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013559.331">class DeprecatedMixin(BaseChecker):
    """A mixin implementing logic for checking deprecated symbols.

    A class implementing mixin must define "deprecated-method" Message.
    """

    @others
</t>
<t tx="ekr.20250131013559.332">DEPRECATED_ATTRIBUTE_MESSAGE: dict[str, MessageDefinitionTuple] = {
    "W4906": (
        "Using deprecated attribute %r",
        "deprecated-attribute",
        "The attribute is marked as deprecated and will be removed in the future.",
        {"shared": True},
    ),
}

DEPRECATED_MODULE_MESSAGE: dict[str, MessageDefinitionTuple] = {
    "W4901": (
        "Deprecated module %r",
        "deprecated-module",
        "A module marked as deprecated is imported.",
        {"old_names": [("W0402", "old-deprecated-module")], "shared": True},
    ),
}

DEPRECATED_METHOD_MESSAGE: dict[str, MessageDefinitionTuple] = {
    "W4902": (
        "Using deprecated method %s()",
        "deprecated-method",
        "The method is marked as deprecated and will be removed in the future.",
        {"old_names": [("W1505", "old-deprecated-method")], "shared": True},
    ),
}

DEPRECATED_ARGUMENT_MESSAGE: dict[str, MessageDefinitionTuple] = {
    "W4903": (
        "Using deprecated argument %s of method %s()",
        "deprecated-argument",
        "The argument is marked as deprecated and will be removed in the future.",
        {"old_names": [("W1511", "old-deprecated-argument")], "shared": True},
    ),
}

DEPRECATED_CLASS_MESSAGE: dict[str, MessageDefinitionTuple] = {
    "W4904": (
        "Using deprecated class %s of module %s",
        "deprecated-class",
        "The class is marked as deprecated and will be removed in the future.",
        {"old_names": [("W1512", "old-deprecated-class")], "shared": True},
    ),
}

DEPRECATED_DECORATOR_MESSAGE: dict[str, MessageDefinitionTuple] = {
    "W4905": (
        "Using deprecated decorator %s()",
        "deprecated-decorator",
        "The decorator is marked as deprecated and will be removed in the future.",
        {"old_names": [("W1513", "old-deprecated-decorator")], "shared": True},
    ),
}

@utils.only_required_for_messages("deprecated-attribute")
def visit_attribute(self, node: astroid.Attribute) -&gt; None:
    """Called when an `astroid.Attribute` node is visited."""
    self.check_deprecated_attribute(node)

</t>
<t tx="ekr.20250131013559.333">@utils.only_required_for_messages(
    "deprecated-method",
    "deprecated-argument",
    "deprecated-class",
)
def visit_call(self, node: nodes.Call) -&gt; None:
    """Called when a :class:`nodes.Call` node is visited."""
    self.check_deprecated_class_in_call(node)
    for inferred in infer_all(node.func):
        # Calling entry point for deprecation check logic.
        self.check_deprecated_method(node, inferred)

</t>
<t tx="ekr.20250131013559.334">@utils.only_required_for_messages(
    "deprecated-module",
    "deprecated-class",
)
def visit_import(self, node: nodes.Import) -&gt; None:
    """Triggered when an import statement is seen."""
    for name in (name for name, _ in node.names):
        self.check_deprecated_module(node, name)
        if "." in name:
            # Checking deprecation for import module with class
            mod_name, class_name = name.split(".", 1)
            self.check_deprecated_class(node, mod_name, (class_name,))

</t>
<t tx="ekr.20250131013559.335">def deprecated_decorators(self) -&gt; Iterable[str]:
    """Callback returning the deprecated decorators.

    Returns:
        collections.abc.Container of deprecated decorator names.
    """
    return ()

</t>
<t tx="ekr.20250131013559.336">@utils.only_required_for_messages("deprecated-decorator")
def visit_decorators(self, node: nodes.Decorators) -&gt; None:
    """Triggered when a decorator statement is seen."""
    children = list(node.get_children())
    if not children:
        return
    if isinstance(children[0], nodes.Call):
        inferred = safe_infer(children[0].func)
    else:
        inferred = safe_infer(children[0])
    if not inferred:
        return
    qname = inferred.qname()
    if qname in self.deprecated_decorators():
        self.add_message("deprecated-decorator", node=node, args=qname)

</t>
<t tx="ekr.20250131013559.337">@utils.only_required_for_messages(
    "deprecated-module",
    "deprecated-class",
)
def visit_importfrom(self, node: nodes.ImportFrom) -&gt; None:
    """Triggered when a from statement is seen."""
    basename = node.modname
    basename = get_import_name(node, basename)
    self.check_deprecated_module(node, basename)
    class_names = (name for name, _ in node.names)
    self.check_deprecated_class(node, basename, class_names)

</t>
<t tx="ekr.20250131013559.338">def deprecated_methods(self) -&gt; Container[str]:
    """Callback returning the deprecated methods/functions.

    Returns:
        collections.abc.Container of deprecated function/method names.
    """
    return ()

</t>
<t tx="ekr.20250131013559.339">def deprecated_arguments(self, method: str) -&gt; Iterable[tuple[int | None, str]]:
    """Callback returning the deprecated arguments of method/function.

    Args:
        method (str): name of function/method checked for deprecated arguments

    Returns:
        collections.abc.Iterable in form:
            ((POSITION1, PARAM1), (POSITION2: PARAM2) ...)
        where
            * POSITIONX - position of deprecated argument PARAMX in function definition.
              If argument is keyword-only, POSITIONX should be None.
            * PARAMX - name of the deprecated argument.
        E.g. suppose function:

        .. code-block:: python
            def bar(arg1, arg2, arg3, arg4, arg5='spam')

        with deprecated arguments `arg2` and `arg4`. `deprecated_arguments` should return:

        .. code-block:: python
            ((1, 'arg2'), (3, 'arg4'))
    """
    # pylint: disable=unused-argument
    return ()

</t>
<t tx="ekr.20250131013559.340">def deprecated_modules(self) -&gt; Iterable[str]:
    """Callback returning the deprecated modules.

    Returns:
        collections.abc.Container of deprecated module names.
    """
    return ()

</t>
<t tx="ekr.20250131013559.341">def deprecated_classes(self, module: str) -&gt; Iterable[str]:
    """Callback returning the deprecated classes of module.

    Args:
        module (str): name of module checked for deprecated classes

    Returns:
        collections.abc.Container of deprecated class names.
    """
    # pylint: disable=unused-argument
    return ()

</t>
<t tx="ekr.20250131013559.342">def deprecated_attributes(self) -&gt; Iterable[str]:
    """Callback returning the deprecated attributes."""
    return ()

</t>
<t tx="ekr.20250131013559.343">def check_deprecated_attribute(self, node: astroid.Attribute) -&gt; None:
    """Checks if the attribute is deprecated."""
    inferred_expr = safe_infer(node.expr)
    if not isinstance(inferred_expr, (nodes.ClassDef, Instance, nodes.Module)):
        return
    attribute_qname = ".".join((inferred_expr.qname(), node.attrname))
    for deprecated_name in self.deprecated_attributes():
        if attribute_qname == deprecated_name:
            self.add_message(
                "deprecated-attribute",
                node=node,
                args=(attribute_qname,),
                confidence=INFERENCE,
            )

</t>
<t tx="ekr.20250131013559.344">def check_deprecated_module(self, node: nodes.Import, mod_path: str | None) -&gt; None:
    """Checks if the module is deprecated."""
    for mod_name in self.deprecated_modules():
        if mod_path == mod_name or (
            mod_path and mod_path.startswith(mod_name + ".")
        ):
            self.add_message("deprecated-module", node=node, args=mod_path)

</t>
<t tx="ekr.20250131013559.345">def check_deprecated_method(self, node: nodes.Call, inferred: nodes.NodeNG) -&gt; None:
    """Executes the checker for the given node.

    This method should be called from the checker implementing this mixin.
    """
    # Reject nodes which aren't of interest to us.
    if not isinstance(inferred, ACCEPTABLE_NODES):
        return

    if isinstance(node.func, nodes.Attribute):
        func_name = node.func.attrname
    elif isinstance(node.func, nodes.Name):
        func_name = node.func.name
    else:
        # Not interested in other nodes.
        return

    qnames = {inferred.qname(), func_name}
    if any(name in self.deprecated_methods() for name in qnames):
        self.add_message("deprecated-method", node=node, args=(func_name,))
        return
    num_of_args = len(node.args)
    kwargs = {kw.arg for kw in node.keywords} if node.keywords else {}
    deprecated_arguments = (self.deprecated_arguments(qn) for qn in qnames)
    for position, arg_name in chain(*deprecated_arguments):
        if arg_name in kwargs:
            # function was called with deprecated argument as keyword argument
            self.add_message(
                "deprecated-argument", node=node, args=(arg_name, func_name)
            )
        elif position is not None and position &lt; num_of_args:
            # function was called with deprecated argument as positional argument
            self.add_message(
                "deprecated-argument", node=node, args=(arg_name, func_name)
            )

</t>
<t tx="ekr.20250131013559.346">def check_deprecated_class(
    self, node: nodes.NodeNG, mod_name: str, class_names: Iterable[str]
) -&gt; None:
    """Checks if the class is deprecated."""
    for class_name in class_names:
        if class_name in self.deprecated_classes(mod_name):
            self.add_message(
                "deprecated-class", node=node, args=(class_name, mod_name)
            )

</t>
<t tx="ekr.20250131013559.347">def check_deprecated_class_in_call(self, node: nodes.Call) -&gt; None:
    """Checks if call the deprecated class."""
    if isinstance(node.func, nodes.Attribute) and isinstance(
        node.func.expr, nodes.Name
    ):
        mod_name = node.func.expr.name
        class_name = node.func.attrname
        self.check_deprecated_class(node, mod_name, (class_name,))
</t>
<t tx="ekr.20250131013559.348">@path pylint/checkers
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Check for signs of poor design."""

from __future__ import annotations

import re
from collections import defaultdict
from collections.abc import Iterator
from typing import TYPE_CHECKING

import astroid
from astroid import nodes

from pylint.checkers import BaseChecker
from pylint.checkers.utils import is_enum, only_required_for_messages
from pylint.interfaces import HIGH
from pylint.typing import MessageDefinitionTuple

if TYPE_CHECKING:
    from pylint.lint import PyLinter

MSGS: dict[str, MessageDefinitionTuple] = (
    {  # pylint: disable=consider-using-namedtuple-or-dataclass
        "R0901": (
            "Too many ancestors (%s/%s)",
            "too-many-ancestors",
            "Used when class has too many parent classes, try to reduce "
            "this to get a simpler (and so easier to use) class.",
        ),
        "R0902": (
            "Too many instance attributes (%s/%s)",
            "too-many-instance-attributes",
            "Used when class has too many instance attributes, try to reduce "
            "this to get a simpler (and so easier to use) class.",
        ),
        "R0903": (
            "Too few public methods (%s/%s)",
            "too-few-public-methods",
            "Used when class has too few public methods, so be sure it's "
            "really worth it.",
        ),
        "R0904": (
            "Too many public methods (%s/%s)",
            "too-many-public-methods",
            "Used when class has too many public methods, try to reduce "
            "this to get a simpler (and so easier to use) class.",
        ),
        "R0911": (
            "Too many return statements (%s/%s)",
            "too-many-return-statements",
            "Used when a function or method has too many return statement, "
            "making it hard to follow.",
        ),
        "R0912": (
            "Too many branches (%s/%s)",
            "too-many-branches",
            "Used when a function or method has too many branches, "
            "making it hard to follow.",
        ),
        "R0913": (
            "Too many arguments (%s/%s)",
            "too-many-arguments",
            "Used when a function or method takes too many arguments.",
        ),
        "R0914": (
            "Too many local variables (%s/%s)",
            "too-many-locals",
            "Used when a function or method has too many local variables.",
        ),
        "R0915": (
            "Too many statements (%s/%s)",
            "too-many-statements",
            "Used when a function or method has too many statements. You "
            "should then split it in smaller functions / methods.",
        ),
        "R0916": (
            "Too many boolean expressions in if statement (%s/%s)",
            "too-many-boolean-expressions",
            "Used when an if statement contains too many boolean expressions.",
        ),
        "R0917": (
            "Too many positional arguments (%s/%s)",
            "too-many-positional-arguments",
            "Used when a function has too many positional arguments.",
        ),
    }
)
SPECIAL_OBJ = re.compile("^_{2}[a-z]+_{2}$")
DATACLASSES_DECORATORS = frozenset({"dataclass", "attrs"})
DATACLASS_IMPORT = "dataclasses"
ATTRS_DECORATORS = frozenset({"define", "frozen"})
ATTRS_IMPORT = "attrs"
TYPING_NAMEDTUPLE = "typing.NamedTuple"
TYPING_TYPEDDICT = "typing.TypedDict"
TYPING_EXTENSIONS_TYPEDDICT = "typing_extensions.TypedDict"

# Set of stdlib classes to ignore when calculating number of ancestors
STDLIB_CLASSES_IGNORE_ANCESTOR = frozenset(
    (
        "builtins.object",
        "builtins.tuple",
        "builtins.dict",
        "builtins.list",
        "builtins.set",
        "bulitins.frozenset",
        "collections.ChainMap",
        "collections.Counter",
        "collections.OrderedDict",
        "collections.UserDict",
        "collections.UserList",
        "collections.UserString",
        "collections.defaultdict",
        "collections.deque",
        "collections.namedtuple",
        "_collections_abc.Awaitable",
        "_collections_abc.Coroutine",
        "_collections_abc.AsyncIterable",
        "_collections_abc.AsyncIterator",
        "_collections_abc.AsyncGenerator",
        "_collections_abc.Hashable",
        "_collections_abc.Iterable",
        "_collections_abc.Iterator",
        "_collections_abc.Generator",
        "_collections_abc.Reversible",
        "_collections_abc.Sized",
        "_collections_abc.Container",
        "_collections_abc.Collection",
        "_collections_abc.Set",
        "_collections_abc.MutableSet",
        "_collections_abc.Mapping",
        "_collections_abc.MutableMapping",
        "_collections_abc.MappingView",
        "_collections_abc.KeysView",
        "_collections_abc.ItemsView",
        "_collections_abc.ValuesView",
        "_collections_abc.Sequence",
        "_collections_abc.MutableSequence",
        "_collections_abc.ByteString",
        "typing.Tuple",
        "typing.List",
        "typing.Dict",
        "typing.Set",
        "typing.FrozenSet",
        "typing.Deque",
        "typing.DefaultDict",
        "typing.OrderedDict",
        "typing.Counter",
        "typing.ChainMap",
        "typing.Awaitable",
        "typing.Coroutine",
        "typing.AsyncIterable",
        "typing.AsyncIterator",
        "typing.AsyncGenerator",
        "typing.Iterable",
        "typing.Iterator",
        "typing.Generator",
        "typing.Reversible",
        "typing.Container",
        "typing.Collection",
        "typing.AbstractSet",
        "typing.MutableSet",
        "typing.Mapping",
        "typing.MutableMapping",
        "typing.Sequence",
        "typing.MutableSequence",
        "typing.ByteString",
        "typing.MappingView",
        "typing.KeysView",
        "typing.ItemsView",
        "typing.ValuesView",
        "typing.ContextManager",
        "typing.AsyncContextManager",
        "typing.Hashable",
        "typing.Sized",
        TYPING_NAMEDTUPLE,
        TYPING_TYPEDDICT,
        TYPING_EXTENSIONS_TYPEDDICT,
    )
)


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013559.349">def _is_exempt_from_public_methods(node: astroid.ClassDef) -&gt; bool:
    """Check if a class is exempt from too-few-public-methods."""
    # If it's a typing.Namedtuple, typing.TypedDict or an Enum
    for ancestor in node.ancestors():
        if is_enum(ancestor):
            return True
        if ancestor.qname() in (
            TYPING_NAMEDTUPLE,
            TYPING_TYPEDDICT,
            TYPING_EXTENSIONS_TYPEDDICT,
        ):
            return True

    # Or if it's a dataclass
    if not node.decorators:
        return False

    root_locals = set(node.root().locals)
    for decorator in node.decorators.nodes:
        if isinstance(decorator, astroid.Call):
            decorator = decorator.func
        if not isinstance(decorator, (astroid.Name, astroid.Attribute)):
            continue
        if isinstance(decorator, astroid.Name):
            name = decorator.name
        else:
            name = decorator.attrname
        if name in DATACLASSES_DECORATORS and (
            root_locals.intersection(DATACLASSES_DECORATORS)
            or DATACLASS_IMPORT in root_locals
        ):
            return True
        if name in ATTRS_DECORATORS and (
            root_locals.intersection(ATTRS_DECORATORS) or ATTRS_IMPORT in root_locals
        ):
            return True
    return False


</t>
<t tx="ekr.20250131013559.350">def _count_boolean_expressions(bool_op: nodes.BoolOp) -&gt; int:
    """Counts the number of boolean expressions in BoolOp `bool_op` (recursive).

    example: a and (b or c or (d and e)) ==&gt; 5 boolean expressions
    """
    nb_bool_expr = 0
    for bool_expr in bool_op.get_children():
        if isinstance(bool_expr, astroid.BoolOp):
            nb_bool_expr += _count_boolean_expressions(bool_expr)
        else:
            nb_bool_expr += 1
    return nb_bool_expr


</t>
<t tx="ekr.20250131013559.351">def _count_methods_in_class(node: nodes.ClassDef) -&gt; int:
    all_methods = sum(1 for method in node.methods() if not method.name.startswith("_"))
    # Special methods count towards the number of public methods,
    # but don't count towards there being too many methods.
    for method in node.mymethods():
        if SPECIAL_OBJ.search(method.name) and method.name != "__init__":
            all_methods += 1
    return all_methods


</t>
<t tx="ekr.20250131013559.352">def _get_parents_iter(
    node: nodes.ClassDef, ignored_parents: frozenset[str]
) -&gt; Iterator[nodes.ClassDef]:
    r"""Get parents of ``node``, excluding ancestors of ``ignored_parents``.

    If we have the following inheritance diagram:

             F
            /
        D  E
         \/
          B  C
           \/
            A      # class A(B, C): ...

    And ``ignored_parents`` is ``{"E"}``, then this function will return
    ``{A, B, C, D}`` -- both ``E`` and its ancestors are excluded.
    """
    parents: set[nodes.ClassDef] = set()
    to_explore = list(node.ancestors(recurs=False))
    while to_explore:
        parent = to_explore.pop()
        if parent.qname() in ignored_parents:
            continue
        if parent not in parents:
            # This guard might appear to be performing the same function as
            # adding the resolved parents to a set to eliminate duplicates
            # (legitimate due to diamond inheritance patterns), but its
            # additional purpose is to prevent cycles (not normally possible,
            # but potential due to inference) and thus guarantee termination
            # of the while-loop
            yield parent
            parents.add(parent)
            to_explore.extend(parent.ancestors(recurs=False))


</t>
<t tx="ekr.20250131013559.353">def _get_parents(
    node: nodes.ClassDef, ignored_parents: frozenset[str]
) -&gt; set[nodes.ClassDef]:
    return set(_get_parents_iter(node, ignored_parents))


</t>
<t tx="ekr.20250131013559.354">class MisdesignChecker(BaseChecker):
    """Checker of potential misdesigns.

    Checks for sign of poor/misdesign:
    * number of methods, attributes, local variables...
    * size, complexity of functions, methods
    """

@others
</t>
<t tx="ekr.20250131013559.355">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(MisdesignChecker(linter))
</t>
<t tx="ekr.20250131013559.356">    # configuration section name
    name = "design"
    # messages
    msgs = MSGS
    # configuration options
    options = (
        (
            "max-args",
            {
                "default": 5,
                "type": "int",
                "metavar": "&lt;int&gt;",
                "help": "Maximum number of arguments for function / method.",
            },
        ),
        (
            "max-positional-arguments",
            {
                "default": 5,
                "type": "int",
                "metavar": "&lt;int&gt;",
                "help": "Maximum number of positional arguments for function / method.",
            },
        ),
        (
            "max-locals",
            {
                "default": 15,
                "type": "int",
                "metavar": "&lt;int&gt;",
                "help": "Maximum number of locals for function / method body.",
            },
        ),
        (
            "max-returns",
            {
                "default": 6,
                "type": "int",
                "metavar": "&lt;int&gt;",
                "help": "Maximum number of return / yield for function / "
                "method body.",
            },
        ),
        (
            "max-branches",
            {
                "default": 12,
                "type": "int",
                "metavar": "&lt;int&gt;",
                "help": "Maximum number of branch for function / method body.",
            },
        ),
        (
            "max-statements",
            {
                "default": 50,
                "type": "int",
                "metavar": "&lt;int&gt;",
                "help": "Maximum number of statements in function / method body.",
            },
        ),
        (
            "max-parents",
            {
                "default": 7,
                "type": "int",
                "metavar": "&lt;num&gt;",
                "help": "Maximum number of parents for a class (see R0901).",
            },
        ),
        (
            "ignored-parents",
            {
                "default": (),
                "type": "csv",
                "metavar": "&lt;comma separated list of class names&gt;",
                "help": "List of qualified class names to ignore when counting class parents (see R0901)",
            },
        ),
        (
            "max-attributes",
            {
                "default": 7,
                "type": "int",
                "metavar": "&lt;num&gt;",
                "help": "Maximum number of attributes for a class \
(see R0902).",
            },
        ),
        (
            "min-public-methods",
            {
                "default": 2,
                "type": "int",
                "metavar": "&lt;num&gt;",
                "help": "Minimum number of public methods for a class \
(see R0903).",
            },
        ),
        (
            "max-public-methods",
            {
                "default": 20,
                "type": "int",
                "metavar": "&lt;num&gt;",
                "help": "Maximum number of public methods for a class \
(see R0904).",
            },
        ),
        (
            "max-bool-expr",
            {
                "default": 5,
                "type": "int",
                "metavar": "&lt;num&gt;",
                "help": "Maximum number of boolean expressions in an if "
                "statement (see R0916).",
            },
        ),
        (
            "exclude-too-few-public-methods",
            {
                "default": [],
                "type": "regexp_csv",
                "metavar": "&lt;pattern&gt;[,&lt;pattern&gt;...]",
                "help": "List of regular expressions of class ancestor names "
                "to ignore when counting public methods (see R0903)",
            },
        ),
    )

    def __init__(self, linter: PyLinter) -&gt; None:
        super().__init__(linter)
        self._returns: list[int]
        self._branches: defaultdict[nodes.LocalsDictNodeNG, int]
        self._stmts: list[int]

</t>
<t tx="ekr.20250131013559.357">    def open(self) -&gt; None:
        """Initialize visit variables."""
        self.linter.stats.reset_node_count()
        self._returns = []
        self._branches = defaultdict(int)
        self._stmts = []
        self._exclude_too_few_public_methods = (
            self.linter.config.exclude_too_few_public_methods
        )

</t>
<t tx="ekr.20250131013559.358">    def _inc_all_stmts(self, amount: int) -&gt; None:
        for i, _ in enumerate(self._stmts):
            self._stmts[i] += amount

</t>
<t tx="ekr.20250131013559.359">    @only_required_for_messages(
        "too-many-ancestors",
        "too-many-instance-attributes",
        "too-few-public-methods",
        "too-many-public-methods",
    )
    def visit_classdef(self, node: nodes.ClassDef) -&gt; None:
        """Check size of inheritance hierarchy and number of instance attributes."""
        parents = _get_parents(
            node,
            STDLIB_CLASSES_IGNORE_ANCESTOR.union(self.linter.config.ignored_parents),
        )
        nb_parents = len(parents)
        if nb_parents &gt; self.linter.config.max_parents:
            self.add_message(
                "too-many-ancestors",
                node=node,
                args=(nb_parents, self.linter.config.max_parents),
            )

        # Something at inference time is modifying instance_attrs to add
        # properties from parent classes. Given how much we cache inference
        # results, mutating instance_attrs can become a real mess. Filter
        # them out here until the root cause is solved.
        # https://github.com/pylint-dev/astroid/issues/2273
        root = node.root()
        filtered_attrs = [
            k for (k, v) in node.instance_attrs.items() if v[0].root() is root
        ]
        if len(filtered_attrs) &gt; self.linter.config.max_attributes:
            self.add_message(
                "too-many-instance-attributes",
                node=node,
                args=(len(filtered_attrs), self.linter.config.max_attributes),
            )

</t>
<t tx="ekr.20250131013559.360">    @only_required_for_messages("too-few-public-methods", "too-many-public-methods")
    def leave_classdef(self, node: nodes.ClassDef) -&gt; None:
        """Check number of public methods."""
        my_methods = sum(
            1 for method in node.mymethods() if not method.name.startswith("_")
        )

        # Does the class contain less than n public methods ?
        # This checks only the methods defined in the current class,
        # since the user might not have control over the classes
        # from the ancestors. It avoids some false positives
        # for classes such as unittest.TestCase, which provides
        # a lot of assert methods. It doesn't make sense to warn
        # when the user subclasses TestCase to add his own tests.
        if my_methods &gt; self.linter.config.max_public_methods:
            self.add_message(
                "too-many-public-methods",
                node=node,
                args=(my_methods, self.linter.config.max_public_methods),
            )

        # Stop here if the class is excluded via configuration.
        if node.type == "class" and self._exclude_too_few_public_methods:
            for ancestor in node.ancestors():
                if any(
                    pattern.match(ancestor.qname())
                    for pattern in self._exclude_too_few_public_methods
                ):
                    return

        # Stop here for exception, metaclass, interface classes and other
        # classes for which we don't need to count the methods.
        if node.type != "class" or _is_exempt_from_public_methods(node):
            return

        # Does the class contain more than n public methods ?
        # This checks all the methods defined by ancestors and
        # by the current class.
        all_methods = _count_methods_in_class(node)
        if all_methods &lt; self.linter.config.min_public_methods:
            self.add_message(
                "too-few-public-methods",
                node=node,
                args=(all_methods, self.linter.config.min_public_methods),
            )

</t>
<t tx="ekr.20250131013559.361">    @only_required_for_messages(
        "too-many-return-statements",
        "too-many-branches",
        "too-many-arguments",
        "too-many-locals",
        "too-many-positional-arguments",
        "too-many-statements",
        "keyword-arg-before-vararg",
    )
    def visit_functiondef(self, node: nodes.FunctionDef) -&gt; None:
        """Check function name, docstring, arguments, redefinition,
        variable names, max locals.
        """
        # init branch and returns counters
        self._returns.append(0)
        # check number of arguments
        args = node.args.args + node.args.posonlyargs + node.args.kwonlyargs
        pos_args = node.args.args + node.args.posonlyargs
        ignored_argument_names = self.linter.config.ignored_argument_names
        if args is not None:
            ignored_args_num = 0
            if ignored_argument_names:
                ignored_pos_args_num = sum(
                    1 for arg in pos_args if ignored_argument_names.match(arg.name)
                )
                ignored_kwonly_args_num = sum(
                    1
                    for arg in node.args.kwonlyargs
                    if ignored_argument_names.match(arg.name)
                )
                ignored_args_num = ignored_pos_args_num + ignored_kwonly_args_num

            argnum = len(args) - ignored_args_num
            if argnum &gt; self.linter.config.max_args:
                self.add_message(
                    "too-many-arguments",
                    node=node,
                    args=(len(args), self.linter.config.max_args),
                )
            pos_args_count = (
                len(args) - len(node.args.kwonlyargs) - ignored_pos_args_num
            )
            if pos_args_count &gt; self.linter.config.max_positional_arguments:
                self.add_message(
                    "too-many-positional-arguments",
                    node=node,
                    args=(pos_args_count, self.linter.config.max_positional_arguments),
                    confidence=HIGH,
                )
        else:
            ignored_args_num = 0
        # check number of local variables
        locnum = len(node.locals) - ignored_args_num

        # decrement number of local variables if '_' is one of them
        if "_" in node.locals:
            locnum -= 1

        if locnum &gt; self.linter.config.max_locals:
            self.add_message(
                "too-many-locals",
                node=node,
                args=(locnum, self.linter.config.max_locals),
            )
        # init new statements counter
        self._stmts.append(1)

</t>
<t tx="ekr.20250131013559.362">    visit_asyncfunctiondef = visit_functiondef

    @only_required_for_messages(
        "too-many-return-statements",
        "too-many-branches",
        "too-many-arguments",
        "too-many-locals",
        "too-many-statements",
    )
    def leave_functiondef(self, node: nodes.FunctionDef) -&gt; None:
        """Most of the work is done here on close:
        checks for max returns, branch, return in __init__.
        """
        returns = self._returns.pop()
        if returns &gt; self.linter.config.max_returns:
            self.add_message(
                "too-many-return-statements",
                node=node,
                args=(returns, self.linter.config.max_returns),
            )
        branches = self._branches[node]
        if branches &gt; self.linter.config.max_branches:
            self.add_message(
                "too-many-branches",
                node=node,
                args=(branches, self.linter.config.max_branches),
            )
        # check number of statements
        stmts = self._stmts.pop()
        if stmts &gt; self.linter.config.max_statements:
            self.add_message(
                "too-many-statements",
                node=node,
                args=(stmts, self.linter.config.max_statements),
            )

</t>
<t tx="ekr.20250131013559.363">    leave_asyncfunctiondef = leave_functiondef

    def visit_return(self, _: nodes.Return) -&gt; None:
        """Count number of returns."""
        if not self._returns:
            return  # return outside function, reported by the base checker
        self._returns[-1] += 1

</t>
<t tx="ekr.20250131013559.364">    def visit_default(self, node: nodes.NodeNG) -&gt; None:
        """Default visit method -&gt; increments the statements counter if
        necessary.
        """
        if node.is_statement:
            self._inc_all_stmts(1)

</t>
<t tx="ekr.20250131013559.365">    def visit_try(self, node: nodes.Try) -&gt; None:
        """Increments the branches counter."""
        branches = len(node.handlers)
        if node.orelse:
            branches += 1
        if node.finalbody:
            branches += 1
        self._inc_branch(node, branches)
        self._inc_all_stmts(branches)

</t>
<t tx="ekr.20250131013559.366">    @only_required_for_messages("too-many-boolean-expressions", "too-many-branches")
    def visit_if(self, node: nodes.If) -&gt; None:
        """Increments the branches counter and checks boolean expressions."""
        self._check_boolean_expressions(node)
        branches = 1
        # don't double count If nodes coming from some 'elif'
        if node.orelse and (
            len(node.orelse) &gt; 1 or not isinstance(node.orelse[0], astroid.If)
        ):
            branches += 1
        self._inc_branch(node, branches)
        self._inc_all_stmts(branches)

</t>
<t tx="ekr.20250131013559.367">    def _check_boolean_expressions(self, node: nodes.If) -&gt; None:
        """Go through "if" node `node` and count its boolean expressions
        if the 'if' node test is a BoolOp node.
        """
        condition = node.test
        if not isinstance(condition, astroid.BoolOp):
            return
        nb_bool_expr = _count_boolean_expressions(condition)
        if nb_bool_expr &gt; self.linter.config.max_bool_expr:
            self.add_message(
                "too-many-boolean-expressions",
                node=condition,
                args=(nb_bool_expr, self.linter.config.max_bool_expr),
            )

</t>
<t tx="ekr.20250131013559.368">    def visit_while(self, node: nodes.While) -&gt; None:
        """Increments the branches counter."""
        branches = 1
        if node.orelse:
            branches += 1
        self._inc_branch(node, branches)

</t>
<t tx="ekr.20250131013559.369">    visit_for = visit_while

    def _inc_branch(self, node: nodes.NodeNG, branchesnum: int = 1) -&gt; None:
        """Increments the branches counter."""
        self._branches[node.scope()] += branchesnum


</t>
<t tx="ekr.20250131013559.370">@path pylint/checkers
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

from typing import TYPE_CHECKING

from astroid import Instance, nodes
from astroid.util import UninferableBase

from pylint.checkers import BaseChecker
from pylint.checkers.utils import safe_infer
from pylint.constants import DUNDER_METHODS, UNNECESSARY_DUNDER_CALL_LAMBDA_EXCEPTIONS
from pylint.interfaces import HIGH

if TYPE_CHECKING:
    from pylint.lint import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013559.371">class DunderCallChecker(BaseChecker):
    """Check for unnecessary dunder method calls.

    Docs: https://docs.python.org/3/reference/datamodel.html#basic-customization
    We exclude names in list pylint.constants.EXTRA_DUNDER_METHODS such as
    __index__ (see https://github.com/pylint-dev/pylint/issues/6795)
    since these either have no alternative method of being called or
    have a genuine use case for being called manually.

    Additionally, we exclude classes that are not instantiated since these
    might be used to access the dunder methods of a base class of an instance.
    We also exclude dunder method calls on super() since
    these can't be written in an alternative manner.
    """

    @others
</t>
<t tx="ekr.20250131013559.372">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(DunderCallChecker(linter))
</t>
<t tx="ekr.20250131013559.373">name = "unnecessary-dunder-call"
msgs = {
    "C2801": (
        "Unnecessarily calls dunder method %s. %s.",
        "unnecessary-dunder-call",
        "Used when a dunder method is manually called instead "
        "of using the corresponding function/method/operator.",
    ),
}
options = ()

def open(self) -&gt; None:
    self._dunder_methods: dict[str, str] = {}
    for since_vers, dunder_methods in DUNDER_METHODS.items():
        if since_vers &lt;= self.linter.config.py_version:
            self._dunder_methods.update(dunder_methods)

</t>
<t tx="ekr.20250131013559.374">@staticmethod
def within_dunder_or_lambda_def(node: nodes.NodeNG) -&gt; bool:
    """Check if dunder method call is within a dunder method definition."""
    parent = node.parent
    while parent is not None:
        if (
            isinstance(parent, nodes.FunctionDef)
            and parent.name.startswith("__")
            and parent.name.endswith("__")
        ) or DunderCallChecker.is_lambda_rule_exception(parent, node):
            return True
        parent = parent.parent
    return False

</t>
<t tx="ekr.20250131013559.375">@staticmethod
def is_lambda_rule_exception(ancestor: nodes.NodeNG, node: nodes.NodeNG) -&gt; bool:
    return (
        isinstance(ancestor, nodes.Lambda)
        and node.func.attrname in UNNECESSARY_DUNDER_CALL_LAMBDA_EXCEPTIONS
    )

</t>
<t tx="ekr.20250131013559.376">def visit_call(self, node: nodes.Call) -&gt; None:
    """Check if method being called is an unnecessary dunder method."""
    if (
        isinstance(node.func, nodes.Attribute)
        and node.func.attrname in self._dunder_methods
        and not self.within_dunder_or_lambda_def(node)
        and not (
            isinstance(node.func.expr, nodes.Call)
            and isinstance(node.func.expr.func, nodes.Name)
            and node.func.expr.func.name == "super"
        )
    ):
        inf_expr = safe_infer(node.func.expr)
        if not (
            inf_expr is None or isinstance(inf_expr, (Instance, UninferableBase))
        ):
            # Skip dunder calls to non instantiated classes.
            return

        self.add_message(
            "unnecessary-dunder-call",
            node=node,
            args=(node.func.attrname, self._dunder_methods[node.func.attrname]),
            confidence=HIGH,
        )


</t>
<t tx="ekr.20250131013559.377">@path pylint/checkers
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Ellipsis checker for Python code."""

from __future__ import annotations

from typing import TYPE_CHECKING

from astroid import nodes

from pylint.checkers import BaseChecker
from pylint.checkers.utils import only_required_for_messages

if TYPE_CHECKING:
    from pylint.lint import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013559.378">class EllipsisChecker(BaseChecker):
    @others
</t>
<t tx="ekr.20250131013559.379">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(EllipsisChecker(linter))
</t>
<t tx="ekr.20250131013559.380">name = "unnecessary_ellipsis"
msgs = {
    "W2301": (
        "Unnecessary ellipsis constant",
        "unnecessary-ellipsis",
        "Used when the ellipsis constant is encountered and can be avoided. "
        "A line of code consisting of an ellipsis is unnecessary if "
        "there is a docstring on the preceding line or if there is a "
        "statement in the same scope.",
    )
}

@only_required_for_messages("unnecessary-ellipsis")
def visit_const(self, node: nodes.Const) -&gt; None:
    """Check if the ellipsis constant is used unnecessarily.

    Emits a warning when:
     - A line consisting of an ellipsis is preceded by a docstring.
     - A statement exists in the same scope as the ellipsis.
       For example: A function consisting of an ellipsis followed by a
       return statement on the next line.
    """
    if (
        node.pytype() == "builtins.Ellipsis"
        and isinstance(node.parent, nodes.Expr)
        and (
            (
                isinstance(node.parent.parent, (nodes.ClassDef, nodes.FunctionDef))
                and node.parent.parent.doc_node
            )
            or len(node.parent.parent.body) &gt; 1
        )
    ):
        self.add_message("unnecessary-ellipsis", node=node)


</t>
<t tx="ekr.20250131013559.381">@path pylint/checkers
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Checks for various exception related errors."""

from __future__ import annotations

import builtins
import inspect
from collections.abc import Generator
from typing import TYPE_CHECKING, Any

import astroid
from astroid import nodes, objects, util
from astroid.context import InferenceContext
from astroid.typing import InferenceResult, SuccessfulInferenceResult

from pylint import checkers
from pylint.checkers import utils
from pylint.interfaces import HIGH, INFERENCE
from pylint.typing import MessageDefinitionTuple

if TYPE_CHECKING:
    from pylint.lint import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013559.382">def _builtin_exceptions() -&gt; set[str]:
    def predicate(obj: Any) -&gt; bool:
        return isinstance(obj, type) and issubclass(obj, BaseException)

    members = inspect.getmembers(builtins, predicate)
    return {exc.__name__ for (_, exc) in members}


</t>
<t tx="ekr.20250131013559.383">def _annotated_unpack_infer(
    stmt: nodes.NodeNG, context: InferenceContext | None = None
) -&gt; Generator[tuple[nodes.NodeNG, SuccessfulInferenceResult]]:
    """Recursively generate nodes inferred by the given statement.

    If the inferred value is a list or a tuple, recurse on the elements.
    Returns an iterator which yields tuples in the format
    ('original node', 'inferred node').
    """
    if isinstance(stmt, (nodes.List, nodes.Tuple)):
        for elt in stmt.elts:
            inferred = utils.safe_infer(elt)
            if inferred and not isinstance(inferred, util.UninferableBase):
                yield elt, inferred
        return
    for inferred in stmt.infer(context):
        if isinstance(inferred, util.UninferableBase):
            continue
        yield stmt, inferred


</t>
<t tx="ekr.20250131013559.384">def _is_raising(body: list[nodes.NodeNG]) -&gt; bool:
    """Return whether the given statement node raises an exception."""
    return any(isinstance(node, nodes.Raise) for node in body)


</t>
<t tx="ekr.20250131013559.385">MSGS: dict[str, MessageDefinitionTuple] = {
    "E0701": (
        "Bad except clauses order (%s)",
        "bad-except-order",
        "Used when except clauses are not in the correct order (from the "
        "more specific to the more generic). If you don't fix the order, "
        "some exceptions may not be caught by the most specific handler.",
    ),
    "E0702": (
        "Raising %s while only classes or instances are allowed",
        "raising-bad-type",
        "Used when something which is neither a class nor an instance "
        "is raised (i.e. a `TypeError` will be raised).",
    ),
    "E0704": (
        "The raise statement is not inside an except clause",
        "misplaced-bare-raise",
        "Used when a bare raise is not used inside an except clause. "
        "This generates an error, since there are no active exceptions "
        "to be reraised. An exception to this rule is represented by "
        "a bare raise inside a finally clause, which might work, as long "
        "as an exception is raised inside the try block, but it is "
        "nevertheless a code smell that must not be relied upon.",
    ),
    "E0705": (
        "Exception cause set to something which is not an exception, nor None",
        "bad-exception-cause",
        'Used when using the syntax "raise ... from ...", '
        "where the exception cause is not an exception, "
        "nor None.",
        {"old_names": [("E0703", "bad-exception-context")]},
    ),
    "E0710": (
        "Raising a class which doesn't inherit from BaseException",
        "raising-non-exception",
        "Used when a class which doesn't inherit from BaseException is raised.",
    ),
    "E0711": (
        "NotImplemented raised - should raise NotImplementedError",
        "notimplemented-raised",
        "Used when NotImplemented is raised instead of NotImplementedError",
    ),
    "E0712": (
        "Catching an exception which doesn't inherit from Exception: %s",
        "catching-non-exception",
        "Used when a class which doesn't inherit from "
        "Exception is used as an exception in an except clause.",
    ),
    "W0702": (
        "No exception type(s) specified",
        "bare-except",
        "A bare ``except:`` clause will catch ``SystemExit`` and "
        "``KeyboardInterrupt`` exceptions, making it harder to interrupt a program "
        "with ``Control-C``, and can disguise other problems. If you want to catch "
        "all exceptions that signal program errors, use ``except Exception:`` (bare "
        "except is equivalent to ``except BaseException:``).",
    ),
    "W0718": (
        "Catching too general exception %s",
        "broad-exception-caught",
        "If you use a naked ``except Exception:`` clause, you might end up catching "
        "exceptions other than the ones you expect to catch. This can hide bugs or "
        "make it harder to debug programs when unrelated errors are hidden.",
        {"old_names": [("W0703", "broad-except")]},
    ),
    "W0705": (
        "Catching previously caught exception type %s",
        "duplicate-except",
        "Used when an except catches a type that was already caught by "
        "a previous handler.",
    ),
    "W0706": (
        "The except handler raises immediately",
        "try-except-raise",
        "Used when an except handler uses raise as its first or only "
        "operator. This is useless because it raises back the exception "
        "immediately. Remove the raise operator or the entire "
        "try-except-raise block!",
    ),
    "W0707": (
        "Consider explicitly re-raising using %s'%s from %s'",
        "raise-missing-from",
        "Python's exception chaining shows the traceback of the current exception, "
        "but also of the original exception. When you raise a new exception after "
        "another exception was caught it's likely that the second exception is a "
        "friendly re-wrapping of the first exception. In such cases `raise from` "
        "provides a better link between the two tracebacks in the final error.",
    ),
    "W0711": (
        'Exception to catch is the result of a binary "%s" operation',
        "binary-op-exception",
        "Used when the exception to catch is of the form "
        '"except A or B:".  If intending to catch multiple, '
        'rewrite as "except (A, B):"',
    ),
    "W0715": (
        "Exception arguments suggest string formatting might be intended",
        "raising-format-tuple",
        "Used when passing multiple arguments to an exception "
        "constructor, the first of them a string literal containing what "
        "appears to be placeholders intended for formatting",
    ),
    "W0716": (
        "Invalid exception operation. %s",
        "wrong-exception-operation",
        "Used when an operation is done against an exception, but the operation "
        "is not valid for the exception in question. Usually emitted when having "
        "binary operations between exceptions in except handlers.",
    ),
    "W0719": (
        "Raising too general exception: %s",
        "broad-exception-raised",
        "Raising exceptions that are too generic force you to catch exceptions "
        "generically too. It will force you to use a naked ``except Exception:`` "
        "clause. You might then end up catching exceptions other than the ones "
        "you expect to catch. This can hide bugs or make it harder to debug programs "
        "when unrelated errors are hidden.",
    ),
}


class BaseVisitor:
    """Base class for visitors defined in this module."""

    @others
</t>
<t tx="ekr.20250131013559.386">class ExceptionRaiseRefVisitor(BaseVisitor):
    """Visit references (anything that is not an AST leaf)."""

    @others
</t>
<t tx="ekr.20250131013559.387">class ExceptionRaiseLeafVisitor(BaseVisitor):
    """Visitor for handling leaf kinds of a raise value."""

    @others
</t>
<t tx="ekr.20250131013559.388">class ExceptionsChecker(checkers.BaseChecker):
    """Exception related checks."""

    @others
</t>
<t tx="ekr.20250131013559.389">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(ExceptionsChecker(linter))
</t>
<t tx="ekr.20250131013559.390">def __init__(self, checker: ExceptionsChecker, node: nodes.Raise) -&gt; None:
    self._checker = checker
    self._node = node

</t>
<t tx="ekr.20250131013559.391">def visit(self, node: SuccessfulInferenceResult) -&gt; None:
    name = node.__class__.__name__.lower()
    dispatch_meth = getattr(self, "visit_" + name, None)
    if dispatch_meth:
        dispatch_meth(node)
    else:
        self.visit_default(node)

</t>
<t tx="ekr.20250131013559.392">def visit_default(self, _: nodes.NodeNG) -&gt; None:
    """Default implementation for all the nodes."""


</t>
<t tx="ekr.20250131013559.393">def visit_name(self, node: nodes.Name) -&gt; None:
    if node.name == "NotImplemented":
        self._checker.add_message(
            "notimplemented-raised", node=self._node, confidence=HIGH
        )
        return
    try:
        exceptions = [
            c
            for _, c in _annotated_unpack_infer(node)
            if isinstance(c, nodes.ClassDef)
        ]
    except astroid.InferenceError:
        return

    for exception in exceptions:
        if self._checker._is_overgeneral_exception(exception):
            self._checker.add_message(
                "broad-exception-raised",
                args=exception.name,
                node=self._node,
                confidence=INFERENCE,
            )

</t>
<t tx="ekr.20250131013559.394">def visit_call(self, node: nodes.Call) -&gt; None:
    if isinstance(node.func, nodes.Name):
        self.visit_name(node.func)
    if (
        len(node.args) &gt; 1
        and isinstance(node.args[0], nodes.Const)
        and isinstance(node.args[0].value, str)
    ):
        msg = node.args[0].value
        if "%" in msg or ("{" in msg and "}" in msg):
            self._checker.add_message(
                "raising-format-tuple", node=self._node, confidence=HIGH
            )


</t>
<t tx="ekr.20250131013559.395">def visit_const(self, node: nodes.Const) -&gt; None:
    self._checker.add_message(
        "raising-bad-type",
        node=self._node,
        args=node.value.__class__.__name__,
        confidence=INFERENCE,
    )

</t>
<t tx="ekr.20250131013559.396">def visit_instance(self, instance: objects.ExceptionInstance) -&gt; None:
    cls = instance._proxied
    self.visit_classdef(cls)

</t>
<t tx="ekr.20250131013559.397"># Exception instances have a particular class type
visit_exceptioninstance = visit_instance

def visit_classdef(self, node: nodes.ClassDef) -&gt; None:
    if not utils.inherit_from_std_ex(node) and utils.has_known_bases(node):
        self._checker.add_message(
            "raising-non-exception",
            node=self._node,
            confidence=INFERENCE,
        )

</t>
<t tx="ekr.20250131013559.398">def visit_tuple(self, _: nodes.Tuple) -&gt; None:
    self._checker.add_message(
        "raising-bad-type",
        node=self._node,
        args="tuple",
        confidence=INFERENCE,
    )

</t>
<t tx="ekr.20250131013559.399">def visit_default(self, node: nodes.NodeNG) -&gt; None:
    name = getattr(node, "name", node.__class__.__name__)
    self._checker.add_message(
        "raising-bad-type",
        node=self._node,
        args=name,
        confidence=INFERENCE,
    )


</t>
<t tx="ekr.20250131013559.400">name = "exceptions"
msgs = MSGS
options = (
    (
        "overgeneral-exceptions",
        {
            "default": ("builtins.BaseException", "builtins.Exception"),
            "type": "csv",
            "metavar": "&lt;comma-separated class names&gt;",
            "help": "Exceptions that will emit a warning when caught.",
        },
    ),
)

def open(self) -&gt; None:
    self._builtin_exceptions = _builtin_exceptions()
    super().open()

</t>
<t tx="ekr.20250131013559.401">@utils.only_required_for_messages(
    "misplaced-bare-raise",
    "raising-bad-type",
    "raising-non-exception",
    "notimplemented-raised",
    "bad-exception-cause",
    "raising-format-tuple",
    "raise-missing-from",
    "broad-exception-raised",
)
def visit_raise(self, node: nodes.Raise) -&gt; None:
    if node.exc is None:
        self._check_misplaced_bare_raise(node)
        return

    if node.cause is None:
        self._check_raise_missing_from(node)
    else:
        self._check_bad_exception_cause(node)

    expr = node.exc
    ExceptionRaiseRefVisitor(self, node).visit(expr)

    inferred = utils.safe_infer(expr)
    if inferred is None or isinstance(inferred, util.UninferableBase):
        return
    ExceptionRaiseLeafVisitor(self, node).visit(inferred)

</t>
<t tx="ekr.20250131013559.402">def _check_misplaced_bare_raise(self, node: nodes.Raise) -&gt; None:
    # Filter out if it's present in __exit__.
    scope = node.scope()
    if (
        isinstance(scope, nodes.FunctionDef)
        and scope.is_method()
        and scope.name == "__exit__"
    ):
        return

    current = node
    # Stop when a new scope is generated or when the raise
    # statement is found inside a Try.
    ignores = (nodes.ExceptHandler, nodes.FunctionDef)
    while current and not isinstance(current.parent, ignores):
        current = current.parent

    expected = (nodes.ExceptHandler,)
    if not current or not isinstance(current.parent, expected):
        self.add_message("misplaced-bare-raise", node=node, confidence=HIGH)

</t>
<t tx="ekr.20250131013559.403">def _check_bad_exception_cause(self, node: nodes.Raise) -&gt; None:
    """Verify that the exception cause is properly set.

    An exception cause can be only `None` or an exception.
    """
    cause = utils.safe_infer(node.cause)
    if cause is None or isinstance(cause, util.UninferableBase):
        return

    if isinstance(cause, nodes.Const):
        if cause.value is not None:
            self.add_message("bad-exception-cause", node=node, confidence=INFERENCE)
    elif not isinstance(cause, nodes.ClassDef) and not utils.inherit_from_std_ex(
        cause
    ):
        self.add_message("bad-exception-cause", node=node, confidence=INFERENCE)

</t>
<t tx="ekr.20250131013559.404">def _check_raise_missing_from(self, node: nodes.Raise) -&gt; None:
    if node.exc is None:
        # This is a plain `raise`, raising the previously-caught exception. No need for a
        # cause.
        return
    # We'd like to check whether we're inside an `except` clause:
    containing_except_node = utils.find_except_wrapper_node_in_scope(node)
    if not containing_except_node:
        return
    # We found a surrounding `except`! We're almost done proving there's a
    # `raise-missing-from` here. The only thing we need to protect against is that maybe
    # the `raise` is raising the exception that was caught, possibly with some shenanigans
    # like `exc.with_traceback(whatever)`. We won't analyze these, we'll just assume
    # there's a violation on two simple cases: `raise SomeException(whatever)` and `raise
    # SomeException`.
    if containing_except_node.name is None:
        # The `except` doesn't have an `as exception:` part, meaning there's no way that
        # the `raise` is raising the same exception.
        class_of_old_error = "Exception"
        if isinstance(containing_except_node.type, (nodes.Name, nodes.Tuple)):
            # 'except ZeroDivisionError' or 'except (ZeroDivisionError, ValueError)'
            class_of_old_error = containing_except_node.type.as_string()
        self.add_message(
            "raise-missing-from",
            node=node,
            args=(
                f"'except {class_of_old_error} as exc' and ",
                node.as_string(),
                "exc",
            ),
            confidence=HIGH,
        )
    elif (
        isinstance(node.exc, nodes.Call) and isinstance(node.exc.func, nodes.Name)
    ) or (
        isinstance(node.exc, nodes.Name)
        and node.exc.name != containing_except_node.name.name
    ):
        # We have a `raise SomeException(whatever)` or a `raise SomeException`
        self.add_message(
            "raise-missing-from",
            node=node,
            args=("", node.as_string(), containing_except_node.name.name),
            confidence=HIGH,
        )

</t>
<t tx="ekr.20250131013559.405">def _check_catching_non_exception(
    self,
    handler: nodes.ExceptHandler,
    exc: SuccessfulInferenceResult,
    part: nodes.NodeNG,
) -&gt; None:
    if isinstance(exc, nodes.Tuple):
        # Check if it is a tuple of exceptions.
        inferred = [utils.safe_infer(elt) for elt in exc.elts]
        if any(isinstance(node, util.UninferableBase) for node in inferred):
            # Don't emit if we don't know every component.
            return
        if all(
            node
            and (utils.inherit_from_std_ex(node) or not utils.has_known_bases(node))
            for node in inferred
        ):
            return

    if not isinstance(exc, nodes.ClassDef):
        # Don't emit the warning if the inferred stmt
        # is None, but the exception handler is something else,
        # maybe it was redefined.
        if isinstance(exc, nodes.Const) and exc.value is None:
            if (
                isinstance(handler.type, nodes.Const) and handler.type.value is None
            ) or handler.type.parent_of(exc):
                # If the exception handler catches None or
                # the exception component, which is None, is
                # defined by the entire exception handler, then
                # emit a warning.
                self.add_message(
                    "catching-non-exception",
                    node=handler.type,
                    args=(part.as_string(),),
                )
        else:
            self.add_message(
                "catching-non-exception",
                node=handler.type,
                args=(part.as_string(),),
            )
        return

    if (
        not utils.inherit_from_std_ex(exc)
        and exc.name not in self._builtin_exceptions
    ):
        if utils.has_known_bases(exc):
            self.add_message(
                "catching-non-exception", node=handler.type, args=(exc.name,)
            )

</t>
<t tx="ekr.20250131013559.406">def _check_try_except_raise(self, node: nodes.Try) -&gt; None:
    def gather_exceptions_from_handler(
        handler: nodes.ExceptHandler,
    ) -&gt; list[InferenceResult] | None:
        exceptions: list[InferenceResult] = []
        if handler.type:
            exceptions_in_handler = utils.safe_infer(handler.type)
            if isinstance(exceptions_in_handler, nodes.Tuple):
                exceptions = list(
                    {
                        exception
                        for exception in exceptions_in_handler.elts
                        if isinstance(exception, (nodes.Name, nodes.Attribute))
                    }
                )
            elif exceptions_in_handler:
                exceptions = [exceptions_in_handler]
            else:
                # Break when we cannot infer anything reliably.
                return None
        return exceptions

    bare_raise = False
    handler_having_bare_raise = None
    exceptions_in_bare_handler: list[InferenceResult] | None = []
    for handler in node.handlers:
        if bare_raise:
            # check that subsequent handler is not parent of handler which had bare raise.
            # since utils.safe_infer can fail for bare except, check it before.
            # also break early if bare except is followed by bare except.

            excs_in_current_handler = gather_exceptions_from_handler(handler)
            if not excs_in_current_handler:
                break
            if exceptions_in_bare_handler is None:
                # It can be `None` when the inference failed
                break
            for exc_in_current_handler in excs_in_current_handler:
                inferred_current = utils.safe_infer(exc_in_current_handler)
                if any(
                    utils.is_subclass_of(utils.safe_infer(e), inferred_current)
                    for e in exceptions_in_bare_handler
                ):
                    bare_raise = False
                    break

        # `raise` as the first operator inside the except handler
        if _is_raising([handler.body[0]]):
            # flags when there is a bare raise
            if handler.body[0].exc is None:
                bare_raise = True
                handler_having_bare_raise = handler
                exceptions_in_bare_handler = gather_exceptions_from_handler(handler)
    else:
        if bare_raise:
            self.add_message("try-except-raise", node=handler_having_bare_raise)

</t>
<t tx="ekr.20250131013559.407">@utils.only_required_for_messages("wrong-exception-operation")
def visit_binop(self, node: nodes.BinOp) -&gt; None:
    if isinstance(node.parent, nodes.ExceptHandler):
        both_sides_tuple_or_uninferable = isinstance(
            utils.safe_infer(node.left), (nodes.Tuple, util.UninferableBase)
        ) and isinstance(
            utils.safe_infer(node.right), (nodes.Tuple, util.UninferableBase)
        )
        # Tuple concatenation allowed
        if both_sides_tuple_or_uninferable:
            if node.op == "+":
                return
            suggestion = f"Did you mean '({node.left.as_string()} + {node.right.as_string()})' instead?"
        # except (V | A)
        else:
            suggestion = f"Did you mean '({node.left.as_string()}, {node.right.as_string()})' instead?"
        self.add_message("wrong-exception-operation", node=node, args=(suggestion,))

</t>
<t tx="ekr.20250131013559.408">@utils.only_required_for_messages("wrong-exception-operation")
def visit_compare(self, node: nodes.Compare) -&gt; None:
    if isinstance(node.parent, nodes.ExceptHandler):
        # except (V &lt; A)
        suggestion = (
            f"Did you mean '({node.left.as_string()}, "
            f"{', '.join(o.as_string() for _, o in node.ops)})' instead?"
        )
        self.add_message("wrong-exception-operation", node=node, args=(suggestion,))

</t>
<t tx="ekr.20250131013559.409">@utils.only_required_for_messages(
    "bare-except",
    "broad-exception-caught",
    "try-except-raise",
    "binary-op-exception",
    "bad-except-order",
    "catching-non-exception",
    "duplicate-except",
)
def visit_trystar(self, node: nodes.TryStar) -&gt; None:
    """Check for empty except*."""
    self.visit_try(node)

</t>
<t tx="ekr.20250131013559.410">def visit_try(self, node: nodes.Try) -&gt; None:
    """Check for empty except."""
    self._check_try_except_raise(node)
    exceptions_classes: list[Any] = []
    nb_handlers = len(node.handlers)
    for index, handler in enumerate(node.handlers):
        if handler.type is None:
            if not _is_raising(handler.body):
                self.add_message("bare-except", node=handler, confidence=HIGH)

            # check if an "except:" is followed by some other
            # except
            if index &lt; (nb_handlers - 1):
                msg = "empty except clause should always appear last"
                self.add_message(
                    "bad-except-order", node=node, args=msg, confidence=HIGH
                )

        elif isinstance(handler.type, nodes.BoolOp):
            self.add_message(
                "binary-op-exception",
                node=handler,
                args=handler.type.op,
                confidence=HIGH,
            )
        else:
            try:
                exceptions = list(_annotated_unpack_infer(handler.type))
            except astroid.InferenceError:
                continue

            for part, exception in exceptions:
                if isinstance(
                    exception, astroid.Instance
                ) and utils.inherit_from_std_ex(exception):
                    exception = exception._proxied

                self._check_catching_non_exception(handler, exception, part)

                if not isinstance(exception, nodes.ClassDef):
                    continue

                exc_ancestors = [
                    a
                    for a in exception.ancestors()
                    if isinstance(a, nodes.ClassDef)
                ]

                for previous_exc in exceptions_classes:
                    if previous_exc in exc_ancestors:
                        msg = f"{previous_exc.name} is an ancestor class of {exception.name}"
                        self.add_message(
                            "bad-except-order",
                            node=handler.type,
                            args=msg,
                            confidence=INFERENCE,
                        )
                if self._is_overgeneral_exception(exception) and not _is_raising(
                    handler.body
                ):
                    self.add_message(
                        "broad-exception-caught",
                        args=exception.name,
                        node=handler.type,
                        confidence=INFERENCE,
                    )

                if exception in exceptions_classes:
                    self.add_message(
                        "duplicate-except",
                        args=exception.name,
                        node=handler.type,
                        confidence=INFERENCE,
                    )

            exceptions_classes += [exc for _, exc in exceptions]

</t>
<t tx="ekr.20250131013559.411">def _is_overgeneral_exception(self, exception: nodes.ClassDef) -&gt; bool:
    return exception.qname() in self.linter.config.overgeneral_exceptions


</t>
<t tx="ekr.20250131013559.412">@path pylint/checkers
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Python code format's checker.

By default, try to follow Guido's style guide :

https://www.python.org/doc/essays/styleguide/

Some parts of the process_token method is based from The Tab Nanny std module.
"""

from __future__ import annotations

import tokenize
from functools import reduce
from re import Match
from typing import TYPE_CHECKING, Literal

from astroid import nodes

from pylint.checkers import BaseRawFileChecker, BaseTokenChecker
from pylint.checkers.utils import only_required_for_messages
from pylint.constants import WarningScope
from pylint.interfaces import HIGH
from pylint.typing import MessageDefinitionTuple
from pylint.utils.pragma_parser import OPTION_PO, PragmaParserError, parse_pragma

if TYPE_CHECKING:
    from pylint.lint import PyLinter


_KEYWORD_TOKENS = {
    "assert",
    "del",
    "elif",
    "except",
    "for",
    "if",
    "in",
    "not",
    "raise",
    "return",
    "while",
    "yield",
    "with",
    "=",
    ":=",
}
_JUNK_TOKENS = {tokenize.COMMENT, tokenize.NL}


MSGS: dict[str, MessageDefinitionTuple] = {
    "C0301": (
        "Line too long (%s/%s)",
        "line-too-long",
        "Used when a line is longer than a given number of characters.",
    ),
    "C0302": (
        "Too many lines in module (%s/%s)",  # was W0302
        "too-many-lines",
        "Used when a module has too many lines, reducing its readability.",
    ),
    "C0303": (
        "Trailing whitespace",
        "trailing-whitespace",
        "Used when there is whitespace between the end of a line and the newline.",
    ),
    "C0304": (
        "Final newline missing",
        "missing-final-newline",
        "Used when the last line in a file is missing a newline.",
    ),
    "C0305": (
        "Trailing newlines",
        "trailing-newlines",
        "Used when there are trailing blank lines in a file.",
    ),
    "W0311": (
        "Bad indentation. Found %s %s, expected %s",
        "bad-indentation",
        "Used when an unexpected number of indentation's tabulations or "
        "spaces has been found.",
    ),
    "W0301": (
        "Unnecessary semicolon",  # was W0106
        "unnecessary-semicolon",
        'Used when a statement is ended by a semi-colon (";"), which '
        "isn't necessary (that's python, not C ;).",
    ),
    "C0321": (
        "More than one statement on a single line",
        "multiple-statements",
        "Used when more than on statement are found on the same line.",
        {"scope": WarningScope.NODE},
    ),
    "C0325": (
        "Unnecessary parens after %r keyword",
        "superfluous-parens",
        "Used when a single item in parentheses follows an if, for, or "
        "other keyword.",
    ),
    "C0327": (
        "Mixed line endings LF and CRLF",
        "mixed-line-endings",
        "Used when there are mixed (LF and CRLF) newline signs in a file.",
    ),
    "C0328": (
        "Unexpected line ending format. There is '%s' while it should be '%s'.",
        "unexpected-line-ending-format",
        "Used when there is different newline than expected.",
    ),
}


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013559.413">def _last_token_on_line_is(tokens: TokenWrapper, line_end: int, token: str) -&gt; bool:
    return (line_end &gt; 0 and tokens.token(line_end - 1) == token) or (
        line_end &gt; 1
        and tokens.token(line_end - 2) == token
        and tokens.type(line_end - 1) == tokenize.COMMENT
    )


</t>
<t tx="ekr.20250131013559.414">class TokenWrapper:
    """A wrapper for readable access to token information."""

    @others
</t>
<t tx="ekr.20250131013559.415">class FormatChecker(BaseTokenChecker, BaseRawFileChecker):
    """Formatting checker.

    Checks for :
    * unauthorized constructions
    * strict indentation
    * line length
    """

    @others
</t>
<t tx="ekr.20250131013559.416">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(FormatChecker(linter))
</t>
<t tx="ekr.20250131013559.417">def __init__(self, tokens: list[tokenize.TokenInfo]) -&gt; None:
    self._tokens = tokens

</t>
<t tx="ekr.20250131013559.418">def token(self, idx: int) -&gt; str:
    return self._tokens[idx][1]

</t>
<t tx="ekr.20250131013559.419">def type(self, idx: int) -&gt; int:
    return self._tokens[idx][0]

</t>
<t tx="ekr.20250131013559.420">def start_line(self, idx: int) -&gt; int:
    return self._tokens[idx][2][0]

</t>
<t tx="ekr.20250131013559.421">def start_col(self, idx: int) -&gt; int:
    return self._tokens[idx][2][1]

</t>
<t tx="ekr.20250131013559.422">def line(self, idx: int) -&gt; str:
    return self._tokens[idx][4]


</t>
<t tx="ekr.20250131013559.423"># configuration section name
name = "format"
# messages
msgs = MSGS
# configuration options
# for available dict keys/values see the optik parser 'add_option' method
options = (
    (
        "max-line-length",
        {
            "default": 100,
            "type": "int",
            "metavar": "&lt;int&gt;",
            "help": "Maximum number of characters on a single line.",
        },
    ),
    (
        "ignore-long-lines",
        {
            "type": "regexp",
            "metavar": "&lt;regexp&gt;",
            "default": r"^\s*(# )?&lt;?https?://\S+&gt;?$",
            "help": (
                "Regexp for a line that is allowed to be longer than the limit."
            ),
        },
    ),
    (
        "single-line-if-stmt",
        {
            "default": False,
            "type": "yn",
            "metavar": "&lt;y or n&gt;",
            "help": (
                "Allow the body of an if to be on the same "
                "line as the test if there is no else."
            ),
        },
    ),
    (
        "single-line-class-stmt",
        {
            "default": False,
            "type": "yn",
            "metavar": "&lt;y or n&gt;",
            "help": (
                "Allow the body of a class to be on the same "
                "line as the declaration if body contains "
                "single statement."
            ),
        },
    ),
    (
        "max-module-lines",
        {
            "default": 1000,
            "type": "int",
            "metavar": "&lt;int&gt;",
            "help": "Maximum number of lines in a module.",
        },
    ),
    (
        "indent-string",
        {
            "default": "    ",
            "type": "non_empty_string",
            "metavar": "&lt;string&gt;",
            "help": "String used as indentation unit. This is usually "
            '"    " (4 spaces) or "\\t" (1 tab).',
        },
    ),
    (
        "indent-after-paren",
        {
            "type": "int",
            "metavar": "&lt;int&gt;",
            "default": 4,
            "help": "Number of spaces of indent required inside a hanging "
            "or continued line.",
        },
    ),
    (
        "expected-line-ending-format",
        {
            "type": "choice",
            "metavar": "&lt;empty or LF or CRLF&gt;",
            "default": "",
            "choices": ["", "LF", "CRLF"],
            "help": (
                "Expected format of line ending, "
                "e.g. empty (any line ending), LF or CRLF."
            ),
        },
    ),
)

def __init__(self, linter: PyLinter) -&gt; None:
    super().__init__(linter)
    self._lines: dict[int, str] = {}
    self._visited_lines: dict[int, Literal[1, 2]] = {}

</t>
<t tx="ekr.20250131013559.424">def new_line(self, tokens: TokenWrapper, line_end: int, line_start: int) -&gt; None:
    """A new line has been encountered, process it if necessary."""
    if _last_token_on_line_is(tokens, line_end, ";"):
        self.add_message("unnecessary-semicolon", line=tokens.start_line(line_end))

    line_num = tokens.start_line(line_start)
    line = tokens.line(line_start)
    if tokens.type(line_start) not in _JUNK_TOKENS:
        self._lines[line_num] = line.split("\n")[0]
    self.check_lines(tokens, line_start, line, line_num)

</t>
<t tx="ekr.20250131013559.425">def process_module(self, node: nodes.Module) -&gt; None:
    pass

</t>
<t tx="ekr.20250131013559.426"># pylint: disable-next = too-many-return-statements, too-many-branches
def _check_keyword_parentheses(
    self, tokens: list[tokenize.TokenInfo], start: int
) -&gt; None:
    """Check that there are not unnecessary parentheses after a keyword.

    Parens are unnecessary if there is exactly one balanced outer pair on a
    line and contains no commas (i.e. is not a tuple).

    Args:
    tokens: The entire list of Tokens.
    start: The position of the keyword in the token list.
    """
    # If the next token is not a paren, we're fine.
    if tokens[start + 1].string != "(":
        return
    if (
        tokens[start].string == "not"
        and start &gt; 0
        and tokens[start - 1].string == "is"
    ):
        # If this is part of an `is not` expression, we have a binary operator
        # so the parentheses are not necessarily redundant.
        return
    found_and_or = False
    contains_walrus_operator = False
    walrus_operator_depth = 0
    contains_double_parens = 0
    depth = 0
    keyword_token = str(tokens[start].string)
    line_num = tokens[start].start[0]
    for i in range(start, len(tokens) - 1):
        token = tokens[i]

        # If we hit a newline, then assume any parens were for continuation.
        if token.type == tokenize.NL:
            return
        # Since the walrus operator doesn't exist below python3.8, the tokenizer
        # generates independent tokens
        if (
            token.string == ":="  # &lt;-- python3.8+ path
            or token.string + tokens[i + 1].string == ":="
        ):
            contains_walrus_operator = True
            walrus_operator_depth = depth
        if token.string == "(":
            depth += 1
            if tokens[i + 1].string == "(":
                contains_double_parens = 1
        elif token.string == ")":
            depth -= 1
            if depth:
                if contains_double_parens and tokens[i + 1].string == ")":
                    # For walrus operators in `if (not)` conditions and comprehensions
                    if keyword_token in {"in", "if", "not"}:
                        continue
                    return
                contains_double_parens -= 1
                continue
            # ')' can't happen after if (foo), since it would be a syntax error.
            if tokens[i + 1].string in {":", ")", "]", "}", "in"} or tokens[
                i + 1
            ].type in {tokenize.NEWLINE, tokenize.ENDMARKER, tokenize.COMMENT}:
                if contains_walrus_operator and walrus_operator_depth - 1 == depth:
                    return
                # The empty tuple () is always accepted.
                if i == start + 2:
                    return
                if found_and_or:
                    return
                if keyword_token == "in":
                    # This special case was added in https://github.com/pylint-dev/pylint/pull/4948
                    # but it could be removed in the future. Avoid churn for now.
                    return
                self.add_message(
                    "superfluous-parens", line=line_num, args=keyword_token
                )
            return
        elif depth == 1:
            # This is a tuple, which is always acceptable.
            if token[1] == ",":
                return
            # 'and' and 'or' are the only boolean operators with lower precedence
            # than 'not', so parens are only required when they are found.
            if token[1] in {"and", "or"}:
                found_and_or = True
            # A yield inside an expression must always be in parentheses,
            # quit early without error.
            elif token[1] == "yield":
                return
            # A generator expression always has a 'for' token in it, and
            # the 'for' token is only legal inside parens when it is in a
            # generator expression.  The parens are necessary here, so bail
            # without an error.
            elif token[1] == "for":
                return
            # A generator expression can have an 'else' token in it.
            # We check the rest of the tokens to see if any problems occur after
            # the 'else'.
            elif token[1] == "else":
                if "(" in (i.string for i in tokens[i:]):
                    self._check_keyword_parentheses(tokens[i:], 0)
                return

</t>
<t tx="ekr.20250131013559.427">def process_tokens(self, tokens: list[tokenize.TokenInfo]) -&gt; None:
    """Process tokens and search for:

    - too long lines (i.e. longer than &lt;max_chars&gt;)
    - optionally bad construct (if given, bad_construct must be a compiled
      regular expression).
    """
    indents = [0]
    check_equal = False
    line_num = 0
    self._lines = {}
    self._visited_lines = {}
    self._last_line_ending: str | None = None
    last_blank_line_num = 0
    for idx, (tok_type, string, start, _, line) in enumerate(tokens):
        if start[0] != line_num:
            line_num = start[0]
            # A tokenizer oddity: if an indented line contains a multi-line
            # docstring, the line member of the INDENT token does not contain
            # the full line; therefore we check the next token on the line.
            if tok_type == tokenize.INDENT:
                self.new_line(TokenWrapper(tokens), idx - 1, idx + 1)
            else:
                self.new_line(TokenWrapper(tokens), idx - 1, idx)

        if tok_type == tokenize.NEWLINE:
            # a program statement, or ENDMARKER, will eventually follow,
            # after some (possibly empty) run of tokens of the form
            #     (NL | COMMENT)* (INDENT | DEDENT+)?
            # If an INDENT appears, setting check_equal is wrong, and will
            # be undone when we see the INDENT.
            check_equal = True
            self._check_line_ending(string, line_num)
        elif tok_type == tokenize.INDENT:
            check_equal = False
            self.check_indent_level(string, indents[-1] + 1, line_num)
            indents.append(indents[-1] + 1)
        elif tok_type == tokenize.DEDENT:
            # there's nothing we need to check here!  what's important is
            # that when the run of DEDENTs ends, the indentation of the
            # program statement (or ENDMARKER) that triggered the run is
            # equal to what's left at the top of the indents stack
            check_equal = True
            if len(indents) &gt; 1:
                del indents[-1]
        elif tok_type == tokenize.NL:
            if not line.strip("\r\n"):
                last_blank_line_num = line_num
        elif tok_type not in (tokenize.COMMENT, tokenize.ENCODING):
            # This is the first concrete token following a NEWLINE, so it
            # must be the first token of the next program statement, or an
            # ENDMARKER; the "line" argument exposes the leading white-space
            # for this statement; in the case of ENDMARKER, line is an empty
            # string, so will properly match the empty string with which the
            # "indents" stack was seeded
            if check_equal:
                check_equal = False
                self.check_indent_level(line, indents[-1], line_num)

        if tok_type == tokenize.NUMBER and string.endswith("l"):
            self.add_message("lowercase-l-suffix", line=line_num)

        if string in _KEYWORD_TOKENS:
            self._check_keyword_parentheses(tokens, idx)

    line_num -= 1  # to be ok with "wc -l"
    if line_num &gt; self.linter.config.max_module_lines:
        # Get the line where the too-many-lines (or its message id)
        # was disabled or default to 1.
        message_definition = self.linter.msgs_store.get_message_definitions(
            "too-many-lines"
        )[0]
        names = (message_definition.msgid, "too-many-lines")
        lineno = next(
            filter(None, (self.linter._pragma_lineno.get(name) for name in names)),
            1,
        )
        self.add_message(
            "too-many-lines",
            args=(line_num, self.linter.config.max_module_lines),
            line=lineno,
        )

    # See if there are any trailing lines.  Do not complain about empty
    # files like __init__.py markers.
    if line_num == last_blank_line_num and line_num &gt; 0:
        self.add_message("trailing-newlines", line=line_num)

</t>
<t tx="ekr.20250131013559.428">def _check_line_ending(self, line_ending: str, line_num: int) -&gt; None:
    # check if line endings are mixed
    if self._last_line_ending is not None:
        # line_ending == "" indicates a synthetic newline added at
        # the end of a file that does not, in fact, end with a
        # newline.
        if line_ending and line_ending != self._last_line_ending:
            self.add_message("mixed-line-endings", line=line_num)

    self._last_line_ending = line_ending

    # check if line ending is as expected
    expected = self.linter.config.expected_line_ending_format
    if expected:
        # reduce multiple \n\n\n\n to one \n
        line_ending = reduce(lambda x, y: x + y if x != y else x, line_ending, "")
        line_ending = "LF" if line_ending == "\n" else "CRLF"
        if line_ending != expected:
            self.add_message(
                "unexpected-line-ending-format",
                args=(line_ending, expected),
                line=line_num,
            )

</t>
<t tx="ekr.20250131013559.429">@only_required_for_messages("multiple-statements")
def visit_default(self, node: nodes.NodeNG) -&gt; None:
    """Check the node line number and check it if not yet done."""
    if not node.is_statement:
        return
    if not node.root().pure_python:
        return
    prev_sibl = node.previous_sibling()
    if prev_sibl is not None:
        prev_line = prev_sibl.fromlineno
    elif isinstance(
        node.parent, nodes.Try
    ) and self._is_first_node_in_else_finally_body(node, node.parent):
        prev_line = self._infer_else_finally_line_number(node, node.parent)
    elif isinstance(node.parent, nodes.Module):
        prev_line = 0
    else:
        prev_line = node.parent.statement().fromlineno
    line = node.fromlineno
    assert line, node
    if prev_line == line and self._visited_lines.get(line) != 2:
        self._check_multi_statement_line(node, line)
        return
    if line in self._visited_lines:
        return
    try:
        tolineno = node.blockstart_tolineno
    except AttributeError:
        tolineno = node.tolineno
    assert tolineno, node
    lines: list[str] = []
    for line in range(line, tolineno + 1):  # noqa: B020
        self._visited_lines[line] = 1
        try:
            lines.append(self._lines[line].rstrip())
        except KeyError:
            lines.append("")

</t>
<t tx="ekr.20250131013559.430">def _is_first_node_in_else_finally_body(
    self, node: nodes.NodeNG, parent: nodes.Try
) -&gt; bool:
    if parent.orelse and node == parent.orelse[0]:
        return True
    if parent.finalbody and node == parent.finalbody[0]:
        return True
    return False

</t>
<t tx="ekr.20250131013559.431">def _infer_else_finally_line_number(
    self, node: nodes.NodeNG, parent: nodes.Try
) -&gt; int:
    last_line_of_prev_block = 0
    if node in parent.finalbody and parent.orelse:
        last_line_of_prev_block = parent.orelse[-1].tolineno
    elif parent.handlers and parent.handlers[-1].body:
        last_line_of_prev_block = parent.handlers[-1].body[-1].tolineno
    elif parent.body:
        last_line_of_prev_block = parent.body[-1].tolineno

    return last_line_of_prev_block + 1 if last_line_of_prev_block else 0

</t>
<t tx="ekr.20250131013559.432">def _check_multi_statement_line(self, node: nodes.NodeNG, line: int) -&gt; None:
    """Check for lines containing multiple statements."""
    if isinstance(node, nodes.With):
        # Do not warn about multiple nested context managers in with statements.
        return
    if (
        isinstance(node.parent, nodes.If)
        and not node.parent.orelse
        and self.linter.config.single_line_if_stmt
    ):
        return
    if (
        isinstance(node.parent, nodes.ClassDef)
        and len(node.parent.body) == 1
        and self.linter.config.single_line_class_stmt
    ):
        return

    # Functions stubs and class with ``Ellipsis`` as body are exempted.
    if (
        isinstance(node, nodes.Expr)
        and isinstance(node.parent, (nodes.FunctionDef, nodes.ClassDef))
        and isinstance(node.value, nodes.Const)
        and node.value.value is Ellipsis
    ):
        return

    self.add_message("multiple-statements", node=node, confidence=HIGH)
    self._visited_lines[line] = 2

</t>
<t tx="ekr.20250131013559.433">def check_trailing_whitespace_ending(self, line: str, i: int) -&gt; None:
    """Check that there is no trailing white-space."""
    # exclude \f (formfeed) from the rstrip
    stripped_line = line.rstrip("\t\n\r\v ")
    if line[len(stripped_line) :] not in ("\n", "\r\n"):
        self.add_message(
            "trailing-whitespace",
            line=i,
            col_offset=len(stripped_line),
            confidence=HIGH,
        )

</t>
<t tx="ekr.20250131013559.434">def check_line_length(self, line: str, i: int, checker_off: bool) -&gt; None:
    """Check that the line length is less than the authorized value."""
    max_chars = self.linter.config.max_line_length
    ignore_long_line = self.linter.config.ignore_long_lines
    line = line.rstrip()
    if len(line) &gt; max_chars and not ignore_long_line.search(line):
        if checker_off:
            self.linter.add_ignored_message("line-too-long", i)
        else:
            self.add_message("line-too-long", line=i, args=(len(line), max_chars))

</t>
<t tx="ekr.20250131013559.435">@staticmethod
def remove_pylint_option_from_lines(options_pattern_obj: Match[str]) -&gt; str:
    """Remove the `# pylint ...` pattern from lines."""
    lines = options_pattern_obj.string
    purged_lines = (
        lines[: options_pattern_obj.start(1)].rstrip()
        + lines[options_pattern_obj.end(1) :]
    )
    return purged_lines

</t>
<t tx="ekr.20250131013559.436">@staticmethod
def is_line_length_check_activated(pylint_pattern_match_object: Match[str]) -&gt; bool:
    """Return True if the line length check is activated."""
    try:
        for pragma in parse_pragma(pylint_pattern_match_object.group(2)):
            if pragma.action == "disable" and "line-too-long" in pragma.messages:
                return False
    except PragmaParserError:
        # Printing useful information dealing with this error is done in the lint package
        pass
    return True

</t>
<t tx="ekr.20250131013559.437">@staticmethod
def specific_splitlines(lines: str) -&gt; list[str]:
    """Split lines according to universal newlines except those in a specific
    sets.
    """
    unsplit_ends = {
        "\x0b",  # synonym of \v
        "\x0c",  # synonym of \f
        "\x1c",
        "\x1d",
        "\x1e",
        "\x85",
        "\u2028",
        "\u2029",
    }
    res: list[str] = []
    buffer = ""
    for atomic_line in lines.splitlines(True):
        if atomic_line[-1] not in unsplit_ends:
            res.append(buffer + atomic_line)
            buffer = ""
        else:
            buffer += atomic_line
    return res

</t>
<t tx="ekr.20250131013559.438">def check_lines(
    self, tokens: TokenWrapper, line_start: int, lines: str, lineno: int
) -&gt; None:
    """Check given lines for potential messages.

    Check if lines have:
    - a final newline
    - no trailing white-space
    - less than a maximum number of characters
    """
    # we're first going to do a rough check whether any lines in this set
    # go over the line limit. If none of them do, then we don't need to
    # parse out the pylint options later on and can just assume that these
    # lines are clean

    # we'll also handle the line ending check here to avoid double-iteration
    # unless the line lengths are suspect

    max_chars = self.linter.config.max_line_length

    split_lines = self.specific_splitlines(lines)

    for offset, line in enumerate(split_lines):
        if not line.endswith("\n"):
            self.add_message("missing-final-newline", line=lineno + offset)
            continue
        # We don't test for trailing whitespaces in strings
        # See https://github.com/pylint-dev/pylint/issues/6936
        # and https://github.com/pylint-dev/pylint/issues/3822
        if tokens.type(line_start) != tokenize.STRING:
            self.check_trailing_whitespace_ending(line, lineno + offset)

    # This check is purposefully simple and doesn't rstrip since this is running
    # on every line you're checking it's advantageous to avoid doing a lot of work
    potential_line_length_warning = any(
        len(line) &gt; max_chars for line in split_lines
    )

    # if there were no lines passing the max_chars config, we don't bother
    # running the full line check (as we've met an even more strict condition)
    if not potential_line_length_warning:
        return

    # Line length check may be deactivated through `pylint: disable` comment
    mobj = OPTION_PO.search(lines)
    checker_off = False
    if mobj:
        if not self.is_line_length_check_activated(mobj):
            checker_off = True
        # The 'pylint: disable whatever' should not be taken into account for line length count
        lines = self.remove_pylint_option_from_lines(mobj)

    # here we re-run specific_splitlines since we have filtered out pylint options above
    for offset, line in enumerate(self.specific_splitlines(lines)):
        self.check_line_length(line, lineno + offset, checker_off)

</t>
<t tx="ekr.20250131013559.439">def check_indent_level(self, string: str, expected: int, line_num: int) -&gt; None:
    """Return the indent level of the string."""
    indent = self.linter.config.indent_string
    if indent == "\\t":  # \t is not interpreted in the configuration file
        indent = "\t"
    level = 0
    unit_size = len(indent)
    while string[:unit_size] == indent:
        string = string[unit_size:]
        level += 1
    suppl = ""
    while string and string[0] in " \t":
        suppl += string[0]
        string = string[1:]
    if level != expected or suppl:
        i_type = "spaces"
        if indent[0] == "\t":
            i_type = "tabs"
        self.add_message(
            "bad-indentation",
            line=line_num,
            args=(level * unit_size + len(suppl), i_type, expected * unit_size),
        )


</t>
<t tx="ekr.20250131013559.440">@path pylint/checkers
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Imports checkers for Python code."""

from __future__ import annotations

import collections
import copy
import os
import sys
from collections import defaultdict
from collections.abc import ItemsView, Sequence
from functools import cached_property
from typing import TYPE_CHECKING, Any, Union

import astroid
from astroid import nodes
from astroid.nodes._base_nodes import ImportNode

from pylint.checkers import BaseChecker, DeprecatedMixin
from pylint.checkers.utils import (
    get_import_name,
    in_type_checking_block,
    is_from_fallback_block,
    is_module_ignored,
    is_sys_guard,
    node_ignores_exception,
)
from pylint.constants import MAX_NUMBER_OF_IMPORT_SHOWN
from pylint.exceptions import EmptyReportError
from pylint.graph import DotBackend, get_cycles
from pylint.interfaces import HIGH
from pylint.reporters.ureports.nodes import Paragraph, Section, VerbatimText
from pylint.typing import MessageDefinitionTuple
from pylint.utils import IsortDriver
from pylint.utils.linterstats import LinterStats

if TYPE_CHECKING:
    from pylint.lint import PyLinter


# The dictionary with Any should actually be a _ImportTree again
# but mypy doesn't support recursive types yet
_ImportTree = dict[str, Union[list[dict[str, Any]], list[str]]]

DEPRECATED_MODULES = {
    (0, 0, 0): {"tkinter.tix", "fpectl"},
    (3, 2, 0): {"optparse"},
    (3, 3, 0): {"xml.etree.cElementTree"},
    (3, 4, 0): {"imp"},
    (3, 5, 0): {"formatter"},
    (3, 6, 0): {"asynchat", "asyncore", "smtpd"},
    (3, 7, 0): {"macpath"},
    (3, 9, 0): {"lib2to3", "parser", "symbol", "binhex"},
    (3, 10, 0): {"distutils", "typing.io", "typing.re"},
    (3, 11, 0): {
        "aifc",
        "audioop",
        "cgi",
        "cgitb",
        "chunk",
        "crypt",
        "imghdr",
        "msilib",
        "mailcap",
        "nis",
        "nntplib",
        "ossaudiodev",
        "pipes",
        "sndhdr",
        "spwd",
        "sunau",
        "sre_compile",
        "sre_constants",
        "sre_parse",
        "telnetlib",
        "uu",
        "xdrlib",
    },
    (3, 13, 0): {"getopt"},
}


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013559.441">def _get_first_import(
    node: ImportNode,
    context: nodes.LocalsDictNodeNG,
    name: str,
    base: str | None,
    level: int | None,
    alias: str | None,
) -&gt; tuple[nodes.Import | nodes.ImportFrom | None, str | None]:
    """Return the node where [base.]&lt;name&gt; is imported or None if not found."""
    fullname = f"{base}.{name}" if base else name

    first = None
    found = False
    msg = "reimported"

    for first in context.body:
        if first is node:
            continue
        if first.scope() is node.scope() and first.fromlineno &gt; node.fromlineno:
            continue
        if isinstance(first, nodes.Import):
            if any(fullname == iname[0] for iname in first.names):
                found = True
                break
            for imported_name, imported_alias in first.names:
                if not imported_alias and imported_name == alias:
                    found = True
                    msg = "shadowed-import"
                    break
            if found:
                break
        elif isinstance(first, nodes.ImportFrom):
            if level == first.level:
                for imported_name, imported_alias in first.names:
                    if fullname == f"{first.modname}.{imported_name}":
                        found = True
                        break
                    if (
                        name != "*"
                        and name == imported_name
                        and not (alias or imported_alias)
                    ):
                        found = True
                        break
                    if not imported_alias and imported_name == alias:
                        found = True
                        msg = "shadowed-import"
                        break
                if found:
                    break
    if found and not astroid.are_exclusive(first, node):
        return first, msg
    return None, None


</t>
<t tx="ekr.20250131013559.442">def _ignore_import_failure(
    node: ImportNode,
    modname: str,
    ignored_modules: Sequence[str],
) -&gt; bool:
    if is_module_ignored(modname, ignored_modules):
        return True

    # Ignore import failure if part of guarded import block
    # I.e. `sys.version_info` or `typing.TYPE_CHECKING`
    if in_type_checking_block(node):
        return True
    if isinstance(node.parent, nodes.If) and is_sys_guard(node.parent):
        return True

    return node_ignores_exception(node, ImportError)


</t>
<t tx="ekr.20250131013559.443"># utilities to represents import dependencies as tree and dot graph ###########


def _make_tree_defs(mod_files_list: ItemsView[str, set[str]]) -&gt; _ImportTree:
    """Get a list of 2-uple (module, list_of_files_which_import_this_module),
    it will return a dictionary to represent this as a tree.
    """
    tree_defs: _ImportTree = {}
    for mod, files in mod_files_list:
        node: list[_ImportTree | list[str]] = [tree_defs, []]
        for prefix in mod.split("."):
            assert isinstance(node[0], dict)
            node = node[0].setdefault(prefix, ({}, []))  # type: ignore[arg-type,assignment]
        assert isinstance(node[1], list)
        node[1].extend(files)
    return tree_defs


</t>
<t tx="ekr.20250131013559.444">def _repr_tree_defs(data: _ImportTree, indent_str: str | None = None) -&gt; str:
    """Return a string which represents imports as a tree."""
    lines = []
    nodes_items = data.items()
    for i, (mod, (sub, files)) in enumerate(sorted(nodes_items, key=lambda x: x[0])):
        files_list = "" if not files else f"({','.join(sorted(files))})"
        if indent_str is None:
            lines.append(f"{mod} {files_list}")
            sub_indent_str = "  "
        else:
            lines.append(rf"{indent_str}\-{mod} {files_list}")
            if i == len(nodes_items) - 1:
                sub_indent_str = f"{indent_str}  "
            else:
                sub_indent_str = f"{indent_str}| "
        if sub and isinstance(sub, dict):
            lines.append(_repr_tree_defs(sub, sub_indent_str))
    return "\n".join(lines)


</t>
<t tx="ekr.20250131013559.445">def _dependencies_graph(filename: str, dep_info: dict[str, set[str]]) -&gt; str:
    """Write dependencies as a dot (graphviz) file."""
    done = {}
    printer = DotBackend(os.path.splitext(os.path.basename(filename))[0], rankdir="LR")
    printer.emit('URL="." node[shape="box"]')
    for modname, dependencies in sorted(dep_info.items()):
        sorted_dependencies = sorted(dependencies)
        done[modname] = 1
        printer.emit_node(modname)
        for depmodname in sorted_dependencies:
            if depmodname not in done:
                done[depmodname] = 1
                printer.emit_node(depmodname)
    for depmodname, dependencies in sorted(dep_info.items()):
        for modname in sorted(dependencies):
            printer.emit_edge(modname, depmodname)
    return printer.generate(filename)


</t>
<t tx="ekr.20250131013559.446">def _make_graph(
    filename: str, dep_info: dict[str, set[str]], sect: Section, gtype: str
) -&gt; None:
    """Generate a dependencies graph and add some information about it in the
    report's section.
    """
    outputfile = _dependencies_graph(filename, dep_info)
    sect.append(Paragraph((f"{gtype}imports graph has been written to {outputfile}",)))


</t>
<t tx="ekr.20250131013559.447"># the import checker itself ###################################################

MSGS: dict[str, MessageDefinitionTuple] = {
    "E0401": (
        "Unable to import %s",
        "import-error",
        "Used when pylint has been unable to import a module.",
        {"old_names": [("F0401", "old-import-error")]},
    ),
    "E0402": (
        "Attempted relative import beyond top-level package",
        "relative-beyond-top-level",
        "Used when a relative import tries to access too many levels "
        "in the current package.",
    ),
    "R0401": (
        "Cyclic import (%s)",
        "cyclic-import",
        "Used when a cyclic import between two or more modules is detected.",
    ),
    "R0402": (
        "Use 'from %s import %s' instead",
        "consider-using-from-import",
        "Emitted when a submodule of a package is imported and "
        "aliased with the same name, "
        "e.g., instead of ``import concurrent.futures as futures`` use "
        "``from concurrent import futures``.",
    ),
    "W0401": (
        "Wildcard import %s",
        "wildcard-import",
        "Used when `from module import *` is detected.",
    ),
    "W0404": (
        "Reimport %r (imported line %s)",
        "reimported",
        "Used when a module is imported more than once.",
    ),
    "W0406": (
        "Module import itself",
        "import-self",
        "Used when a module is importing itself.",
    ),
    "W0407": (
        "Prefer importing %r instead of %r",
        "preferred-module",
        "Used when a module imported has a preferred replacement module.",
    ),
    "W0410": (
        "__future__ import is not the first non docstring statement",
        "misplaced-future",
        "Python 2.5 and greater require __future__ import to be the "
        "first non docstring statement in the module.",
    ),
    "C0410": (
        "Multiple imports on one line (%s)",
        "multiple-imports",
        "Used when import statement importing multiple modules is detected.",
    ),
    "C0411": (
        "%s should be placed before %s",
        "wrong-import-order",
        "Used when PEP8 import order is not respected (standard imports "
        "first, then third-party libraries, then local imports).",
    ),
    "C0412": (
        "Imports from package %s are not grouped",
        "ungrouped-imports",
        "Used when imports are not grouped by packages.",
    ),
    "C0413": (
        'Import "%s" should be placed at the top of the module',
        "wrong-import-position",
        "Used when code and imports are mixed.",
    ),
    "C0414": (
        "Import alias does not rename original package",
        "useless-import-alias",
        "Used when an import alias is same as original package, "
        "e.g., using import numpy as numpy instead of import numpy as np.",
    ),
    "C0415": (
        "Import outside toplevel (%s)",
        "import-outside-toplevel",
        "Used when an import statement is used anywhere other than the module "
        "toplevel. Move this import to the top of the file.",
    ),
    "W0416": (
        "Shadowed %r (imported line %s)",
        "shadowed-import",
        "Used when a module is aliased with a name that shadows another import.",
    ),
}


DEFAULT_STANDARD_LIBRARY = ()
DEFAULT_KNOWN_THIRD_PARTY = ("enchant",)
DEFAULT_PREFERRED_MODULES = ()


class ImportsChecker(DeprecatedMixin, BaseChecker):
    """BaseChecker for import statements.

    Checks for
    * external modules dependencies
    * relative / wildcard imports
    * cyclic imports
    * uses of deprecated modules
    * uses of modules instead of preferred modules
    """

    @others
</t>
<t tx="ekr.20250131013559.448">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(ImportsChecker(linter))
</t>
<t tx="ekr.20250131013559.449">name = "imports"
msgs = {** DeprecatedMixin.DEPRECATED_MODULE_MESSAGE, ** MSGS}
default_deprecated_modules = ()

options = (
    (
        "deprecated-modules",
        {
            "default": default_deprecated_modules,
            "type": "csv",
            "metavar": "&lt;modules&gt;",
            "help": "Deprecated modules which should not be used,"
            " separated by a comma.",
        },
    ),
    (
        "preferred-modules",
        {
            "default": DEFAULT_PREFERRED_MODULES,
            "type": "csv",
            "metavar": "&lt;module:preferred-module&gt;",
            "help": "Couples of modules and preferred modules,"
            " separated by a comma.",
        },
    ),
    (
        "import-graph",
        {
            "default": "",
            "type": "path",
            "metavar": "&lt;file.gv&gt;",
            "help": "Output a graph (.gv or any supported image format) of"
            " all (i.e. internal and external) dependencies to the given file"
            " (report RP0402 must not be disabled).",
        },
    ),
    (
        "ext-import-graph",
        {
            "default": "",
            "type": "path",
            "metavar": "&lt;file.gv&gt;",
            "help": "Output a graph (.gv or any supported image format)"
            " of external dependencies to the given file"
            " (report RP0402 must not be disabled).",
        },
    ),
    (
        "int-import-graph",
        {
            "default": "",
            "type": "path",
            "metavar": "&lt;file.gv&gt;",
            "help": "Output a graph (.gv or any supported image format)"
            " of internal dependencies to the given file"
            " (report RP0402 must not be disabled).",
        },
    ),
    (
        "known-standard-library",
        {
            "default": DEFAULT_STANDARD_LIBRARY,
            "type": "csv",
            "metavar": "&lt;modules&gt;",
            "help": "Force import order to recognize a module as part of "
            "the standard compatibility libraries.",
        },
    ),
    (
        "known-third-party",
        {
            "default": DEFAULT_KNOWN_THIRD_PARTY,
            "type": "csv",
            "metavar": "&lt;modules&gt;",
            "help": "Force import order to recognize a module as part of "
            "a third party library.",
        },
    ),
    (
        "allow-any-import-level",
        {
            "default": (),
            "type": "csv",
            "metavar": "&lt;modules&gt;",
            "help": (
                "List of modules that can be imported at any level, not just "
                "the top level one."
            ),
        },
    ),
    (
        "allow-wildcard-with-all",
        {
            "default": False,
            "type": "yn",
            "metavar": "&lt;y or n&gt;",
            "help": "Allow wildcard imports from modules that define __all__.",
        },
    ),
    (
        "allow-reexport-from-package",
        {
            "default": False,
            "type": "yn",
            "metavar": "&lt;y or n&gt;",
            "help": "Allow explicit reexports by alias from a package __init__.",
        },
    ),
)

def __init__(self, linter: PyLinter) -&gt; None:
    BaseChecker.__init__(self, linter)
    self.import_graph: defaultdict[str, set[str]] = defaultdict(set)
    self._imports_stack: list[tuple[ImportNode, str]] = []
    self._first_non_import_node = None
    self._module_pkg: dict[Any, Any] = (
        {}
    )  # mapping of modules to the pkg they belong in
    self._allow_any_import_level: set[Any] = set()
    self.reports = (
        ("RP0401", "External dependencies", self._report_external_dependencies),
        ("RP0402", "Modules dependencies graph", self._report_dependencies_graph),
    )
    self._excluded_edges: defaultdict[str, set[str]] = defaultdict(set)

</t>
<t tx="ekr.20250131013559.450">def open(self) -&gt; None:
    """Called before visiting project (i.e set of modules)."""
    self.linter.stats.dependencies = {}
    self.linter.stats = self.linter.stats
    self.import_graph = defaultdict(set)
    self._module_pkg = {}  # mapping of modules to the pkg they belong in
    self._current_module_package = False
    self._ignored_modules: Sequence[str] = self.linter.config.ignored_modules
    # Build a mapping {'module': 'preferred-module'}
    self.preferred_modules = dict(
        module.split(":")
        for module in self.linter.config.preferred_modules
        if ":" in module
    )
    self._allow_any_import_level = set(self.linter.config.allow_any_import_level)
    self._allow_reexport_package = self.linter.config.allow_reexport_from_package

</t>
<t tx="ekr.20250131013559.451">def _import_graph_without_ignored_edges(self) -&gt; defaultdict[str, set[str]]:
    filtered_graph = copy.deepcopy(self.import_graph)
    for node in filtered_graph:
        filtered_graph[node].difference_update(self._excluded_edges[node])
    return filtered_graph

</t>
<t tx="ekr.20250131013559.452">def close(self) -&gt; None:
    """Called before visiting project (i.e set of modules)."""
    if self.linter.is_message_enabled("cyclic-import"):
        graph = self._import_graph_without_ignored_edges()
        vertices = list(graph)
        for cycle in get_cycles(graph, vertices=vertices):
            self.add_message("cyclic-import", args=" -&gt; ".join(cycle))

</t>
<t tx="ekr.20250131013559.453">def get_map_data(
    self,
) -&gt; tuple[defaultdict[str, set[str]], defaultdict[str, set[str]]]:
    if self.linter.is_message_enabled("cyclic-import"):
        return (self.import_graph, self._excluded_edges)
    return (defaultdict(set), defaultdict(set))

</t>
<t tx="ekr.20250131013559.454">def reduce_map_data(
    self,
    linter: PyLinter,
    data: list[tuple[defaultdict[str, set[str]], defaultdict[str, set[str]]]],
) -&gt; None:
    if self.linter.is_message_enabled("cyclic-import"):
        self.import_graph = defaultdict(set)
        self._excluded_edges = defaultdict(set)
        for to_update in data:
            graph, excluded_edges = to_update
            self.import_graph.update(graph)
            self._excluded_edges.update(excluded_edges)

        self.close()

</t>
<t tx="ekr.20250131013559.455">def deprecated_modules(self) -&gt; set[str]:
    """Callback returning the deprecated modules."""
    # First get the modules the user indicated
    all_deprecated_modules = set(self.linter.config.deprecated_modules)
    # Now get the hard-coded ones from the stdlib
    for since_vers, mod_set in DEPRECATED_MODULES.items():
        if since_vers &lt;= sys.version_info:
            all_deprecated_modules = all_deprecated_modules.union(mod_set)
    return all_deprecated_modules

</t>
<t tx="ekr.20250131013559.456">def visit_module(self, node: nodes.Module) -&gt; None:
    """Store if current module is a package, i.e. an __init__ file."""
    self._current_module_package = node.package

</t>
<t tx="ekr.20250131013559.457">def visit_import(self, node: nodes.Import) -&gt; None:
    """Triggered when an import statement is seen."""
    self._check_reimport(node)
    self._check_import_as_rename(node)
    self._check_toplevel(node)

    names = [name for name, _ in node.names]
    if len(names) &gt;= 2:
        self.add_message("multiple-imports", args=", ".join(names), node=node)

    for name in names:
        self.check_deprecated_module(node, name)
        self._check_preferred_module(node, name)
        imported_module = self._get_imported_module(node, name)
        if isinstance(node.parent, nodes.Module):
            # Allow imports nested
            self._check_position(node)
        if isinstance(node.scope(), nodes.Module):
            self._record_import(node, imported_module)

        if imported_module is None:
            continue

        self._add_imported_module(node, imported_module.name)

</t>
<t tx="ekr.20250131013559.458">def visit_importfrom(self, node: nodes.ImportFrom) -&gt; None:
    """Triggered when a from statement is seen."""
    basename = node.modname
    imported_module = self._get_imported_module(node, basename)
    absolute_name = get_import_name(node, basename)

    self._check_import_as_rename(node)
    self._check_misplaced_future(node)
    self.check_deprecated_module(node, absolute_name)
    self._check_preferred_module(node, basename)
    self._check_wildcard_imports(node, imported_module)
    self._check_same_line_imports(node)
    self._check_reimport(node, basename=basename, level=node.level)
    self._check_toplevel(node)

    if isinstance(node.parent, nodes.Module):
        # Allow imports nested
        self._check_position(node)
    if isinstance(node.scope(), nodes.Module):
        self._record_import(node, imported_module)
    if imported_module is None:
        return
    for name, _ in node.names:
        if name != "*":
            self._add_imported_module(node, f"{imported_module.name}.{name}")
        else:
            self._add_imported_module(node, imported_module.name)

</t>
<t tx="ekr.20250131013559.459">def leave_module(self, node: nodes.Module) -&gt; None:
    # Check imports are grouped by category (standard, 3rd party, local)
    std_imports, ext_imports, loc_imports = self._check_imports_order(node)

    # Check that imports are grouped by package within a given category
    met_import: set[str] = set()  # set for 'import x' style
    met_from: set[str] = set()  # set for 'from x import y' style
    current_package = None
    for import_node, import_name in std_imports + ext_imports + loc_imports:
        met = met_from if isinstance(import_node, nodes.ImportFrom) else met_import
        package, _, _ = import_name.partition(".")
        if (
            current_package
            and current_package != package
            and package in met
            and not in_type_checking_block(import_node)
            and not (
                isinstance(import_node.parent, nodes.If)
                and is_sys_guard(import_node.parent)
            )
        ):
            self.add_message("ungrouped-imports", node=import_node, args=package)
        current_package = package
        if not self.linter.is_message_enabled(
            "ungrouped-imports", import_node.fromlineno
        ):
            continue
        met.add(package)

    self._imports_stack = []
    self._first_non_import_node = None

</t>
<t tx="ekr.20250131013559.460">def compute_first_non_import_node(
    self,
    node: (
        nodes.If
        | nodes.Expr
        | nodes.Comprehension
        | nodes.IfExp
        | nodes.Assign
        | nodes.AssignAttr
        | nodes.Try
    ),
</t>
<t tx="ekr.20250131013559.461">) -&gt; None:
    # if the node does not contain an import instruction, and if it is the
    # first node of the module, keep a track of it (all the import positions
    # of the module will be compared to the position of this first
    # instruction)
    if self._first_non_import_node:
        return
    if not isinstance(node.parent, nodes.Module):
        return
    if isinstance(node, nodes.Try) and any(
        node.nodes_of_class((nodes.Import, nodes.ImportFrom))
    ):
        return
    if isinstance(node, nodes.Assign):
        # Add compatibility for module level dunder names
        # https://www.python.org/dev/peps/pep-0008/#module-level-dunder-names
        valid_targets = [
            isinstance(target, nodes.AssignName)
            and target.name.startswith("__")
            and target.name.endswith("__")
            for target in node.targets
        ]
        if all(valid_targets):
            return
    self._first_non_import_node = node

visit_try = visit_assignattr = visit_assign = visit_ifexp = visit_comprehension = (
    visit_expr
) = visit_if = compute_first_non_import_node

def visit_functiondef(
    self, node: nodes.FunctionDef | nodes.While | nodes.For | nodes.ClassDef
) -&gt; None:
    # If it is the first non import instruction of the module, record it.
    if self._first_non_import_node:
        return

    # Check if the node belongs to an `If` or a `Try` block. If they
    # contain imports, skip recording this node.
    if not isinstance(node.parent.scope(), nodes.Module):
        return

    root = node
    while not isinstance(root.parent, nodes.Module):
        root = root.parent

    if isinstance(root, (nodes.If, nodes.Try)):
        if any(root.nodes_of_class((nodes.Import, nodes.ImportFrom))):
            return

    self._first_non_import_node = node

</t>
<t tx="ekr.20250131013559.462">visit_classdef = visit_for = visit_while = visit_functiondef

def _check_misplaced_future(self, node: nodes.ImportFrom) -&gt; None:
    basename = node.modname
    if basename == "__future__":
        # check if this is the first non-docstring statement in the module
        prev = node.previous_sibling()
        if prev:
            # consecutive future statements are possible
            if not (
                isinstance(prev, nodes.ImportFrom) and prev.modname == "__future__"
            ):
                self.add_message("misplaced-future", node=node)

</t>
<t tx="ekr.20250131013559.463">def _check_same_line_imports(self, node: nodes.ImportFrom) -&gt; None:
    # Detect duplicate imports on the same line.
    names = (name for name, _ in node.names)
    counter = collections.Counter(names)
    for name, count in counter.items():
        if count &gt; 1:
            self.add_message("reimported", node=node, args=(name, node.fromlineno))

</t>
<t tx="ekr.20250131013559.464">def _check_position(self, node: ImportNode) -&gt; None:
    """Check `node` import or importfrom node position is correct.

    Send a message  if `node` comes before another instruction
    """
    # if a first non-import instruction has already been encountered,
    # it means the import comes after it and therefore is not well placed
    if self._first_non_import_node:
        if self.linter.is_message_enabled(
            "wrong-import-position", self._first_non_import_node.fromlineno
        ):
            self.add_message(
                "wrong-import-position", node=node, args=node.as_string()
            )
        else:
            self.linter.add_ignored_message(
                "wrong-import-position", node.fromlineno, node
            )

</t>
<t tx="ekr.20250131013559.465">def _record_import(
    self,
    node: ImportNode,
    importedmodnode: nodes.Module | None,
) -&gt; None:
    """Record the package `node` imports from."""
    if isinstance(node, nodes.ImportFrom):
        importedname = node.modname
    else:
        importedname = importedmodnode.name if importedmodnode else None
    if not importedname:
        importedname = node.names[0][0].split(".")[0]

    if isinstance(node, nodes.ImportFrom) and (node.level or 0) &gt;= 1:
        # We need the importedname with first point to detect local package
        # Example of node:
        #  'from .my_package1 import MyClass1'
        #  the output should be '.my_package1' instead of 'my_package1'
        # Example of node:
        #  'from . import my_package2'
        #  the output should be '.my_package2' instead of '{pyfile}'
        importedname = "." + importedname

    self._imports_stack.append((node, importedname))

</t>
<t tx="ekr.20250131013559.466">@staticmethod
def _is_fallback_import(
    node: ImportNode, imports: list[tuple[ImportNode, str]]
) -&gt; bool:
    imports = [import_node for (import_node, _) in imports]
    return any(astroid.are_exclusive(import_node, node) for import_node in imports)

</t>
<t tx="ekr.20250131013559.467"># pylint: disable = too-many-statements
def _check_imports_order(self, _module_node: nodes.Module) -&gt; tuple[
    list[tuple[ImportNode, str]],
    list[tuple[ImportNode, str]],
    list[tuple[ImportNode, str]],
</t>
<t tx="ekr.20250131013559.468">]:
    """Checks imports of module `node` are grouped by category.

    Imports must follow this order: standard, 3rd party, local
    """
    std_imports: list[tuple[ImportNode, str]] = []
    third_party_imports: list[tuple[ImportNode, str]] = []
    first_party_imports: list[tuple[ImportNode, str]] = []
    # need of a list that holds third or first party ordered import
    external_imports: list[tuple[ImportNode, str]] = []
    local_imports: list[tuple[ImportNode, str]] = []
    third_party_not_ignored: list[tuple[ImportNode, str]] = []
    first_party_not_ignored: list[tuple[ImportNode, str]] = []
    local_not_ignored: list[tuple[ImportNode, str]] = []
    isort_driver = IsortDriver(self.linter.config)
    for node, modname in self._imports_stack:
        if modname.startswith("."):
            package = "." + modname.split(".")[1]
        else:
            package = modname.split(".")[0]
        nested = not isinstance(node.parent, nodes.Module)
        ignore_for_import_order = not self.linter.is_message_enabled(
            "wrong-import-order", node.fromlineno
        )
        import_category = isort_driver.place_module(package)
        node_and_package_import = (node, package)

        if import_category in {"FUTURE", "STDLIB"}:
            std_imports.append(node_and_package_import)
            wrong_import = (
                third_party_not_ignored
                or first_party_not_ignored
                or local_not_ignored
            )
            if self._is_fallback_import(node, wrong_import):
                continue
            if wrong_import and not nested:
                self.add_message(
                    "wrong-import-order",
                    node=node,
                    args=(  ## TODO - this isn't right for multiple on the same line...
                        f'standard import "{self._get_full_import_name((node, package))}"',
                        self._get_out_of_order_string(
                            third_party_not_ignored,
                            first_party_not_ignored,
                            local_not_ignored,
                        ),
                    ),
                )
        elif import_category == "THIRDPARTY":
            third_party_imports.append(node_and_package_import)
            external_imports.append(node_and_package_import)
            if not nested:
                if not ignore_for_import_order:
                    third_party_not_ignored.append(node_and_package_import)
                else:
                    self.linter.add_ignored_message(
                        "wrong-import-order", node.fromlineno, node
                    )
            wrong_import = first_party_not_ignored or local_not_ignored
            if wrong_import and not nested:
                self.add_message(
                    "wrong-import-order",
                    node=node,
                    args=(
                        f'third party import "{self._get_full_import_name((node, package))}"',
                        self._get_out_of_order_string(
                            None, first_party_not_ignored, local_not_ignored
                        ),
                    ),
                )
        elif import_category == "FIRSTPARTY":
            first_party_imports.append(node_and_package_import)
            external_imports.append(node_and_package_import)
            if not nested:
                if not ignore_for_import_order:
                    first_party_not_ignored.append(node_and_package_import)
                else:
                    self.linter.add_ignored_message(
                        "wrong-import-order", node.fromlineno, node
                    )
            wrong_import = local_not_ignored
            if wrong_import and not nested:
                self.add_message(
                    "wrong-import-order",
                    node=node,
                    args=(
                        f'first party import "{self._get_full_import_name((node, package))}"',
                        self._get_out_of_order_string(
                            None, None, local_not_ignored
                        ),
                    ),
                )
        elif import_category == "LOCALFOLDER":
            local_imports.append((node, package))
            if not nested:
                if not ignore_for_import_order:
                    local_not_ignored.append((node, package))
                else:
                    self.linter.add_ignored_message(
                        "wrong-import-order", node.fromlineno, node
                    )
    return std_imports, external_imports, local_imports

def _get_out_of_order_string(
    self,
    third_party_imports: list[tuple[ImportNode, str]] | None,
    first_party_imports: list[tuple[ImportNode, str]] | None,
    local_imports: list[tuple[ImportNode, str]] | None,
) -&gt; str:
    # construct the string listing out of order imports used in the message
    # for wrong-import-order
    if third_party_imports:
        plural = "s" if len(third_party_imports) &gt; 1 else ""
        if len(third_party_imports) &gt; MAX_NUMBER_OF_IMPORT_SHOWN:
            imports_list = (
                ", ".join(
                    [
                        f'"{self._get_full_import_name(tpi)}"'
                        for tpi in third_party_imports[
                            : int(MAX_NUMBER_OF_IMPORT_SHOWN // 2)
                        ]
                    ]
                )
                + " (...) "
                + ", ".join(
                    [
                        f'"{self._get_full_import_name(tpi)}"'
                        for tpi in third_party_imports[
                            int(-MAX_NUMBER_OF_IMPORT_SHOWN // 2) :
                        ]
                    ]
                )
            )
        else:
            imports_list = ", ".join(
                [
                    f'"{self._get_full_import_name(tpi)}"'
                    for tpi in third_party_imports
                ]
            )
        third_party = f"third party import{plural} {imports_list}"
    else:
        third_party = ""

    if first_party_imports:
        plural = "s" if len(first_party_imports) &gt; 1 else ""
        if len(first_party_imports) &gt; MAX_NUMBER_OF_IMPORT_SHOWN:
            imports_list = (
                ", ".join(
                    [
                        f'"{self._get_full_import_name(tpi)}"'
                        for tpi in first_party_imports[
                            : int(MAX_NUMBER_OF_IMPORT_SHOWN // 2)
                        ]
                    ]
                )
                + " (...) "
                + ", ".join(
                    [
                        f'"{self._get_full_import_name(tpi)}"'
                        for tpi in first_party_imports[
                            int(-MAX_NUMBER_OF_IMPORT_SHOWN // 2) :
                        ]
                    ]
                )
            )
        else:
            imports_list = ", ".join(
                [
                    f'"{self._get_full_import_name(fpi)}"'
                    for fpi in first_party_imports
                ]
            )
        first_party = f"first party import{plural} {imports_list}"
    else:
        first_party = ""

    if local_imports:
        plural = "s" if len(local_imports) &gt; 1 else ""
        if len(local_imports) &gt; MAX_NUMBER_OF_IMPORT_SHOWN:
            imports_list = (
                ", ".join(
                    [
                        f'"{self._get_full_import_name(tpi)}"'
                        for tpi in local_imports[
                            : int(MAX_NUMBER_OF_IMPORT_SHOWN // 2)
                        ]
                    ]
                )
                + " (...) "
                + ", ".join(
                    [
                        f'"{self._get_full_import_name(tpi)}"'
                        for tpi in local_imports[
                            int(-MAX_NUMBER_OF_IMPORT_SHOWN // 2) :
                        ]
                    ]
                )
            )
        else:
            imports_list = ", ".join(
                [f'"{self._get_full_import_name(li)}"' for li in local_imports]
            )
        local = f"local import{plural} {imports_list}"
    else:
        local = ""

    delimiter_third_party = (
        (
            ", "
            if (first_party and local)
            else (" and " if (first_party or local) else "")
        )
        if third_party
        else ""
    )
    delimiter_first_party1 = (
        (", " if (third_party and local) else " ") if first_party else ""
    )
    delimiter_first_party2 = ("and " if local else "") if first_party else ""
    delimiter_first_party = f"{delimiter_first_party1}{delimiter_first_party2}"
    msg = (
        f"{third_party}{delimiter_third_party}"
        f"{first_party}{delimiter_first_party}"
        f'{local if local else ""}'
    )

    return msg

</t>
<t tx="ekr.20250131013559.469">def _get_full_import_name(self, importNode: ImportNode) -&gt; str:
    # construct a more descriptive name of the import
    # for: import X, this returns X
    # for: import X.Y this returns X.Y
    # for: from X import Y, this returns X.Y

    try:
        # this will only succeed for ImportFrom nodes, which in themselves
        # contain the information needed to reconstruct the package
        return f"{importNode[0].modname}.{importNode[0].names[0][0]}"
    except AttributeError:
        # in all other cases, the import will either be X or X.Y
        node: str = importNode[0].names[0][0]
        package: str = importNode[1]

        if node.split(".")[0] == package:
            # this is sufficient with one import per line, since package = X
            # and node = X.Y or X
            return node

        # when there is a node that contains multiple imports, the "current"
        # import being analyzed is specified by package (node is the first
        # import on the line and therefore != package in this case)
        return package

</t>
<t tx="ekr.20250131013559.470">def _get_imported_module(
    self, importnode: ImportNode, modname: str
) -&gt; nodes.Module | None:
    try:
        return importnode.do_import_module(modname)
    except astroid.TooManyLevelsError:
        if _ignore_import_failure(importnode, modname, self._ignored_modules):
            return None
        self.add_message("relative-beyond-top-level", node=importnode)
    except astroid.AstroidSyntaxError as exc:
        message = f"Cannot import {modname!r} due to '{exc.error}'"
        self.add_message(
            "syntax-error", line=importnode.lineno, args=message, confidence=HIGH
        )

    except astroid.AstroidBuildingError:
        if not self.linter.is_message_enabled("import-error"):
            return None
        if _ignore_import_failure(importnode, modname, self._ignored_modules):
            return None
        if (
            not self.linter.config.analyse_fallback_blocks
            and is_from_fallback_block(importnode)
        ):
            return None

        dotted_modname = get_import_name(importnode, modname)
        self.add_message("import-error", args=repr(dotted_modname), node=importnode)
    except Exception as e:  # pragma: no cover
        raise astroid.AstroidError from e
    return None

</t>
<t tx="ekr.20250131013559.471">def _add_imported_module(self, node: ImportNode, importedmodname: str) -&gt; None:
    """Notify an imported module, used to analyze dependencies."""
    module_file = node.root().file
    context_name = node.root().name
    base = os.path.splitext(os.path.basename(module_file))[0]

    try:
        if isinstance(node, nodes.ImportFrom) and node.level:
            importedmodname = astroid.modutils.get_module_part(
                importedmodname, module_file
            )
        else:
            importedmodname = astroid.modutils.get_module_part(importedmodname)
    except ImportError:
        pass

    if context_name == importedmodname:
        self.add_message("import-self", node=node)

    elif not astroid.modutils.is_stdlib_module(importedmodname):
        # if this is not a package __init__ module
        if base != "__init__" and context_name not in self._module_pkg:
            # record the module's parent, or the module itself if this is
            # a top level module, as the package it belongs to
            self._module_pkg[context_name] = context_name.rsplit(".", 1)[0]

        # handle dependencies
        dependencies_stat: dict[str, set[str]] = self.linter.stats.dependencies
        importedmodnames = dependencies_stat.setdefault(importedmodname, set())
        if context_name not in importedmodnames:
            importedmodnames.add(context_name)

        # update import graph
        self.import_graph[context_name].add(importedmodname)
        if not self.linter.is_message_enabled(
            "cyclic-import", line=node.lineno
        ) or in_type_checking_block(node):
            self._excluded_edges[context_name].add(importedmodname)

</t>
<t tx="ekr.20250131013559.472">def _check_preferred_module(self, node: ImportNode, mod_path: str) -&gt; None:
    """Check if the module has a preferred replacement."""
    mod_compare = [mod_path]
    # build a comparison list of possible names using importfrom
    if isinstance(node, astroid.nodes.node_classes.ImportFrom):
        mod_compare = [f"{node.modname}.{name[0]}" for name in node.names]

    # find whether there are matches with the import vs preferred_modules keys
    matches = [
        k
        for k in self.preferred_modules
        for mod in mod_compare
        # exact match
        if k == mod
        # checks for base module matches
        or k in mod.split(".")[0]
    ]

    # if we have matches, add message
    if matches:
        self.add_message(
            "preferred-module",
            node=node,
            args=(self.preferred_modules[matches[0]], matches[0]),
        )

</t>
<t tx="ekr.20250131013559.473">def _check_import_as_rename(self, node: ImportNode) -&gt; None:
    names = node.names
    for name in names:
        if not all(name):
            return

        splitted_packages = name[0].rsplit(".", maxsplit=1)
        import_name = splitted_packages[-1]
        aliased_name = name[1]
        if import_name != aliased_name:
            continue

        if len(splitted_packages) == 1 and (
            self._allow_reexport_package is False
            or self._current_module_package is False
        ):
            self.add_message("useless-import-alias", node=node, confidence=HIGH)
        elif len(splitted_packages) == 2:
            self.add_message(
                "consider-using-from-import",
                node=node,
                args=(splitted_packages[0], import_name),
            )

</t>
<t tx="ekr.20250131013559.474">def _check_reimport(
    self,
    node: ImportNode,
    basename: str | None = None,
    level: int | None = None,
) -&gt; None:
    """Check if a module with the same name is already imported or aliased."""
    if not self.linter.is_message_enabled(
        "reimported"
    ) and not self.linter.is_message_enabled("shadowed-import"):
        return

    frame = node.frame()
    root = node.root()
    contexts = [(frame, level)]
    if root is not frame:
        contexts.append((root, None))

    for known_context, known_level in contexts:
        for name, alias in node.names:
            first, msg = _get_first_import(
                node, known_context, name, basename, known_level, alias
            )
            if first is not None and msg is not None:
                name = name if msg == "reimported" else alias
                self.add_message(
                    msg, node=node, args=(name, first.fromlineno), confidence=HIGH
                )

</t>
<t tx="ekr.20250131013559.475">def _report_external_dependencies(
    self, sect: Section, _: LinterStats, _dummy: LinterStats | None
) -&gt; None:
    """Return a verbatim layout for displaying dependencies."""
    dep_info = _make_tree_defs(self._external_dependencies_info.items())
    if not dep_info:
        raise EmptyReportError()
    tree_str = _repr_tree_defs(dep_info)
    sect.append(VerbatimText(tree_str))

</t>
<t tx="ekr.20250131013559.476">def _report_dependencies_graph(
    self, sect: Section, _: LinterStats, _dummy: LinterStats | None
) -&gt; None:
    """Write dependencies as a dot (graphviz) file."""
    dep_info = self.linter.stats.dependencies
    if not dep_info or not (
        self.linter.config.import_graph
        or self.linter.config.ext_import_graph
        or self.linter.config.int_import_graph
    ):
        raise EmptyReportError()
    filename = self.linter.config.import_graph
    if filename:
        _make_graph(filename, dep_info, sect, "")
    filename = self.linter.config.ext_import_graph
    if filename:
        _make_graph(filename, self._external_dependencies_info, sect, "external ")
    filename = self.linter.config.int_import_graph
    if filename:
        _make_graph(filename, self._internal_dependencies_info, sect, "internal ")

</t>
<t tx="ekr.20250131013559.477">def _filter_dependencies_graph(self, internal: bool) -&gt; defaultdict[str, set[str]]:
    """Build the internal or the external dependency graph."""
    graph: defaultdict[str, set[str]] = defaultdict(set)
    for importee, importers in self.linter.stats.dependencies.items():
        for importer in importers:
            package = self._module_pkg.get(importer, importer)
            is_inside = importee.startswith(package)
            if (is_inside and internal) or (not is_inside and not internal):
                graph[importee].add(importer)
    return graph

</t>
<t tx="ekr.20250131013559.478">@cached_property
def _external_dependencies_info(self) -&gt; defaultdict[str, set[str]]:
    """Return cached external dependencies information or build and
    cache them.
    """
    return self._filter_dependencies_graph(internal=False)

</t>
<t tx="ekr.20250131013559.479">@cached_property
def _internal_dependencies_info(self) -&gt; defaultdict[str, set[str]]:
    """Return cached internal dependencies information or build and
    cache them.
    """
    return self._filter_dependencies_graph(internal=True)

</t>
<t tx="ekr.20250131013559.480">def _check_wildcard_imports(
    self, node: nodes.ImportFrom, imported_module: nodes.Module | None
) -&gt; None:
    if node.root().package:
        # Skip the check if in __init__.py issue #2026
        return

    wildcard_import_is_allowed = self._wildcard_import_is_allowed(imported_module)
    for name, _ in node.names:
        if name == "*" and not wildcard_import_is_allowed:
            self.add_message("wildcard-import", args=node.modname, node=node)

</t>
<t tx="ekr.20250131013559.481">def _wildcard_import_is_allowed(self, imported_module: nodes.Module | None) -&gt; bool:
    return (
        self.linter.config.allow_wildcard_with_all
        and imported_module is not None
        and "__all__" in imported_module.locals
    )

</t>
<t tx="ekr.20250131013559.482">def _check_toplevel(self, node: ImportNode) -&gt; None:
    """Check whether the import is made outside the module toplevel."""
    # If the scope of the import is a module, then obviously it is
    # not outside the module toplevel.
    if isinstance(node.scope(), nodes.Module):
        return

    module_names = [
        (
            f"{node.modname}.{name[0]}"
            if isinstance(node, nodes.ImportFrom)
            else name[0]
        )
        for name in node.names
    ]

    # Get the full names of all the imports that are only allowed at the module level
    scoped_imports = [
        name for name in module_names if name not in self._allow_any_import_level
    ]

    if scoped_imports:
        self.add_message(
            "import-outside-toplevel", args=", ".join(scoped_imports), node=node
        )


</t>
<t tx="ekr.20250131013559.483">@path pylint/checkers
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

from itertools import zip_longest
from typing import TYPE_CHECKING

from astroid import nodes

from pylint.checkers import BaseChecker
from pylint.interfaces import HIGH

if TYPE_CHECKING:
    from pylint.lint import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013559.484">class LambdaExpressionChecker(BaseChecker):
    """Check for unnecessary usage of lambda expressions."""

    @others
</t>
<t tx="ekr.20250131013559.485">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(LambdaExpressionChecker(linter))
</t>
<t tx="ekr.20250131013559.486">name = "lambda-expressions"
msgs = {
    "C3001": (
        "Lambda expression assigned to a variable. "
        'Define a function using the "def" keyword instead.',
        "unnecessary-lambda-assignment",
        "Used when a lambda expression is assigned to variable "
        'rather than defining a standard function with the "def" keyword.',
    ),
    "C3002": (
        "Lambda expression called directly. Execute the expression inline instead.",
        "unnecessary-direct-lambda-call",
        "Used when a lambda expression is directly called "
        "rather than executing its contents inline.",
    ),
}
options = ()

def visit_assign(self, node: nodes.Assign) -&gt; None:
    """Check if lambda expression is assigned to a variable."""
    if isinstance(node.targets[0], nodes.AssignName) and isinstance(
        node.value, nodes.Lambda
    ):
        self.add_message(
            "unnecessary-lambda-assignment",
            node=node.value,
            confidence=HIGH,
        )
    elif isinstance(node.targets[0], nodes.Tuple) and isinstance(
        node.value, (nodes.Tuple, nodes.List)
    ):
        # Iterate over tuple unpacking assignment elements and
        # see if any lambdas are assigned to a variable.
        # N.B. We may encounter W0632 (unbalanced-tuple-unpacking)
        # and still need to flag the lambdas that are being assigned.
        for lhs_elem, rhs_elem in zip_longest(
            node.targets[0].elts, node.value.elts
        ):
            if lhs_elem is None or rhs_elem is None:
                # unbalanced tuple unpacking. stop checking.
                break
            if isinstance(lhs_elem, nodes.AssignName) and isinstance(
                rhs_elem, nodes.Lambda
            ):
                self.add_message(
                    "unnecessary-lambda-assignment",
                    node=rhs_elem,
                    confidence=HIGH,
                )

</t>
<t tx="ekr.20250131013559.487">def visit_namedexpr(self, node: nodes.NamedExpr) -&gt; None:
    if isinstance(node.target, nodes.AssignName) and isinstance(
        node.value, nodes.Lambda
    ):
        self.add_message(
            "unnecessary-lambda-assignment",
            node=node.value,
            confidence=HIGH,
        )

</t>
<t tx="ekr.20250131013559.488">def visit_call(self, node: nodes.Call) -&gt; None:
    """Check if lambda expression is called directly."""
    if isinstance(node.func, nodes.Lambda):
        self.add_message(
            "unnecessary-direct-lambda-call",
            node=node,
            confidence=HIGH,
        )


</t>
<t tx="ekr.20250131013559.489">@path pylint/checkers
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Checker for use of Python logging."""

from __future__ import annotations

import string
from typing import TYPE_CHECKING, Literal

import astroid
from astroid import bases, nodes
from astroid.typing import InferenceResult

from pylint import checkers
from pylint.checkers import utils
from pylint.checkers.utils import infer_all
from pylint.interfaces import HIGH
from pylint.typing import MessageDefinitionTuple

if TYPE_CHECKING:
    from pylint.lint import PyLinter

MSGS: dict[str, MessageDefinitionTuple] = (
    {  # pylint: disable=consider-using-namedtuple-or-dataclass
        "W1201": (
            "Use %s formatting in logging functions",
            "logging-not-lazy",
            "Used when a logging statement has a call form of "
            '"logging.&lt;logging method&gt;(format_string % (format_args...))". '
            "Use another type of string formatting instead. "
            "You can use % formatting but leave interpolation to "
            "the logging function by passing the parameters as arguments. "
            "If logging-fstring-interpolation is disabled then "
            "you can use fstring formatting. "
            "If logging-format-interpolation is disabled then "
            "you can use str.format.",
        ),
        "W1202": (
            "Use %s formatting in logging functions",
            "logging-format-interpolation",
            "Used when a logging statement has a call form of "
            '"logging.&lt;logging method&gt;(format_string.format(format_args...))". '
            "Use another type of string formatting instead. "
            "You can use % formatting but leave interpolation to "
            "the logging function by passing the parameters as arguments. "
            "If logging-fstring-interpolation is disabled then "
            "you can use fstring formatting. "
            "If logging-not-lazy is disabled then "
            "you can use % formatting as normal.",
        ),
        "W1203": (
            "Use %s formatting in logging functions",
            "logging-fstring-interpolation",
            "Used when a logging statement has a call form of "
            '"logging.&lt;logging method&gt;(f"...")".'
            "Use another type of string formatting instead. "
            "You can use % formatting but leave interpolation to "
            "the logging function by passing the parameters as arguments. "
            "If logging-format-interpolation is disabled then "
            "you can use str.format. "
            "If logging-not-lazy is disabled then "
            "you can use % formatting as normal.",
        ),
        "E1200": (
            "Unsupported logging format character %r (%#02x) at index %d",
            "logging-unsupported-format",
            "Used when an unsupported format character is used in a logging "
            "statement format string.",
        ),
        "E1201": (
            "Logging format string ends in middle of conversion specifier",
            "logging-format-truncated",
            "Used when a logging statement format string terminates before "
            "the end of a conversion specifier.",
        ),
        "E1205": (
            "Too many arguments for logging format string",
            "logging-too-many-args",
            "Used when a logging format string is given too many arguments.",
        ),
        "E1206": (
            "Not enough arguments for logging format string",
            "logging-too-few-args",
            "Used when a logging format string is given too few arguments.",
        ),
    }
)


CHECKED_CONVENIENCE_FUNCTIONS = {
    "critical",
    "debug",
    "error",
    "exception",
    "fatal",
    "info",
    "warn",
    "warning",
}

MOST_COMMON_FORMATTING = frozenset(["%s", "%d", "%f", "%r"])


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013559.490">def is_method_call(
    func: bases.BoundMethod, types: tuple[str, ...] = (), methods: tuple[str, ...] = ()
</t>
<t tx="ekr.20250131013559.491">) -&gt; bool:
    """Determines if a BoundMethod node represents a method call.

    Args:
      func: The BoundMethod AST node to check.
      types: Optional sequence of caller type names to restrict check.
      methods: Optional sequence of method names to restrict check.

    Returns:
      true if the node represents a method call for the given type and
      method names, False otherwise.
    """
    return (
        isinstance(func, astroid.BoundMethod)
        and isinstance(func.bound, astroid.Instance)
        and (func.bound.name in types if types else True)
        and (func.name in methods if methods else True)
    )


class LoggingChecker(checkers.BaseChecker):
    """Checks use of the logging module."""

    @others
</t>
<t tx="ekr.20250131013559.492">def is_complex_format_str(node: nodes.NodeNG) -&gt; bool:
    """Return whether the node represents a string with complex formatting specs."""
    inferred = utils.safe_infer(node)
    if inferred is None or not (
        isinstance(inferred, nodes.Const) and isinstance(inferred.value, str)
    ):
        return True
    try:
        parsed = list(string.Formatter().parse(inferred.value))
    except ValueError:
        # This format string is invalid
        return False
    return any(format_spec for (_, _, format_spec, _) in parsed)


</t>
<t tx="ekr.20250131013559.493">def _count_supplied_tokens(args: list[nodes.NodeNG]) -&gt; int:
    """Counts the number of tokens in an args list.

    The Python log functions allow for special keyword arguments: func,
    exc_info and extra. To handle these cases correctly, we only count
    arguments that aren't keywords.

    Args:
      args: AST nodes that are arguments for a log format string.

    Returns:
      Number of AST nodes that aren't keywords.
    """
    return sum(1 for arg in args if not isinstance(arg, nodes.Keyword))


</t>
<t tx="ekr.20250131013559.494">def str_formatting_in_f_string(node: nodes.JoinedStr) -&gt; bool:
    """Determine whether the node represents an f-string with string formatting.

    For example: `f'Hello %s'`
    """
    # Check "%" presence first for performance.
    return any(
        "%" in val.value and any(x in val.value for x in MOST_COMMON_FORMATTING)
        for val in node.values
        if isinstance(val, nodes.Const)
    )


</t>
<t tx="ekr.20250131013559.495">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(LoggingChecker(linter))
</t>
<t tx="ekr.20250131013559.496">name = "logging"
msgs = MSGS

options = (
    (
        "logging-modules",
        {
            "default": ("logging",),
            "type": "csv",
            "metavar": "&lt;comma separated list&gt;",
            "help": "Logging modules to check that the string format "
            "arguments are in logging function parameter format.",
        },
    ),
    (
        "logging-format-style",
        {
            "default": "old",
            "type": "choice",
            "metavar": "&lt;old (%) or new ({)&gt;",
            "choices": ["old", "new"],
            "help": "The type of string formatting that logging methods do. "
            "`old` means using % formatting, `new` is for `{}` formatting.",
        },
    ),
)

def visit_module(self, _: nodes.Module) -&gt; None:
    """Clears any state left in this checker from last module checked."""
    # The code being checked can just as easily "import logging as foo",
    # so it is necessary to process the imports and store in this field
    # what name the logging module is actually given.
    self._logging_names: set[str] = set()
    logging_mods = self.linter.config.logging_modules

    self._format_style = self.linter.config.logging_format_style

    self._logging_modules = set(logging_mods)
    self._from_imports = {}
    for logging_mod in logging_mods:
        parts = logging_mod.rsplit(".", 1)
        if len(parts) &gt; 1:
            self._from_imports[parts[0]] = parts[1]

</t>
<t tx="ekr.20250131013559.497">def visit_importfrom(self, node: nodes.ImportFrom) -&gt; None:
    """Checks to see if a module uses a non-Python logging module."""
    try:
        logging_name = self._from_imports[node.modname]
        for module, as_name in node.names:
            if module == logging_name:
                self._logging_names.add(as_name or module)
    except KeyError:
        pass

</t>
<t tx="ekr.20250131013559.498">def visit_import(self, node: nodes.Import) -&gt; None:
    """Checks to see if this module uses Python's built-in logging."""
    for module, as_name in node.names:
        if module in self._logging_modules:
            self._logging_names.add(as_name or module)

</t>
<t tx="ekr.20250131013559.499">def visit_call(self, node: nodes.Call) -&gt; None:
    """Checks calls to logging methods."""

    def is_logging_name() -&gt; bool:
        return (
            isinstance(node.func, nodes.Attribute)
            and isinstance(node.func.expr, nodes.Name)
            and node.func.expr.name in self._logging_names
        )

    def is_logger_class() -&gt; tuple[bool, str | None]:
        for inferred in infer_all(node.func):
            if isinstance(inferred, astroid.BoundMethod):
                parent = inferred._proxied.parent
                if isinstance(parent, nodes.ClassDef) and (
                    parent.qname() == "logging.Logger"
                    or any(
                        ancestor.qname() == "logging.Logger"
                        for ancestor in parent.ancestors()
                    )
                ):
                    return True, inferred._proxied.name
        return False, None

    if is_logging_name():
        name = node.func.attrname
    else:
        result, name = is_logger_class()
        if not result:
            return
    self._check_log_method(node, name)

</t>
<t tx="ekr.20250131013559.500">def _check_log_method(self, node: nodes.Call, name: str) -&gt; None:
    """Checks calls to logging.log(level, format, *format_args)."""
    if name == "log":
        if node.starargs or node.kwargs or len(node.args) &lt; 2:
            # Either a malformed call, star args, or double-star args. Beyond
            # the scope of this checker.
            return
        format_pos: Literal[0, 1] = 1
    elif name in CHECKED_CONVENIENCE_FUNCTIONS:
        if node.starargs or node.kwargs or not node.args:
            # Either no args, star args, or double-star args. Beyond the
            # scope of this checker.
            return
        format_pos = 0
    else:
        return

    format_arg = node.args[format_pos]
    if isinstance(format_arg, nodes.BinOp):
        binop = format_arg
        emit = binop.op == "%"
        if binop.op == "+" and not self._is_node_explicit_str_concatenation(binop):
            total_number_of_strings = sum(
                1
                for operand in (binop.left, binop.right)
                if self._is_operand_literal_str(utils.safe_infer(operand))
            )
            emit = total_number_of_strings &gt; 0
        if emit:
            self.add_message(
                "logging-not-lazy",
                node=node,
                args=(self._helper_string(node),),
            )
    elif isinstance(format_arg, nodes.Call):
        self._check_call_func(format_arg)
    elif isinstance(format_arg, nodes.Const):
        self._check_format_string(node, format_pos)
    elif isinstance(format_arg, nodes.JoinedStr):
        if str_formatting_in_f_string(format_arg):
            return
        self.add_message(
            "logging-fstring-interpolation",
            node=node,
            args=(self._helper_string(node),),
        )

</t>
<t tx="ekr.20250131013559.501">def _helper_string(self, node: nodes.Call) -&gt; str:
    """Create a string that lists the valid types of formatting for this node."""
    valid_types = ["lazy %"]

    if not self.linter.is_message_enabled(
        "logging-fstring-formatting", node.fromlineno
    ):
        valid_types.append("fstring")
    if not self.linter.is_message_enabled(
        "logging-format-interpolation", node.fromlineno
    ):
        valid_types.append(".format()")
    if not self.linter.is_message_enabled("logging-not-lazy", node.fromlineno):
        valid_types.append("%")

    return " or ".join(valid_types)

</t>
<t tx="ekr.20250131013559.502">@staticmethod
def _is_operand_literal_str(operand: InferenceResult | None) -&gt; bool:
    """Return True if the operand in argument is a literal string."""
    return isinstance(operand, nodes.Const) and operand.name == "str"

</t>
<t tx="ekr.20250131013559.503">@staticmethod
def _is_node_explicit_str_concatenation(node: nodes.NodeNG) -&gt; bool:
    """Return True if the node represents an explicitly concatenated string."""
    if not isinstance(node, nodes.BinOp):
        return False
    return (
        LoggingChecker._is_operand_literal_str(node.left)
        or LoggingChecker._is_node_explicit_str_concatenation(node.left)
    ) and (
        LoggingChecker._is_operand_literal_str(node.right)
        or LoggingChecker._is_node_explicit_str_concatenation(node.right)
    )

</t>
<t tx="ekr.20250131013559.504">def _check_call_func(self, node: nodes.Call) -&gt; None:
    """Checks that function call is not format_string.format()."""
    func = utils.safe_infer(node.func)
    types = ("str", "unicode")
    methods = ("format",)
    if (
        isinstance(func, astroid.BoundMethod)
        and is_method_call(func, types, methods)
        and not is_complex_format_str(func.bound)
    ):
        self.add_message(
            "logging-format-interpolation",
            node=node,
            args=(self._helper_string(node),),
        )

</t>
<t tx="ekr.20250131013559.505">def _check_format_string(self, node: nodes.Call, format_arg: Literal[0, 1]) -&gt; None:
    """Checks that format string tokens match the supplied arguments.

    Args:
      node: AST node to be checked.
      format_arg: Index of the format string in the node arguments.
    """
    num_args = _count_supplied_tokens(node.args[format_arg + 1 :])
    if not num_args:
        # If no args were supplied the string is not interpolated and can contain
        # formatting characters - it's used verbatim. Don't check any further.
        return

    format_string = node.args[format_arg].value
    required_num_args = 0
    if isinstance(format_string, bytes):
        format_string = format_string.decode()
    if isinstance(format_string, str):
        try:
            if self._format_style == "old":
                keyword_args, required_num_args, _, _ = utils.parse_format_string(
                    format_string
                )
                if keyword_args:
                    # Keyword checking on logging strings is complicated by
                    # special keywords - out of scope.
                    return
            elif self._format_style == "new":
                (
                    keyword_arguments,
                    implicit_pos_args,
                    explicit_pos_args,
                ) = utils.parse_format_method_string(format_string)

                keyword_args_cnt = len(
                    {k for k, _ in keyword_arguments if not isinstance(k, int)}
                )
                required_num_args = (
                    keyword_args_cnt + implicit_pos_args + explicit_pos_args
                )
        except utils.UnsupportedFormatCharacter as ex:
            char = format_string[ex.index]
            self.add_message(
                "logging-unsupported-format",
                node=node,
                args=(char, ord(char), ex.index),
            )
            return
        except utils.IncompleteFormatString:
            self.add_message("logging-format-truncated", node=node)
            return
    if num_args &gt; required_num_args:
        self.add_message("logging-too-many-args", node=node, confidence=HIGH)
    elif num_args &lt; required_num_args:
        self.add_message("logging-too-few-args", node=node)


</t>
<t tx="ekr.20250131013559.506">@path pylint/checkers
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Variables checkers for Python code."""

from __future__ import annotations

from typing import TYPE_CHECKING

import astroid
from astroid import arguments, bases, nodes

from pylint.checkers import BaseChecker, utils
from pylint.interfaces import INFERENCE

if TYPE_CHECKING:
    from pylint.lint import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013559.507">class MethodArgsChecker(BaseChecker):
    """BaseChecker for method_args.

    Checks for
    * missing-timeout
    * positional-only-arguments-expected
    """

    @others
</t>
<t tx="ekr.20250131013559.508">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(MethodArgsChecker(linter))
</t>
<t tx="ekr.20250131013559.509">name = "method_args"
msgs = {
    "W3101": (
        "Missing timeout argument for method '%s' can cause your program to hang indefinitely",
        "missing-timeout",
        "Used when a method needs a 'timeout' parameter in order to avoid waiting "
        "for a long time. If no timeout is specified explicitly the default value "
        "is used. For example for 'requests' the program will never time out "
        "(i.e. hang indefinitely).",
    ),
    "E3102": (
        "`%s()` got some positional-only arguments passed as keyword arguments: %s",
        "positional-only-arguments-expected",
        "Emitted when positional-only arguments have been passed as keyword arguments. "
        "Remove the keywords for the affected arguments in the function call.",
    ),
}
options = (
    (
        "timeout-methods",
        {
            "default": (
                "requests.api.delete",
                "requests.api.get",
                "requests.api.head",
                "requests.api.options",
                "requests.api.patch",
                "requests.api.post",
                "requests.api.put",
                "requests.api.request",
            ),
            "type": "csv",
            "metavar": "&lt;comma separated list&gt;",
            "help": "List of qualified names (i.e., library.method) which require a timeout parameter "
            "e.g. 'requests.api.get,requests.api.post'",
        },
    ),
)

@utils.only_required_for_messages(
    "missing-timeout", "positional-only-arguments-expected"
)
def visit_call(self, node: nodes.Call) -&gt; None:
    self._check_missing_timeout(node)
    self._check_positional_only_arguments_expected(node)

</t>
<t tx="ekr.20250131013559.510">def _check_missing_timeout(self, node: nodes.Call) -&gt; None:
    """Check if the call needs a timeout parameter based on package.func_name
    configured in config.timeout_methods.

    Package uses inferred node in order to know the package imported.
    """
    inferred = utils.safe_infer(node.func)
    call_site = arguments.CallSite.from_call(node)
    if (
        inferred
        and not call_site.has_invalid_keywords()
        and isinstance(
            inferred, (nodes.FunctionDef, nodes.ClassDef, bases.UnboundMethod)
        )
        and inferred.qname() in self.linter.config.timeout_methods
    ):
        keyword_arguments = [keyword.arg for keyword in node.keywords]
        keyword_arguments.extend(call_site.keyword_arguments)
        if "timeout" not in keyword_arguments:
            self.add_message(
                "missing-timeout",
                node=node,
                args=(node.func.as_string(),),
                confidence=INFERENCE,
            )

</t>
<t tx="ekr.20250131013559.511">def _check_positional_only_arguments_expected(self, node: nodes.Call) -&gt; None:
    """Check if positional only arguments have been passed as keyword arguments by
    inspecting its method definition.
    """
    inferred_func = utils.safe_infer(node.func)
    while isinstance(inferred_func, (astroid.BoundMethod, astroid.UnboundMethod)):
        inferred_func = inferred_func._proxied
    if not (
        isinstance(inferred_func, (nodes.FunctionDef))
        and inferred_func.args.posonlyargs
    ):
        return
    if inferred_func.args.kwarg:
        return
    pos_args = [a.name for a in inferred_func.args.posonlyargs]
    kws = [k.arg for k in node.keywords if k.arg in pos_args]
    if not kws:
        return

    self.add_message(
        "positional-only-arguments-expected",
        node=node,
        args=(node.func.as_string(), ", ".join(f"'{k}'" for k in kws)),
        confidence=INFERENCE,
    )


</t>
<t tx="ekr.20250131013559.512">@path pylint/checkers
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Check source code is ascii only or has an encoding declaration (PEP 263)."""

from __future__ import annotations

import re
import tokenize
from typing import TYPE_CHECKING

from astroid import nodes

from pylint.checkers import BaseRawFileChecker, BaseTokenChecker
from pylint.typing import ManagedMessage

if TYPE_CHECKING:
    from pylint.lint import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013559.513">class ByIdManagedMessagesChecker(BaseRawFileChecker):
    """Checks for messages that are enabled or disabled by id instead of symbol."""

    @others
</t>
<t tx="ekr.20250131013559.514">class EncodingChecker(BaseTokenChecker, BaseRawFileChecker):
    """BaseChecker for encoding issues and fixme notes.

    Checks for:
    * warning notes in the code like FIXME, XXX
    * encoding issues.
    """

    @others
</t>
<t tx="ekr.20250131013559.515">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(EncodingChecker(linter))
    linter.register_checker(ByIdManagedMessagesChecker(linter))
</t>
<t tx="ekr.20250131013559.516">name = "miscellaneous"
msgs = {
    "I0023": (
        "%s",
        "use-symbolic-message-instead",
        "Used when a message is enabled or disabled by id.",
        {"default_enabled": False},
    )
}
options = ()

def _clear_by_id_managed_msgs(self) -&gt; None:
    self.linter._by_id_managed_msgs.clear()

</t>
<t tx="ekr.20250131013559.517">def _get_by_id_managed_msgs(self) -&gt; list[ManagedMessage]:
    return self.linter._by_id_managed_msgs

</t>
<t tx="ekr.20250131013559.518">def process_module(self, node: nodes.Module) -&gt; None:
    """Inspect the source file to find messages activated or deactivated by id."""
    managed_msgs = self._get_by_id_managed_msgs()
    for mod_name, msgid, symbol, lineno, is_disabled in managed_msgs:
        if mod_name == node.name:
            verb = "disable" if is_disabled else "enable"
            txt = f"'{msgid}' is cryptic: use '# pylint: {verb}={symbol}' instead"
            self.add_message("use-symbolic-message-instead", line=lineno, args=txt)
    self._clear_by_id_managed_msgs()


</t>
<t tx="ekr.20250131013559.519"># configuration section name
name = "miscellaneous"
msgs = {
    "W0511": (
        "%s",
        "fixme",
        "Used when a warning note as FIXME or XXX is detected.",
    )
}

options = (
    (
        "notes",
        {
            "type": "csv",
            "metavar": "&lt;comma separated values&gt;",
            "default": ("FIXME", "XXX", "TODO"),
            "help": (
                "List of note tags to take in consideration, "
                "separated by a comma."
            ),
        },
    ),
    (
        "notes-rgx",
        {
            "type": "string",
            "metavar": "&lt;regexp&gt;",
            "help": "Regular expression of note tags to take in consideration.",
            "default": "",
        },
    ),
    (
        "check-fixme-in-docstring",
        {
            "type": "yn",
            "metavar": "&lt;y or n&gt;",
            "default": False,
            "help": "Whether or not to search for fixme's in docstrings.",
        },
    ),
)

def open(self) -&gt; None:
    super().open()

    notes = "|".join(re.escape(note) for note in self.linter.config.notes)
    if self.linter.config.notes_rgx:
        notes += f"|{self.linter.config.notes_rgx}"

    comment_regex = rf"#\s*(?P&lt;msg&gt;({notes})(?=(:|\s|\Z)).*?$)"
    self._comment_fixme_pattern = re.compile(comment_regex, re.I)

    # single line docstring like '''this''' or """this"""
    docstring_regex = rf"((\"\"\")|(\'\'\'))\s*(?P&lt;msg&gt;({notes})(?=(:|\s|\Z)).*?)((\"\"\")|(\'\'\'))"
    self._docstring_fixme_pattern = re.compile(docstring_regex, re.I)

    # multiline docstrings which will be split into newlines
    # so we do not need to look for quotes/double-quotes
    multiline_docstring_regex = rf"^\s*(?P&lt;msg&gt;({notes})(?=(:|\s|\Z)).*$)"
    self._multiline_docstring_fixme_pattern = re.compile(
        multiline_docstring_regex, re.I
    )

</t>
<t tx="ekr.20250131013559.520">def _check_encoding(
    self, lineno: int, line: bytes, file_encoding: str
) -&gt; str | None:
    try:
        return line.decode(file_encoding)
    except UnicodeDecodeError:
        pass
    except LookupError:
        if (
            line.startswith(b"#")
            and "coding" in str(line)
            and file_encoding in str(line)
        ):
            msg = f"Cannot decode using encoding '{file_encoding}', bad encoding"
            self.add_message("syntax-error", line=lineno, args=msg)
    return None

</t>
<t tx="ekr.20250131013559.521">def process_module(self, node: nodes.Module) -&gt; None:
    """Inspect the source file to find encoding problem."""
    encoding = node.file_encoding if node.file_encoding else "ascii"

    with node.stream() as stream:
        for lineno, line in enumerate(stream):
            self._check_encoding(lineno + 1, line, encoding)

</t>
<t tx="ekr.20250131013559.522">def process_tokens(self, tokens: list[tokenize.TokenInfo]) -&gt; None:
    """Inspect the source to find fixme problems."""
    if not self.linter.config.notes:
        return
    for token_info in tokens:
        if token_info.type == tokenize.COMMENT:
            if match := self._comment_fixme_pattern.match(token_info.string):
                self.add_message(
                    "fixme",
                    col_offset=token_info.start[1] + 1,
                    args=match.group("msg"),
                    line=token_info.start[0],
                )
        elif self.linter.config.check_fixme_in_docstring:
            if self._is_multiline_docstring(token_info):
                docstring_lines = token_info.string.split("\n")
                for line_no, line in enumerate(docstring_lines):
                    if match := self._multiline_docstring_fixme_pattern.match(line):
                        self.add_message(
                            "fixme",
                            col_offset=token_info.start[1] + 1,
                            args=match.group("msg"),
                            line=token_info.start[0] + line_no,
                        )
            elif match := self._docstring_fixme_pattern.match(token_info.string):
                self.add_message(
                    "fixme",
                    col_offset=token_info.start[1] + 1,
                    args=match.group("msg"),
                    line=token_info.start[0],
                )

</t>
<t tx="ekr.20250131013559.523">def _is_multiline_docstring(self, token_info: tokenize.TokenInfo) -&gt; bool:
    return (
        token_info.type == tokenize.STRING
        and (token_info.line.lstrip().startswith(('"""', "'''")))
        and "\n" in token_info.line.rstrip()
    )


</t>
<t tx="ekr.20250131013559.524">@path pylint/checkers
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

from typing import TYPE_CHECKING

from astroid import nodes

from pylint import checkers, interfaces
from pylint.checkers import utils

if TYPE_CHECKING:
    from pylint.lint import PyLinter


_LIST_MODIFIER_METHODS = {"append", "remove"}
_SET_MODIFIER_METHODS = {"add", "clear", "discard", "pop", "remove"}


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013559.525">class ModifiedIterationChecker(checkers.BaseChecker):
    """Checks for modified iterators in for loops iterations.

    Currently supports `for` loops for Sets, Dictionaries and Lists.
    """

    @others
</t>
<t tx="ekr.20250131013559.526">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(ModifiedIterationChecker(linter))
</t>
<t tx="ekr.20250131013559.527">name = "modified_iteration"

msgs = {
    "W4701": (
        "Iterated list '%s' is being modified inside for loop body, consider iterating through a copy of it "
        "instead.",
        "modified-iterating-list",
        "Emitted when items are added or removed to a list being iterated through. "
        "Doing so can result in unexpected behaviour, that is why it is preferred to use a copy of the list.",
    ),
    "E4702": (
        "Iterated dict '%s' is being modified inside for loop body, iterate through a copy of it instead.",
        "modified-iterating-dict",
        "Emitted when items are added or removed to a dict being iterated through. "
        "Doing so raises a RuntimeError.",
    ),
    "E4703": (
        "Iterated set '%s' is being modified inside for loop body, iterate through a copy of it instead.",
        "modified-iterating-set",
        "Emitted when items are added or removed to a set being iterated through. "
        "Doing so raises a RuntimeError.",
    ),
}

options = ()

@utils.only_required_for_messages(
    "modified-iterating-list", "modified-iterating-dict", "modified-iterating-set"
)
def visit_for(self, node: nodes.For) -&gt; None:
    iter_obj = node.iter
    for body_node in node.body:
        self._modified_iterating_check_on_node_and_children(body_node, iter_obj)

</t>
<t tx="ekr.20250131013559.528">def _modified_iterating_check_on_node_and_children(
    self, body_node: nodes.NodeNG, iter_obj: nodes.NodeNG
) -&gt; None:
    """See if node or any of its children raises modified iterating messages."""
    self._modified_iterating_check(body_node, iter_obj)
    for child in body_node.get_children():
        self._modified_iterating_check_on_node_and_children(child, iter_obj)

</t>
<t tx="ekr.20250131013559.529">def _modified_iterating_check(
    self, node: nodes.NodeNG, iter_obj: nodes.NodeNG
) -&gt; None:
    msg_id = None
    if isinstance(node, nodes.Delete) and any(
        self._deleted_iteration_target_cond(t, iter_obj) for t in node.targets
    ):
        inferred = utils.safe_infer(iter_obj)
        if isinstance(inferred, nodes.List):
            msg_id = "modified-iterating-list"
        elif isinstance(inferred, nodes.Dict):
            msg_id = "modified-iterating-dict"
        elif isinstance(inferred, nodes.Set):
            msg_id = "modified-iterating-set"
    elif not isinstance(iter_obj, (nodes.Name, nodes.Attribute)):
        pass
    elif self._modified_iterating_list_cond(node, iter_obj):
        msg_id = "modified-iterating-list"
    elif self._modified_iterating_dict_cond(node, iter_obj):
        msg_id = "modified-iterating-dict"
    elif self._modified_iterating_set_cond(node, iter_obj):
        msg_id = "modified-iterating-set"
    if msg_id:
        self.add_message(
            msg_id,
            node=node,
            args=(iter_obj.repr_name(),),
            confidence=interfaces.INFERENCE,
        )

</t>
<t tx="ekr.20250131013559.530">@staticmethod
def _is_node_expr_that_calls_attribute_name(node: nodes.NodeNG) -&gt; bool:
    return (
        isinstance(node, nodes.Expr)
        and isinstance(node.value, nodes.Call)
        and isinstance(node.value.func, nodes.Attribute)
        and isinstance(node.value.func.expr, nodes.Name)
    )

</t>
<t tx="ekr.20250131013559.531">@staticmethod
def _common_cond_list_set(
    node: nodes.Expr,
    iter_obj: nodes.Name | nodes.Attribute,
    infer_val: nodes.List | nodes.Set,
) -&gt; bool:
    iter_obj_name = (
        iter_obj.attrname
        if isinstance(iter_obj, nodes.Attribute)
        else iter_obj.name
    )
    return (infer_val == utils.safe_infer(iter_obj)) and (  # type: ignore[no-any-return]
        node.value.func.expr.name == iter_obj_name
    )

</t>
<t tx="ekr.20250131013559.532">@staticmethod
def _is_node_assigns_subscript_name(node: nodes.NodeNG) -&gt; bool:
    return isinstance(node, nodes.Assign) and (
        isinstance(node.targets[0], nodes.Subscript)
        and (isinstance(node.targets[0].value, nodes.Name))
    )

</t>
<t tx="ekr.20250131013559.533">def _modified_iterating_list_cond(
    self, node: nodes.NodeNG, iter_obj: nodes.Name | nodes.Attribute
) -&gt; bool:
    if not self._is_node_expr_that_calls_attribute_name(node):
        return False
    infer_val = utils.safe_infer(node.value.func.expr)
    if not isinstance(infer_val, nodes.List):
        return False
    return (
        self._common_cond_list_set(node, iter_obj, infer_val)
        and node.value.func.attrname in _LIST_MODIFIER_METHODS
    )

</t>
<t tx="ekr.20250131013559.534">def _modified_iterating_dict_cond(
    self, node: nodes.NodeNG, iter_obj: nodes.Name | nodes.Attribute
) -&gt; bool:
    if not self._is_node_assigns_subscript_name(node):
        return False
    # Do not emit when merely updating the same key being iterated
    if (
        isinstance(iter_obj, nodes.Name)
        and iter_obj.name == node.targets[0].value.name
        and isinstance(iter_obj.parent.target, nodes.AssignName)
        and isinstance(node.targets[0].slice, nodes.Name)
        and iter_obj.parent.target.name == node.targets[0].slice.name
    ):
        return False
    infer_val = utils.safe_infer(node.targets[0].value)
    if not isinstance(infer_val, nodes.Dict):
        return False
    if infer_val != utils.safe_infer(iter_obj):
        return False
    if isinstance(iter_obj, nodes.Attribute):
        iter_obj_name = iter_obj.attrname
    else:
        iter_obj_name = iter_obj.name
    return node.targets[0].value.name == iter_obj_name  # type: ignore[no-any-return]

</t>
<t tx="ekr.20250131013559.535">def _modified_iterating_set_cond(
    self, node: nodes.NodeNG, iter_obj: nodes.Name | nodes.Attribute
) -&gt; bool:
    if not self._is_node_expr_that_calls_attribute_name(node):
        return False
    infer_val = utils.safe_infer(node.value.func.expr)
    if not isinstance(infer_val, nodes.Set):
        return False
    return (
        self._common_cond_list_set(node, iter_obj, infer_val)
        and node.value.func.attrname in _SET_MODIFIER_METHODS
    )

</t>
<t tx="ekr.20250131013559.536">def _deleted_iteration_target_cond(
    self, node: nodes.DelName, iter_obj: nodes.NodeNG
) -&gt; bool:
    if not isinstance(node, nodes.DelName):
        return False
    if not isinstance(iter_obj.parent, nodes.For):
        return False
    if not isinstance(
        iter_obj.parent.target, (nodes.AssignName, nodes.BaseContainer)
    ):
        return False
    return any(
        t == node.name
        for t in utils.find_assigned_names_recursive(iter_obj.parent.target)
    )


</t>
<t tx="ekr.20250131013559.537">@path pylint/checkers
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Check for use of nested min/max functions."""

from __future__ import annotations

import copy
from typing import TYPE_CHECKING

from astroid import nodes, objects
from astroid.const import Context

from pylint.checkers import BaseChecker
from pylint.checkers.utils import only_required_for_messages, safe_infer
from pylint.interfaces import INFERENCE

if TYPE_CHECKING:
    from pylint.lint import PyLinter

DICT_TYPES = (
    objects.DictValues,
    objects.DictKeys,
    objects.DictItems,
    nodes.node_classes.Dict,
)


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013559.538">class NestedMinMaxChecker(BaseChecker):
    """Multiple nested min/max calls on the same line will raise multiple messages.

    This behaviour is intended as it would slow down the checker to check
    for nested call with minimal benefits.
    """

    @others
</t>
<t tx="ekr.20250131013559.539">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(NestedMinMaxChecker(linter))
</t>
<t tx="ekr.20250131013559.540">FUNC_NAMES = ("builtins.min", "builtins.max")

name = "nested_min_max"
msgs = {
    "W3301": (
        "Do not use nested call of '%s'; it's possible to do '%s' instead",
        "nested-min-max",
        "Nested calls ``min(1, min(2, 3))`` can be rewritten as ``min(1, 2, 3)``.",
    )
}

@classmethod
def is_min_max_call(cls, node: nodes.NodeNG) -&gt; bool:
    if not isinstance(node, nodes.Call):
        return False

    inferred = safe_infer(node.func)
    return (
        isinstance(inferred, nodes.FunctionDef)
        and inferred.qname() in cls.FUNC_NAMES
    )

</t>
<t tx="ekr.20250131013559.541">@classmethod
def get_redundant_calls(cls, node: nodes.Call) -&gt; list[nodes.Call]:
    return [
        arg
        for arg in node.args
        if (
            cls.is_min_max_call(arg)
            and arg.func.name == node.func.name
            # Nesting is useful for finding the maximum in a matrix.
            # Allow: max(max([[1, 2, 3], [4, 5, 6]]))
            # Meaning, redundant call only if parent max call has more than 1 arg.
            and len(arg.parent.args) &gt; 1
        )
    ]

</t>
<t tx="ekr.20250131013559.542">@only_required_for_messages("nested-min-max")
def visit_call(self, node: nodes.Call) -&gt; None:
    if not self.is_min_max_call(node):
        return

    redundant_calls = self.get_redundant_calls(node)
    if not redundant_calls:
        return

    fixed_node = copy.copy(node)
    while len(redundant_calls) &gt; 0:
        for i, arg in enumerate(fixed_node.args):
            # Exclude any calls with generator expressions as there is no
            # clear better suggestion for them.
            if isinstance(arg, nodes.Call) and any(
                isinstance(a, nodes.GeneratorExp) for a in arg.args
            ):
                return

            if arg in redundant_calls:
                fixed_node.args = (
                    fixed_node.args[:i] + arg.args + fixed_node.args[i + 1 :]
                )
                break

        redundant_calls = self.get_redundant_calls(fixed_node)

    for idx, arg in enumerate(fixed_node.args):
        if not isinstance(arg, nodes.Const):
            if self._is_splattable_expression(arg):
                splat_node = nodes.Starred(
                    ctx=Context.Load,
                    lineno=arg.lineno,
                    col_offset=0,
                    parent=nodes.NodeNG(
                        lineno=None,
                        col_offset=None,
                        end_lineno=None,
                        end_col_offset=None,
                        parent=None,
                    ),
                    end_lineno=0,
                    end_col_offset=0,
                )
                splat_node.value = arg
                fixed_node.args = (
                    fixed_node.args[:idx]
                    + [splat_node]
                    + fixed_node.args[idx + 1 : idx]
                )

    self.add_message(
        "nested-min-max",
        node=node,
        args=(node.func.name, fixed_node.as_string()),
        confidence=INFERENCE,
    )

</t>
<t tx="ekr.20250131013559.543">def _is_splattable_expression(self, arg: nodes.NodeNG) -&gt; bool:
    """Returns true if expression under min/max could be converted to splat
    expression.
    """
    # Support sequence addition (operator __add__)
    if isinstance(arg, nodes.BinOp) and arg.op == "+":
        return self._is_splattable_expression(
            arg.left
        ) and self._is_splattable_expression(arg.right)
    # Support dict merge (operator __or__)
    if isinstance(arg, nodes.BinOp) and arg.op == "|":
        return self._is_splattable_expression(
            arg.left
        ) and self._is_splattable_expression(arg.right)

    inferred = safe_infer(arg)
    if inferred and inferred.pytype() in {"builtins.list", "builtins.tuple"}:
        return True
    if isinstance(
        inferred or arg,
        (
            nodes.List,
            nodes.Tuple,
            nodes.Set,
            nodes.ListComp,
            nodes.DictComp,
            *DICT_TYPES,
        ),
    ):
        return True

    return False


</t>
<t tx="ekr.20250131013559.544">@path pylint/checkers
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Check for new / old style related problems."""

from __future__ import annotations

from typing import TYPE_CHECKING

import astroid
from astroid import nodes

from pylint.checkers import BaseChecker
from pylint.checkers.utils import node_frame_class, only_required_for_messages
from pylint.typing import MessageDefinitionTuple

if TYPE_CHECKING:
    from pylint.lint import PyLinter

MSGS: dict[str, MessageDefinitionTuple] = {
    "E1003": (
        "Bad first argument %r given to super()",
        "bad-super-call",
        "Used when another argument than the current class is given as "
        "first argument of the super builtin.",
    )
}


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013559.545">class NewStyleConflictChecker(BaseChecker):
    """Checks for usage of new style capabilities on old style classes and
    other new/old styles conflicts problems.

    * use of property, __slots__, super
    * "super" usage
    """

    @others
    visit_asyncfunctiondef = visit_functiondef


</t>
<t tx="ekr.20250131013559.546">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(NewStyleConflictChecker(linter))
</t>
<t tx="ekr.20250131013559.547"># configuration section name
name = "newstyle"
# messages
msgs = MSGS
# configuration options
options = ()

@only_required_for_messages("bad-super-call")
def visit_functiondef(self, node: nodes.FunctionDef) -&gt; None:
    """Check use of super."""
    # ignore actual functions or method within a new style class
    if not node.is_method():
        return
    klass = node.parent.frame()
    for stmt in node.nodes_of_class(nodes.Call):
        if node_frame_class(stmt) != node_frame_class(node):
            # Don't look down in other scopes.
            continue

        expr = stmt.func
        if not isinstance(expr, nodes.Attribute):
            continue

        call = expr.expr
        # skip the test if using super
        if not (
            isinstance(call, nodes.Call)
            and isinstance(call.func, nodes.Name)
            and call.func.name == "super"
        ):
            continue

        # super first arg should not be the class
        if not call.args:
            continue

        # calling super(type(self), self) can lead to recursion loop
        # in derived classes
        arg0 = call.args[0]
        if (
            isinstance(arg0, nodes.Call)
            and isinstance(arg0.func, nodes.Name)
            and arg0.func.name == "type"
        ):
            self.add_message("bad-super-call", node=call, args=("type",))
            continue

        # calling super(self.__class__, self) can lead to recursion loop
        # in derived classes
        if (
            len(call.args) &gt;= 2
            and isinstance(call.args[1], nodes.Name)
            and call.args[1].name == "self"
            and isinstance(arg0, nodes.Attribute)
            and arg0.attrname == "__class__"
        ):
            self.add_message("bad-super-call", node=call, args=("self.__class__",))
            continue

        try:
            supcls = call.args and next(call.args[0].infer(), None)
        except astroid.InferenceError:
            continue

        # If the supcls is in the ancestors of klass super can be used to skip
        # a step in the mro() and get a method from a higher parent
        if klass is not supcls and all(i != supcls for i in klass.ancestors()):
            name = None
            # if supcls is not Uninferable, then supcls was inferred
            # and use its name. Otherwise, try to look
            # for call.args[0].name
            if supcls:
                name = supcls.name
            elif call.args and hasattr(call.args[0], "name"):
                name = call.args[0].name
            if name:
                self.add_message("bad-super-call", node=call, args=(name,))

</t>
<t tx="ekr.20250131013559.548">@path pylint/checkers
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""All alphanumeric unicode character are allowed in Python but due
to similarities in how they look they can be confused.

See: https://peps.python.org/pep-0672/#confusing-features

The following checkers are intended to make users are aware of these issues.
"""

from __future__ import annotations

from astroid import nodes

from pylint import constants, interfaces, lint
from pylint.checkers import base_checker, utils

NON_ASCII_HELP = (
    "Used when the name contains at least one non-ASCII unicode character. "
    "See https://peps.python.org/pep-0672/#confusing-features"
    " for a background why this could be bad. \n"
    "If your programming guideline defines that you are programming in "
    "English, then there should be no need for non ASCII characters in "
    "Python Names. If not you can simply disable this check."
)


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013559.549">class NonAsciiNameChecker(base_checker.BaseChecker):
    """A strict name checker only allowing ASCII.

    Note: This check only checks Names, so it ignores the content of
          docstrings and comments!
    """

    @others
</t>
<t tx="ekr.20250131013559.550">def register(linter: lint.PyLinter) -&gt; None:
    linter.register_checker(NonAsciiNameChecker(linter))
</t>
<t tx="ekr.20250131013559.551">msgs = {
    "C2401": (
        '%s name "%s" contains a non-ASCII character, consider renaming it.',
        "non-ascii-name",
        NON_ASCII_HELP,
        {"old_names": [("C0144", "old-non-ascii-name")]},
    ),
    # First %s will always be "file"
    "W2402": (
        '%s name "%s" contains a non-ASCII character.',
        "non-ascii-file-name",
        (
            # Some = PyCharm at the time of writing didn't display the non_ascii_name_loł
            # files. That's also why this is a warning and not only a convention!
            "Under python 3.5, PEP 3131 allows non-ascii identifiers, but not non-ascii file names."
            "Since Python 3.5, even though Python supports UTF-8 files, some editors or tools "
            "don't."
        ),
    ),
    # First %s will always be "module"
    "C2403": (
        '%s name "%s" contains a non-ASCII character, use an ASCII-only alias for import.',
        "non-ascii-module-import",
        NON_ASCII_HELP,
    ),
}

name = "NonASCII-Checker"

def _check_name(self, node_type: str, name: str | None, node: nodes.NodeNG) -&gt; None:
    """Check whether a name is using non-ASCII characters."""
    if name is None:
        # For some nodes i.e. *kwargs from a dict, the name will be empty
        return

    if not str(name).isascii():
        type_label = constants.HUMAN_READABLE_TYPES[node_type]
        args = (type_label.capitalize(), name)

        msg = "non-ascii-name"

        # Some node types have customized messages
        if node_type == "file":
            msg = "non-ascii-file-name"
        elif node_type == "module":
            msg = "non-ascii-module-import"

        self.add_message(msg, node=node, args=args, confidence=interfaces.HIGH)

</t>
<t tx="ekr.20250131013559.552">@utils.only_required_for_messages("non-ascii-name", "non-ascii-file-name")
def visit_module(self, node: nodes.Module) -&gt; None:
    self._check_name("file", node.name.split(".")[-1], node)

</t>
<t tx="ekr.20250131013559.553">@utils.only_required_for_messages("non-ascii-name")
def visit_functiondef(
    self, node: nodes.FunctionDef | nodes.AsyncFunctionDef
) -&gt; None:
    self._check_name("function", node.name, node)

    # Check argument names
    arguments = node.args

    # Check position only arguments
    if arguments.posonlyargs:
        for pos_only_arg in arguments.posonlyargs:
            self._check_name("argument", pos_only_arg.name, pos_only_arg)

    # Check "normal" arguments
    if arguments.args:
        for arg in arguments.args:
            self._check_name("argument", arg.name, arg)

    # Check key word only arguments
    if arguments.kwonlyargs:
        for kwarg in arguments.kwonlyargs:
            self._check_name("argument", kwarg.name, kwarg)

</t>
<t tx="ekr.20250131013559.554">visit_asyncfunctiondef = visit_functiondef

@utils.only_required_for_messages("non-ascii-name")
def visit_global(self, node: nodes.Global) -&gt; None:
    for name in node.names:
        self._check_name("const", name, node)

</t>
<t tx="ekr.20250131013559.555">@utils.only_required_for_messages("non-ascii-name")
def visit_assignname(self, node: nodes.AssignName) -&gt; None:
    """Check module level assigned names."""
    # The NameChecker from which this Checker originates knows a lot of different
    # versions of variables, i.e. constants, inline variables etc.
    # To simplify we use only `variable` here, as we don't need to apply different
    # rules to different types of variables.
    frame = node.frame()

    if isinstance(frame, nodes.FunctionDef):
        if node.parent in frame.body:
            # Only perform the check if the assignment was done in within the body
            # of the function (and not the function parameter definition
            # (will be handled in visit_functiondef)
            # or within a decorator (handled in visit_call)
            self._check_name("variable", node.name, node)
    elif isinstance(frame, nodes.ClassDef):
        self._check_name("attr", node.name, node)
    else:
        # Possibilities here:
        # - isinstance(node.assign_type(), nodes.Comprehension) == inlinevar
        # - isinstance(frame, nodes.Module) == variable (constant?)
        # - some other kind of assignment missed but still most likely a variable
        self._check_name("variable", node.name, node)

</t>
<t tx="ekr.20250131013559.556">@utils.only_required_for_messages("non-ascii-name")
def visit_classdef(self, node: nodes.ClassDef) -&gt; None:
    self._check_name("class", node.name, node)
    for attr, anodes in node.instance_attrs.items():
        if not any(node.instance_attr_ancestors(attr)):
            self._check_name("attr", attr, anodes[0])

</t>
<t tx="ekr.20250131013559.557">def _check_module_import(self, node: nodes.ImportFrom | nodes.Import) -&gt; None:
    for module_name, alias in node.names:
        name = alias or module_name
        self._check_name("module", name, node)

</t>
<t tx="ekr.20250131013559.558">@utils.only_required_for_messages("non-ascii-name", "non-ascii-module-import")
def visit_import(self, node: nodes.Import) -&gt; None:
    self._check_module_import(node)

</t>
<t tx="ekr.20250131013559.559">@utils.only_required_for_messages("non-ascii-name", "non-ascii-module-import")
def visit_importfrom(self, node: nodes.ImportFrom) -&gt; None:
    self._check_module_import(node)

</t>
<t tx="ekr.20250131013559.560">@utils.only_required_for_messages("non-ascii-name")
def visit_call(self, node: nodes.Call) -&gt; None:
    """Check if the used keyword args are correct."""
    for keyword in node.keywords:
        self._check_name("argument", keyword.arg, keyword)


</t>
<t tx="ekr.20250131013559.561">@path pylint/checkers
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import tokenize
from typing import TYPE_CHECKING, Any, Literal, cast

from pylint.checkers import BaseTokenChecker
from pylint.reporters.ureports.nodes import Paragraph, Section, Table, Text
from pylint.utils import LinterStats, diff_string

if TYPE_CHECKING:
    from pylint.lint import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013559.562">def report_raw_stats(
    sect: Section,
    stats: LinterStats,
    old_stats: LinterStats | None,
) -&gt; None:
    """Calculate percentage of code / doc / comment / empty."""
    total_lines = stats.code_type_count["total"]
    sect.insert(0, Paragraph([Text(f"{total_lines} lines have been analyzed\n")]))
    lines = ["type", "number", "%", "previous", "difference"]
    for node_type in ("code", "docstring", "comment", "empty"):
        node_type = cast(Literal["code", "docstring", "comment", "empty"], node_type)
        total = stats.code_type_count[node_type]
        percent = float(total * 100) / total_lines if total_lines else None
        old = old_stats.code_type_count[node_type] if old_stats else None
        diff_str = diff_string(old, total) if old else None
        lines += [
            node_type,
            str(total),
            f"{percent:.2f}" if percent is not None else "NC",
            str(old) if old else "NC",
            diff_str if diff_str else "NC",
        ]
    sect.append(Table(children=lines, cols=5, rheaders=1))


</t>
<t tx="ekr.20250131013559.563">class RawMetricsChecker(BaseTokenChecker):
    """Checker that provides raw metrics instead of checking anything.

    Provides:
    * total number of lines
    * total number of code lines
    * total number of docstring lines
    * total number of comments lines
    * total number of empty lines
    """

    @others
</t>
<t tx="ekr.20250131013559.564">JUNK = (tokenize.NL, tokenize.INDENT, tokenize.NEWLINE, tokenize.ENDMARKER)


def get_type(
    tokens: list[tokenize.TokenInfo], start_index: int
) -&gt; tuple[int, int, Literal["code", "docstring", "comment", "empty"]]:
    """Return the line type : docstring, comment, code, empty."""
    i = start_index
    start = tokens[i][2]
    pos = start
    line_type = None
    while i &lt; len(tokens) and tokens[i][2][0] == start[0]:
        tok_type = tokens[i][0]
        pos = tokens[i][3]
        if line_type is None:
            if tok_type == tokenize.STRING:
                line_type = "docstring"
            elif tok_type == tokenize.COMMENT:
                line_type = "comment"
            elif tok_type in JUNK:
                pass
            else:
                line_type = "code"
        i += 1
    if line_type is None:
        line_type = "empty"
    elif i &lt; len(tokens) and tokens[i][0] == tokenize.NEWLINE:
        i += 1
    # Mypy fails to infer the literal of line_type
    return i, pos[0] - start[0] + 1, line_type  # type: ignore[return-value]


</t>
<t tx="ekr.20250131013559.565">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(RawMetricsChecker(linter))
</t>
<t tx="ekr.20250131013559.566"># configuration section name
name = "metrics"
# configuration options
options = ()
# messages
msgs: Any = {}
# reports
reports = (("RP0701", "Raw metrics", report_raw_stats),)

def open(self) -&gt; None:
    """Init statistics."""
    self.linter.stats.reset_code_count()

</t>
<t tx="ekr.20250131013559.567">def process_tokens(self, tokens: list[tokenize.TokenInfo]) -&gt; None:
    """Update stats."""
    i = 0
    tokens = list(tokens)
    while i &lt; len(tokens):
        i, lines_number, line_type = get_type(tokens, i)
        self.linter.stats.code_type_count["total"] += lines_number
        self.linter.stats.code_type_count[line_type] += lines_number


</t>
<t tx="ekr.20250131013559.568">@path pylint/checkers
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Checker for spelling errors in comments and docstrings."""

from __future__ import annotations

import re
import tokenize
from re import Pattern
from typing import TYPE_CHECKING, Any, Literal

from astroid import nodes

from pylint.checkers import BaseTokenChecker
from pylint.checkers.utils import only_required_for_messages

if TYPE_CHECKING:
    from pylint.lint import PyLinter

try:
    import enchant
    from enchant.tokenize import (
        Chunker,
        EmailFilter,
        Filter,
        URLFilter,
        WikiWordFilter,
        get_tokenizer,
    )

    PYENCHANT_AVAILABLE = True
except ImportError:  # pragma: no cover
    enchant = None
    PYENCHANT_AVAILABLE = False

@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013559.569">    class EmailFilter:  # type: ignore[no-redef]
        ...

</t>
<t tx="ekr.20250131013559.570">    class URLFilter:  # type: ignore[no-redef]
        ...

</t>
<t tx="ekr.20250131013559.571">    class WikiWordFilter:  # type: ignore[no-redef]
        ...

</t>
<t tx="ekr.20250131013559.572">    class Filter:  # type: ignore[no-redef]
        @others
</t>
<t tx="ekr.20250131013559.573">    class Chunker:  # type: ignore[no-redef]
        pass

</t>
<t tx="ekr.20250131013559.574">    def get_tokenizer(
        tag: str | None = None,  # pylint: disable=unused-argument
        chunkers: list[Chunker] | None = None,  # pylint: disable=unused-argument
        filters: list[Filter] | None = None,  # pylint: disable=unused-argument
    ) -&gt; Filter:
        return Filter()


</t>
<t tx="ekr.20250131013559.575">def _get_enchant_dicts() -&gt; list[tuple[Any, enchant.ProviderDesc]]:
    return enchant.Broker().list_dicts() if PYENCHANT_AVAILABLE else []


</t>
<t tx="ekr.20250131013559.576">def _get_enchant_dict_choices(
    inner_enchant_dicts: list[tuple[Any, enchant.ProviderDesc]]
) -&gt; list[str]:
    return [""] + [d[0] for d in inner_enchant_dicts]


</t>
<t tx="ekr.20250131013559.577">def _get_enchant_dict_help(
    inner_enchant_dicts: list[tuple[Any, enchant.ProviderDesc]],
    pyenchant_available: bool,
) -&gt; str:
    if inner_enchant_dicts:
        dict_as_str = [f"{d[0]} ({d[1].name})" for d in inner_enchant_dicts]
        enchant_help = f"Available dictionaries: {', '.join(dict_as_str)}"
    else:
        enchant_help = "No available dictionaries : You need to install "
        if not pyenchant_available:
            enchant_help += "both the python package and "
        enchant_help += "the system dependency for enchant to work"
    return f"Spelling dictionary name. {enchant_help}."


</t>
<t tx="ekr.20250131013559.578">enchant_dicts = _get_enchant_dicts()


class WordsWithDigitsFilter(Filter):  # type: ignore[misc]
    """Skips words with digits."""

    @others
</t>
<t tx="ekr.20250131013559.579">class WordsWithUnderscores(Filter):  # type: ignore[misc]
    """Skips words with underscores.

    They are probably function parameter names.
    """

    @others
</t>
<t tx="ekr.20250131013559.580">class RegExFilter(Filter):  # type: ignore[misc]
    """Parent class for filters using regular expressions.

    This filter skips any words the match the expression
    assigned to the class attribute ``_pattern``.
    """

    @others
</t>
<t tx="ekr.20250131013559.581">class CamelCasedWord(RegExFilter):
    r"""Filter skipping over camelCasedWords.
    This filter skips any words matching the following regular expression:

           ^([a-z]\w+[A-Z]+\w+)

    That is, any words that are camelCasedWords.
    """

    _pattern = re.compile(r"^([a-z]+(\d|[A-Z])(?:\w+)?)")


</t>
<t tx="ekr.20250131013559.582">class SphinxDirectives(RegExFilter):
    r"""Filter skipping over Sphinx Directives.
    This filter skips any words matching the following regular expression:

           ^(:([a-z]+)){1,2}:`([^`]+)(`)?

    That is, for example, :class:`BaseQuery`
    """

    # The final ` in the pattern is optional because enchant strips it out
    _pattern = re.compile(r"^(:([a-z]+)){1,2}:`([^`]+)(`)?")


</t>
<t tx="ekr.20250131013559.583">class ForwardSlashChunker(Chunker):  # type: ignore[misc]
    """This chunker allows splitting words like 'before/after' into 'before' and
    'after'.
    """

    @others
</t>
<t tx="ekr.20250131013559.584">CODE_FLANKED_IN_BACKTICK_REGEX = re.compile(r"(\s|^)(`{1,2})([^`]+)(\2)([^`]|$)")


def _strip_code_flanked_in_backticks(line: str) -&gt; str:
    """Alter line so code flanked in back-ticks is ignored.

    Pyenchant automatically strips back-ticks when parsing tokens,
    so this cannot be done at the individual filter level.
    """

    def replace_code_but_leave_surrounding_characters(match_obj: re.Match[str]) -&gt; str:
        return match_obj.group(1) + match_obj.group(5)

    return CODE_FLANKED_IN_BACKTICK_REGEX.sub(
        replace_code_but_leave_surrounding_characters, line
    )


</t>
<t tx="ekr.20250131013559.585">class SpellingChecker(BaseTokenChecker):
    """Check spelling in comments and docstrings."""

    @others
    ) -&gt; None:
        """Check if the node has any spelling errors."""
        if not self.initialized:
            return
        if not node.doc_node:
            return
        start_line = node.lineno + 1
        # Go through lines of docstring
        for idx, line in enumerate(node.doc_node.value.splitlines()):
            self._check_spelling("wrong-spelling-in-docstring", line, start_line + idx)


</t>
<t tx="ekr.20250131013559.586">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(SpellingChecker(linter))
</t>
<t tx="ekr.20250131013559.587">def _skip(self, word: str) -&gt; bool:
    raise NotImplementedError

</t>
<t tx="ekr.20250131013559.588">def _skip(self, word: str) -&gt; bool:
    return any(char.isdigit() for char in word)


</t>
<t tx="ekr.20250131013559.589">def _skip(self, word: str) -&gt; bool:
    return "_" in word


</t>
<t tx="ekr.20250131013559.590">_pattern: Pattern[str]

def _skip(self, word: str) -&gt; bool:
    return bool(self._pattern.match(word))


</t>
<t tx="ekr.20250131013559.591">_text: str

def next(self) -&gt; tuple[str, int]:
    while True:
        if not self._text:
            raise StopIteration()
        if "/" not in self._text:
            text = self._text
            self._offset = 0
            self._text = ""
            return text, 0
        pre_text, post_text = self._text.split("/", 1)
        self._text = post_text
        self._offset = 0
        if (
            not pre_text
            or not post_text
            or not pre_text[-1].isalpha()
            or not post_text[0].isalpha()
        ):
            self._text = ""
            self._offset = 0
            return f"{pre_text}/{post_text}", 0
        return pre_text, 0

</t>
<t tx="ekr.20250131013559.592">def _next(self) -&gt; tuple[str, Literal[0]]:
    while True:
        if "/" not in self._text:
            return self._text, 0
        pre_text, post_text = self._text.split("/", 1)
        if not pre_text or not post_text:
            break
        if not pre_text[-1].isalpha() or not post_text[0].isalpha():
            raise StopIteration()
        self._text = pre_text + " " + post_text
    raise StopIteration()


</t>
<t tx="ekr.20250131013559.593">name = "spelling"
msgs = {
    "C0401": (
        "Wrong spelling of a word '%s' in a comment:\n%s\n"
        "%s\nDid you mean: '%s'?",
        "wrong-spelling-in-comment",
        "Used when a word in comment is not spelled correctly.",
    ),
    "C0402": (
        "Wrong spelling of a word '%s' in a docstring:\n%s\n"
        "%s\nDid you mean: '%s'?",
        "wrong-spelling-in-docstring",
        "Used when a word in docstring is not spelled correctly.",
    ),
    "C0403": (
        "Invalid characters %r in a docstring",
        "invalid-characters-in-docstring",
        "Used when a word in docstring cannot be checked by enchant.",
    ),
}
options = (
    (
        "spelling-dict",
        {
            "default": "",
            "type": "choice",
            "metavar": "&lt;dict name&gt;",
            "choices": _get_enchant_dict_choices(enchant_dicts),
            "help": _get_enchant_dict_help(enchant_dicts, PYENCHANT_AVAILABLE),
        },
    ),
    (
        "spelling-ignore-words",
        {
            "default": "",
            "type": "string",
            "metavar": "&lt;comma separated words&gt;",
            "help": "List of comma separated words that should not be checked.",
        },
    ),
    (
        "spelling-private-dict-file",
        {
            "default": "",
            "type": "path",
            "metavar": "&lt;path to file&gt;",
            "help": "A path to a file that contains the private "
            "dictionary; one word per line.",
        },
    ),
    (
        "spelling-store-unknown-words",
        {
            "default": "n",
            "type": "yn",
            "metavar": "&lt;y or n&gt;",
            "help": "Tells whether to store unknown words to the "
            "private dictionary (see the "
            "--spelling-private-dict-file option) instead of "
            "raising a message.",
        },
    ),
    (
        "max-spelling-suggestions",
        {
            "default": 4,
            "type": "int",
            "metavar": "N",
            "help": "Limits count of emitted suggestions for spelling mistakes.",
        },
    ),
    (
        "spelling-ignore-comment-directives",
        {
            "default": "fmt: on,fmt: off,noqa:,noqa,nosec,isort:skip,mypy:",
            "type": "string",
            "metavar": "&lt;comma separated words&gt;",
            "help": "List of comma separated words that should be considered "
            "directives if they appear at the beginning of a comment "
            "and should not be checked.",
        },
    ),
)

def open(self) -&gt; None:
    self.initialized = False
    if not PYENCHANT_AVAILABLE:
        return
    dict_name = self.linter.config.spelling_dict
    if not dict_name:
        return

    self.ignore_list = [
        w.strip() for w in self.linter.config.spelling_ignore_words.split(",")
    ]
    # "param" appears in docstring in param description and
    # "pylint" appears in comments in pylint pragmas.
    self.ignore_list.extend(["param", "pylint"])

    self.ignore_comment_directive_list = [
        w.strip()
        for w in self.linter.config.spelling_ignore_comment_directives.split(",")
    ]

    if self.linter.config.spelling_private_dict_file:
        self.spelling_dict = enchant.DictWithPWL(
            dict_name, self.linter.config.spelling_private_dict_file
        )
    else:
        self.spelling_dict = enchant.Dict(dict_name)

    if self.linter.config.spelling_store_unknown_words:
        self.unknown_words: set[str] = set()

    self.tokenizer = get_tokenizer(
        dict_name,
        chunkers=[ForwardSlashChunker],
        filters=[
            EmailFilter,
            URLFilter,
            WikiWordFilter,
            WordsWithDigitsFilter,
            WordsWithUnderscores,
            CamelCasedWord,
            SphinxDirectives,
        ],
    )
    self.initialized = True

</t>
<t tx="ekr.20250131013559.594"># pylint: disable = too-many-statements
def _check_spelling(self, msgid: str, line: str, line_num: int) -&gt; None:
    original_line = line
    try:
        # The mypy warning is caught by the except statement
        initial_space = re.search(r"^\s+", line).regs[0][1]  # type: ignore[union-attr]
    except(IndexError, AttributeError):
        initial_space = 0
    if line.strip().startswith("#") and "docstring" not in msgid:
        line = line.strip()[1:]
        # A ``Filter`` cannot determine if the directive is at the beginning of a line,
        #   nor determine if a colon is present or not (``pyenchant`` strips trailing colons).
        #   So implementing this here.
        for iter_directive in self.ignore_comment_directive_list:
            if line.startswith(" " + iter_directive):
                line = line[(len(iter_directive) + 1) :]
                break
        starts_with_comment = True
    else:
        starts_with_comment = False

    line = _strip_code_flanked_in_backticks(line)

    for word, word_start_at in self.tokenizer(line.strip()):
        word_start_at += initial_space
        lower_cased_word = word.casefold()

        # Skip words from ignore list.
        if word in self.ignore_list or lower_cased_word in self.ignore_list:
            continue

        # Strip starting u' from unicode literals and r' from raw strings.
        if word.startswith(("u'", 'u"', "r'", 'r"')) and len(word) &gt; 2:
            word = word[2:]
            lower_cased_word = lower_cased_word[2:]

        # If it is a known word, then continue.
        try:
            if self.spelling_dict.check(lower_cased_word):
                # The lower cased version of word passed spell checking
                continue

            # If we reached this far, it means there was a spelling mistake.
            # Let's retry with the original work because 'unicode' is a
            # spelling mistake but 'Unicode' is not
            if self.spelling_dict.check(word):
                continue
        except enchant.errors.Error:
            self.add_message(
                "invalid-characters-in-docstring", line=line_num, args=(word,)
            )
            continue

        # Store word to private dict or raise a message.
        if self.linter.config.spelling_store_unknown_words:
            if lower_cased_word not in self.unknown_words:
                with open(
                    self.linter.config.spelling_private_dict_file,
                    "a",
                    encoding="utf-8",
                ) as f:
                    f.write(f"{lower_cased_word}\n")
                self.unknown_words.add(lower_cased_word)
        else:
            # Present up to N suggestions.
            suggestions = self.spelling_dict.suggest(word)
            del suggestions[self.linter.config.max_spelling_suggestions:]
            line_segment = line[word_start_at:]
            match = re.search(rf"(\W|^)({word})(\W|$)", line_segment)
            if match:
                # Start position of second group in regex.
                col = match.regs[2][0]
            else:
                col = line_segment.index(word)
            col += word_start_at
            if starts_with_comment:
                col += 1
            indicator = (" " * col) + ("^" * len(word))
            all_suggestion = "' or '".join(suggestions)
            args = (word, original_line, indicator, f"'{all_suggestion}'")
            self.add_message(msgid, line=line_num, args=args)

</t>
<t tx="ekr.20250131013559.595">def process_tokens(self, tokens: list[tokenize.TokenInfo]) -&gt; None:
    if not self.initialized:
        return

    # Process tokens and look for comments.
    for tok_type, token, (start_row, _), _, _ in tokens:
        if tok_type == tokenize.COMMENT:
            if start_row == 1 and token.startswith("#!/"):
                # Skip shebang lines
                continue
            if token.startswith("# pylint:"):
                # Skip pylint enable/disable comments
                continue
            if token.startswith("# type: "):
                # Skip python 2 type comments and mypy type ignore comments
                # mypy do not support additional text in type comments
                continue
            self._check_spelling("wrong-spelling-in-comment", token, start_row)

</t>
<t tx="ekr.20250131013559.596">@only_required_for_messages("wrong-spelling-in-docstring")
def visit_module(self, node: nodes.Module) -&gt; None:
    self._check_docstring(node)

</t>
<t tx="ekr.20250131013559.597">@only_required_for_messages("wrong-spelling-in-docstring")
def visit_classdef(self, node: nodes.ClassDef) -&gt; None:
    self._check_docstring(node)

</t>
<t tx="ekr.20250131013559.598">@only_required_for_messages("wrong-spelling-in-docstring")
def visit_functiondef(
    self, node: nodes.FunctionDef | nodes.AsyncFunctionDef
) -&gt; None:
    self._check_docstring(node)

</t>
<t tx="ekr.20250131013559.599">visit_asyncfunctiondef = visit_functiondef

def _check_docstring(
    self,
    node: (
        nodes.FunctionDef | nodes.AsyncFunctionDef | nodes.ClassDef | nodes.Module
    ),
</t>
<t tx="ekr.20250131013559.600">@path pylint/checkers
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Checkers for various standard library functions."""

from __future__ import annotations

import sys
from collections.abc import Iterable
from typing import TYPE_CHECKING, Any

import astroid
from astroid import nodes, util
from astroid.typing import InferenceResult

from pylint import interfaces
from pylint.checkers import BaseChecker, DeprecatedMixin, utils
from pylint.interfaces import HIGH, INFERENCE
from pylint.typing import MessageDefinitionTuple

if TYPE_CHECKING:
    from pylint.lint import PyLinter

DeprecationDict = dict[tuple[int, int, int], set[str]]

OPEN_FILES_MODE = ("open", "file")
OPEN_FILES_FUNCS = (* OPEN_FILES_MODE, "read_text", "write_text")
UNITTEST_CASE = "unittest.case"
THREADING_THREAD = "threading.Thread"
COPY_COPY = "copy.copy"
OS_ENVIRON = "os._Environ"
ENV_GETTERS = ("os.getenv",)
SUBPROCESS_POPEN = "subprocess.Popen"
SUBPROCESS_RUN = "subprocess.run"
OPEN_MODULE = {"_io", "pathlib", "pathlib._local"}
PATHLIB_MODULE = {"pathlib", "pathlib._local"}
DEBUG_BREAKPOINTS = ("builtins.breakpoint", "sys.breakpointhook", "pdb.set_trace")
LRU_CACHE = {
    "functools.lru_cache",  # Inferred for @lru_cache
    "functools._lru_cache_wrapper.wrapper",  # Inferred for @lru_cache() on &gt;= Python 3.8
    "functools.lru_cache.decorating_function",  # Inferred for @lru_cache() on &lt;= Python 3.7
}
NON_INSTANCE_METHODS = {"builtins.staticmethod", "builtins.classmethod"}


# For modules, see ImportsChecker

DEPRECATED_ARGUMENTS: dict[
    tuple[int, int, int], dict[str, tuple[tuple[int | None, str], ...]]
] = {
    (0, 0, 0): {
        "int": ((None, "x"),),
        "bool": ((None, "x"),),
        "float": ((None, "x"),),
    },
    (3, 5, 0): {
        "importlib._bootstrap_external.cache_from_source": ((1, "debug_override"),),
    },
    (3, 8, 0): {
        "asyncio.tasks.sleep": ((None, "loop"),),
        "asyncio.tasks.gather": ((None, "loop"),),
        "asyncio.tasks.shield": ((None, "loop"),),
        "asyncio.tasks.wait_for": ((None, "loop"),),
        "asyncio.tasks.wait": ((None, "loop"),),
        "asyncio.tasks.as_completed": ((None, "loop"),),
        "asyncio.subprocess.create_subprocess_exec": ((None, "loop"),),
        "asyncio.subprocess.create_subprocess_shell": ((4, "loop"),),
        "gettext.translation": ((5, "codeset"),),
        "gettext.install": ((2, "codeset"),),
        "functools.partialmethod": ((None, "func"),),
        "weakref.finalize": ((None, "func"), (None, "obj")),
        "profile.Profile.runcall": ((None, "func"),),
        "cProfile.Profile.runcall": ((None, "func"),),
        "bdb.Bdb.runcall": ((None, "func"),),
        "trace.Trace.runfunc": ((None, "func"),),
        "curses.wrapper": ((None, "func"),),
        "unittest.case.TestCase.addCleanup": ((None, "function"),),
        "concurrent.futures.thread.ThreadPoolExecutor.submit": ((None, "fn"),),
        "concurrent.futures.process.ProcessPoolExecutor.submit": ((None, "fn"),),
        "contextlib._BaseExitStack.callback": ((None, "callback"),),
        "contextlib.AsyncExitStack.push_async_callback": ((None, "callback"),),
        "multiprocessing.managers.Server.create": ((None, "c"), (None, "typeid")),
        "multiprocessing.managers.SharedMemoryServer.create": (
            (None, "c"),
            (None, "typeid"),
        ),
    },
    (3, 9, 0): {"random.Random.shuffle": ((1, "random"),)},
    (3, 12, 0): {
        "argparse.BooleanOptionalAction": ((3, "type"), (4, "choices"), (7, "metavar")),
        "coroutine.throw": ((1, "value"), (2, "traceback")),
        "email.utils.localtime": ((1, "isdst"),),
        "shutil.rmtree": ((2, "onerror"),),
    },
    (3, 13, 0): {
        "dis.get_instructions": ((2, "show_caches"),),
    },
}

DEPRECATED_DECORATORS: DeprecationDict = {
    (3, 8, 0): {"asyncio.coroutine"},
    (3, 3, 0): {
        "abc.abstractclassmethod",
        "abc.abstractstaticmethod",
        "abc.abstractproperty",
    },
    (3, 4, 0): {"importlib.util.module_for_loader"},
    (3, 13, 0): {"typing.no_type_check_decorator"},
}


DEPRECATED_METHODS: dict[int, DeprecationDict] = {
    0: {
        (0, 0, 0): {
            "cgi.parse_qs",
            "cgi.parse_qsl",
            "ctypes.c_buffer",
            "distutils.command.register.register.check_metadata",
            "distutils.command.sdist.sdist.check_metadata",
            "tkinter.Misc.tk_menuBar",
            "tkinter.Menu.tk_bindForTraversal",
        }
    },
    2: {
        (2, 6, 0): {
            "commands.getstatus",
            "os.popen2",
            "os.popen3",
            "os.popen4",
            "macostools.touched",
        },
        (2, 7, 0): {
            "unittest.case.TestCase.assertEquals",
            "unittest.case.TestCase.assertNotEquals",
            "unittest.case.TestCase.assertAlmostEquals",
            "unittest.case.TestCase.assertNotAlmostEquals",
            "unittest.case.TestCase.assert_",
            "xml.etree.ElementTree.Element.getchildren",
            "xml.etree.ElementTree.Element.getiterator",
            "xml.etree.ElementTree.XMLParser.getiterator",
            "xml.etree.ElementTree.XMLParser.doctype",
        },
    },
    3: {
        (3, 0, 0): {
            "inspect.getargspec",
            "failUnlessEqual",
            "assertEquals",
            "failIfEqual",
            "assertNotEquals",
            "failUnlessAlmostEqual",
            "assertAlmostEquals",
            "failIfAlmostEqual",
            "assertNotAlmostEquals",
            "failUnless",
            "assert_",
            "failUnlessRaises",
            "failIf",
            "assertRaisesRegexp",
            "assertRegexpMatches",
            "assertNotRegexpMatches",
        },
        (3, 1, 0): {
            "base64.encodestring",
            "base64.decodestring",
            "ntpath.splitunc",
            "os.path.splitunc",
            "os.stat_float_times",
            "turtle.RawTurtle.settiltangle",
        },
        (3, 2, 0): {
            "cgi.escape",
            "configparser.RawConfigParser.readfp",
            "xml.etree.ElementTree.Element.getchildren",
            "xml.etree.ElementTree.Element.getiterator",
            "xml.etree.ElementTree.XMLParser.getiterator",
            "xml.etree.ElementTree.XMLParser.doctype",
        },
        (3, 3, 0): {
            "inspect.getmoduleinfo",
            "logging.warn",
            "logging.Logger.warn",
            "logging.LoggerAdapter.warn",
            "nntplib._NNTPBase.xpath",
            "platform.popen",
            "sqlite3.OptimizedUnicode",
            "time.clock",
        },
        (3, 4, 0): {
            "importlib.find_loader",
            "importlib.abc.Loader.load_module",
            "importlib.abc.Loader.module_repr",
            "importlib.abc.PathEntryFinder.find_loader",
            "importlib.abc.PathEntryFinder.find_module",
            "plistlib.readPlist",
            "plistlib.writePlist",
            "plistlib.readPlistFromBytes",
            "plistlib.writePlistToBytes",
        },
        (3, 4, 4): {"asyncio.tasks.async"},
        (3, 5, 0): {
            "fractions.gcd",
            "inspect.formatargspec",
            "inspect.getcallargs",
            "platform.linux_distribution",
            "platform.dist",
        },
        (3, 6, 0): {
            "importlib._bootstrap_external.FileLoader.load_module",
            "_ssl.RAND_pseudo_bytes",
        },
        (3, 7, 0): {
            "sys.set_coroutine_wrapper",
            "sys.get_coroutine_wrapper",
            "aifc.openfp",
            "threading.Thread.isAlive",
            "asyncio.Task.current_task",
            "asyncio.Task.all_task",
            "locale.format",
            "ssl.wrap_socket",
            "ssl.match_hostname",
            "sunau.openfp",
            "wave.openfp",
        },
        (3, 8, 0): {
            "gettext.lgettext",
            "gettext.ldgettext",
            "gettext.lngettext",
            "gettext.ldngettext",
            "gettext.bind_textdomain_codeset",
            "gettext.NullTranslations.output_charset",
            "gettext.NullTranslations.set_output_charset",
            "threading.Thread.isAlive",
        },
        (3, 9, 0): {
            "binascii.b2a_hqx",
            "binascii.a2b_hqx",
            "binascii.rlecode_hqx",
            "binascii.rledecode_hqx",
            "importlib.resources.contents",
            "importlib.resources.is_resource",
            "importlib.resources.open_binary",
            "importlib.resources.open_text",
            "importlib.resources.path",
            "importlib.resources.read_binary",
            "importlib.resources.read_text",
        },
        (3, 10, 0): {
            "_sqlite3.enable_shared_cache",
            "importlib.abc.Finder.find_module",
            "pathlib.Path.link_to",
            "zipimport.zipimporter.load_module",
            "zipimport.zipimporter.find_module",
            "zipimport.zipimporter.find_loader",
            "threading.currentThread",
            "threading.activeCount",
            "threading.Condition.notifyAll",
            "threading.Event.isSet",
            "threading.Thread.setName",
            "threading.Thread.getName",
            "threading.Thread.isDaemon",
            "threading.Thread.setDaemon",
            "cgi.log",
        },
        (3, 11, 0): {
            "locale.getdefaultlocale",
            "locale.resetlocale",
            "re.template",
            "unittest.findTestCases",
            "unittest.makeSuite",
            "unittest.getTestCaseNames",
            "unittest.TestLoader.loadTestsFromModule",
            "unittest.TestLoader.loadTestsFromTestCase",
            "unittest.TestLoader.getTestCaseNames",
            "unittest.TestProgram.usageExit",
        },
        (3, 12, 0): {
            "asyncio.get_child_watcher",
            "asyncio.set_child_watcher",
            "asyncio.AbstractEventLoopPolicy.get_child_watcher",
            "asyncio.AbstractEventLoopPolicy.set_child_watcher",
            "builtins.bool.__invert__",
            "datetime.datetime.utcfromtimestamp",
            "datetime.datetime.utcnow",
            "pkgutil.find_loader",
            "pkgutil.get_loader",
            "pty.master_open",
            "pty.slave_open",
            "xml.etree.ElementTree.Element.__bool__",
        },
        (3, 13, 0): {
            "ctypes.SetPointerType",
            "pathlib.PurePath.is_reserved",
            "platform.java_ver",
            "pydoc.is_package",
            "sys._enablelegacywindowsfsencoding",
            "wave.Wave_read.getmark",
            "wave.Wave_read.getmarkers",
            "wave.Wave_read.setmark",
            "wave.Wave_write.getmark",
            "wave.Wave_write.getmarkers",
            "wave.Wave_write.setmark",
        },
    },
}


DEPRECATED_CLASSES: dict[tuple[int, int, int], dict[str, set[str]]] = {
    (3, 2, 0): {
        "configparser": {
            "LegacyInterpolation",
            "SafeConfigParser",
        },
    },
    (3, 3, 0): {
        "importlib.abc": {
            "Finder",
        },
        "pkgutil": {
            "ImpImporter",
            "ImpLoader",
        },
        "collections": {
            "Awaitable",
            "Coroutine",
            "AsyncIterable",
            "AsyncIterator",
            "AsyncGenerator",
            "Hashable",
            "Iterable",
            "Iterator",
            "Generator",
            "Reversible",
            "Sized",
            "Container",
            "Callable",
            "Collection",
            "Set",
            "MutableSet",
            "Mapping",
            "MutableMapping",
            "MappingView",
            "KeysView",
            "ItemsView",
            "ValuesView",
            "Sequence",
            "MutableSequence",
            "ByteString",
        },
    },
    (3, 9, 0): {
        "smtpd": {
            "MailmanProxy",
        }
    },
    (3, 11, 0): {
        "typing": {
            "Text",
        },
        "urllib.parse": {
            "Quoter",
        },
        "webbrowser": {
            "MacOSX",
        },
    },
    (3, 12, 0): {
        "ast": {
            "Bytes",
            "Ellipsis",
            "NameConstant",
            "Num",
            "Str",
        },
        "asyncio": {
            "AbstractChildWatcher",
            "MultiLoopChildWatcher",
            "FastChildWatcher",
            "SafeChildWatcher",
        },
        "collections.abc": {
            "ByteString",
        },
        "importlib.abc": {
            "ResourceReader",
            "Traversable",
            "TraversableResources",
        },
        "typing": {
            "ByteString",
            "Hashable",
            "Sized",
        },
    },
    (3, 13, 0): {
        "glob": {
            "glob.glob0",
            "glob.glob1",
        },
        "http.server": {
            "CGIHTTPRequestHandler",
        },
    },
}


DEPRECATED_ATTRIBUTES: DeprecationDict = {
    (3, 2, 0): {
        "configparser.ParsingError.filename",
    },
    (3, 12, 0): {
        "calendar.January",
        "calendar.February",
        "sqlite3.version",
        "sqlite3.version_info",
        "sys.last_traceback",
        "sys.last_type",
        "sys.last_value",
    },
    (3, 13, 0): {
        "dis.HAVE_ARGUMENT",
        "tarfile.TarFile.tarfile",
        "traceback.TracebackException.exc_type",
        "typing.AnyStr",
    },
}


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013559.601">def _check_mode_str(mode: Any) -&gt; bool:
    # check type
    if not isinstance(mode, str):
        return False
    # check syntax
    modes = set(mode)
    _mode = "rwatb+Ux"
    creating = "x" in modes
    if modes - set(_mode) or len(mode) &gt; len(modes):
        return False
    # check logic
    reading = "r" in modes
    writing = "w" in modes
    appending = "a" in modes
    text = "t" in modes
    binary = "b" in modes
    if "U" in modes:
        if writing or appending or creating:
            return False
        reading = True
    if text and binary:
        return False
    total = reading + writing + appending + creating
    if total &gt; 1:
        return False
    if not (reading or writing or appending or creating):
        return False
    return True


</t>
<t tx="ekr.20250131013559.602">class StdlibChecker(DeprecatedMixin, BaseChecker):
    @others
</t>
<t tx="ekr.20250131013559.603">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(StdlibChecker(linter))
</t>
<t tx="ekr.20250131013559.604">name = "stdlib"

msgs: dict[str, MessageDefinitionTuple] = {
    ** DeprecatedMixin.DEPRECATED_METHOD_MESSAGE,
    ** DeprecatedMixin.DEPRECATED_ARGUMENT_MESSAGE,
    ** DeprecatedMixin.DEPRECATED_CLASS_MESSAGE,
    ** DeprecatedMixin.DEPRECATED_DECORATOR_MESSAGE,
    ** DeprecatedMixin.DEPRECATED_ATTRIBUTE_MESSAGE,
    "W1501": (
        '"%s" is not a valid mode for open.',
        "bad-open-mode",
        "Python supports: r, w, a[, x] modes with b, +, "
        "and U (only with r) options. "
        "See https://docs.python.org/3/library/functions.html#open",
    ),
    "W1502": (
        "Using datetime.time in a boolean context.",
        "boolean-datetime",
        "Using datetime.time in a boolean context can hide "
        "subtle bugs when the time they represent matches "
        "midnight UTC. This behaviour was fixed in Python 3.5. "
        "See https://bugs.python.org/issue13936 for reference.",
        {"maxversion": (3, 5)},
    ),
    "W1503": (
        "Redundant use of %s with constant value %r",
        "redundant-unittest-assert",
        "The first argument of assertTrue and assertFalse is "
        "a condition. If a constant is passed as parameter, that "
        "condition will be always true. In this case a warning "
        "should be emitted.",
    ),
    "W1506": (
        "threading.Thread needs the target function",
        "bad-thread-instantiation",
        "The warning is emitted when a threading.Thread class "
        "is instantiated without the target function being passed as a kwarg or as a second argument. "
        "By default, the first parameter is the group param, not the target param.",
    ),
    "W1507": (
        "Using copy.copy(os.environ). Use os.environ.copy() instead.",
        "shallow-copy-environ",
        "os.environ is not a dict object but proxy object, so "
        "shallow copy has still effects on original object. "
        "See https://bugs.python.org/issue15373 for reference.",
    ),
    "E1507": (
        "%s does not support %s type argument",
        "invalid-envvar-value",
        "Env manipulation functions support only string type arguments. "
        "See https://docs.python.org/3/library/os.html#os.getenv.",
    ),
    "E1519": (
        "singledispatch decorator should not be used with methods, "
        "use singledispatchmethod instead.",
        "singledispatch-method",
        "singledispatch should decorate functions and not class/instance methods. "
        "Use singledispatchmethod for those cases.",
    ),
    "E1520": (
        "singledispatchmethod decorator should not be used with functions, "
        "use singledispatch instead.",
        "singledispatchmethod-function",
        "singledispatchmethod should decorate class/instance methods and not functions. "
        "Use singledispatch for those cases.",
    ),
    "W1508": (
        "%s default type is %s. Expected str or None.",
        "invalid-envvar-default",
        "Env manipulation functions return None or str values. "
        "Supplying anything different as a default may cause bugs. "
        "See https://docs.python.org/3/library/os.html#os.getenv.",
    ),
    "W1509": (
        "Using preexec_fn keyword which may be unsafe in the presence "
        "of threads",
        "subprocess-popen-preexec-fn",
        "The preexec_fn parameter is not safe to use in the presence "
        "of threads in your application. The child process could "
        "deadlock before exec is called. If you must use it, keep it "
        "trivial! Minimize the number of libraries you call into. "
        "See https://docs.python.org/3/library/subprocess.html#popen-constructor",
    ),
    "W1510": (
        "'subprocess.run' used without explicitly defining the value for 'check'.",
        "subprocess-run-check",
        "The ``check`` keyword  is set to False by default. It means the process "
        "launched by ``subprocess.run`` can exit with a non-zero exit code and "
        "fail silently. It's better to set it explicitly to make clear what the "
        "error-handling behavior is.",
    ),
    "W1514": (
        "Using open without explicitly specifying an encoding",
        "unspecified-encoding",
        "It is better to specify an encoding when opening documents. "
        "Using the system default implicitly can create problems on other operating systems. "
        "See https://peps.python.org/pep-0597/",
    ),
    "W1515": (
        "Leaving functions creating breakpoints in production code is not recommended",
        "forgotten-debug-statement",
        "Calls to breakpoint(), sys.breakpointhook() and pdb.set_trace() should be removed "
        "from code that is not actively being debugged.",
    ),
    "W1518": (
        "'lru_cache(maxsize=None)' or 'cache' will keep all method args alive indefinitely, including 'self'",
        "method-cache-max-size-none",
        "By decorating a method with lru_cache or cache the 'self' argument will be linked to "
        "the function and therefore never garbage collected. Unless your instance "
        "will never need to be garbage collected (singleton) it is recommended to refactor "
        "code to avoid this pattern or add a maxsize to the cache. "
        "The default value for maxsize is 128.",
        {
            "old_names": [
                ("W1516", "lru-cache-decorating-method"),
                ("W1517", "cache-max-size-none"),
            ]
        },
    ),
}

def __init__(self, linter: PyLinter) -&gt; None:
    BaseChecker.__init__(self, linter)
    self._deprecated_methods: set[str] = set()
    self._deprecated_arguments: dict[str, tuple[tuple[int | None, str], ...]] = {}
    self._deprecated_classes: dict[str, set[str]] = {}
    self._deprecated_decorators: set[str] = set()
    self._deprecated_attributes: set[str] = set()

    for since_vers, func_list in DEPRECATED_METHODS[sys.version_info[0]].items():
        if since_vers &lt;= sys.version_info:
            self._deprecated_methods.update(func_list)
    for since_vers, args_list in DEPRECATED_ARGUMENTS.items():
        if since_vers &lt;= sys.version_info:
            self._deprecated_arguments.update(args_list)
    for since_vers, class_list in DEPRECATED_CLASSES.items():
        if since_vers &lt;= sys.version_info:
            self._deprecated_classes.update(class_list)
    for since_vers, decorator_list in DEPRECATED_DECORATORS.items():
        if since_vers &lt;= sys.version_info:
            self._deprecated_decorators.update(decorator_list)
    for since_vers, attribute_list in DEPRECATED_ATTRIBUTES.items():
        if since_vers &lt;= sys.version_info:
            self._deprecated_attributes.update(attribute_list)
</t>
<t tx="ekr.20250131013559.605">    # Modules are checked by the ImportsChecker, because the list is
    # synced with the config argument deprecated-modules

def _check_bad_thread_instantiation(self, node: nodes.Call) -&gt; None:
    func_kwargs = {key.arg for key in node.keywords}
    if "target" in func_kwargs:
        return

    if len(node.args) &lt; 2 and (not node.kwargs or "target" not in func_kwargs):
        self.add_message(
            "bad-thread-instantiation", node=node, confidence=interfaces.HIGH
        )

</t>
<t tx="ekr.20250131013559.606">def _check_for_preexec_fn_in_popen(self, node: nodes.Call) -&gt; None:
    if node.keywords:
        for keyword in node.keywords:
            if keyword.arg == "preexec_fn":
                self.add_message("subprocess-popen-preexec-fn", node=node)

</t>
<t tx="ekr.20250131013559.607">def _check_for_check_kw_in_run(self, node: nodes.Call) -&gt; None:
    kwargs = {keyword.arg for keyword in (node.keywords or ())}
    if "check" not in kwargs:
        self.add_message("subprocess-run-check", node=node, confidence=INFERENCE)

</t>
<t tx="ekr.20250131013559.608">def _check_shallow_copy_environ(self, node: nodes.Call) -&gt; None:
    confidence = HIGH
    try:
        arg = utils.get_argument_from_call(node, position=0, keyword="x")
    except utils.NoSuchArgumentError:
        arg = utils.infer_kwarg_from_call(node, keyword="x")
        if not arg:
            return
        confidence = INFERENCE
    try:
        inferred_args = arg.inferred()
    except astroid.InferenceError:
        return
    for inferred in inferred_args:
        if inferred.qname() == OS_ENVIRON:
            self.add_message(
                "shallow-copy-environ", node=node, confidence=confidence
            )
            break

</t>
<t tx="ekr.20250131013559.609">@utils.only_required_for_messages(
    "bad-open-mode",
    "redundant-unittest-assert",
    "deprecated-method",
    "deprecated-argument",
    "bad-thread-instantiation",
    "shallow-copy-environ",
    "invalid-envvar-value",
    "invalid-envvar-default",
    "subprocess-popen-preexec-fn",
    "subprocess-run-check",
    "deprecated-class",
    "unspecified-encoding",
    "forgotten-debug-statement",
)
def visit_call(self, node: nodes.Call) -&gt; None:
    """Visit a Call node."""
    self.check_deprecated_class_in_call(node)
    for inferred in utils.infer_all(node.func):
        if isinstance(inferred, util.UninferableBase):
            continue
        if inferred.root().name in OPEN_MODULE:
            open_func_name: str | None = None
            if isinstance(node.func, nodes.Name):
                open_func_name = node.func.name
            if isinstance(node.func, nodes.Attribute):
                open_func_name = node.func.attrname
            if open_func_name in OPEN_FILES_FUNCS:
                self._check_open_call(node, inferred.root().name, open_func_name)
        elif inferred.root().name == UNITTEST_CASE:
            self._check_redundant_assert(node, inferred)
        elif isinstance(inferred, nodes.ClassDef):
            if inferred.qname() == THREADING_THREAD:
                self._check_bad_thread_instantiation(node)
            elif inferred.qname() == SUBPROCESS_POPEN:
                self._check_for_preexec_fn_in_popen(node)
        elif isinstance(inferred, nodes.FunctionDef):
            name = inferred.qname()
            if name == COPY_COPY:
                self._check_shallow_copy_environ(node)
            elif name in ENV_GETTERS:
                self._check_env_function(node, inferred)
            elif name == SUBPROCESS_RUN:
                self._check_for_check_kw_in_run(node)
            elif name in DEBUG_BREAKPOINTS:
                self.add_message("forgotten-debug-statement", node=node)
        self.check_deprecated_method(node, inferred)

</t>
<t tx="ekr.20250131013559.610">@utils.only_required_for_messages("boolean-datetime")
def visit_unaryop(self, node: nodes.UnaryOp) -&gt; None:
    if node.op == "not":
        self._check_datetime(node.operand)

</t>
<t tx="ekr.20250131013559.611">@utils.only_required_for_messages("boolean-datetime")
def visit_if(self, node: nodes.If) -&gt; None:
    self._check_datetime(node.test)

</t>
<t tx="ekr.20250131013559.612">@utils.only_required_for_messages("boolean-datetime")
def visit_ifexp(self, node: nodes.IfExp) -&gt; None:
    self._check_datetime(node.test)

</t>
<t tx="ekr.20250131013559.613">@utils.only_required_for_messages("boolean-datetime")
def visit_boolop(self, node: nodes.BoolOp) -&gt; None:
    for value in node.values:
        self._check_datetime(value)

</t>
<t tx="ekr.20250131013559.614">@utils.only_required_for_messages(
    "method-cache-max-size-none",
    "singledispatch-method",
    "singledispatchmethod-function",
)
def visit_functiondef(self, node: nodes.FunctionDef) -&gt; None:
    if node.decorators:
        if isinstance(node.parent, nodes.ClassDef):
            self._check_lru_cache_decorators(node)
        self._check_dispatch_decorators(node)

</t>
<t tx="ekr.20250131013559.615">def _check_lru_cache_decorators(self, node: nodes.FunctionDef) -&gt; None:
    """Check if instance methods are decorated with functools.lru_cache."""
    if any(utils.is_enum(ancestor) for ancestor in node.parent.ancestors()):
        # method of class inheriting from Enum is exempt from this check.
        return

    lru_cache_nodes: list[nodes.NodeNG] = []
    for d_node in node.decorators.nodes:
        # pylint: disable = too-many-try-statements
        try:
            for infered_node in d_node.infer():
                q_name = infered_node.qname()
                if q_name in NON_INSTANCE_METHODS:
                    return

                # Check if there is a maxsize argument set to None in the call
                if q_name in LRU_CACHE and isinstance(d_node, nodes.Call):
                    try:
                        arg = utils.get_argument_from_call(
                            d_node, position=0, keyword="maxsize"
                        )
                    except utils.NoSuchArgumentError:
                        arg = utils.infer_kwarg_from_call(d_node, "maxsize")

                    if not isinstance(arg, nodes.Const) or arg.value is not None:
                        break

                    lru_cache_nodes.append(d_node)
                    break

                if q_name == "functools.cache":
                    lru_cache_nodes.append(d_node)
                    break
        except astroid.InferenceError:
            pass
    for lru_cache_node in lru_cache_nodes:
        self.add_message(
            "method-cache-max-size-none",
            node=lru_cache_node,
            confidence=interfaces.INFERENCE,
        )

</t>
<t tx="ekr.20250131013559.616">def _check_dispatch_decorators(self, node: nodes.FunctionDef) -&gt; None:
    decorators_map: dict[str, tuple[nodes.NodeNG, interfaces.Confidence]] = {}

    for decorator in node.decorators.nodes:
        if isinstance(decorator, nodes.Name) and decorator.name:
            decorators_map[decorator.name] = (decorator, interfaces.HIGH)
        elif utils.is_registered_in_singledispatch_function(node):
            decorators_map["singledispatch"] = (decorator, interfaces.INFERENCE)
        elif utils.is_registered_in_singledispatchmethod_function(node):
            decorators_map["singledispatchmethod"] = (
                decorator,
                interfaces.INFERENCE,
            )

    if node.is_method():
        if "singledispatch" in decorators_map:
            self.add_message(
                "singledispatch-method",
                node=decorators_map["singledispatch"][0],
                confidence=decorators_map["singledispatch"][1],
            )
    elif "singledispatchmethod" in decorators_map:
        self.add_message(
            "singledispatchmethod-function",
            node=decorators_map["singledispatchmethod"][0],
            confidence=decorators_map["singledispatchmethod"][1],
        )

</t>
<t tx="ekr.20250131013559.617">def _check_redundant_assert(self, node: nodes.Call, infer: InferenceResult) -&gt; None:
    if (
        isinstance(infer, astroid.BoundMethod)
        and node.args
        and isinstance(node.args[0], nodes.Const)
        and infer.name in {"assertTrue", "assertFalse"}
    ):
        self.add_message(
            "redundant-unittest-assert",
            args=(infer.name, node.args[0].value),
            node=node,
        )

</t>
<t tx="ekr.20250131013559.618">def _check_datetime(self, node: nodes.NodeNG) -&gt; None:
    """Check that a datetime was inferred, if so, emit boolean-datetime warning."""
    try:
        inferred = next(node.infer())
    except astroid.InferenceError:
        return
    if isinstance(inferred, astroid.Instance) and inferred.qname() in {
        "_pydatetime.time",
        "datetime.time",
    }:
        self.add_message("boolean-datetime", node=node)

</t>
<t tx="ekr.20250131013559.619">def _check_open_call(
    self, node: nodes.Call, open_module: str, func_name: str
) -&gt; None:
    """Various checks for an open call."""
    mode_arg = None
    confidence = HIGH
    try:
        if open_module == "_io":
            mode_arg = utils.get_argument_from_call(
                node, position=1, keyword="mode"
            )
        elif open_module in PATHLIB_MODULE:
            mode_arg = utils.get_argument_from_call(
                node, position=0, keyword="mode"
            )
    except utils.NoSuchArgumentError:
        mode_arg = utils.infer_kwarg_from_call(node, keyword="mode")
        if mode_arg:
            confidence = INFERENCE

    if mode_arg:
        mode_arg = utils.safe_infer(mode_arg)
        if (
            func_name in OPEN_FILES_MODE
            and isinstance(mode_arg, nodes.Const)
            and not _check_mode_str(mode_arg.value)
        ):
            self.add_message(
                "bad-open-mode",
                node=node,
                args=mode_arg.value or str(mode_arg.value),
                confidence=confidence,
            )

    if not mode_arg or (
        isinstance(mode_arg, nodes.Const)
        and (not mode_arg.value or "b" not in str(mode_arg.value))
    ):
        confidence = HIGH
        try:
            if open_module in PATHLIB_MODULE:
                if node.func.attrname == "read_text":
                    encoding_arg = utils.get_argument_from_call(
                        node, position=0, keyword="encoding"
                    )
                elif node.func.attrname == "write_text":
                    encoding_arg = utils.get_argument_from_call(
                        node, position=1, keyword="encoding"
                    )
                else:
                    encoding_arg = utils.get_argument_from_call(
                        node, position=2, keyword="encoding"
                    )
            else:
                encoding_arg = utils.get_argument_from_call(
                    node, position=3, keyword="encoding"
                )
        except utils.NoSuchArgumentError:
            encoding_arg = utils.infer_kwarg_from_call(node, keyword="encoding")
            if encoding_arg:
                confidence = INFERENCE
            else:
                self.add_message(
                    "unspecified-encoding", node=node, confidence=confidence
                )

        if encoding_arg:
            encoding_arg = utils.safe_infer(encoding_arg)

            if isinstance(encoding_arg, nodes.Const) and encoding_arg.value is None:
                self.add_message(
                    "unspecified-encoding", node=node, confidence=confidence
                )

</t>
<t tx="ekr.20250131013559.620">def _check_env_function(self, node: nodes.Call, infer: nodes.FunctionDef) -&gt; None:
    env_name_kwarg = "key"
    env_value_kwarg = "default"
    if node.keywords:
        kwargs = {keyword.arg: keyword.value for keyword in node.keywords}
    else:
        kwargs = None
    if node.args:
        env_name_arg = node.args[0]
    elif kwargs and env_name_kwarg in kwargs:
        env_name_arg = kwargs[env_name_kwarg]
    else:
        env_name_arg = None

    if env_name_arg:
        self._check_invalid_envvar_value(
            node=node,
            message="invalid-envvar-value",
            call_arg=utils.safe_infer(env_name_arg),
            infer=infer,
            allow_none=False,
        )

    if len(node.args) == 2:
        env_value_arg = node.args[1]
    elif kwargs and env_value_kwarg in kwargs:
        env_value_arg = kwargs[env_value_kwarg]
    else:
        env_value_arg = None

    if env_value_arg:
        self._check_invalid_envvar_value(
            node=node,
            infer=infer,
            message="invalid-envvar-default",
            call_arg=utils.safe_infer(env_value_arg),
            allow_none=True,
        )

</t>
<t tx="ekr.20250131013559.621">def _check_invalid_envvar_value(
    self,
    node: nodes.Call,
    infer: nodes.FunctionDef,
    message: str,
    call_arg: InferenceResult | None,
    allow_none: bool,
) -&gt; None:
    if call_arg is None or isinstance(call_arg, util.UninferableBase):
        return

    name = infer.qname()
    if isinstance(call_arg, nodes.Const):
        emit = False
        if call_arg.value is None:
            emit = not allow_none
        elif not isinstance(call_arg.value, str):
            emit = True
        if emit:
            self.add_message(message, node=node, args=(name, call_arg.pytype()))
    else:
        self.add_message(message, node=node, args=(name, call_arg.pytype()))

</t>
<t tx="ekr.20250131013559.622">def deprecated_methods(self) -&gt; set[str]:
    return self._deprecated_methods

</t>
<t tx="ekr.20250131013559.623">def deprecated_arguments(self, method: str) -&gt; tuple[tuple[int | None, str], ...]:
    return self._deprecated_arguments.get(method, ())

</t>
<t tx="ekr.20250131013559.624">def deprecated_classes(self, module: str) -&gt; Iterable[str]:
    return self._deprecated_classes.get(module, ())

</t>
<t tx="ekr.20250131013559.625">def deprecated_decorators(self) -&gt; Iterable[str]:
    return self._deprecated_decorators

</t>
<t tx="ekr.20250131013559.626">def deprecated_attributes(self) -&gt; Iterable[str]:
    return self._deprecated_attributes


</t>
<t tx="ekr.20250131013559.627">@path pylint/checkers
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Checker for string formatting operations."""

from __future__ import annotations

import collections
import re
import sys
import tokenize
from collections import Counter
from collections.abc import Iterable, Sequence
from typing import TYPE_CHECKING, Literal

import astroid
from astroid import bases, nodes, util
from astroid.typing import SuccessfulInferenceResult

from pylint.checkers import BaseChecker, BaseRawFileChecker, BaseTokenChecker, utils
from pylint.checkers.utils import only_required_for_messages
from pylint.interfaces import HIGH
from pylint.typing import MessageDefinitionTuple

if TYPE_CHECKING:
    from pylint.lint import PyLinter


_AST_NODE_STR_TYPES = ("__builtin__.unicode", "__builtin__.str", "builtins.str")
# Prefixes for both strings and bytes literals per
# https://docs.python.org/3/reference/lexical_analysis.html#string-and-bytes-literals
_PREFIXES = {
    "r",
    "u",
    "R",
    "U",
    "f",
    "F",
    "fr",
    "Fr",
    "fR",
    "FR",
    "rf",
    "rF",
    "Rf",
    "RF",
    "b",
    "B",
    "br",
    "Br",
    "bR",
    "BR",
    "rb",
    "rB",
    "Rb",
    "RB",
}
_PAREN_IGNORE_TOKEN_TYPES = (
    tokenize.NEWLINE,
    tokenize.NL,
    tokenize.COMMENT,
)
SINGLE_QUOTED_REGEX = re.compile(f"({'|'.join(_PREFIXES)})?'''")
DOUBLE_QUOTED_REGEX = re.compile(f"({'|'.join(_PREFIXES)})?\"\"\"")
QUOTE_DELIMITER_REGEX = re.compile(f"({'|'.join(_PREFIXES)})?(\"|')", re.DOTALL)

MSGS: dict[str, MessageDefinitionTuple] = (
    {  # pylint: disable=consider-using-namedtuple-or-dataclass
        "E1300": (
            "Unsupported format character %r (%#02x) at index %d",
            "bad-format-character",
            "Used when an unsupported format character is used in a format string.",
        ),
        "E1301": (
            "Format string ends in middle of conversion specifier",
            "truncated-format-string",
            "Used when a format string terminates before the end of a "
            "conversion specifier.",
        ),
        "E1302": (
            "Mixing named and unnamed conversion specifiers in format string",
            "mixed-format-string",
            "Used when a format string contains both named (e.g. '%(foo)d') "
            "and unnamed (e.g. '%d') conversion specifiers.  This is also "
            "used when a named conversion specifier contains * for the "
            "minimum field width and/or precision.",
        ),
        "E1303": (
            "Expected mapping for format string, not %s",
            "format-needs-mapping",
            "Used when a format string that uses named conversion specifiers "
            "is used with an argument that is not a mapping.",
        ),
        "W1300": (
            "Format string dictionary key should be a string, not %s",
            "bad-format-string-key",
            "Used when a format string that uses named conversion specifiers "
            "is used with a dictionary whose keys are not all strings.",
        ),
        "W1301": (
            "Unused key %r in format string dictionary",
            "unused-format-string-key",
            "Used when a format string that uses named conversion specifiers "
            "is used with a dictionary that contains keys not required by the "
            "format string.",
        ),
        "E1304": (
            "Missing key %r in format string dictionary",
            "missing-format-string-key",
            "Used when a format string that uses named conversion specifiers "
            "is used with a dictionary that doesn't contain all the keys "
            "required by the format string.",
        ),
        "E1305": (
            "Too many arguments for format string",
            "too-many-format-args",
            "Used when a format string that uses unnamed conversion "
            "specifiers is given too many arguments.",
        ),
        "E1306": (
            "Not enough arguments for format string",
            "too-few-format-args",
            "Used when a format string that uses unnamed conversion "
            "specifiers is given too few arguments",
        ),
        "E1307": (
            "Argument %r does not match format type %r",
            "bad-string-format-type",
            "Used when a type required by format string "
            "is not suitable for actual argument type",
        ),
        "E1310": (
            "Suspicious argument in %s.%s call",
            "bad-str-strip-call",
            "The argument to a str.{l,r,}strip call contains a duplicate character,",
        ),
        "W1302": (
            "Invalid format string",
            "bad-format-string",
            "Used when a PEP 3101 format string is invalid.",
        ),
        "W1303": (
            "Missing keyword argument %r for format string",
            "missing-format-argument-key",
            "Used when a PEP 3101 format string that uses named fields "
            "doesn't receive one or more required keywords.",
        ),
        "W1304": (
            "Unused format argument %r",
            "unused-format-string-argument",
            "Used when a PEP 3101 format string that uses named "
            "fields is used with an argument that "
            "is not required by the format string.",
        ),
        "W1305": (
            "Format string contains both automatic field numbering "
            "and manual field specification",
            "format-combined-specification",
            "Used when a PEP 3101 format string contains both automatic "
            "field numbering (e.g. '{}') and manual field "
            "specification (e.g. '{0}').",
        ),
        "W1306": (
            "Missing format attribute %r in format specifier %r",
            "missing-format-attribute",
            "Used when a PEP 3101 format string uses an "
            "attribute specifier ({0.length}), but the argument "
            "passed for formatting doesn't have that attribute.",
        ),
        "W1307": (
            "Using invalid lookup key %r in format specifier %r",
            "invalid-format-index",
            "Used when a PEP 3101 format string uses a lookup specifier "
            "({a[1]}), but the argument passed for formatting "
            "doesn't contain or doesn't have that key as an attribute.",
        ),
        "W1308": (
            "Duplicate string formatting argument %r, consider passing as named argument",
            "duplicate-string-formatting-argument",
            "Used when we detect that a string formatting is "
            "repeating an argument instead of using named string arguments",
        ),
        "W1309": (
            "Using an f-string that does not have any interpolated variables",
            "f-string-without-interpolation",
            "Used when we detect an f-string that does not use any interpolation variables, "
            "in which case it can be either a normal string or a bug in the code.",
        ),
        "W1310": (
            "Using formatting for a string that does not have any interpolated variables",
            "format-string-without-interpolation",
            "Used when we detect a string that does not have any interpolation variables, "
            "in which case it can be either a normal string without formatting or a bug in the code.",
        ),
    }
)

OTHER_NODES = (
    nodes.Const,
    nodes.List,
    nodes.Lambda,
    nodes.FunctionDef,
    nodes.ListComp,
    nodes.SetComp,
    nodes.GeneratorExp,
)


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013559.628">def get_access_path(key: str | Literal[0], parts: list[tuple[bool, str]]) -&gt; str:
    """Given a list of format specifiers, returns
    the final access path (e.g. a.b.c[0][1]).
    """
    path = []
    for is_attribute, specifier in parts:
        if is_attribute:
            path.append(f".{specifier}")
        else:
            path.append(f"[{specifier!r}]")
    return str(key) + "".join(path)


</t>
<t tx="ekr.20250131013559.629">def arg_matches_format_type(
    arg_type: SuccessfulInferenceResult, format_type: str
) -&gt; bool:
    if format_type in "sr":
        # All types can be printed with %s and %r
        return True
    if isinstance(arg_type, astroid.Instance):
        arg_type = arg_type.pytype()
        if arg_type == "builtins.str":
            return format_type == "c"
        if arg_type == "builtins.float":
            return format_type in "deEfFgGn%"
        if arg_type == "builtins.int":
            # Integers allow all types
            return True
        return False
    return True


</t>
<t tx="ekr.20250131013559.630">class StringFormatChecker(BaseChecker):
    """Checks string formatting operations to ensure that the format string
    is valid and the arguments match the format string.
    """

    @others
</t>
<t tx="ekr.20250131013559.631">class StringConstantChecker(BaseTokenChecker, BaseRawFileChecker):
    """Check string literals."""

    @others
</t>
<t tx="ekr.20250131013559.632">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(StringFormatChecker(linter))
    linter.register_checker(StringConstantChecker(linter))


</t>
<t tx="ekr.20250131013559.633">def str_eval(token: str) -&gt; str:
    """Mostly replicate `ast.literal_eval(token)` manually to avoid any performance hit.

    This supports f-strings, contrary to `ast.literal_eval`.
    We have to support all string literal notations:
    https://docs.python.org/3/reference/lexical_analysis.html#string-and-bytes-literals
    """
    if token[0:2].lower() in {"fr", "rf"}:
        token = token[2:]
    elif token[0].lower() in {"r", "u", "f"}:
        token = token[1:]
    if token[0:3] in {'"""', "'''"}:
        return token[3:-3]
    return token[1:-1]


</t>
<t tx="ekr.20250131013559.634">def _is_long_string(string_token: str) -&gt; bool:
    """Is this string token a "longstring" (is it triple-quoted)?

    Long strings are triple-quoted as defined in
    https://docs.python.org/3/reference/lexical_analysis.html#string-and-bytes-literals

    This function only checks characters up through the open quotes.  Because it's meant
    to be applied only to tokens that represent string literals, it doesn't bother to
    check for close-quotes (demonstrating that the literal is a well-formed string).

    Args:
        string_token: The string token to be parsed.

    Returns:
        A boolean representing whether this token matches a longstring
        regex.
    """
    return bool(
        SINGLE_QUOTED_REGEX.match(string_token)
        or DOUBLE_QUOTED_REGEX.match(string_token)
    )


</t>
<t tx="ekr.20250131013559.635">def _get_quote_delimiter(string_token: str) -&gt; str:
    """Returns the quote character used to delimit this token string.

    This function checks whether the token is a well-formed string.

    Args:
        string_token: The token to be parsed.

    Returns:
        A string containing solely the first quote delimiter character in the
        given string.

    Raises:
      ValueError: No quote delimiter characters are present.
    """
    match = QUOTE_DELIMITER_REGEX.match(string_token)
    if not match:
        raise ValueError(f"string token {string_token} is not a well-formed string")
    return match.group(2)


</t>
<t tx="ekr.20250131013559.636">def _is_quote_delimiter_chosen_freely(string_token: str) -&gt; bool:
    """Was there a non-awkward option for the quote delimiter?

    Args:
        string_token: The quoted string whose delimiters are to be checked.

    Returns:
        Whether there was a choice in this token's quote character that would
        not have involved backslash-escaping an interior quote character.  Long
        strings are excepted from this analysis under the assumption that their
        quote characters are set by policy.
    """
    quote_delimiter = _get_quote_delimiter(string_token)
    unchosen_delimiter = '"' if quote_delimiter == "'" else "'"
    return bool(
        quote_delimiter
        and not _is_long_string(string_token)
        and unchosen_delimiter not in str_eval(string_token)
    )
</t>
<t tx="ekr.20250131013559.637">name = "string"
msgs = MSGS

# pylint: disable = too-many-branches, too-many-locals, too-many-statements
@only_required_for_messages(
    "bad-format-character",
    "truncated-format-string",
    "mixed-format-string",
    "bad-format-string-key",
    "missing-format-string-key",
    "unused-format-string-key",
    "bad-string-format-type",
    "format-needs-mapping",
    "too-many-format-args",
    "too-few-format-args",
    "format-string-without-interpolation",
)
def visit_binop(self, node: nodes.BinOp) -&gt; None:
    if node.op != "%":
        return
    left = node.left
    args = node.right

    if not (isinstance(left, nodes.Const) and isinstance(left.value, str)):
        return
    format_string = left.value
    try:
        (
            required_keys,
            required_num_args,
            required_key_types,
            required_arg_types,
        ) = utils.parse_format_string(format_string)
    except utils.UnsupportedFormatCharacter as exc:
        formatted = format_string[exc.index]
        self.add_message(
            "bad-format-character",
            node=node,
            args=(formatted, ord(formatted), exc.index),
        )
        return
    except utils.IncompleteFormatString:
        self.add_message("truncated-format-string", node=node)
        return
    if not required_keys and not required_num_args:
        self.add_message("format-string-without-interpolation", node=node)
        return
    if required_keys and required_num_args:
        # The format string uses both named and unnamed format
        # specifiers.
        self.add_message("mixed-format-string", node=node)
    elif required_keys:
        # The format string uses only named format specifiers.
        # Check that the RHS of the % operator is a mapping object
        # that contains precisely the set of keys required by the
        # format string.
        if isinstance(args, nodes.Dict):
            keys = set()
            unknown_keys = False
            for k, _ in args.items:
                if isinstance(k, nodes.Const):
                    key = k.value
                    if isinstance(key, str):
                        keys.add(key)
                    else:
                        self.add_message(
                            "bad-format-string-key", node=node, args=key
                        )
                else:
                    # One of the keys was something other than a
                    # constant.  Since we can't tell what it is,
                    # suppress checks for missing keys in the
                    # dictionary.
                    unknown_keys = True
            if not unknown_keys:
                for key in required_keys:
                    if key not in keys:
                        self.add_message(
                            "missing-format-string-key", node=node, args=key
                        )
            for key in keys:
                if key not in required_keys:
                    self.add_message(
                        "unused-format-string-key", node=node, args=key
                    )
            for key, arg in args.items:
                if not isinstance(key, nodes.Const):
                    continue
                format_type = required_key_types.get(key.value, None)
                arg_type = utils.safe_infer(arg)
                if (
                    format_type is not None
                    and arg_type
                    and not isinstance(arg_type, util.UninferableBase)
                    and not arg_matches_format_type(arg_type, format_type)
                ):
                    self.add_message(
                        "bad-string-format-type",
                        node=node,
                        args=(arg_type.pytype(), format_type),
                    )
        elif isinstance(args, (OTHER_NODES, nodes.Tuple)):
            type_name = type(args).__name__
            self.add_message("format-needs-mapping", node=node, args=type_name)
        # else:
        # The RHS of the format specifier is a name or
        # expression.  It may be a mapping object, so
        # there's nothing we can check.
    else:
        # The format string uses only unnamed format specifiers.
        # Check that the number of arguments passed to the RHS of
        # the % operator matches the number required by the format
        # string.
        args_elts = []
        if isinstance(args, nodes.Tuple):
            rhs_tuple = utils.safe_infer(args)
            num_args = None
            if isinstance(rhs_tuple, nodes.BaseContainer):
                args_elts = rhs_tuple.elts
                num_args = len(args_elts)
        elif isinstance(args, (OTHER_NODES, (nodes.Dict, nodes.DictComp))):
            args_elts = [args]
            num_args = 1
        elif isinstance(args, nodes.Name):
            inferred = utils.safe_infer(args)
            if isinstance(inferred, nodes.Tuple):
                # The variable is a tuple, so we need to get the elements
                # from it for further inspection
                args_elts = inferred.elts
                num_args = len(args_elts)
            elif isinstance(inferred, nodes.Const):
                args_elts = [inferred]
                num_args = 1
            else:
                num_args = None
        else:
            # The RHS of the format specifier is an expression.
            # It could be a tuple of unknown size, so
            # there's nothing we can check.
            num_args = None
        if num_args is not None:
            if num_args &gt; required_num_args:
                self.add_message("too-many-format-args", node=node)
            elif num_args &lt; required_num_args:
                self.add_message("too-few-format-args", node=node)
            for arg, format_type in zip(args_elts, required_arg_types):
                if not arg:
                    continue
                arg_type = utils.safe_infer(arg)
                if (
                    arg_type
                    and not isinstance(arg_type, util.UninferableBase)
                    and not arg_matches_format_type(arg_type, format_type)
                ):
                    self.add_message(
                        "bad-string-format-type",
                        node=node,
                        args=(arg_type.pytype(), format_type),
                    )

</t>
<t tx="ekr.20250131013559.638">@only_required_for_messages("f-string-without-interpolation")
def visit_joinedstr(self, node: nodes.JoinedStr) -&gt; None:
    self._check_interpolation(node)

</t>
<t tx="ekr.20250131013559.639">def _check_interpolation(self, node: nodes.JoinedStr) -&gt; None:
    if isinstance(node.parent, nodes.FormattedValue):
        return
    for value in node.values:
        if isinstance(value, nodes.FormattedValue):
            return
    self.add_message("f-string-without-interpolation", node=node)

</t>
<t tx="ekr.20250131013559.640">def visit_call(self, node: nodes.Call) -&gt; None:
    func = utils.safe_infer(node.func)
    if (
        isinstance(func, astroid.BoundMethod)
        and isinstance(func.bound, astroid.Instance)
        and func.bound.name in {"str", "unicode", "bytes"}
    ):
        if func.name in {"strip", "lstrip", "rstrip"} and node.args:
            arg = utils.safe_infer(node.args[0])
            if not isinstance(arg, nodes.Const) or not isinstance(arg.value, str):
                return
            if len(arg.value) != len(set(arg.value)):
                self.add_message(
                    "bad-str-strip-call",
                    node=node,
                    args=(func.bound.name, func.name),
                )
        elif func.name == "format":
            self._check_new_format(node, func)

</t>
<t tx="ekr.20250131013559.641">def _detect_vacuous_formatting(
    self, node: nodes.Call, positional_arguments: list[SuccessfulInferenceResult]
) -&gt; None:
    counter = collections.Counter(
        arg.name for arg in positional_arguments if isinstance(arg, nodes.Name)
    )
    for name, count in counter.items():
        if count == 1:
            continue
        self.add_message(
            "duplicate-string-formatting-argument", node=node, args=(name,)
        )

</t>
<t tx="ekr.20250131013559.642">def _check_new_format(self, node: nodes.Call, func: bases.BoundMethod) -&gt; None:
    """Check the new string formatting."""
    # Skip format nodes which don't have an explicit string on the
    # left side of the format operation.
    # We do this because our inference engine can't properly handle
    # redefinition of the original string.
    # Note that there may not be any left side at all, if the format method
    # has been assigned to another variable. See issue 351. For example:
    #
    #    fmt = 'some string {}'.format
    #    fmt('arg')
    if isinstance(node.func, nodes.Attribute) and not isinstance(
        node.func.expr, nodes.Const
    ):
        return
    if node.starargs or node.kwargs:
        return
    try:
        strnode = next(func.bound.infer())
    except astroid.InferenceError:
        return
    if not (isinstance(strnode, nodes.Const) and isinstance(strnode.value, str)):
        return
    try:
        call_site = astroid.arguments.CallSite.from_call(node)
    except astroid.InferenceError:
        return

    try:
        fields, num_args, manual_pos = utils.parse_format_method_string(
            strnode.value
        )
    except utils.IncompleteFormatString:
        self.add_message("bad-format-string", node=node)
        return

    positional_arguments = call_site.positional_arguments
    named_arguments = call_site.keyword_arguments
    named_fields = {field[0] for field in fields if isinstance(field[0], str)}
    if num_args and manual_pos:
        self.add_message("format-combined-specification", node=node)
        return

    check_args = False
    # Consider "{[0]} {[1]}" as num_args.
    num_args += sum(1 for field in named_fields if not field)
    if named_fields:
        for field in named_fields:
            if field and field not in named_arguments:
                self.add_message(
                    "missing-format-argument-key", node=node, args=(field,)
                )
        for field in named_arguments:
            if field not in named_fields:
                self.add_message(
                    "unused-format-string-argument", node=node, args=(field,)
                )
        # num_args can be 0 if manual_pos is not.
        num_args = num_args or manual_pos
        if positional_arguments or num_args:
            empty = not all(field for field in named_fields)
            if named_arguments or empty:
                # Verify the required number of positional arguments
                # only if the .format got at least one keyword argument.
                # This means that the format strings accepts both
                # positional and named fields and we should warn
                # when one of them is missing or is extra.
                check_args = True
    else:
        check_args = True
    if check_args:
        # num_args can be 0 if manual_pos is not.
        num_args = num_args or manual_pos
        if not num_args:
            self.add_message("format-string-without-interpolation", node=node)
            return
        if len(positional_arguments) &gt; num_args:
            self.add_message("too-many-format-args", node=node)
        elif len(positional_arguments) &lt; num_args:
            self.add_message("too-few-format-args", node=node)

    self._detect_vacuous_formatting(node, positional_arguments)
    self._check_new_format_specifiers(node, fields, named_arguments)

</t>
<t tx="ekr.20250131013559.643"># pylint: disable = too-many-statements
def _check_new_format_specifiers(
    self,
    node: nodes.Call,
    fields: list[tuple[str, list[tuple[bool, str]]]],
    named: dict[str, SuccessfulInferenceResult],
) -&gt; None:
    """Check attribute and index access in the format
    string ("{0.a}" and "{0[a]}").
    """
    key: Literal[0] | str
    for key, specifiers in fields:
        # Obtain the argument. If it can't be obtained
        # or inferred, skip this check.
        if not key:
            # {[0]} will have an unnamed argument, defaulting
            # to 0. It will not be present in `named`, so use the value
            # 0 for it.
            key = 0
        if isinstance(key, int):
            try:
                argname = utils.get_argument_from_call(node, key)
            except utils.NoSuchArgumentError:
                continue
        else:
            if key not in named:
                continue
            argname = named[key]
        if argname is None or isinstance(argname, util.UninferableBase):
            continue
        try:
            argument = utils.safe_infer(argname)
        except astroid.InferenceError:
            continue
        if not specifiers or not argument:
            # No need to check this key if it doesn't
            # use attribute / item access
            continue
        if argument.parent and isinstance(argument.parent, nodes.Arguments):
            # Ignore any object coming from an argument,
            # because we can't infer its value properly.
            continue
        previous = argument
        parsed: list[tuple[bool, str]] = []
        for is_attribute, specifier in specifiers:
            if isinstance(previous, util.UninferableBase):
                break
            parsed.append((is_attribute, specifier))
            if is_attribute:
                try:
                    previous = previous.getattr(specifier)[0]
                except astroid.NotFoundError:
                    if (
                        hasattr(previous, "has_dynamic_getattr")
                        and previous.has_dynamic_getattr()
                    ):
                        # Don't warn if the object has a custom __getattr__
                        break
                    path = get_access_path(key, parsed)
                    self.add_message(
                        "missing-format-attribute",
                        args=(specifier, path),
                        node=node,
                    )
                    break
            else:
                warn_error = False
                if hasattr(previous, "getitem"):
                    try:
                        previous = previous.getitem(nodes.Const(specifier))
                    except(
                        astroid.AstroidIndexError,
                        astroid.AstroidTypeError,
                        astroid.AttributeInferenceError,
                    ):
                        warn_error = True
                    except astroid.InferenceError:
                        break
                    if isinstance(previous, util.UninferableBase):
                        break
                else:
                    try:
                        # Lookup __getitem__ in the current node,
                        # but skip further checks, because we can't
                        # retrieve the looked object
                        previous.getattr("__getitem__")
                        break
                    except astroid.NotFoundError:
                        warn_error = True
                if warn_error:
                    path = get_access_path(key, parsed)
                    self.add_message(
                        "invalid-format-index", args=(specifier, path), node=node
                    )
                    break

            try:
                previous = next(previous.infer())
            except astroid.InferenceError:
                # can't check further if we can't infer it
                break


</t>
<t tx="ekr.20250131013559.644">name = "string"
msgs = {
    "W1401": (
        "Anomalous backslash in string: '%s'. "
        "String constant might be missing an r prefix.",
        "anomalous-backslash-in-string",
        "Used when a backslash is in a literal string but not as an escape.",
    ),
    "W1402": (
        "Anomalous Unicode escape in byte string: '%s'. "
        "String constant might be missing an r or u prefix.",
        "anomalous-unicode-escape-in-string",
        "Used when an escape like \\u is encountered in a byte "
        "string where it has no effect.",
    ),
    "W1404": (
        "Implicit string concatenation found in %s",
        "implicit-str-concat",
        "String literals are implicitly concatenated in a "
        "literal iterable definition : "
        "maybe a comma is missing ?",
        {"old_names": [("W1403", "implicit-str-concat-in-sequence")]},
    ),
    "W1405": (
        "Quote delimiter %s is inconsistent with the rest of the file",
        "inconsistent-quotes",
        "Quote delimiters are not used consistently throughout a module "
        "(with allowances made for avoiding unnecessary escaping).",
    ),
    "W1406": (
        "The u prefix for strings is no longer necessary in Python &gt;=3.0",
        "redundant-u-string-prefix",
        "Used when we detect a string with a u prefix. These prefixes were necessary "
        "in Python 2 to indicate a string was Unicode, but since Python 3.0 strings "
        "are Unicode by default.",
    ),
}
options = (
    (
        "check-str-concat-over-line-jumps",
        {
            "default": False,
            "type": "yn",
            "metavar": "&lt;y or n&gt;",
            "help": "This flag controls whether the "
            "implicit-str-concat should generate a warning "
            "on implicit string concatenation in sequences defined over "
            "several lines.",
        },
    ),
    (
        "check-quote-consistency",
        {
            "default": False,
            "type": "yn",
            "metavar": "&lt;y or n&gt;",
            "help": "This flag controls whether inconsistent-quotes generates a "
            "warning when the character used as a quote delimiter is used "
            "inconsistently within a module.",
        },
    ),
)

# Characters that have a special meaning after a backslash in either
# Unicode or byte strings.
ESCAPE_CHARACTERS = "abfnrtvx\n\r\t\\'\"01234567"

# Characters that have a special meaning after a backslash but only in
# Unicode strings.
UNICODE_ESCAPE_CHARACTERS = "uUN"

def __init__(self, linter: PyLinter) -&gt; None:
    super().__init__(linter)
    self.string_tokens: dict[
        tuple[int, int], tuple[str, tokenize.TokenInfo | None]
    ] = {}
    """Token position -&gt; (token value, next token)."""
    self._parenthesized_string_tokens: dict[tuple[int, int], bool] = {}

</t>
<t tx="ekr.20250131013559.645">def process_module(self, node: nodes.Module) -&gt; None:
    self._unicode_literals = "unicode_literals" in node.future_imports

</t>
<t tx="ekr.20250131013559.646">def process_tokens(self, tokens: list[tokenize.TokenInfo]) -&gt; None:
    encoding = "ascii"
    for i, (token_type, token, start, _, line) in enumerate(tokens):
        if token_type == tokenize.ENCODING:
            # this is always the first token processed
            encoding = token
        elif token_type == tokenize.STRING:
            # 'token' is the whole un-parsed token; we can look at the start
            # of it to see whether it's a raw or unicode string etc.
            self.process_string_token(token, start[0], start[1])
            # We figure the next token, ignoring comments &amp; newlines:
            j = i + 1
            while j &lt; len(tokens) and tokens[j].type in (
                tokenize.NEWLINE,
                tokenize.NL,
                tokenize.COMMENT,
            ):
                j += 1
            next_token = tokens[j] if j &lt; len(tokens) else None
            if encoding != "ascii":
                # We convert `tokenize` character count into a byte count,
                # to match with astroid `.col_offset`
                start = (start[0], len(line[: start[1]].encode(encoding)))
            self.string_tokens[start] = (str_eval(token), next_token)
            is_parenthesized = self._is_initial_string_token(
                i, tokens
            ) and self._is_parenthesized(i, tokens)
            self._parenthesized_string_tokens[start] = is_parenthesized

    if self.linter.config.check_quote_consistency:
        self.check_for_consistent_string_delimiters(tokens)

</t>
<t tx="ekr.20250131013559.647">def _is_initial_string_token(
    self, index: int, tokens: Sequence[tokenize.TokenInfo]
) -&gt; bool:
    # Must NOT be preceded by a string literal
    prev_token = self._find_prev_token(index, tokens)
    if prev_token and prev_token.type == tokenize.STRING:
        return False
    # Must be followed by a string literal token.
    next_token = self._find_next_token(index, tokens)
    return bool(next_token and next_token.type == tokenize.STRING)

</t>
<t tx="ekr.20250131013559.648">def _is_parenthesized(self, index: int, tokens: list[tokenize.TokenInfo]) -&gt; bool:
    prev_token = self._find_prev_token(
        index, tokens, ignore=(*_PAREN_IGNORE_TOKEN_TYPES, tokenize.STRING)
    )
    if not prev_token or prev_token.type != tokenize.OP or prev_token[1] != "(":
        return False
    next_token = self._find_next_token(
        index, tokens, ignore=(*_PAREN_IGNORE_TOKEN_TYPES, tokenize.STRING)
    )
    return bool(
        next_token and next_token.type == tokenize.OP and next_token[1] == ")"
    )

</t>
<t tx="ekr.20250131013559.649">def _find_prev_token(
    self,
    index: int,
    tokens: Sequence[tokenize.TokenInfo],
    *,
    ignore: tuple[int, ...] = _PAREN_IGNORE_TOKEN_TYPES,
) -&gt; tokenize.TokenInfo | None:
    i = index - 1
    while i &gt;= 0 and tokens[i].type in ignore:
        i -= 1
    return tokens[i] if i &gt;= 0 else None

</t>
<t tx="ekr.20250131013559.650">def _find_next_token(
    self,
    index: int,
    tokens: Sequence[tokenize.TokenInfo],
    *,
    ignore: tuple[int, ...] = _PAREN_IGNORE_TOKEN_TYPES,
) -&gt; tokenize.TokenInfo | None:
    i = index + 1
    while i &lt; len(tokens) and tokens[i].type in ignore:
        i += 1
    return tokens[i] if i &lt; len(tokens) else None

</t>
<t tx="ekr.20250131013559.651">@only_required_for_messages("implicit-str-concat")
def visit_call(self, node: nodes.Call) -&gt; None:
    self.check_for_concatenated_strings(node.args, "call")

</t>
<t tx="ekr.20250131013559.652">@only_required_for_messages("implicit-str-concat")
def visit_list(self, node: nodes.List) -&gt; None:
    self.check_for_concatenated_strings(node.elts, "list")

</t>
<t tx="ekr.20250131013559.653">@only_required_for_messages("implicit-str-concat")
def visit_set(self, node: nodes.Set) -&gt; None:
    self.check_for_concatenated_strings(node.elts, "set")

</t>
<t tx="ekr.20250131013559.654">@only_required_for_messages("implicit-str-concat")
def visit_tuple(self, node: nodes.Tuple) -&gt; None:
    self.check_for_concatenated_strings(node.elts, "tuple")

</t>
<t tx="ekr.20250131013559.655">def visit_assign(self, node: nodes.Assign) -&gt; None:
    if isinstance(node.value, nodes.Const) and isinstance(node.value.value, str):
        self.check_for_concatenated_strings([node.value], "assignment")

</t>
<t tx="ekr.20250131013559.656">def check_for_consistent_string_delimiters(
    self, tokens: Iterable[tokenize.TokenInfo]
) -&gt; None:
    """Adds a message for each string using inconsistent quote delimiters.

    Quote delimiters are used inconsistently if " and ' are mixed in a module's
    shortstrings without having done so to avoid escaping an internal quote
    character.

    Args:
      tokens: The tokens to be checked against for consistent usage.
    """
    string_delimiters: Counter[str] = collections.Counter()

    inside_fstring = False  # whether token is inside f-string (since 3.12)
    target_py312 = self.linter.config.py_version &gt;= (3, 12)

    # First, figure out which quote character predominates in the module
    for tok_type, token, _, _, _ in tokens:
        if sys.version_info[:2] &gt;= (3, 12):
            # pylint: disable=no-member,useless-suppression
            if tok_type == tokenize.FSTRING_START:
                inside_fstring = True
            elif tok_type == tokenize.FSTRING_END:
                inside_fstring = False

            if inside_fstring and not target_py312:
                # skip analysis of f-string contents
                continue

        if tok_type == tokenize.STRING and _is_quote_delimiter_chosen_freely(token):
            string_delimiters[_get_quote_delimiter(token)] += 1

    if len(string_delimiters) &gt; 1:
        # Ties are broken arbitrarily
        most_common_delimiter = string_delimiters.most_common(1)[0][0]
        for tok_type, token, start, _, _ in tokens:
            if tok_type != tokenize.STRING:
                continue
            quote_delimiter = _get_quote_delimiter(token)
            if (
                _is_quote_delimiter_chosen_freely(token)
                and quote_delimiter != most_common_delimiter
            ):
                self.add_message(
                    "inconsistent-quotes", line=start[0], args=(quote_delimiter,)
                )

</t>
<t tx="ekr.20250131013559.657">def check_for_concatenated_strings(
    self, elements: Sequence[nodes.NodeNG], iterable_type: str
) -&gt; None:
    for elt in elements:
        if not (
            isinstance(elt, nodes.Const) and elt.pytype() in _AST_NODE_STR_TYPES
        ):
            continue
        if elt.col_offset &lt; 0:
            # This can happen in case of escaped newlines
            continue
        token_index = (elt.lineno, elt.col_offset)
        if token_index not in self.string_tokens:
            # This may happen with Latin1 encoding
            # cf. https://github.com/pylint-dev/pylint/issues/2610
            continue
        matching_token, next_token = self.string_tokens[token_index]
        # We detect string concatenation: the AST Const is the
        # combination of 2 string tokens
        if (
            matching_token != elt.value
            and next_token is not None
            and next_token.type == tokenize.STRING
        ):
            if next_token.start[0] == elt.lineno or (
                self.linter.config.check_str_concat_over_line_jumps
                # Allow implicitly concatenated strings in parens.
                # See https://github.com/pylint-dev/pylint/issues/8552.
                and not self._parenthesized_string_tokens.get(
                    (elt.lineno, elt.col_offset)
                )
            ):
                self.add_message(
                    "implicit-str-concat",
                    line=elt.lineno,
                    args=(iterable_type,),
                    confidence=HIGH,
                )

</t>
<t tx="ekr.20250131013559.658">def process_string_token(self, token: str, start_row: int, start_col: int) -&gt; None:
    quote_char = None
    for _index, char in enumerate(token):
        if char in "'\"":
            quote_char = char
            break
    if quote_char is None:
        return
    # pylint: disable=undefined-loop-variable
    prefix = token[:_index].lower()  # markers like u, b, r.
    after_prefix = token[_index:]
    # pylint: enable=undefined-loop-variable
    # Chop off quotes
    quote_length = (
        3 if after_prefix[:3] == after_prefix[-3:] == 3 * quote_char else 1
    )
    string_body = after_prefix[quote_length:-quote_length]
    # No special checks on raw strings at the moment.
    if "r" not in prefix:
        self.process_non_raw_string_token(
            prefix,
            string_body,
            start_row,
            start_col + len(prefix) + quote_length,
        )

</t>
<t tx="ekr.20250131013559.659">def process_non_raw_string_token(
    self, prefix: str, string_body: str, start_row: int, string_start_col: int
) -&gt; None:
    """Check for bad escapes in a non-raw string.

    prefix: lowercase string of string prefix markers ('ur').
    string_body: the un-parsed body of the string, not including the quote
    marks.
    start_row: line number in the source.
    string_start_col: col number of the string start in the source.
    """
    # Walk through the string; if we see a backslash then escape the next
    # character, and skip over it.  If we see a non-escaped character,
    # alert, and continue.
    #
    # Accept a backslash when it escapes a backslash, or a quote, or
    # end-of-line, or one of the letters that introduce a special escape
    # sequence &lt;https://docs.python.org/reference/lexical_analysis.html&gt;
    #
    index = 0
    while True:
        index = string_body.find("\\", index)
        if index == -1:
            break
        # There must be a next character; having a backslash at the end
        # of the string would be a SyntaxError.
        next_char = string_body[index + 1]
        match = string_body[index : index + 2]
        # The column offset will vary depending on whether the string token
        # is broken across lines. Calculate relative to the nearest line
        # break or relative to the start of the token's line.
        last_newline = string_body.rfind("\n", 0, index)
        if last_newline == -1:
            line = start_row
            col_offset = index + string_start_col
        else:
            line = start_row + string_body.count("\n", 0, index)
            col_offset = index - last_newline - 1
        if next_char in self.UNICODE_ESCAPE_CHARACTERS:
            if "u" in prefix:
                pass
            elif "b" not in prefix:
                pass  # unicode by default
            else:
                self.add_message(
                    "anomalous-unicode-escape-in-string",
                    line=line,
                    args=(match,),
                    col_offset=col_offset,
                )
        elif next_char not in self.ESCAPE_CHARACTERS:
            self.add_message(
                "anomalous-backslash-in-string",
                line=line,
                args=(match,),
                col_offset=col_offset,
            )
        # Whether it was a valid escape or not, backslash followed by
        # another character can always be consumed whole: the second
        # character can never be the start of a new backslash escape.
        index += 2

</t>
<t tx="ekr.20250131013559.660">@only_required_for_messages("redundant-u-string-prefix")
def visit_const(self, node: nodes.Const) -&gt; None:
    if node.pytype() == "builtins.str" and not isinstance(
        node.parent, nodes.JoinedStr
    ):
        self._detect_u_string_prefix(node)

</t>
<t tx="ekr.20250131013559.661">def _detect_u_string_prefix(self, node: nodes.Const) -&gt; None:
    """Check whether strings include a 'u' prefix like u'String'."""
    if node.kind == "u":
        self.add_message(
            "redundant-u-string-prefix",
            line=node.lineno,
            col_offset=node.col_offset,
        )


</t>
<t tx="ekr.20250131013559.662">@path pylint/checkers
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""A similarities / code duplication command line tool and pylint checker.

The algorithm is based on comparing the hash value of n successive lines of a file.
First the files are read and any line that doesn't fulfill requirement are removed
(comments, docstrings...)

Those stripped lines are stored in the LineSet class which gives access to them.
Then each index of the stripped lines collection is associated with the hash of n
successive entries of the stripped lines starting at the current index (n is the
minimum common lines option).

The common hashes between both linesets are then looked for. If there are matches, then
the match indices in both linesets are stored and associated with the corresponding
couples (start line number/end line number) in both files.

This association is then post-processed to handle the case of successive matches. For
example if the minimum common lines setting is set to four, then the hashes are
computed with four lines. If one of match indices couple (12, 34) is the
successor of another one (11, 33) then it means that there are in fact five lines which
are common.

Once post-processed the values of association table are the result looked for, i.e.
start and end lines numbers of common lines in both files.
"""

from __future__ import annotations

import argparse
import copy
import functools
import itertools
import operator
import re
import sys
import warnings
from collections import defaultdict
from collections.abc import Callable, Generator, Iterable, Sequence
from io import BufferedIOBase, BufferedReader, BytesIO
from itertools import chain
from typing import TYPE_CHECKING, NamedTuple, NewType, NoReturn, TextIO, Union

import astroid
from astroid import nodes

from pylint.checkers import BaseChecker, BaseRawFileChecker, table_lines_from_stats
from pylint.reporters.ureports.nodes import Section, Table
from pylint.typing import MessageDefinitionTuple, Options
from pylint.utils import LinterStats, decoding_stream

if TYPE_CHECKING:
    from pylint.lint import PyLinter

DEFAULT_MIN_SIMILARITY_LINE = 4

REGEX_FOR_LINES_WITH_CONTENT = re.compile(r".*\w+")

# Index defines a location in a LineSet stripped lines collection
Index = NewType("Index", int)

# LineNumber defines a location in a LinesSet real lines collection (the whole file lines)
LineNumber = NewType("LineNumber", int)


# LineSpecifs holds characteristics of a line in a file
@others
if __name__ == "__main__":
    Run()
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013559.663">class LineSpecifs(NamedTuple):
    line_number: LineNumber
    text: str


</t>
<t tx="ekr.20250131013559.664"># Links LinesChunk object to the starting indices (in lineset's stripped lines)
# of the different chunk of lines that are used to compute the hash
HashToIndex_T = dict["LinesChunk", list[Index]]

# Links index in the lineset's stripped lines to the real lines in the file
IndexToLines_T = dict[Index, "SuccessiveLinesLimits"]

# The types the streams read by pylint can take. Originating from astroid.nodes.Module.stream() and open()
STREAM_TYPES = Union[TextIO, BufferedReader, BytesIO]


class CplSuccessiveLinesLimits:
    """Holds a SuccessiveLinesLimits object for each checked file and counts the number
    of common lines between both stripped lines collections extracted from both files.
    """

    @others
</t>
<t tx="ekr.20250131013559.665"># Links the indices to the starting line in both lineset's stripped lines to
# the start and end lines in both files
CplIndexToCplLines_T = dict["LineSetStartCouple", CplSuccessiveLinesLimits]


class LinesChunk:
    """The LinesChunk object computes and stores the hash of some consecutive stripped
    lines of a lineset.
    """

    @others
</t>
<t tx="ekr.20250131013559.666">class SuccessiveLinesLimits:
    """A class to handle the numbering of begin and end of successive lines.

    :note: Only the end line number can be updated.
    """

    @others
</t>
<t tx="ekr.20250131013559.667">class LineSetStartCouple(NamedTuple):
    """Indices in both linesets that mark the beginning of successive lines."""

    @others
</t>
<t tx="ekr.20250131013559.668">LinesChunkLimits_T = tuple["LineSet", LineNumber, LineNumber]


def hash_lineset(
    lineset: LineSet, min_common_lines: int = DEFAULT_MIN_SIMILARITY_LINE
) -&gt; tuple[HashToIndex_T, IndexToLines_T]:
    """Return two dicts.

    The first associates the hash of successive stripped lines of a lineset
    to the indices of the starting lines.
    The second dict, associates the index of the starting line in the lineset's stripped lines to the
    couple [start, end] lines number in the corresponding file.

    :param lineset: lineset object (i.e the lines in a file)
    :param min_common_lines: number of successive lines that are used to compute the hash
    :return: a dict linking hashes to corresponding start index and a dict that links this
             index to the start and end lines in the file
    """
    hash2index = defaultdict(list)
    index2lines = {}
    # Comments, docstring and other specific patterns maybe excluded -&gt; call to stripped_lines
    # to get only what is desired
    lines = tuple(x.text for x in lineset.stripped_lines)
    # Need different iterators on same lines but each one is shifted 1 from the precedent
    shifted_lines = [iter(lines[i:]) for i in range(min_common_lines)]

    for i, * succ_lines in enumerate(zip(*shifted_lines)):
        start_linenumber = LineNumber(lineset.stripped_lines[i].line_number)
        try:
            end_linenumber = lineset.stripped_lines[i + min_common_lines].line_number
        except IndexError:
            end_linenumber = LineNumber(lineset.stripped_lines[-1].line_number + 1)

        index = Index(i)
        index2lines[index] = SuccessiveLinesLimits(
            start=start_linenumber, end=end_linenumber
        )

        l_c = LinesChunk(lineset.name, index, *succ_lines)
        hash2index[l_c].append(index)

    return hash2index, index2lines


</t>
<t tx="ekr.20250131013559.669">def remove_successive(all_couples: CplIndexToCplLines_T) -&gt; None:
    """Removes all successive entries in the dictionary in argument.

    :param all_couples: collection that has to be cleaned up from successive entries.
                        The keys are couples of indices that mark the beginning of common entries
                        in both linesets. The values have two parts. The first one is the couple
                        of starting and ending line numbers of common successive lines in the first file.
                        The second part is the same for the second file.

    For example consider the following dict:

    &gt;&gt;&gt; all_couples
    {(11, 34): ([5, 9], [27, 31]),
     (23, 79): ([15, 19], [45, 49]),
     (12, 35): ([6, 10], [28, 32])}

    There are two successive keys (11, 34) and (12, 35).
    It means there are two consecutive similar chunks of lines in both files.
    Thus remove last entry and update the last line numbers in the first entry

    &gt;&gt;&gt; remove_successive(all_couples)
    &gt;&gt;&gt; all_couples
    {(11, 34): ([5, 10], [27, 32]),
     (23, 79): ([15, 19], [45, 49])}
    """
    couple: LineSetStartCouple
    for couple in tuple(all_couples.keys()):
        to_remove = []
        test = couple.increment(Index(1))
        while test in all_couples:
            all_couples[couple].first_file.end = all_couples[test].first_file.end
            all_couples[couple].second_file.end = all_couples[test].second_file.end
            all_couples[couple].effective_cmn_lines_nb += 1
            to_remove.append(test)
            test = test.increment(Index(1))

        for target in to_remove:
            try:
                all_couples.pop(target)
            except KeyError:
                pass


</t>
<t tx="ekr.20250131013559.670">def filter_noncode_lines(
    ls_1: LineSet,
    stindex_1: Index,
    ls_2: LineSet,
    stindex_2: Index,
    common_lines_nb: int,
) -&gt; int:
    """Return the effective number of common lines between lineset1
    and lineset2 filtered from non code lines.

    That is to say the number of common successive stripped
    lines except those that do not contain code (for example
    a line with only an ending parenthesis)

    :param ls_1: first lineset
    :param stindex_1: first lineset starting index
    :param ls_2: second lineset
    :param stindex_2: second lineset starting index
    :param common_lines_nb: number of common successive stripped lines before being filtered from non code lines
    :return: the number of common successive stripped lines that contain code
    """
    stripped_l1 = [
        lspecif.text
        for lspecif in ls_1.stripped_lines[stindex_1 : stindex_1 + common_lines_nb]
        if REGEX_FOR_LINES_WITH_CONTENT.match(lspecif.text)
    ]
    stripped_l2 = [
        lspecif.text
        for lspecif in ls_2.stripped_lines[stindex_2 : stindex_2 + common_lines_nb]
        if REGEX_FOR_LINES_WITH_CONTENT.match(lspecif.text)
    ]
    return sum(sline_1 == sline_2 for sline_1, sline_2 in zip(stripped_l1, stripped_l2))


</t>
<t tx="ekr.20250131013559.671">class Commonality(NamedTuple):
    cmn_lines_nb: int
    fst_lset: LineSet
    fst_file_start: LineNumber
    fst_file_end: LineNumber
    snd_lset: LineSet
    snd_file_start: LineNumber
    snd_file_end: LineNumber


</t>
<t tx="ekr.20250131013559.672">class Symilar:
    """Finds copy-pasted lines of code in a project."""

    @others
</t>
<t tx="ekr.20250131013559.673">def stripped_lines(
    lines: Iterable[str],
    ignore_comments: bool,
    ignore_docstrings: bool,
    ignore_imports: bool,
    ignore_signatures: bool,
    line_enabled_callback: Callable[[str, int], bool] | None = None,
) -&gt; list[LineSpecifs]:
    """Return tuples of line/line number/line type with leading/trailing white-space and
    any ignored code features removed.

    :param lines: a collection of lines
    :param ignore_comments: if true, any comment in the lines collection is removed from the result
    :param ignore_docstrings: if true, any line that is a docstring is removed from the result
    :param ignore_imports: if true, any line that is an import is removed from the result
    :param ignore_signatures: if true, any line that is part of a function signature is removed from the result
    :param line_enabled_callback: If called with "R0801" and a line number, a return value of False will disregard
           the line
    :return: the collection of line/line number/line type tuples
    """
    ignore_lines: set[int] = set()
    if ignore_imports or ignore_signatures:
        tree = astroid.parse("".join(lines))
        if ignore_imports:
            ignore_lines.update(
                chain.from_iterable(
                    range(node.lineno, (node.end_lineno or node.lineno) + 1)
                    for node in tree.nodes_of_class((nodes.Import, nodes.ImportFrom))
                )
            )
        if ignore_signatures:

            def _get_functions(
                functions: list[nodes.NodeNG], tree: nodes.NodeNG
            ) -&gt; list[nodes.NodeNG]:
                """Recursively get all functions including nested in the classes from
                the.

                tree.
                """
                for node in tree.body:
                    if isinstance(node, (nodes.FunctionDef, nodes.AsyncFunctionDef)):
                        functions.append(node)

                    if isinstance(
                        node,
                        (nodes.ClassDef, nodes.FunctionDef, nodes.AsyncFunctionDef),
                    ):
                        _get_functions(functions, node)

                return functions

            functions = _get_functions([], tree)
            ignore_lines.update(
                chain.from_iterable(
                    range(
                        func.lineno,
                        func.body[0].lineno if func.body else func.tolineno + 1,
                    )
                    for func in functions
                )
            )

    strippedlines = []
    docstring = None
    for lineno, line in enumerate(lines, start=1):
        if line_enabled_callback is not None and not line_enabled_callback(
            "R0801", lineno
        ):
            continue
        line = line.strip()
        if ignore_docstrings:
            if not docstring:
                if line.startswith(('"""', "'''")):
                    docstring = line[:3]
                    line = line[3:]
                elif line.startswith(('r"""', "r'''")):
                    docstring = line[1:4]
                    line = line[4:]
            if docstring:
                if line.endswith(docstring):
                    docstring = None
                line = ""
        if ignore_comments:
            line = line.split("#", 1)[0].strip()
        if lineno in ignore_lines:
            line = ""
        if line:
            strippedlines.append(
                LineSpecifs(text=line, line_number=LineNumber(lineno - 1))
            )
    return strippedlines


</t>
<t tx="ekr.20250131013559.674">@functools.total_ordering
class LineSet:
    """Holds and indexes all the lines of a single source file.

    Allows for correspondence between real lines of the source file and stripped ones, which
    are the real ones from which undesired patterns have been removed.
    """

    @others
</t>
<t tx="ekr.20250131013559.675">MSGS: dict[str, MessageDefinitionTuple] = {
    "R0801": (
        "Similar lines in %s files\n%s",
        "duplicate-code",
        "Indicates that a set of similar lines has been detected "
        "among multiple file. This usually means that the code should "
        "be refactored to avoid this duplication.",
    )
}


def report_similarities(
    sect: Section,
    stats: LinterStats,
    old_stats: LinterStats | None,
) -&gt; None:
    """Make a layout with some stats about duplication."""
    lines = ["", "now", "previous", "difference"]
    lines += table_lines_from_stats(stats, old_stats, "duplicated_lines")
    sect.append(Table(children=lines, cols=4, rheaders=1, cheaders=1))


</t>
<t tx="ekr.20250131013559.676"># wrapper to get a pylint checker from the similar class
class SimilaritiesChecker(BaseRawFileChecker, Symilar):
    """Checks for similarities and duplicated code.

    This computation may be memory / CPU intensive, so you
    should disable it if you experience some problems.
    """

    @others
</t>
<t tx="ekr.20250131013559.677">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(SimilaritiesChecker(linter))


</t>
<t tx="ekr.20250131013559.678">def Run(argv: Sequence[str] | None = None) -&gt; NoReturn:
    """Standalone command line access point."""
    parser = argparse.ArgumentParser(
        prog="symilar", description="Finds copy pasted blocks in a set of files."
    )
    parser.add_argument("files", nargs="+")
    parser.add_argument(
        "-d",
        "--duplicates",
        type=int,
        default=DEFAULT_MIN_SIMILARITY_LINE,
        help=SimilaritiesChecker.MIN_SIMILARITY_HELP,
    )
    parser.add_argument(
        "-i",
        "--ignore-comments",
        action="store_true",
        help=SimilaritiesChecker.IGNORE_COMMENTS_HELP,
    )
    parser.add_argument(
        "--ignore-docstrings",
        action="store_true",
        help=SimilaritiesChecker.IGNORE_DOCSTRINGS_HELP,
    )
    parser.add_argument(
        "--ignore-imports",
        action="store_true",
        help=SimilaritiesChecker.IGNORE_IMPORTS_HELP,
    )
    parser.add_argument(
        "--ignore-signatures",
        action="store_true",
        help=SimilaritiesChecker.IGNORE_SIGNATURES_HELP,
    )
    parsed_args = parser.parse_args(args=argv)
    similar_runner = Symilar(
        min_lines=parsed_args.duplicates,
        ignore_comments=parsed_args.ignore_comments,
        ignore_docstrings=parsed_args.ignore_docstrings,
        ignore_imports=parsed_args.ignore_imports,
        ignore_signatures=parsed_args.ignore_signatures,
    )
    for filename in parsed_args.files:
        with open(filename, encoding="utf-8") as stream:
            similar_runner.append_stream(filename, stream)
    similar_runner.run()
    # the sys exit must be kept because of the unit tests that rely on it
    sys.exit(0)


</t>
<t tx="ekr.20250131013559.679">__slots__ = ("effective_cmn_lines_nb", "first_file", "second_file")

def __init__(
    self,
    first_file: SuccessiveLinesLimits,
    second_file: SuccessiveLinesLimits,
    effective_cmn_lines_nb: int,
) -&gt; None:
    self.first_file = first_file
    self.second_file = second_file
    self.effective_cmn_lines_nb = effective_cmn_lines_nb


</t>
<t tx="ekr.20250131013559.680">__slots__ = ("_fileid", "_hash", "_index")

def __init__(self, fileid: str, num_line: int, *lines: Iterable[str]) -&gt; None:
    self._fileid: str = fileid
    """The name of the file from which the LinesChunk object is generated."""

    self._index: Index = Index(num_line)
    """The index in the stripped lines that is the starting of consecutive
    lines.
    """

    self._hash: int = sum(hash(lin) for lin in lines)
    """The hash of some consecutive lines."""

</t>
<t tx="ekr.20250131013559.681">def __eq__(self, o: object) -&gt; bool:
    if not isinstance(o, LinesChunk):
        return NotImplemented
    return self._hash == o._hash

</t>
<t tx="ekr.20250131013559.682">def __hash__(self) -&gt; int:
    return self._hash

</t>
<t tx="ekr.20250131013559.683">def __repr__(self) -&gt; str:
    return (
        f"&lt;LinesChunk object for file {self._fileid} ({self._index}, {self._hash})&gt;"
    )

</t>
<t tx="ekr.20250131013559.684">def __str__(self) -&gt; str:
    return (
        f"LinesChunk object for file {self._fileid}, starting at line {self._index} \n"
        f"Hash is {self._hash}"
    )


</t>
<t tx="ekr.20250131013559.685">__slots__ = ("_end", "_start")

def __init__(self, start: LineNumber, end: LineNumber) -&gt; None:
    self._start: LineNumber = start
    self._end: LineNumber = end

</t>
<t tx="ekr.20250131013559.686">@property
def start(self) -&gt; LineNumber:
    return self._start

</t>
<t tx="ekr.20250131013559.687">@property
def end(self) -&gt; LineNumber:
    return self._end

</t>
<t tx="ekr.20250131013559.688">@end.setter
def end(self, value: LineNumber) -&gt; None:
    self._end = value

</t>
<t tx="ekr.20250131013559.689">def __repr__(self) -&gt; str:
    return f"&lt;SuccessiveLinesLimits &lt;{self._start};{self._end}&gt;&gt;"


</t>
<t tx="ekr.20250131013559.690">fst_lineset_index: Index
snd_lineset_index: Index

def __repr__(self) -&gt; str:
    return (
        f"&lt;LineSetStartCouple &lt;{self.fst_lineset_index};{self.snd_lineset_index}&gt;&gt;"
    )

</t>
<t tx="ekr.20250131013559.691">def __eq__(self, other: object) -&gt; bool:
    if not isinstance(other, LineSetStartCouple):
        return NotImplemented
    return (
        self.fst_lineset_index == other.fst_lineset_index
        and self.snd_lineset_index == other.snd_lineset_index
    )

</t>
<t tx="ekr.20250131013559.692">def __hash__(self) -&gt; int:
    return hash(self.fst_lineset_index) + hash(self.snd_lineset_index)

</t>
<t tx="ekr.20250131013559.693">def increment(self, value: Index) -&gt; LineSetStartCouple:
    return LineSetStartCouple(
        Index(self.fst_lineset_index + value),
        Index(self.snd_lineset_index + value),
    )


</t>
<t tx="ekr.20250131013559.694">def __init__(
    self,
    min_lines: int = DEFAULT_MIN_SIMILARITY_LINE,
    ignore_comments: bool = False,
    ignore_docstrings: bool = False,
    ignore_imports: bool = False,
    ignore_signatures: bool = False,
) -&gt; None:
    # If we run in pylint mode we link the namespace objects
    if isinstance(self, BaseChecker):
        self.namespace = self.linter.config
    else:
        self.namespace = argparse.Namespace()

    self.namespace.min_similarity_lines = min_lines
    self.namespace.ignore_comments = ignore_comments
    self.namespace.ignore_docstrings = ignore_docstrings
    self.namespace.ignore_imports = ignore_imports
    self.namespace.ignore_signatures = ignore_signatures
    self.linesets: list[LineSet] = []

</t>
<t tx="ekr.20250131013559.695">def append_stream(
    self, streamid: str, stream: STREAM_TYPES, encoding: str | None = None
) -&gt; None:
    """Append a file to search for similarities."""
    if isinstance(stream, BufferedIOBase):
        if encoding is None:
            raise ValueError
        readlines = decoding_stream(stream, encoding).readlines
    else:
        # hint parameter is incorrectly typed as non-optional
        readlines = stream.readlines  # type: ignore[assignment]

    try:
        lines = readlines()
    except UnicodeDecodeError:
        lines = []

    self.linesets.append(
        LineSet(
            streamid,
            lines,
            self.namespace.ignore_comments,
            self.namespace.ignore_docstrings,
            self.namespace.ignore_imports,
            self.namespace.ignore_signatures,
            line_enabled_callback=(
                self.linter._is_one_message_enabled
                if hasattr(self, "linter")
                else None
            ),
        )
    )

</t>
<t tx="ekr.20250131013559.696">def run(self) -&gt; None:
    """Start looking for similarities and display results on stdout."""
    if self.namespace.min_similarity_lines == 0:
        return
    self._display_sims(self._compute_sims())

</t>
<t tx="ekr.20250131013559.697">def _compute_sims(self) -&gt; list[tuple[int, set[LinesChunkLimits_T]]]:
    """Compute similarities in appended files."""
    no_duplicates: dict[int, list[set[LinesChunkLimits_T]]] = defaultdict(list)

    for commonality in self._iter_sims():
        num = commonality.cmn_lines_nb
        lineset1 = commonality.fst_lset
        start_line_1 = commonality.fst_file_start
        end_line_1 = commonality.fst_file_end
        lineset2 = commonality.snd_lset
        start_line_2 = commonality.snd_file_start
        end_line_2 = commonality.snd_file_end

        duplicate = no_duplicates[num]
        couples: set[LinesChunkLimits_T]
        for couples in duplicate:
            if (lineset1, start_line_1, end_line_1) in couples or (
                lineset2,
                start_line_2,
                end_line_2,
            ) in couples:
                break
        else:
            duplicate.append(
                {
                    (lineset1, start_line_1, end_line_1),
                    (lineset2, start_line_2, end_line_2),
                }
            )
    sims: list[tuple[int, set[LinesChunkLimits_T]]] = []
    ensembles: list[set[LinesChunkLimits_T]]
    for num, ensembles in no_duplicates.items():
        cpls: set[LinesChunkLimits_T]
        for cpls in ensembles:
            sims.append((num, cpls))
    sims.sort()
    sims.reverse()
    return sims

</t>
<t tx="ekr.20250131013559.698">def _display_sims(
    self, similarities: list[tuple[int, set[LinesChunkLimits_T]]]
) -&gt; None:
    """Display computed similarities on stdout."""
    report = self._get_similarity_report(similarities)
    print(report)

</t>
<t tx="ekr.20250131013559.699">def _get_similarity_report(
    self, similarities: list[tuple[int, set[LinesChunkLimits_T]]]
) -&gt; str:
    """Create a report from similarities."""
    report: str = ""
    duplicated_line_number: int = 0
    for number, couples in similarities:
        report += f"\n{number} similar lines in {len(couples)} files\n"
        couples_l = sorted(couples)
        line_set = start_line = end_line = None
        for line_set, start_line, end_line in couples_l:
            report += f"=={line_set.name}:[{start_line}:{end_line}]\n"
        if line_set:
            for line in line_set._real_lines[start_line:end_line]:
                report += f"   {line.rstrip()}\n" if line.rstrip() else "\n"
        duplicated_line_number += number * (len(couples_l) - 1)
    total_line_number: int = sum(len(lineset) for lineset in self.linesets)
    report += (
        f"TOTAL lines={total_line_number} "
        f"duplicates={duplicated_line_number} "
        f"percent={duplicated_line_number * 100.0 / total_line_number:.2f}\n"
    )
    return report

</t>
<t tx="ekr.20250131013559.700"># pylint: disable = too-many-locals
def _find_common(
    self, lineset1: LineSet, lineset2: LineSet
) -&gt; Generator[Commonality]:
    """Find similarities in the two given linesets.

    This the core of the algorithm. The idea is to compute the hashes of a
    minimal number of successive lines of each lineset and then compare the
    hashes. Every match of such comparison is stored in a dict that links the
    couple of starting indices in both linesets to the couple of corresponding
    starting and ending lines in both files.

    Last regroups all successive couples in a bigger one. It allows to take into
    account common chunk of lines that have more than the minimal number of
    successive lines required.
    """
    hash_to_index_1: HashToIndex_T
    hash_to_index_2: HashToIndex_T
    index_to_lines_1: IndexToLines_T
    index_to_lines_2: IndexToLines_T
    hash_to_index_1, index_to_lines_1 = hash_lineset(
        lineset1, self.namespace.min_similarity_lines
    )
    hash_to_index_2, index_to_lines_2 = hash_lineset(
        lineset2, self.namespace.min_similarity_lines
    )

    hash_1: frozenset[LinesChunk] = frozenset(hash_to_index_1.keys())
    hash_2: frozenset[LinesChunk] = frozenset(hash_to_index_2.keys())

    common_hashes: Iterable[LinesChunk] = sorted(
        hash_1 &amp; hash_2, key=lambda m: hash_to_index_1[m][0]
    )

    # all_couples is a dict that links the couple of indices in both linesets that mark the beginning of
    # successive common lines, to the corresponding starting and ending number lines in both files
    all_couples: CplIndexToCplLines_T = {}

    for c_hash in sorted(common_hashes, key=operator.attrgetter("_index")):
        for indices_in_linesets in itertools.product(
            hash_to_index_1[c_hash], hash_to_index_2[c_hash]
        ):
            index_1 = indices_in_linesets[0]
            index_2 = indices_in_linesets[1]
            all_couples[LineSetStartCouple(index_1, index_2)] = (
                CplSuccessiveLinesLimits(
                    copy.copy(index_to_lines_1[index_1]),
                    copy.copy(index_to_lines_2[index_2]),
                    effective_cmn_lines_nb=self.namespace.min_similarity_lines,
                )
            )

    remove_successive(all_couples)

    for cml_stripped_l, cmn_l in all_couples.items():
        start_index_1 = cml_stripped_l.fst_lineset_index
        start_index_2 = cml_stripped_l.snd_lineset_index
        nb_common_lines = cmn_l.effective_cmn_lines_nb

        com = Commonality(
            cmn_lines_nb=nb_common_lines,
            fst_lset=lineset1,
            fst_file_start=cmn_l.first_file.start,
            fst_file_end=cmn_l.first_file.end,
            snd_lset=lineset2,
            snd_file_start=cmn_l.second_file.start,
            snd_file_end=cmn_l.second_file.end,
        )

        eff_cmn_nb = filter_noncode_lines(
            lineset1, start_index_1, lineset2, start_index_2, nb_common_lines
        )

        if eff_cmn_nb &gt; self.namespace.min_similarity_lines:
            yield com

</t>
<t tx="ekr.20250131013559.701">def _iter_sims(self) -&gt; Generator[Commonality]:
    """Iterate on similarities among all files, by making a Cartesian
    product.
    """
    for idx, lineset in enumerate(self.linesets[:-1]):
        for lineset2 in self.linesets[idx + 1 :]:
            yield from self._find_common(lineset, lineset2)

</t>
<t tx="ekr.20250131013559.702">def get_map_data(self) -&gt; list[LineSet]:
    """Returns the data we can use for a map/reduce process.

    In this case we are returning this instance's Linesets, that is all file
    information that will later be used for vectorisation.
    """
    return self.linesets

</t>
<t tx="ekr.20250131013559.703">def combine_mapreduce_data(self, linesets_collection: list[list[LineSet]]) -&gt; None:
    """Reduces and recombines data into a format that we can report on.

    The partner function of get_map_data()
    """
    self.linesets = [line for lineset in linesets_collection for line in lineset]


</t>
<t tx="ekr.20250131013559.704">def __init__(
    self,
    name: str,
    lines: list[str],
    ignore_comments: bool = False,
    ignore_docstrings: bool = False,
    ignore_imports: bool = False,
    ignore_signatures: bool = False,
    line_enabled_callback: Callable[[str, int], bool] | None = None,
) -&gt; None:
    self.name = name
    self._real_lines = lines
    self._stripped_lines = stripped_lines(
        lines,
        ignore_comments,
        ignore_docstrings,
        ignore_imports,
        ignore_signatures,
        line_enabled_callback=line_enabled_callback,
    )

</t>
<t tx="ekr.20250131013559.705">def __str__(self) -&gt; str:
    return f"&lt;Lineset for {self.name}&gt;"

</t>
<t tx="ekr.20250131013559.706">def __len__(self) -&gt; int:
    return len(self._real_lines)

</t>
<t tx="ekr.20250131013559.707">def __getitem__(self, index: int) -&gt; LineSpecifs:
    return self._stripped_lines[index]

</t>
<t tx="ekr.20250131013559.708">def __lt__(self, other: LineSet) -&gt; bool:
    return self.name &lt; other.name

</t>
<t tx="ekr.20250131013559.709">def __hash__(self) -&gt; int:
    return id(self)

</t>
<t tx="ekr.20250131013559.710">def __eq__(self, other: object) -&gt; bool:
    if not isinstance(other, LineSet):
        return False
    return self.__dict__ == other.__dict__

</t>
<t tx="ekr.20250131013559.711">@property
def stripped_lines(self) -&gt; list[LineSpecifs]:
    return self._stripped_lines

</t>
<t tx="ekr.20250131013559.712">@property
def real_lines(self) -&gt; list[str]:
    return self._real_lines


</t>
<t tx="ekr.20250131013559.713">name = "similarities"
msgs = MSGS
MIN_SIMILARITY_HELP = "Minimum lines number of a similarity."
IGNORE_COMMENTS_HELP = "Comments are removed from the similarity computation"
IGNORE_DOCSTRINGS_HELP = "Docstrings are removed from the similarity computation"
IGNORE_IMPORTS_HELP = "Imports are removed from the similarity computation"
IGNORE_SIGNATURES_HELP = "Signatures are removed from the similarity computation"
# for available dict keys/values see the option parser 'add_option' method
options: Options = (
    (
        "min-similarity-lines",
        {
            "default": DEFAULT_MIN_SIMILARITY_LINE,
            "type": "int",
            "metavar": "&lt;int&gt;",
            "help": MIN_SIMILARITY_HELP,
        },
    ),
    (
        "ignore-comments",
        {
            "default": True,
            "type": "yn",
            "metavar": "&lt;y or n&gt;",
            "help": IGNORE_COMMENTS_HELP,
        },
    ),
    (
        "ignore-docstrings",
        {
            "default": True,
            "type": "yn",
            "metavar": "&lt;y or n&gt;",
            "help": IGNORE_DOCSTRINGS_HELP,
        },
    ),
    (
        "ignore-imports",
        {
            "default": True,
            "type": "yn",
            "metavar": "&lt;y or n&gt;",
            "help": IGNORE_IMPORTS_HELP,
        },
    ),
    (
        "ignore-signatures",
        {
            "default": True,
            "type": "yn",
            "metavar": "&lt;y or n&gt;",
            "help": IGNORE_SIGNATURES_HELP,
        },
    ),
)
reports = (("RP0801", "Duplication", report_similarities),)

def __init__(self, linter: PyLinter) -&gt; None:
    BaseRawFileChecker.__init__(self, linter)
    Symilar.__init__(
        self,
        min_lines=self.linter.config.min_similarity_lines,
        ignore_comments=self.linter.config.ignore_comments,
        ignore_docstrings=self.linter.config.ignore_docstrings,
        ignore_imports=self.linter.config.ignore_imports,
        ignore_signatures=self.linter.config.ignore_signatures,
    )

</t>
<t tx="ekr.20250131013559.714">def open(self) -&gt; None:
    """Init the checkers: reset linesets and statistics information."""
    self.linesets = []
    self.linter.stats.reset_duplicated_lines()

</t>
<t tx="ekr.20250131013559.715">def process_module(self, node: nodes.Module) -&gt; None:
    """Process a module.

    the module's content is accessible via the stream object

    stream must implement the readlines method
    """
    if self.linter.current_name is None:
        # TODO: 4.0 Fix current_name
        warnings.warn(
            (
                "In pylint 3.0 the current_name attribute of the linter object should be a string. "
                "If unknown it should be initialized as an empty string."
            ),
            DeprecationWarning,
            stacklevel=2,
        )
    with node.stream() as stream:
        self.append_stream(self.linter.current_name, stream, node.file_encoding)

</t>
<t tx="ekr.20250131013559.716">def close(self) -&gt; None:
    """Compute and display similarities on closing (i.e. end of parsing)."""
    total = sum(len(lineset) for lineset in self.linesets)
    duplicated = 0
    stats = self.linter.stats
    for num, couples in self._compute_sims():
        msg = []
        lineset = start_line = end_line = None
        for lineset, start_line, end_line in couples:
            msg.append(f"=={lineset.name}:[{start_line}:{end_line}]")
        msg.sort()

        if lineset:
            for line in lineset.real_lines[start_line:end_line]:
                msg.append(line.rstrip())

        self.add_message("R0801", args=(len(couples), "\n".join(msg)))
        duplicated += num * (len(couples) - 1)
    stats.nb_duplicated_lines += int(duplicated)
    stats.percent_duplicated_lines += float(total and duplicated * 100.0 / total)

</t>
<t tx="ekr.20250131013559.717">def get_map_data(self) -&gt; list[LineSet]:
    """Passthru override."""
    return Symilar.get_map_data(self)

</t>
<t tx="ekr.20250131013559.718">def reduce_map_data(self, linter: PyLinter, data: list[list[LineSet]]) -&gt; None:
    """Reduces and recombines data into a format that we can report on.

    The partner function of get_map_data()

    Calls self.close() to actually calculate and report duplicate code.
    """
    Symilar.combine_mapreduce_data(self, linesets_collection=data)
    self.close()


</t>
<t tx="ekr.20250131013559.719">@path pylint/checkers
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

from typing import TYPE_CHECKING

from astroid import nodes

from pylint.checkers import BaseChecker
from pylint.checkers.utils import only_required_for_messages, safe_infer

if TYPE_CHECKING:
    from pylint.lint import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013559.720">class ThreadingChecker(BaseChecker):
    """Checks for threading module.

    - useless with lock - locking used in wrong way that has no effect (with threading.Lock():)
    """

    @others
</t>
<t tx="ekr.20250131013559.721">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(ThreadingChecker(linter))
</t>
<t tx="ekr.20250131013559.722">name = "threading"

LOCKS = frozenset(
    (
        "threading.Lock",
        "threading.RLock",
        "threading.Condition",
        "threading.Semaphore",
        "threading.BoundedSemaphore",
    )
)

msgs = {
    "W2101": (
        "'%s()' directly created in 'with' has no effect",
        "useless-with-lock",
        "Used when a new lock instance is created by using with statement "
        "which has no effect. Instead, an existing instance should be used to acquire lock.",
    ),
}

@only_required_for_messages("useless-with-lock")
def visit_with(self, node: nodes.With) -&gt; None:
    context_managers = (c for c, _ in node.items if isinstance(c, nodes.Call))
    for context_manager in context_managers:
        if isinstance(context_manager, nodes.Call):
            infered_function = safe_infer(context_manager.func)
            if infered_function is None:
                continue
            qname = infered_function.qname()
            if qname in self.LOCKS:
                self.add_message("useless-with-lock", node=node, args=qname)


</t>
<t tx="ekr.20250131013559.723">@path pylint/checkers
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Try to find more bugs in the code using astroid inference capabilities."""

from __future__ import annotations

import heapq
import itertools
import operator
import re
import shlex
import sys
from collections.abc import Callable, Iterable
from functools import cached_property, singledispatch
from re import Pattern
from typing import TYPE_CHECKING, Any, Literal, Union

import astroid
import astroid.exceptions
import astroid.helpers
from astroid import arguments, bases, nodes, util
from astroid.nodes import _base_nodes
from astroid.typing import InferenceResult, SuccessfulInferenceResult

from pylint.checkers import BaseChecker, utils
from pylint.checkers.utils import (
    decorated_with,
    decorated_with_property,
    has_known_bases,
    is_builtin_object,
    is_comprehension,
    is_hashable,
    is_inside_abstract_class,
    is_iterable,
    is_mapping,
    is_module_ignored,
    is_node_in_type_annotation_context,
    is_none,
    is_overload_stub,
    is_postponed_evaluation_enabled,
    is_super,
    node_ignores_exception,
    only_required_for_messages,
    safe_infer,
    supports_delitem,
    supports_getitem,
    supports_membership_test,
    supports_setitem,
)
from pylint.constants import PY310_PLUS
from pylint.interfaces import HIGH, INFERENCE
from pylint.typing import MessageDefinitionTuple

if TYPE_CHECKING:
    from pylint.lint import PyLinter

CallableObjects = Union[
    bases.BoundMethod,
    bases.UnboundMethod,
    nodes.FunctionDef,
    nodes.Lambda,
    nodes.ClassDef,
]

STR_FORMAT = {"builtins.str.format"}
ASYNCIO_COROUTINE = "asyncio.coroutines.coroutine"
BUILTIN_TUPLE = "builtins.tuple"
TYPE_ANNOTATION_NODES_TYPES = (
    nodes.AnnAssign,
    nodes.Arguments,
    nodes.FunctionDef,
)
BUILTINS_IMPLICIT_RETURN_NONE = {
    "builtins.dict": {"clear", "update"},
    "builtins.list": {
        "append",
        "clear",
        "extend",
        "insert",
        "remove",
        "reverse",
        "sort",
    },
    "builtins.set": {
        "add",
        "clear",
        "difference_update",
        "discard",
        "intersection_update",
        "remove",
        "symmetric_difference_update",
        "update",
    },
}


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013559.724">class VERSION_COMPATIBLE_OVERLOAD:
    pass


</t>
<t tx="ekr.20250131013559.725">VERSION_COMPATIBLE_OVERLOAD_SENTINEL = VERSION_COMPATIBLE_OVERLOAD()


def _is_owner_ignored(
    owner: SuccessfulInferenceResult,
    attrname: str | None,
    ignored_classes: Iterable[str],
    ignored_modules: Iterable[str],
) -&gt; bool:
    """Check if the given owner should be ignored.

    This will verify if the owner's module is in *ignored_modules*
    or the owner's module fully qualified name is in *ignored_modules*
    or if the *ignored_modules* contains a pattern which catches
    the fully qualified name of the module.

    Also, similar checks are done for the owner itself, if its name
    matches any name from the *ignored_classes* or if its qualified
    name can be found in *ignored_classes*.
    """
    if is_module_ignored(owner.root().qname(), ignored_modules):
        return True

    # Match against ignored classes.
    ignored_classes = set(ignored_classes)
    qname = owner.qname() if hasattr(owner, "qname") else ""
    return any(ignore in (attrname, qname) for ignore in ignored_classes)


</t>
<t tx="ekr.20250131013559.726">@singledispatch
def _node_names(node: SuccessfulInferenceResult) -&gt; Iterable[str]:
    if not hasattr(node, "locals"):
        return []
    return node.locals.keys()  # type: ignore[no-any-return]


</t>
<t tx="ekr.20250131013559.727">@_node_names.register(nodes.ClassDef)
@_node_names.register(astroid.Instance)
def _(node: nodes.ClassDef | bases.Instance) -&gt; Iterable[str]:
    values = itertools.chain(node.instance_attrs.keys(), node.locals.keys())

    try:
        mro = node.mro()[1:]
    except(NotImplementedError, TypeError, astroid.MroError):
        mro = node.ancestors()

    other_values = [value for cls in mro for value in _node_names(cls)]
    return itertools.chain(values, other_values)


</t>
<t tx="ekr.20250131013559.728">def _string_distance(seq1: str, seq2: str) -&gt; int:
    seq2_length = len(seq2)

    row = [* list(range(1, seq2_length + 1)), 0]
    for seq1_index, seq1_char in enumerate(seq1):
        last_row = row
        row = [0] * seq2_length + [seq1_index + 1]

        for seq2_index, seq2_char in enumerate(seq2):
            row[seq2_index] = min(
                last_row[seq2_index] + 1,
                row[seq2_index - 1] + 1,
                last_row[seq2_index - 1] + (seq1_char != seq2_char),
            )

    return row[seq2_length - 1]


</t>
<t tx="ekr.20250131013559.729">def _similar_names(
    owner: SuccessfulInferenceResult,
    attrname: str | None,
    distance_threshold: int,
    max_choices: int,
) -&gt; list[str]:
    """Given an owner and a name, try to find similar names.

    The similar names are searched given a distance metric and only
    a given number of choices will be returned.
    """
    possible_names: list[tuple[str, int]] = []
    names = _node_names(owner)

    for name in names:
        if name == attrname:
            continue

        distance = _string_distance(attrname or "", name)
        if distance &lt;= distance_threshold:
            possible_names.append((name, distance))

    # Now get back the values with a minimum, up to the given
    # limit or choices.
    picked = [
        name
        for (name, _) in heapq.nsmallest(
            max_choices, possible_names, key=operator.itemgetter(1)
        )
    ]
    return sorted(picked)


</t>
<t tx="ekr.20250131013559.730">def _missing_member_hint(
    owner: SuccessfulInferenceResult,
    attrname: str | None,
    distance_threshold: int,
    max_choices: int,
) -&gt; str:
    names = _similar_names(owner, attrname, distance_threshold, max_choices)
    if not names:
        # No similar name.
        return ""

    names = [repr(name) for name in names]
    if len(names) == 1:
        names_hint = ", ".join(names)
    else:
        names_hint = f"one of {', '.join(names[:-1])} or {names[-1]}"

    return f"; maybe {names_hint}?"


</t>
<t tx="ekr.20250131013559.731">MSGS: dict[str, MessageDefinitionTuple] = {
    "E1101": (
        "%s %r has no %r member%s",
        "no-member",
        "Used when a variable is accessed for a nonexistent member.",
        {"old_names": [("E1103", "maybe-no-member")]},
    ),
    "I1101": (
        "%s %r has no %r member%s, but source is unavailable. Consider "
        "adding this module to extension-pkg-allow-list if you want "
        "to perform analysis based on run-time introspection of living objects.",
        "c-extension-no-member",
        "Used when a variable is accessed for non-existent member of C "
        "extension. Due to unavailability of source static analysis is impossible, "
        "but it may be performed by introspecting living objects in run-time.",
    ),
    "E1102": (
        "%s is not callable",
        "not-callable",
        "Used when an object being called has been inferred to a non "
        "callable object.",
    ),
    "E1111": (
        "Assigning result of a function call, where the function has no return",
        "assignment-from-no-return",
        "Used when an assignment is done on a function call but the "
        "inferred function doesn't return anything.",
    ),
    "E1120": (
        "No value for argument %s in %s call",
        "no-value-for-parameter",
        "Used when a function call passes too few arguments.",
    ),
    "E1121": (
        "Too many positional arguments for %s call",
        "too-many-function-args",
        "Used when a function call passes too many positional arguments.",
    ),
    "E1123": (
        "Unexpected keyword argument %r in %s call",
        "unexpected-keyword-arg",
        "Used when a function call passes a keyword argument that "
        "doesn't correspond to one of the function's parameter names.",
    ),
    "E1124": (
        "Argument %r passed by position and keyword in %s call",
        "redundant-keyword-arg",
        "Used when a function call would result in assigning multiple "
        "values to a function parameter, one value from a positional "
        "argument and one from a keyword argument.",
    ),
    "E1125": (
        "Missing mandatory keyword argument %r in %s call",
        "missing-kwoa",
        (
            "Used when a function call does not pass a mandatory"
            " keyword-only argument."
        ),
    ),
    "E1126": (
        "Sequence index is not an int, slice, or instance with __index__",
        "invalid-sequence-index",
        "Used when a sequence type is indexed with an invalid type. "
        "Valid types are ints, slices, and objects with an __index__ "
        "method.",
    ),
    "E1127": (
        "Slice index is not an int, None, or instance with __index__",
        "invalid-slice-index",
        "Used when a slice index is not an integer, None, or an object "
        "with an __index__ method.",
    ),
    "E1128": (
        "Assigning result of a function call, where the function returns None",
        "assignment-from-none",
        "Used when an assignment is done on a function call but the "
        "inferred function returns nothing but None.",
        {"old_names": [("W1111", "old-assignment-from-none")]},
    ),
    "E1129": (
        "Context manager '%s' doesn't implement __enter__ and __exit__.",
        "not-context-manager",
        "Used when an instance in a with statement doesn't implement "
        "the context manager protocol(__enter__/__exit__).",
    ),
    "E1130": (
        "%s",
        "invalid-unary-operand-type",
        "Emitted when a unary operand is used on an object which does not "
        "support this type of operation.",
    ),
    "E1131": (
        "%s",
        "unsupported-binary-operation",
        "Emitted when a binary arithmetic operation between two "
        "operands is not supported.",
    ),
    "E1132": (
        "Got multiple values for keyword argument %r in function call",
        "repeated-keyword",
        "Emitted when a function call got multiple values for a keyword.",
    ),
    "E1135": (
        "Value '%s' doesn't support membership test",
        "unsupported-membership-test",
        "Emitted when an instance in membership test expression doesn't "
        "implement membership protocol (__contains__/__iter__/__getitem__).",
    ),
    "E1136": (
        "Value '%s' is unsubscriptable",
        "unsubscriptable-object",
        "Emitted when a subscripted value doesn't support subscription "
        "(i.e. doesn't define __getitem__ method or __class_getitem__ for a class).",
    ),
    "E1137": (
        "%r does not support item assignment",
        "unsupported-assignment-operation",
        "Emitted when an object does not support item assignment "
        "(i.e. doesn't define __setitem__ method).",
    ),
    "E1138": (
        "%r does not support item deletion",
        "unsupported-delete-operation",
        "Emitted when an object does not support item deletion "
        "(i.e. doesn't define __delitem__ method).",
    ),
    "E1139": (
        "Invalid metaclass %r used",
        "invalid-metaclass",
        "Emitted whenever we can detect that a class is using, "
        "as a metaclass, something which might be invalid for using as "
        "a metaclass.",
    ),
    "E1141": (
        "Unpacking a dictionary in iteration without calling .items()",
        "dict-iter-missing-items",
        "Emitted when trying to iterate through a dict without calling .items()",
    ),
    "E1142": (
        "'await' should be used within an async function",
        "await-outside-async",
        "Emitted when await is used outside an async function.",
    ),
    "E1143": (
        "'%s' is unhashable and can't be used as a %s in a %s",
        "unhashable-member",
        "Emitted when a dict key or set member is not hashable "
        "(i.e. doesn't define __hash__ method).",
        {"old_names": [("E1140", "unhashable-dict-key")]},
    ),
    "E1144": (
        "Slice step cannot be 0",
        "invalid-slice-step",
        "Used when a slice step is 0 and the object doesn't implement "
        "a custom __getitem__ method.",
    ),
    "W1113": (
        "Keyword argument before variable positional arguments list "
        "in the definition of %s function",
        "keyword-arg-before-vararg",
        "When defining a keyword argument before variable positional arguments, one can "
        "end up in having multiple values passed for the aforementioned parameter in "
        "case the method is called with keyword arguments.",
    ),
    "W1114": (
        "Positional arguments appear to be out of order",
        "arguments-out-of-order",
        "Emitted  when the caller's argument names fully match the parameter "
        "names in the function signature but do not have the same order.",
    ),
    "W1115": (
        "Non-string value assigned to __name__",
        "non-str-assignment-to-dunder-name",
        "Emitted when a non-string value is assigned to __name__",
    ),
    "W1116": (
        "Second argument of isinstance is not a type",
        "isinstance-second-argument-not-valid-type",
        "Emitted when the second argument of an isinstance call is not a type.",
    ),
    "W1117": (
        "%r will be included in %r since a positional-only parameter with this name already exists",
        "kwarg-superseded-by-positional-arg",
        "Emitted when a function is called with a keyword argument that has the "
        "same name as a positional-only parameter and the function contains a "
        "keyword variadic parameter dict.",
    ),
}

# builtin sequence types in Python 2 and 3.
SEQUENCE_TYPES = {
    "str",
    "unicode",
    "list",
    "tuple",
    "bytearray",
    "xrange",
    "range",
    "bytes",
    "memoryview",
}


def _emit_no_member(
    node: nodes.Attribute | nodes.AssignAttr | nodes.DelAttr,
    owner: InferenceResult,
    owner_name: str | None,
    mixin_class_rgx: Pattern[str],
    ignored_mixins: bool = True,
    ignored_none: bool = True,
) -&gt; bool:
    """Try to see if no-member should be emitted for the given owner.

    The following cases are ignored:

        * the owner is a function and it has decorators.
        * the owner is an instance and it has __getattr__, __getattribute__ implemented
        * the module is explicitly ignored from no-member checks
        * the owner is a class and the name can be found in its metaclass.
        * The access node is protected by an except handler, which handles
          AttributeError, Exception or bare except.
        * The node is guarded behind and `IF` or `IFExp` node
    """
    # pylint: disable = too-many-return-statements, too-many-branches
    if node_ignores_exception(node, AttributeError):
        return False
    if ignored_none and isinstance(owner, nodes.Const) and owner.value is None:
        return False
    if is_super(owner) or getattr(owner, "type", None) == "metaclass":
        return False
    if owner_name and ignored_mixins and mixin_class_rgx.match(owner_name):
        return False
    if isinstance(owner, nodes.FunctionDef) and (
        owner.decorators or owner.is_abstract()
    ):
        return False
    if isinstance(owner, (astroid.Instance, nodes.ClassDef)):
        # Issue #2565: Don't ignore enums, as they have a `__getattr__` but it's not
        # invoked at this point.
        try:
            metaclass = owner.metaclass()
        except astroid.MroError:
            pass
        else:
            # Renamed in Python 3.10 to `EnumType`
            if metaclass and metaclass.qname() in {"enum.EnumMeta", "enum.EnumType"}:
                return not _enum_has_attribute(owner, node)
        if owner.has_dynamic_getattr():
            return False
        if not has_known_bases(owner):
            return False

        # Exclude typed annotations, since these might actually exist
        # at some point during the runtime of the program.
        if utils.is_attribute_typed_annotation(owner, node.attrname):
            return False
    if isinstance(owner, astroid.objects.Super):
        # Verify if we are dealing with an invalid Super object.
        # If it is invalid, then there's no point in checking that
        # it has the required attribute. Also, don't fail if the
        # MRO is invalid.
        try:
            owner.super_mro()
        except(astroid.MroError, astroid.SuperError):
            return False
        if not all(has_known_bases(base) for base in owner.type.mro()):
            return False
    if isinstance(owner, nodes.Module):
        try:
            owner.getattr("__getattr__")
            return False
        except astroid.NotFoundError:
            pass
    if owner_name and node.attrname.startswith("_" + owner_name):
        # Test if an attribute has been mangled ('private' attribute)
        unmangled_name = node.attrname.split("_" + owner_name)[-1]
        try:
            if owner.getattr(unmangled_name, context=None) is not None:
                return False
        except astroid.NotFoundError:
            return True

    # Don't emit no-member if guarded behind `IF` or `IFExp`
    #   * Walk up recursively until if statement is found.
    #   * Check if condition can be inferred as `Const`,
    #       would evaluate as `False`,
    #       and whether the node is part of the `body`.
    #   * Continue checking until scope of node is reached.
    scope: nodes.NodeNG = node.scope()
    node_origin: nodes.NodeNG = node
    parent: nodes.NodeNG = node.parent
    while parent != scope:
        if isinstance(parent, (nodes.If, nodes.IfExp)):
            inferred = safe_infer(parent.test)
            if (  # pylint: disable=too-many-boolean-expressions
                isinstance(inferred, nodes.Const)
                and inferred.bool_value() is False
                and (
                    (isinstance(parent, nodes.If) and node_origin in parent.body)
                    or (isinstance(parent, nodes.IfExp) and node_origin == parent.body)
                )
            ):
                return False
        node_origin, parent = parent, parent.parent

    return True


</t>
<t tx="ekr.20250131013559.732">def _get_all_attribute_assignments(
    node: nodes.FunctionDef, name: str | None = None
) -&gt; set[str]:
    attributes: set[str] = set()
    for child in node.nodes_of_class((nodes.Assign, nodes.AnnAssign)):
        targets = []
        if isinstance(child, nodes.Assign):
            targets = child.targets
        elif isinstance(child, nodes.AnnAssign):
            targets = [child.target]
        for assign_target in targets:
            if isinstance(assign_target, nodes.Tuple):
                targets.extend(assign_target.elts)
                continue
            if (
                isinstance(assign_target, nodes.AssignAttr)
                and isinstance(assign_target.expr, nodes.Name)
                and (name is None or assign_target.expr.name == name)
            ):
                attributes.add(assign_target.attrname)
    return attributes


</t>
<t tx="ekr.20250131013559.733">def _enum_has_attribute(
    owner: astroid.Instance | nodes.ClassDef, node: nodes.Attribute
) -&gt; bool:
    if isinstance(owner, astroid.Instance):
        enum_def = next(
            (b.parent for b in owner.bases if isinstance(b.parent, nodes.ClassDef)),
            None,
        )

        if enum_def is None:
            # We don't inherit from anything, so try to find the parent
            # class definition and roll with that
            enum_def = node
            while enum_def is not None and not isinstance(enum_def, nodes.ClassDef):
                enum_def = enum_def.parent

        # If this blows, something is clearly wrong
        assert enum_def is not None, "enum_def unexpectedly None"
    else:
        enum_def = owner

    # Find __new__ and __init__
    dunder_new = next((m for m in enum_def.methods() if m.name == "__new__"), None)
    dunder_init = next((m for m in enum_def.methods() if m.name == "__init__"), None)

    enum_attributes: set[str] = set()

    # Find attributes defined in __new__
    if dunder_new:
        # Get the object returned in __new__
        returned_obj_name = next(
            (c.value for c in dunder_new.get_children() if isinstance(c, nodes.Return)),
            None,
        )
        if isinstance(returned_obj_name, nodes.Name):
            # Find all attribute assignments to the returned object
            enum_attributes |= _get_all_attribute_assignments(
                dunder_new, returned_obj_name.name
            )

    # Find attributes defined in __init__
    if dunder_init and dunder_init.body and dunder_init.args:
        # Grab the name referring to `self` from the function def
        enum_attributes |= _get_all_attribute_assignments(
            dunder_init, dunder_init.args.arguments[0].name
        )

    return node.attrname in enum_attributes


</t>
<t tx="ekr.20250131013559.734">def _determine_callable(
    callable_obj: nodes.NodeNG,
) -&gt; tuple[CallableObjects, int, str]:
    # TODO: The typing of the second return variable is actually Literal[0,1]
    # We need typing on astroid.NodeNG.implicit_parameters for this
    # TODO: The typing of the third return variable can be narrowed to a Literal
    # We need typing on astroid.NodeNG.type for this

    # Ordering is important, since BoundMethod is a subclass of UnboundMethod,
    # and Function inherits Lambda.
    parameters = 0
    if hasattr(callable_obj, "implicit_parameters"):
        parameters = callable_obj.implicit_parameters()
    if isinstance(callable_obj, bases.BoundMethod):
        # Bound methods have an extra implicit 'self' argument.
        return callable_obj, parameters, callable_obj.type
    if isinstance(callable_obj, bases.UnboundMethod):
        return callable_obj, parameters, "unbound method"
    if isinstance(callable_obj, nodes.FunctionDef):
        return callable_obj, parameters, callable_obj.type
    if isinstance(callable_obj, nodes.Lambda):
        return callable_obj, parameters, "lambda"
    if isinstance(callable_obj, nodes.ClassDef):
        # Class instantiation, lookup __new__ instead.
        # If we only find object.__new__, we can safely check __init__
        # instead. If __new__ belongs to builtins, then we look
        # again for __init__ in the locals, since we won't have
        # argument information for the builtin __new__ function.
        try:
            # Use the last definition of __new__.
            new = callable_obj.local_attr("__new__")[-1]
        except astroid.NotFoundError:
            new = None

        from_object = new and new.parent.scope().name == "object"
        from_builtins = new and new.root().name in sys.builtin_module_names

        if not new or from_object or from_builtins:
            try:
                # Use the last definition of __init__.
                callable_obj = callable_obj.local_attr("__init__")[-1]
            except astroid.NotFoundError as e:
                raise ValueError from e
        else:
            callable_obj = new

        if not isinstance(callable_obj, nodes.FunctionDef):
            raise ValueError
        # both have an extra implicit 'cls'/'self' argument.
        return callable_obj, parameters, "constructor"

    raise ValueError


</t>
<t tx="ekr.20250131013559.735">def _has_parent_of_type(
    node: nodes.Call,
    node_type: nodes.Keyword | nodes.Starred,
    statement: _base_nodes.Statement,
) -&gt; bool:
    """Check if the given node has a parent of the given type."""
    parent = node.parent
    while not isinstance(parent, node_type) and statement.parent_of(parent):
        parent = parent.parent
    return isinstance(parent, node_type)


</t>
<t tx="ekr.20250131013559.736">def _no_context_variadic_keywords(node: nodes.Call, scope: nodes.Lambda) -&gt; bool:
    statement = node.statement()
    variadics = []

    if (
        isinstance(scope, nodes.Lambda) and not isinstance(scope, nodes.FunctionDef)
    ) or isinstance(statement, nodes.With):
        variadics = list(node.keywords or []) + node.kwargs
    elif isinstance(statement, (nodes.Return, nodes.Expr, nodes.Assign)) and isinstance(
        statement.value, nodes.Call
    ):
        call = statement.value
        variadics = list(call.keywords or []) + call.kwargs

    return _no_context_variadic(node, scope.args.kwarg, nodes.Keyword, variadics)


</t>
<t tx="ekr.20250131013559.737">def _no_context_variadic_positional(node: nodes.Call, scope: nodes.Lambda) -&gt; bool:
    variadics = node.starargs + node.kwargs
    return _no_context_variadic(node, scope.args.vararg, nodes.Starred, variadics)


</t>
<t tx="ekr.20250131013559.738">def _no_context_variadic(
    node: nodes.Call,
    variadic_name: str | None,
    variadic_type: nodes.Keyword | nodes.Starred,
    variadics: list[nodes.Keyword | nodes.Starred],
) -&gt; bool:
    """Verify if the given call node has variadic nodes without context.

    This is a workaround for handling cases of nested call functions
    which don't have the specific call context at hand.
    Variadic arguments (variable positional arguments and variable
    keyword arguments) are inferred, inherently wrong, by astroid
    as a Tuple, respectively a Dict with empty elements.
    This can lead pylint to believe that a function call receives
    too few arguments.
    """
    scope = node.scope()
    is_in_lambda_scope = not isinstance(scope, nodes.FunctionDef) and isinstance(
        scope, nodes.Lambda
    )
    statement = node.statement()
    for name in statement.nodes_of_class(nodes.Name):
        if name.name != variadic_name:
            continue

        inferred = safe_infer(name)
        if isinstance(inferred, (nodes.List, nodes.Tuple)):
            length = len(inferred.elts)
        elif isinstance(inferred, nodes.Dict):
            length = len(inferred.items)
        else:
            continue

        if is_in_lambda_scope and isinstance(inferred.parent, nodes.Arguments):
            # The statement of the variadic will be the assignment itself,
            # so we need to go the lambda instead
            inferred_statement = inferred.parent.parent
        else:
            inferred_statement = inferred.statement()

        if not length and isinstance(
            inferred_statement, (nodes.Lambda, nodes.FunctionDef)
        ):
            is_in_starred_context = _has_parent_of_type(node, variadic_type, statement)
            used_as_starred_argument = any(
                variadic.value == name or variadic.value.parent_of(name)
                for variadic in variadics
            )
            if is_in_starred_context or used_as_starred_argument:
                return True
    return False


</t>
<t tx="ekr.20250131013559.739">def _is_invalid_metaclass(metaclass: nodes.ClassDef) -&gt; bool:
    try:
        mro = metaclass.mro()
    except(astroid.DuplicateBasesError, astroid.InconsistentMroError):
        return True
    return not any(is_builtin_object(cls) and cls.name == "type" for cls in mro)


</t>
<t tx="ekr.20250131013559.740">def _infer_from_metaclass_constructor(
    cls: nodes.ClassDef, func: nodes.FunctionDef
) -&gt; InferenceResult | None:
    """Try to infer what the given *func* constructor is building.

    :param astroid.FunctionDef func:
        A metaclass constructor. Metaclass definitions can be
        functions, which should accept three arguments, the name of
        the class, the bases of the class and the attributes.
        The function could return anything, but usually it should
        be a proper metaclass.
    :param astroid.ClassDef cls:
        The class for which the *func* parameter should generate
        a metaclass.
    :returns:
        The class generated by the function or None,
        if we couldn't infer it.
    :rtype: astroid.ClassDef
    """
    context = astroid.context.InferenceContext()

    class_bases = nodes.List()
    class_bases.postinit(elts=cls.bases)

    attrs = nodes.Dict(
        lineno=0, col_offset=0, parent=None, end_lineno=0, end_col_offset=0
    )
    local_names = [(name, values[-1]) for name, values in cls.locals.items()]
    attrs.postinit(local_names)

    builder_args = nodes.Tuple()
    builder_args.postinit([cls.name, class_bases, attrs])

    context.callcontext = astroid.context.CallContext(builder_args)
    try:
        inferred = next(func.infer_call_result(func, context), None)
    except astroid.InferenceError:
        return None
    return inferred or None


</t>
<t tx="ekr.20250131013559.741">def _is_c_extension(module_node: InferenceResult) -&gt; bool:
    return (
        isinstance(module_node, nodes.Module)
        and not astroid.modutils.is_stdlib_module(module_node.name)
        and not module_node.fully_defined()
    )


</t>
<t tx="ekr.20250131013559.742">def _is_invalid_isinstance_type(arg: nodes.NodeNG) -&gt; bool:
    # Return True if we are sure that arg is not a type
    if PY310_PLUS and isinstance(arg, nodes.BinOp) and arg.op == "|":
        return any(
            _is_invalid_isinstance_type(elt) and not is_none(elt)
            for elt in (arg.left, arg.right)
        )
    inferred = utils.safe_infer(arg)
    if not inferred:
        # Cannot infer it so skip it.
        return False
    if isinstance(inferred, nodes.Tuple):
        return any(_is_invalid_isinstance_type(elt) for elt in inferred.elts)
    if isinstance(inferred, nodes.ClassDef):
        return False
    if isinstance(inferred, astroid.Instance) and inferred.qname() == BUILTIN_TUPLE:
        return False
    if PY310_PLUS and isinstance(inferred, bases.UnionType):
        return any(
            _is_invalid_isinstance_type(elt) and not is_none(elt)
            for elt in (inferred.left, inferred.right)
        )
    return True


</t>
<t tx="ekr.20250131013559.743">class TypeChecker(BaseChecker):
    """Try to find bugs in the code using type inference."""

@others
</t>
<t tx="ekr.20250131013559.744">class IterableChecker(BaseChecker):
    """Checks for non-iterables used in an iterable context.

    Contexts include:
    - for-statement
    - starargs in function call
    - `yield from`-statement
    - list, dict and set comprehensions
    - generator expressions
    Also checks for non-mappings in function call kwargs.
    """

    @others
</t>
<t tx="ekr.20250131013559.745">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(TypeChecker(linter))
    linter.register_checker(IterableChecker(linter))
</t>
<t tx="ekr.20250131013559.746">    # configuration section name
    name = "typecheck"
    # messages
    msgs = MSGS
    # configuration options
    options = (
        (
            "ignore-on-opaque-inference",
            {
                "default": True,
                "type": "yn",
                "metavar": "&lt;y or n&gt;",
                "help": "This flag controls whether pylint should warn about "
                "no-member and similar checks whenever an opaque object "
                "is returned when inferring. The inference can return "
                "multiple potential results while evaluating a Python object, "
                "but some branches might not be evaluated, which results in "
                "partial inference. In that case, it might be useful to still emit "
                "no-member and other checks for the rest of the inferred objects.",
            },
        ),
        (
            "mixin-class-rgx",
            {
                "default": ".*[Mm]ixin",
                "type": "regexp",
                "metavar": "&lt;regexp&gt;",
                "help": "Regex pattern to define which classes are considered mixins.",
            },
        ),
        (
            "ignore-mixin-members",
            {
                "default": True,
                "type": "yn",
                "metavar": "&lt;y or n&gt;",
                "help": "Tells whether missing members accessed in mixin "
                "class should be ignored. A class is considered mixin if its name matches "
                "the mixin-class-rgx option.",
                "kwargs": {"new_names": ["ignore-checks-for-mixin"]},
            },
        ),
        (
            "ignored-checks-for-mixins",
            {
                "default": [
                    "no-member",
                    "not-async-context-manager",
                    "not-context-manager",
                    "attribute-defined-outside-init",
                ],
                "type": "csv",
                "metavar": "&lt;list of messages names&gt;",
                "help": "List of symbolic message names to ignore for Mixin members.",
            },
        ),
        (
            "ignore-none",
            {
                "default": True,
                "type": "yn",
                "metavar": "&lt;y or n&gt;",
                "help": "Tells whether to warn about missing members when the owner "
                "of the attribute is inferred to be None.",
            },
        ),
        # the defaults here are *stdlib* names that (almost) always
        # lead to false positives, since their idiomatic use is
        # 'too dynamic' for pylint to grok.
        (
            "ignored-classes",
            {
                "default": (
                    "optparse.Values",
                    "thread._local",
                    "_thread._local",
                    "argparse.Namespace",
                ),
                "type": "csv",
                "metavar": "&lt;members names&gt;",
                "help": "List of class names for which member attributes "
                "should not be checked (useful for classes with "
                "dynamically set attributes). This supports "
                "the use of qualified names.",
            },
        ),
        (
            "generated-members",
            {
                "default": (),
                "type": "string",
                "metavar": "&lt;members names&gt;",
                "help": "List of members which are set dynamically and \
missed by pylint inference system, and so shouldn't trigger E1101 when \
accessed. Python regular expressions are accepted.",
            },
        ),
        (
            "contextmanager-decorators",
            {
                "default": ["contextlib.contextmanager"],
                "type": "csv",
                "metavar": "&lt;decorator names&gt;",
                "help": "List of decorators that produce context managers, "
                "such as contextlib.contextmanager. Add to this list "
                "to register other decorators that produce valid "
                "context managers.",
            },
        ),
        (
            "missing-member-hint-distance",
            {
                "default": 1,
                "type": "int",
                "metavar": "&lt;member hint edit distance&gt;",
                "help": "The minimum edit distance a name should have in order "
                "to be considered a similar match for a missing member name.",
            },
        ),
        (
            "missing-member-max-choices",
            {
                "default": 1,
                "type": "int",
                "metavar": "&lt;member hint max choices&gt;",
                "help": "The total number of similar names that should be taken in "
                "consideration when showing a hint for a missing member.",
            },
        ),
        (
            "missing-member-hint",
            {
                "default": True,
                "type": "yn",
                "metavar": "&lt;missing member hint&gt;",
                "help": "Show a hint with possible names when a member name was not "
                "found. The aspect of finding the hint is based on edit distance.",
            },
        ),
        (
            "signature-mutators",
            {
                "default": [],
                "type": "csv",
                "metavar": "&lt;decorator names&gt;",
                "help": "List of decorators that change the signature of "
                "a decorated function.",
            },
        ),
    )

    def open(self) -&gt; None:
        py_version = self.linter.config.py_version
        self._py310_plus = py_version &gt;= (3, 10)
        self._mixin_class_rgx = self.linter.config.mixin_class_rgx

</t>
<t tx="ekr.20250131013559.747">    @cached_property
    def _suggestion_mode(self) -&gt; bool:
        return self.linter.config.suggestion_mode  # type: ignore[no-any-return]

</t>
<t tx="ekr.20250131013559.748">    @cached_property
    def _compiled_generated_members(self) -&gt; tuple[Pattern[str], ...]:
        # do this lazily since config not fully initialized in __init__
        # generated_members may contain regular expressions
        # (surrounded by quote `"` and followed by a comma `,`)
        # REQUEST,aq_parent,"[a-zA-Z]+_set{1,2}"' =&gt;
        # ('REQUEST', 'aq_parent', '[a-zA-Z]+_set{1,2}')
        generated_members = self.linter.config.generated_members
        if isinstance(generated_members, str):
            gen = shlex.shlex(generated_members)
            gen.whitespace += ","
            gen.wordchars += r"[]-+\.*?()|"
            generated_members = tuple(tok.strip('"') for tok in gen)
        return tuple(re.compile(exp) for exp in generated_members)

</t>
<t tx="ekr.20250131013559.749">    @only_required_for_messages("keyword-arg-before-vararg")
    def visit_functiondef(self, node: nodes.FunctionDef) -&gt; None:
        # check for keyword arg before varargs.

        if node.args.vararg and node.args.defaults:
            # When `positional-only` parameters are present then only
            # `positional-or-keyword` parameters are checked. I.e:
            # &gt;&gt;&gt; def name(pos_only_params, /, pos_or_keyword_params, *args): ...
            if node.args.posonlyargs and not node.args.args:
                return
            self.add_message("keyword-arg-before-vararg", node=node, args=(node.name))

</t>
<t tx="ekr.20250131013559.750">    visit_asyncfunctiondef = visit_functiondef

    @only_required_for_messages("invalid-metaclass")
    def visit_classdef(self, node: nodes.ClassDef) -&gt; None:
        def _metaclass_name(metaclass: InferenceResult) -&gt; str | None:
            # pylint: disable=unidiomatic-typecheck
            if isinstance(metaclass, (nodes.ClassDef, nodes.FunctionDef)):
                return metaclass.name  # type: ignore[no-any-return]
            if type(metaclass) is bases.Instance:
                # Really do mean type, not isinstance, since subclasses of bases.Instance
                # like Const or Dict should use metaclass.as_string below.
                return str(metaclass)
            return metaclass.as_string()  # type: ignore[no-any-return]

        metaclass = node.declared_metaclass()
        if not metaclass:
            return

        if isinstance(metaclass, nodes.FunctionDef):
            # Try to infer the result.
            metaclass = _infer_from_metaclass_constructor(node, metaclass)
            if not metaclass:
                # Don't do anything if we cannot infer the result.
                return

        if isinstance(metaclass, nodes.ClassDef):
            if _is_invalid_metaclass(metaclass):
                self.add_message(
                    "invalid-metaclass", node=node, args=(_metaclass_name(metaclass),)
                )
        else:
            self.add_message(
                "invalid-metaclass", node=node, args=(_metaclass_name(metaclass),)
            )

</t>
<t tx="ekr.20250131013559.751">    def visit_assignattr(self, node: nodes.AssignAttr) -&gt; None:
        if isinstance(node.assign_type(), nodes.AugAssign):
            self.visit_attribute(node)

</t>
<t tx="ekr.20250131013559.752">    def visit_delattr(self, node: nodes.DelAttr) -&gt; None:
        self.visit_attribute(node)

</t>
<t tx="ekr.20250131013559.753">    # pylint: disable = too-many-branches, too-many-statements
    @only_required_for_messages("no-member", "c-extension-no-member")
    def visit_attribute(
        self, node: nodes.Attribute | nodes.AssignAttr | nodes.DelAttr
    ) -&gt; None:
        """Check that the accessed attribute exists.

        to avoid too much false positives for now, we'll consider the code as
        correct if a single of the inferred nodes has the accessed attribute.

        function/method, super call and metaclasses are ignored
        """
        if any(
            pattern.match(name)
            for name in (node.attrname, node.as_string())
            for pattern in self._compiled_generated_members
        ):
            return

        if is_postponed_evaluation_enabled(node) and is_node_in_type_annotation_context(
            node
        ):
            return

        try:
            inferred = list(node.expr.infer())
        except astroid.InferenceError:
            return

        # list of (node, nodename) which are missing the attribute
        missingattr: set[tuple[SuccessfulInferenceResult, str | None]] = set()

        non_opaque_inference_results: list[SuccessfulInferenceResult] = [
            owner
            for owner in inferred
            if not isinstance(owner, (nodes.Unknown, util.UninferableBase))
        ]
        if (
            len(non_opaque_inference_results) != len(inferred)
            and self.linter.config.ignore_on_opaque_inference
        ):
            # There is an ambiguity in the inference. Since we can't
            # make sure that we won't emit a false positive, we just stop
            # whenever the inference returns an opaque inference object.
            return
        for owner in non_opaque_inference_results:
            name = getattr(owner, "name", None)
            if _is_owner_ignored(
                owner,
                name,
                self.linter.config.ignored_classes,
                self.linter.config.ignored_modules,
            ):
                continue

            qualname = f"{owner.pytype()}.{node.attrname}"
            if any(
                pattern.match(qualname) for pattern in self._compiled_generated_members
            ):
                return

            try:
                attr_nodes = owner.getattr(node.attrname)
            except AttributeError:
                continue
            except astroid.DuplicateBasesError:
                continue
            except astroid.NotFoundError:
                # Avoid false positive in case a decorator supplies member.
                if (
                    isinstance(owner, (astroid.FunctionDef, astroid.BoundMethod))
                    and owner.decorators
                ):
                    continue
                # This can't be moved before the actual .getattr call,
                # because there can be more values inferred and we are
                # stopping after the first one which has the attribute in question.
                # The problem is that if the first one has the attribute,
                # but we continue to the next values which doesn't have the
                # attribute, then we'll have a false positive.
                # So call this only after the call has been made.
                if not _emit_no_member(
                    node,
                    owner,
                    name,
                    self._mixin_class_rgx,
                    ignored_mixins=(
                        "no-member" in self.linter.config.ignored_checks_for_mixins
                    ),
                    ignored_none=self.linter.config.ignore_none,
                ):
                    continue
                missingattr.add((owner, name))
                continue
            else:
                for attr_node in attr_nodes:
                    attr_parent = attr_node.parent
                    # Skip augmented assignments
                    try:
                        if isinstance(attr_node.statement(), nodes.AugAssign) or (
                            isinstance(attr_parent, nodes.Assign)
                            and utils.is_augmented_assign(attr_parent)[0]
                        ):
                            continue
                    except astroid.exceptions.StatementMissing:
                        break
                    # Skip self-referencing assignments
                    if attr_parent is node.parent:
                        continue
                    break
                else:
                    missingattr.add((owner, name))
                    continue
            # stop on the first found
            break
        else:
            # we have not found any node with the attributes, display the
            # message for inferred nodes
            done = set()
            for owner, name in missingattr:
                if isinstance(owner, astroid.Instance):
                    actual = owner._proxied
                else:
                    actual = owner
                if actual in done:
                    continue
                done.add(actual)

                msg, hint = self._get_nomember_msgid_hint(node, owner)
                self.add_message(
                    msg,
                    node=node,
                    args=(owner.display_type(), name, node.attrname, hint),
                    confidence=INFERENCE,
                )

</t>
<t tx="ekr.20250131013559.754">    def _get_nomember_msgid_hint(
        self,
        node: nodes.Attribute | nodes.AssignAttr | nodes.DelAttr,
        owner: SuccessfulInferenceResult,
    ) -&gt; tuple[Literal["c-extension-no-member", "no-member"], str]:
        suggestions_are_possible = self._suggestion_mode and isinstance(
            owner, nodes.Module
        )
        if suggestions_are_possible and _is_c_extension(owner):
            msg = "c-extension-no-member"
            hint = ""
        else:
            msg = "no-member"
            if self.linter.config.missing_member_hint:
                hint = _missing_member_hint(
                    owner,
                    node.attrname,
                    self.linter.config.missing_member_hint_distance,
                    self.linter.config.missing_member_max_choices,
                )
            else:
                hint = ""
        return msg, hint  # type: ignore[return-value]

</t>
<t tx="ekr.20250131013559.755">    @only_required_for_messages(
        "assignment-from-no-return",
        "assignment-from-none",
        "non-str-assignment-to-dunder-name",
    )
    def visit_assign(self, node: nodes.Assign) -&gt; None:
        """Process assignments in the AST."""
        self._check_assignment_from_function_call(node)
        self._check_dundername_is_string(node)

</t>
<t tx="ekr.20250131013559.756">    def _check_assignment_from_function_call(self, node: nodes.Assign) -&gt; None:
        """When assigning to a function call, check that the function returns a valid
        value.
        """
        if not isinstance(node.value, nodes.Call):
            return

        function_node = safe_infer(node.value.func)
        funcs = (nodes.FunctionDef, astroid.UnboundMethod, astroid.BoundMethod)
        if not isinstance(function_node, funcs):
            return

        # Unwrap to get the actual function node object
        if isinstance(function_node, astroid.BoundMethod) and isinstance(
            function_node._proxied, astroid.UnboundMethod
        ):
            function_node = function_node._proxied._proxied

        # Make sure that it's a valid function that we can analyze.
        # Ordered from less expensive to more expensive checks.
        if (
            not function_node.is_function
            or function_node.decorators
            or self._is_ignored_function(function_node)
        ):
            return

        # Handle builtins such as list.sort() or dict.update()
        if self._is_builtin_no_return(node):
            self.add_message(
                "assignment-from-no-return", node=node, confidence=INFERENCE
            )
            return

        if not function_node.root().fully_defined():
            return

        return_nodes = list(
            function_node.nodes_of_class(nodes.Return, skip_klass=nodes.FunctionDef)
        )
        if not return_nodes:
            self.add_message("assignment-from-no-return", node=node)
        else:
            for ret_node in return_nodes:
                if not (
                    (
                        isinstance(ret_node.value, nodes.Const)
                        and ret_node.value.value is None
                    )
                    or ret_node.value is None
                ):
                    break
            else:
                self.add_message("assignment-from-none", node=node)

</t>
<t tx="ekr.20250131013559.757">    @staticmethod
    def _is_ignored_function(
        function_node: nodes.FunctionDef | bases.UnboundMethod,
    ) -&gt; bool:
        return (
            isinstance(function_node, nodes.AsyncFunctionDef)
            or utils.is_error(function_node)
            or function_node.is_generator()
            or function_node.is_abstract(pass_is_abstract=False)
        )

</t>
<t tx="ekr.20250131013559.758">    @staticmethod
    def _is_builtin_no_return(node: nodes.Assign) -&gt; bool:
        return (
            isinstance(node.value, nodes.Call)
            and isinstance(node.value.func, nodes.Attribute)
            and bool(inferred := utils.safe_infer(node.value.func.expr))
            and isinstance(inferred, bases.Instance)
            and node.value.func.attrname
            in BUILTINS_IMPLICIT_RETURN_NONE.get(inferred.pytype(), ())
        )

</t>
<t tx="ekr.20250131013559.759">    def _check_dundername_is_string(self, node: nodes.Assign) -&gt; None:
        """Check a string is assigned to self.__name__."""
        # Check the left-hand side of the assignment is &lt;something&gt;.__name__
        lhs = node.targets[0]
        if not isinstance(lhs, nodes.AssignAttr):
            return
        if not lhs.attrname == "__name__":
            return

        # If the right-hand side is not a string
        rhs = node.value
        if isinstance(rhs, nodes.Const) and isinstance(rhs.value, str):
            return
        inferred = utils.safe_infer(rhs)
        if not inferred:
            return
        if not (isinstance(inferred, nodes.Const) and isinstance(inferred.value, str)):
            # Add the message
            self.add_message("non-str-assignment-to-dunder-name", node=node)

</t>
<t tx="ekr.20250131013559.760">    def _check_uninferable_call(self, node: nodes.Call) -&gt; None:
        """Check that the given uninferable Call node does not
        call an actual function.
        """
        if not isinstance(node.func, nodes.Attribute):
            return

        # Look for properties. First, obtain
        # the lhs of the Attribute node and search the attribute
        # there. If that attribute is a property or a subclass of properties,
        # then most likely it's not callable.

        expr = node.func.expr
        klass = safe_infer(expr)
        if not isinstance(klass, astroid.Instance):
            return

        try:
            attrs = klass._proxied.getattr(node.func.attrname)
        except astroid.NotFoundError:
            return

        for attr in attrs:
            if not isinstance(attr, nodes.FunctionDef):
                continue

            # Decorated, see if it is decorated with a property.
            # Also, check the returns and see if they are callable.
            if decorated_with_property(attr):
                try:
                    call_results = list(attr.infer_call_result(node))
                except astroid.InferenceError:
                    continue

                if all(
                    isinstance(return_node, util.UninferableBase)
                    for return_node in call_results
                ):
                    # We were unable to infer return values of the call, skipping
                    continue

                if any(return_node.callable() for return_node in call_results):
                    # Only raise this issue if *all* the inferred values are not callable
                    continue

                self.add_message("not-callable", node=node, args=node.func.as_string())

</t>
<t tx="ekr.20250131013559.761">    def _check_argument_order(
        self,
        node: nodes.Call,
        call_site: arguments.CallSite,
        called: CallableObjects,
        called_param_names: list[str | None],
    ) -&gt; None:
        """Match the supplied argument names against the function parameters.

        Warn if some argument names are not in the same order as they are in
        the function signature.
        """
        # Check for called function being an object instance function
        # If so, ignore the initial 'self' argument in the signature
        try:
            is_classdef = isinstance(called.parent, nodes.ClassDef)
            if is_classdef and called_param_names[0] == "self":
                called_param_names = called_param_names[1:]
        except IndexError:
            return

        try:
            # extract argument names, if they have names
            calling_parg_names = [p.name for p in call_site.positional_arguments]

            # Additionally, get names of keyword arguments to use in a full match
            # against parameters
            calling_kwarg_names = [
                arg.name for arg in call_site.keyword_arguments.values()
            ]
        except AttributeError:
            # the type of arg does not provide a `.name`. In this case we
            # stop checking for out-of-order arguments because it is only relevant
            # for named variables.
            return

        # Don't check for ordering if there is an unmatched arg or param
        arg_set = set(calling_parg_names) | set(calling_kwarg_names)
        param_set = set(called_param_names)
        if arg_set != param_set:
            return

        # Warn based on the equality of argument ordering
        if calling_parg_names != called_param_names[: len(calling_parg_names)]:
            self.add_message("arguments-out-of-order", node=node, args=())

</t>
<t tx="ekr.20250131013559.762">    def _check_isinstance_args(self, node: nodes.Call, callable_name: str) -&gt; None:
        if len(node.args) &gt; 2:
            # for when isinstance called with too many args
            self.add_message(
                "too-many-function-args",
                node=node,
                args=(callable_name,),
                confidence=HIGH,
            )
        elif len(node.args) &lt; 2:
            # NOTE: Hard-coding the parameters for `isinstance` is fragile,
            # but as noted elsewhere, built-in functions do not provide
            # argument info, making this necessary for now.
            parameters = ("'_obj'", "'__class_or_tuple'")
            for parameter in parameters[len(node.args) :]:
                self.add_message(
                    "no-value-for-parameter",
                    node=node,
                    args=(parameter, callable_name),
                    confidence=HIGH,
                )
            return

        second_arg = node.args[1]
        if _is_invalid_isinstance_type(second_arg):
            self.add_message(
                "isinstance-second-argument-not-valid-type",
                node=node,
                confidence=INFERENCE,
            )

</t>
<t tx="ekr.20250131013559.763">    # pylint: disable = too-many-branches, too-many-locals, too-many-statements
    def visit_call(self, node: nodes.Call) -&gt; None:
        """Check that called functions/methods are inferred to callable objects,
        and that passed arguments match the parameters in the inferred function.
        """
        called = safe_infer(node.func, compare_constructors=True)

        self._check_not_callable(node, called)

        try:
            called, implicit_args, callable_name = _determine_callable(called)
        except ValueError:
            # Any error occurred during determining the function type, most of
            # those errors are handled by different warnings.
            return

        if called.args.args is None:
            if called.name == "isinstance":
                # Verify whether second argument of isinstance is a valid type
                self._check_isinstance_args(node, callable_name)
            # Built-in functions have no argument information.
            return

        if len(called.argnames()) != len(set(called.argnames())):
            # Duplicate parameter name (see duplicate-argument).  We can't really
            # make sense of the function call in this case, so just return.
            return

        # Build the set of keyword arguments, checking for duplicate keywords,
        # and count the positional arguments.
        call_site = astroid.arguments.CallSite.from_call(node)

        # Warn about duplicated keyword arguments, such as `f=24, **{'f': 24}`
        for keyword in call_site.duplicated_keywords:
            self.add_message("repeated-keyword", node=node, args=(keyword,))

        if call_site.has_invalid_arguments() or call_site.has_invalid_keywords():
            # Can't make sense of this.
            return

        # Has the function signature changed in ways we cannot reliably detect?
        if hasattr(called, "decorators") and decorated_with(
            called, self.linter.config.signature_mutators
        ):
            return

        num_positional_args = len(call_site.positional_arguments)
        keyword_args = list(call_site.keyword_arguments.keys())
        overload_function = is_overload_stub(called)

        # Determine if we don't have a context for our call and we use variadics.
        node_scope = node.scope()
        if isinstance(node_scope, (nodes.Lambda, nodes.FunctionDef)):
            has_no_context_positional_variadic = _no_context_variadic_positional(
                node, node_scope
            )
            has_no_context_keywords_variadic = _no_context_variadic_keywords(
                node, node_scope
            )
        else:
            has_no_context_positional_variadic = has_no_context_keywords_variadic = (
                False
            )

        # These are coming from the functools.partial implementation in astroid
        already_filled_positionals = getattr(called, "filled_positionals", 0)
        already_filled_keywords = getattr(called, "filled_keywords", {})

        keyword_args += list(already_filled_keywords)
        num_positional_args += implicit_args + already_filled_positionals

        # Decrement `num_positional_args` by 1 when a function call is assigned to a class attribute
        # inside the class where the function is defined.
        # This avoids emitting `too-many-function-args` since `num_positional_args`
        # includes an implicit `self` argument which is not present in `called.args`.
        if (
            isinstance(node.frame(), nodes.ClassDef)
            and isinstance(called, nodes.FunctionDef)
            and called in node.frame().body
            and num_positional_args &gt; 0
            and "builtins.staticmethod" not in called.decoratornames()
        ):
            num_positional_args -= 1

        # Analyze the list of formal parameters.
        args = list(itertools.chain(called.args.posonlyargs or (), called.args.args))
        num_mandatory_parameters = len(args) - len(called.args.defaults)
        parameters: list[tuple[tuple[str | None, nodes.NodeNG | None], bool]] = []
        parameter_name_to_index = {}
        for i, arg in enumerate(args):
            name = arg.name
            parameter_name_to_index[name] = i
            if i &gt;= num_mandatory_parameters:
                defval = called.args.defaults[i - num_mandatory_parameters]
            else:
                defval = None
            parameters.append(((name, defval), False))

        kwparams = {}
        for i, arg in enumerate(called.args.kwonlyargs):
            if isinstance(arg, nodes.Keyword):
                name = arg.arg
            else:
                assert isinstance(arg, nodes.AssignName)
                name = arg.name
            kwparams[name] = [called.args.kw_defaults[i], False]

        self._check_argument_order(
            node, call_site, called, [p[0][0] for p in parameters]
        )

        # 1. Match the positional arguments.
        for i in range(num_positional_args):
            if i &lt; len(parameters):
                parameters[i] = (parameters[i][0], True)
            elif called.args.vararg is not None:
                # The remaining positional arguments get assigned to the *args
                # parameter.
                break
            elif not overload_function:
                # Too many positional arguments.
                self.add_message(
                    "too-many-function-args",
                    node=node,
                    args=(callable_name,),
                )
                break

        # 2. Match the keyword arguments.
        for keyword in keyword_args:
            # Skip if `keyword` is the same name as a positional-only parameter
            # and a `**kwargs` parameter exists.
            if called.args.kwarg and keyword in [
                arg.name for arg in called.args.posonlyargs
            ]:
                self.add_message(
                    "kwarg-superseded-by-positional-arg",
                    node=node,
                    args=(keyword, f"**{called.args.kwarg}"),
                    confidence=HIGH,
                )
                continue
            if keyword in parameter_name_to_index:
                i = parameter_name_to_index[keyword]
                if parameters[i][1]:
                    # Duplicate definition of function parameter.

                    # Might be too hard-coded, but this can actually
                    # happen when using str.format and `self` is passed
                    # by keyword argument, as in `.format(self=self)`.
                    # It's perfectly valid to so, so we're just skipping
                    # it if that's the case.
                    if not (keyword == "self" and called.qname() in STR_FORMAT):
                        self.add_message(
                            "redundant-keyword-arg",
                            node=node,
                            args=(keyword, callable_name),
                        )
                else:
                    parameters[i] = (parameters[i][0], True)
            elif keyword in kwparams:
                if kwparams[keyword][1]:
                    # Duplicate definition of function parameter.
                    self.add_message(
                        "redundant-keyword-arg",
                        node=node,
                        args=(keyword, callable_name),
                    )
                else:
                    kwparams[keyword][1] = True
            elif called.args.kwarg is not None:
                # The keyword argument gets assigned to the **kwargs parameter.
                pass
            elif isinstance(
                called, nodes.FunctionDef
            ) and self._keyword_argument_is_in_all_decorator_returns(called, keyword):
                pass
            elif not overload_function:
                # Unexpected keyword argument.
                self.add_message(
                    "unexpected-keyword-arg", node=node, args=(keyword, callable_name)
                )

        # 3. Match the **kwargs, if any.
        if node.kwargs:
            for i, [(name, _defval), _assigned] in enumerate(parameters):
                # Assume that *kwargs provides values for all remaining
                # unassigned named parameters.
                if name is not None:
                    parameters[i] = (parameters[i][0], True)
                else:
                    # **kwargs can't assign to tuples.
                    pass

        # Check that any parameters without a default have been assigned
        # values.
        for [(name, defval), assigned] in parameters:
            if (defval is None) and not assigned:
                display_name = "&lt;tuple&gt;" if name is None else repr(name)
                if not has_no_context_positional_variadic and not overload_function:
                    self.add_message(
                        "no-value-for-parameter",
                        node=node,
                        args=(display_name, callable_name),
                    )

        for name, val in kwparams.items():
            defval, assigned = val
            if (
                defval is None
                and not assigned
                and not has_no_context_keywords_variadic
                and not overload_function
            ):
                self.add_message(
                    "missing-kwoa",
                    node=node,
                    args=(name, callable_name),
                    confidence=INFERENCE,
                )

</t>
<t tx="ekr.20250131013559.764">    @staticmethod
    def _keyword_argument_is_in_all_decorator_returns(
        func: nodes.FunctionDef, keyword: str
    ) -&gt; bool:
        """Check if the keyword argument exists in all signatures of the
        return values of all decorators of the function.
        """
        if not func.decorators:
            return False

        for decorator in func.decorators.nodes:
            inferred = safe_infer(decorator)

            # If we can't infer the decorator we assume it satisfies consumes
            # the keyword, so we don't raise false positives
            if not inferred:
                return True

            # We only check arguments of function decorators
            if not isinstance(inferred, nodes.FunctionDef):
                return False

            for return_value in inferred.infer_call_result(caller=None):
                # infer_call_result() returns nodes.Const.None for None return values
                # so this also catches non-returning decorators
                if not isinstance(return_value, nodes.FunctionDef):
                    return False

                # If the return value uses a kwarg the keyword will be consumed
                if return_value.args.kwarg:
                    continue

                # Check if the keyword is another type of argument
                if return_value.args.is_argument(keyword):
                    continue

                return False

        return True

</t>
<t tx="ekr.20250131013559.765">    def _check_invalid_sequence_index(self, subscript: nodes.Subscript) -&gt; None:
        # Look for index operations where the parent is a sequence type.
        # If the types can be determined, only allow indices to be int,
        # slice or instances with __index__.
        parent_type = safe_infer(subscript.value)
        if not isinstance(
            parent_type, (nodes.ClassDef, astroid.Instance)
        ) or not has_known_bases(parent_type):
            return None

        # Determine what method on the parent this index will use
        # The parent of this node will be a Subscript, and the parent of that
        # node determines if the Subscript is a get, set, or delete operation.
        if subscript.ctx is astroid.Context.Store:
            methodname = "__setitem__"
        elif subscript.ctx is astroid.Context.Del:
            methodname = "__delitem__"
        else:
            methodname = "__getitem__"

        # Check if this instance's __getitem__, __setitem__, or __delitem__, as
        # appropriate to the statement, is implemented in a builtin sequence
        # type. This way we catch subclasses of sequence types but skip classes
        # that override __getitem__ and which may allow non-integer indices.
        try:
            methods = astroid.interpreter.dunder_lookup.lookup(parent_type, methodname)
            if isinstance(methods, util.UninferableBase):
                return None
            itemmethod = methods[0]
        except(
            astroid.AttributeInferenceError,
            IndexError,
        ):
            return None
        if (
            not isinstance(itemmethod, nodes.FunctionDef)
            or itemmethod.root().name != "builtins"
            or not itemmethod.parent
            or itemmethod.parent.frame().name not in SEQUENCE_TYPES
        ):
            return None

        index_type = safe_infer(subscript.slice)
        if index_type is None or isinstance(index_type, util.UninferableBase):
            return None
        # Constants must be of type int
        if isinstance(index_type, nodes.Const):
            if isinstance(index_type.value, int):
                return None
        # Instance values must be int, slice, or have an __index__ method
        elif isinstance(index_type, astroid.Instance):
            if index_type.pytype() in {"builtins.int", "builtins.slice"}:
                return None
            try:
                index_type.getattr("__index__")
                return None
            except astroid.NotFoundError:
                pass
        elif isinstance(index_type, nodes.Slice):
            # A slice can be present
            # here after inferring the index node, which could
            # be a `slice(...)` call for instance.
            return self._check_invalid_slice_index(index_type)

        # Anything else is an error
        self.add_message("invalid-sequence-index", node=subscript)
        return None

</t>
<t tx="ekr.20250131013559.766">    def _check_not_callable(
        self, node: nodes.Call, inferred_call: nodes.NodeNG | None
    ) -&gt; None:
        """Checks to see if the not-callable message should be emitted.

        Only functions, generators and objects defining __call__ are "callable"
        We ignore instances of descriptors since astroid cannot properly handle them yet
        """
        # Handle uninferable calls
        if not inferred_call or inferred_call.callable():
            self._check_uninferable_call(node)
            return

        if not isinstance(inferred_call, astroid.Instance):
            self.add_message("not-callable", node=node, args=node.func.as_string())
            return

        # Don't emit if we can't make sure this object is callable.
        if not has_known_bases(inferred_call):
            return

        if inferred_call.parent and isinstance(inferred_call.scope(), nodes.ClassDef):
            # Ignore descriptor instances
            if "__get__" in inferred_call.locals:
                return
            # NamedTuple instances are callable
            if inferred_call.qname() == "typing.NamedTuple":
                return

        self.add_message("not-callable", node=node, args=node.func.as_string())

</t>
<t tx="ekr.20250131013559.767">    def _check_invalid_slice_index(self, node: nodes.Slice) -&gt; None:
        # Check the type of each part of the slice
        invalid_slices_nodes: list[nodes.NodeNG] = []
        for index in (node.lower, node.upper, node.step):
            if index is None:
                continue

            index_type = safe_infer(index)
            if index_type is None or isinstance(index_type, util.UninferableBase):
                continue

            # Constants must be of type int or None
            if isinstance(index_type, nodes.Const):
                if isinstance(index_type.value, (int, type(None))):
                    continue
            # Instance values must be of type int, None or an object
            # with __index__
            elif isinstance(index_type, astroid.Instance):
                if index_type.pytype() in {"builtins.int", "builtins.NoneType"}:
                    continue

                try:
                    index_type.getattr("__index__")
                    return
                except astroid.NotFoundError:
                    pass
            invalid_slices_nodes.append(index)

        invalid_slice_step = (
            node.step and isinstance(node.step, nodes.Const) and node.step.value == 0
        )

        if not (invalid_slices_nodes or invalid_slice_step):
            return

        # Anything else is an error, unless the object that is indexed
        # is a custom object, which knows how to handle this kind of slices
        parent = node.parent
        if isinstance(parent, nodes.Subscript):
            inferred = safe_infer(parent.value)
            if inferred is None or isinstance(inferred, util.UninferableBase):
                # Don't know what this is
                return
            known_objects = (
                nodes.List,
                nodes.Dict,
                nodes.Tuple,
                astroid.objects.FrozenSet,
                nodes.Set,
            )
            if not (
                isinstance(inferred, known_objects)
                or (
                    isinstance(inferred, nodes.Const)
                    and inferred.pytype() in {"builtins.str", "builtins.bytes"}
                )
                or (
                    isinstance(inferred, astroid.bases.Instance)
                    and inferred.pytype() == "builtins.range"
                )
            ):
                # Might be an instance that knows how to handle this slice object
                return
        for snode in invalid_slices_nodes:
            self.add_message("invalid-slice-index", node=snode)
        if invalid_slice_step:
            self.add_message("invalid-slice-step", node=node.step, confidence=HIGH)

</t>
<t tx="ekr.20250131013559.768">    @only_required_for_messages("not-context-manager")
    def visit_with(self, node: nodes.With) -&gt; None:
        for ctx_mgr, _ in node.items:
            context = astroid.context.InferenceContext()
            inferred = safe_infer(ctx_mgr, context=context)
            if inferred is None or isinstance(inferred, util.UninferableBase):
                continue

            if isinstance(inferred, astroid.bases.Generator):
                # Check if we are dealing with a function decorated
                # with contextlib.contextmanager.
                if decorated_with(
                    inferred.parent, self.linter.config.contextmanager_decorators
                ):
                    continue
                # If the parent of the generator is not the context manager itself,
                # that means that it could have been returned from another
                # function which was the real context manager.
                # The following approach is more of a hack rather than a real
                # solution: walk all the inferred statements for the
                # given *ctx_mgr* and if you find one function scope
                # which is decorated, consider it to be the real
                # manager and give up, otherwise emit not-context-manager.
                # See the test file for not_context_manager for a couple
                # of self explaining tests.

                # Retrieve node from all previously visited nodes in the
                # inference history
                for inferred_path, _ in context.path:
                    if not inferred_path:
                        continue
                    if isinstance(inferred_path, nodes.Call):
                        scope = safe_infer(inferred_path.func)
                    else:
                        scope = inferred_path.scope()
                    if not isinstance(scope, nodes.FunctionDef):
                        continue
                    if decorated_with(
                        scope, self.linter.config.contextmanager_decorators
                    ):
                        break
                else:
                    self.add_message(
                        "not-context-manager", node=node, args=(inferred.name,)
                    )
            else:
                try:
                    inferred.getattr("__enter__")
                    inferred.getattr("__exit__")
                except astroid.NotFoundError:
                    if isinstance(inferred, astroid.Instance):
                        # If we do not know the bases of this class,
                        # just skip it.
                        if not has_known_bases(inferred):
                            continue
                        # Just ignore mixin classes.
                        if (
                            "not-context-manager"
                            in self.linter.config.ignored_checks_for_mixins
                        ):
                            if inferred.name[-5:].lower() == "mixin":
                                continue

                    self.add_message(
                        "not-context-manager", node=node, args=(inferred.name,)
                    )

</t>
<t tx="ekr.20250131013559.769">    @only_required_for_messages("invalid-unary-operand-type")
    def visit_unaryop(self, node: nodes.UnaryOp) -&gt; None:
        """Detect TypeErrors for unary operands."""
        for error in node.type_errors():
            # Let the error customize its output.
            self.add_message("invalid-unary-operand-type", args=str(error), node=node)

</t>
<t tx="ekr.20250131013559.770">    @only_required_for_messages("unsupported-binary-operation")
    def visit_binop(self, node: nodes.BinOp) -&gt; None:
        if node.op == "|":
            self._detect_unsupported_alternative_union_syntax(node)

</t>
<t tx="ekr.20250131013559.771">    def _detect_unsupported_alternative_union_syntax(self, node: nodes.BinOp) -&gt; None:
        """Detect if unsupported alternative Union syntax (PEP 604) was used."""
        if self._py310_plus:  # 310+ supports the new syntax
            return

        if isinstance(
            node.parent, TYPE_ANNOTATION_NODES_TYPES
        ) and not is_postponed_evaluation_enabled(node):
            # Use in type annotations only allowed if
            # postponed evaluation is enabled.
            self._check_unsupported_alternative_union_syntax(node)

        if isinstance(
            node.parent,
            (
                nodes.Assign,
                nodes.Call,
                nodes.Keyword,
                nodes.Dict,
                nodes.Tuple,
                nodes.Set,
                nodes.List,
                nodes.BinOp,
            ),
        ):
            # Check other contexts the syntax might appear, but are invalid.
            # Make sure to filter context if postponed evaluation is enabled
            # and parent is allowed node type.
            allowed_nested_syntax = False
            if is_postponed_evaluation_enabled(node):
                parent_node = node.parent
                while True:
                    if isinstance(parent_node, TYPE_ANNOTATION_NODES_TYPES):
                        allowed_nested_syntax = True
                        break
                    parent_node = parent_node.parent
                    if isinstance(parent_node, nodes.Module):
                        break
            if not allowed_nested_syntax:
                self._check_unsupported_alternative_union_syntax(node)

</t>
<t tx="ekr.20250131013559.772">    def _includes_version_compatible_overload(self, attrs: list[nodes.NodeNG]) -&gt; bool:
        """Check if a set of overloads of an operator includes one that
        can be relied upon for our configured Python version.

        If we are running under a Python 3.10+ runtime but configured for
        pre-3.10 compatibility then Astroid will have inferred the
        existence of __or__ / __ror__ on builtins.type, but these aren't
        available in the configured version of Python.
        """
        is_py310_builtin = all(
            isinstance(attr, (nodes.FunctionDef, astroid.BoundMethod))
            and attr.parent.qname() == "builtins.type"
            for attr in attrs
        )
        return not is_py310_builtin or self._py310_plus

</t>
<t tx="ekr.20250131013559.773">    def _recursive_search_for_classdef_type(
        self, node: nodes.ClassDef, operation: Literal["__or__", "__ror__"]
    ) -&gt; bool | VERSION_COMPATIBLE_OVERLOAD:
        if not isinstance(node, nodes.ClassDef):
            return False
        try:
            attrs = node.getattr(operation)
        except astroid.NotFoundError:
            return True
        if self._includes_version_compatible_overload(attrs):
            return VERSION_COMPATIBLE_OVERLOAD_SENTINEL
        return True

</t>
<t tx="ekr.20250131013559.774">    def _check_unsupported_alternative_union_syntax(self, node: nodes.BinOp) -&gt; None:
        """Check if left or right node is of type `type`.

        If either is, and doesn't support an or operator via a metaclass,
        infer that this is a mistaken attempt to use alternative union
        syntax when not supported.
        """
        msg = "unsupported operand type(s) for |"
        left_obj = astroid.helpers.object_type(node.left)
        right_obj = astroid.helpers.object_type(node.right)
        left_is_type = self._recursive_search_for_classdef_type(left_obj, "__or__")
        if left_is_type is VERSION_COMPATIBLE_OVERLOAD_SENTINEL:
            return
        right_is_type = self._recursive_search_for_classdef_type(right_obj, "__ror__")
        if right_is_type is VERSION_COMPATIBLE_OVERLOAD_SENTINEL:
            return

        if left_is_type or right_is_type:
            self.add_message(
                "unsupported-binary-operation",
                args=msg,
                node=node,
                confidence=INFERENCE,
            )

</t>
<t tx="ekr.20250131013559.775">    # TODO: This check was disabled (by adding the leading underscore)
    # due to false positives several years ago - can we re-enable it?
    # https://github.com/pylint-dev/pylint/issues/6359
    @only_required_for_messages("unsupported-binary-operation")
    def _visit_binop(self, node: nodes.BinOp) -&gt; None:
        """Detect TypeErrors for binary arithmetic operands."""
        self._check_binop_errors(node)

</t>
<t tx="ekr.20250131013559.776">    # TODO: This check was disabled (by adding the leading underscore)
    # due to false positives several years ago - can we re-enable it?
    # https://github.com/pylint-dev/pylint/issues/6359
    @only_required_for_messages("unsupported-binary-operation")
    def _visit_augassign(self, node: nodes.AugAssign) -&gt; None:
        """Detect TypeErrors for augmented binary arithmetic operands."""
        self._check_binop_errors(node)

</t>
<t tx="ekr.20250131013559.777">    def _check_binop_errors(self, node: nodes.BinOp | nodes.AugAssign) -&gt; None:
        for error in node.type_errors():
            # Let the error customize its output.
            if any(
                isinstance(obj, nodes.ClassDef) and not has_known_bases(obj)
                for obj in (error.left_type, error.right_type)
            ):
                continue
            self.add_message("unsupported-binary-operation", args=str(error), node=node)

</t>
<t tx="ekr.20250131013559.778">    def _check_membership_test(self, node: nodes.NodeNG) -&gt; None:
        if is_inside_abstract_class(node):
            return
        if is_comprehension(node):
            return
        inferred = safe_infer(node)
        if inferred is None or isinstance(inferred, util.UninferableBase):
            return
        if not supports_membership_test(inferred):
            self.add_message(
                "unsupported-membership-test", args=node.as_string(), node=node
            )

</t>
<t tx="ekr.20250131013559.779">    @only_required_for_messages("unsupported-membership-test")
    def visit_compare(self, node: nodes.Compare) -&gt; None:
        if len(node.ops) != 1:
            return

        op, right = node.ops[0]
        if op in {"in", "not in"}:
            self._check_membership_test(right)

</t>
<t tx="ekr.20250131013559.780">    @only_required_for_messages("unhashable-member")
    def visit_dict(self, node: nodes.Dict) -&gt; None:
        for k, _ in node.items:
            if not is_hashable(k):
                self.add_message(
                    "unhashable-member",
                    node=k,
                    args=(k.as_string(), "key", "dict"),
                    confidence=INFERENCE,
                )

</t>
<t tx="ekr.20250131013559.781">    @only_required_for_messages("unhashable-member")
    def visit_set(self, node: nodes.Set) -&gt; None:
        for element in node.elts:
            if not is_hashable(element):
                self.add_message(
                    "unhashable-member",
                    node=element,
                    args=(element.as_string(), "member", "set"),
                    confidence=INFERENCE,
                )

</t>
<t tx="ekr.20250131013559.782">    @only_required_for_messages(
        "unsubscriptable-object",
        "unsupported-assignment-operation",
        "unsupported-delete-operation",
        "unhashable-member",
        "invalid-sequence-index",
        "invalid-slice-index",
        "invalid-slice-step",
    )
    def visit_subscript(self, node: nodes.Subscript) -&gt; None:
        self._check_invalid_sequence_index(node)

        supported_protocol: Callable[[Any, Any], bool] | None = None
        if isinstance(node.value, (nodes.ListComp, nodes.DictComp)):
            return

        if isinstance(node.value, nodes.Dict):
            # Assert dict key is hashable
            if not is_hashable(node.slice):
                self.add_message(
                    "unhashable-member",
                    node=node.value,
                    args=(node.slice.as_string(), "key", "dict"),
                    confidence=INFERENCE,
                )

        if node.ctx == astroid.Context.Load:
            supported_protocol = supports_getitem
            msg = "unsubscriptable-object"
        elif node.ctx == astroid.Context.Store:
            supported_protocol = supports_setitem
            msg = "unsupported-assignment-operation"
        elif node.ctx == astroid.Context.Del:
            supported_protocol = supports_delitem
            msg = "unsupported-delete-operation"

        if isinstance(node.value, nodes.SetComp):
            # pylint: disable-next=possibly-used-before-assignment
            self.add_message(msg, args=node.value.as_string(), node=node.value)
            return

        if is_inside_abstract_class(node):
            return

        inferred = safe_infer(node.value)

        if inferred is None or isinstance(inferred, util.UninferableBase):
            return

        if getattr(inferred, "decorators", None):
            first_decorator = astroid.util.safe_infer(inferred.decorators.nodes[0])
            if isinstance(first_decorator, nodes.ClassDef):
                inferred = first_decorator.instantiate_class()
            else:
                return  # It would be better to handle function
                # decorators, but let's start slow.

        if (
            supported_protocol
            and not supported_protocol(inferred, node)
            and not utils.in_type_checking_block(node)
        ):
            self.add_message(msg, args=node.value.as_string(), node=node.value)

</t>
<t tx="ekr.20250131013559.783">    @only_required_for_messages("dict-items-missing-iter")
    def visit_for(self, node: nodes.For) -&gt; None:
        if not isinstance(node.target, nodes.Tuple):
            # target is not a tuple
            return
        if not len(node.target.elts) == 2:
            # target is not a tuple of two elements
            return

        iterable = node.iter
        if not isinstance(iterable, nodes.Name):
            # it's not a bare variable
            return

        inferred = safe_infer(iterable)
        if not inferred:
            return
        if not isinstance(inferred, nodes.Dict):
            # the iterable is not a dict
            return

        if all(isinstance(i[0], nodes.Tuple) for i in inferred.items):
            # if all keys are tuples
            return

        self.add_message("dict-iter-missing-items", node=node)

</t>
<t tx="ekr.20250131013559.784">    @only_required_for_messages("await-outside-async")
    def visit_await(self, node: nodes.Await) -&gt; None:
        self._check_await_outside_coroutine(node)

</t>
<t tx="ekr.20250131013559.785">    def _check_await_outside_coroutine(self, node: nodes.Await) -&gt; None:
        node_scope = node.scope()
        while not isinstance(node_scope, nodes.Module):
            if isinstance(node_scope, nodes.AsyncFunctionDef):
                return
            if isinstance(node_scope, (nodes.FunctionDef, nodes.Lambda)):
                break
            node_scope = node_scope.parent.scope()
        self.add_message("await-outside-async", node=node)


</t>
<t tx="ekr.20250131013559.786">name = "typecheck"

msgs = {
    "E1133": (
        "Non-iterable value %s is used in an iterating context",
        "not-an-iterable",
        "Used when a non-iterable value is used in place where "
        "iterable is expected",
    ),
    "E1134": (
        "Non-mapping value %s is used in a mapping context",
        "not-a-mapping",
        "Used when a non-mapping value is used in place where "
        "mapping is expected",
    ),
}

@staticmethod
def _is_asyncio_coroutine(node: nodes.NodeNG) -&gt; bool:
    if not isinstance(node, nodes.Call):
        return False

    inferred_func = safe_infer(node.func)
    if not isinstance(inferred_func, nodes.FunctionDef):
        return False
    if not inferred_func.decorators:
        return False
    for decorator in inferred_func.decorators.nodes:
        inferred_decorator = safe_infer(decorator)
        if not isinstance(inferred_decorator, nodes.FunctionDef):
            continue
        if inferred_decorator.qname() != ASYNCIO_COROUTINE:
            continue
        return True
    return False

</t>
<t tx="ekr.20250131013559.787">def _check_iterable(self, node: nodes.NodeNG, check_async: bool = False) -&gt; None:
    if is_inside_abstract_class(node):
        return
    inferred = safe_infer(node)
    if not inferred or is_comprehension(inferred):
        return
    if not is_iterable(inferred, check_async=check_async):
        self.add_message("not-an-iterable", args=node.as_string(), node=node)

</t>
<t tx="ekr.20250131013559.788">def _check_mapping(self, node: nodes.NodeNG) -&gt; None:
    if is_inside_abstract_class(node):
        return
    if isinstance(node, nodes.DictComp):
        return
    inferred = safe_infer(node)
    if inferred is None or isinstance(inferred, util.UninferableBase):
        return
    if not is_mapping(inferred):
        self.add_message("not-a-mapping", args=node.as_string(), node=node)

</t>
<t tx="ekr.20250131013559.789">@only_required_for_messages("not-an-iterable")
def visit_for(self, node: nodes.For) -&gt; None:
    self._check_iterable(node.iter)

</t>
<t tx="ekr.20250131013559.790">@only_required_for_messages("not-an-iterable")
def visit_asyncfor(self, node: nodes.AsyncFor) -&gt; None:
    self._check_iterable(node.iter, check_async=True)

</t>
<t tx="ekr.20250131013559.791">@only_required_for_messages("not-an-iterable")
def visit_yieldfrom(self, node: nodes.YieldFrom) -&gt; None:
    if self._is_asyncio_coroutine(node.value):
        return
    self._check_iterable(node.value)

</t>
<t tx="ekr.20250131013559.792">@only_required_for_messages("not-an-iterable", "not-a-mapping")
def visit_call(self, node: nodes.Call) -&gt; None:
    for stararg in node.starargs:
        self._check_iterable(stararg.value)
    for kwarg in node.kwargs:
        self._check_mapping(kwarg.value)

</t>
<t tx="ekr.20250131013559.793">@only_required_for_messages("not-an-iterable")
def visit_listcomp(self, node: nodes.ListComp) -&gt; None:
    for gen in node.generators:
        self._check_iterable(gen.iter, check_async=gen.is_async)

</t>
<t tx="ekr.20250131013559.794">@only_required_for_messages("not-an-iterable")
def visit_dictcomp(self, node: nodes.DictComp) -&gt; None:
    for gen in node.generators:
        self._check_iterable(gen.iter, check_async=gen.is_async)

</t>
<t tx="ekr.20250131013559.795">@only_required_for_messages("not-an-iterable")
def visit_setcomp(self, node: nodes.SetComp) -&gt; None:
    for gen in node.generators:
        self._check_iterable(gen.iter, check_async=gen.is_async)

</t>
<t tx="ekr.20250131013559.796">@only_required_for_messages("not-an-iterable")
def visit_generatorexp(self, node: nodes.GeneratorExp) -&gt; None:
    for gen in node.generators:
        self._check_iterable(gen.iter, check_async=gen.is_async)


</t>
<t tx="ekr.20250131013559.797">@path pylint/checkers
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Unicode and some other ASCII characters can be used to create programs that run
much different compared to what a human reader would expect from them.

PEP 672 lists some examples.
See: https://www.python.org/dev/peps/pep-0672/

The following checkers are intended to make users are aware of these issues.
"""

from __future__ import annotations

import codecs
import contextlib
import io
import re
from collections import OrderedDict
from collections.abc import Iterable
from functools import lru_cache
from tokenize import detect_encoding
from typing import NamedTuple, TypeVar

from astroid import nodes

import pylint.interfaces
import pylint.lint
from pylint import checkers

_StrLike = TypeVar("_StrLike", str, bytes)

# Based on:
# https://golangexample.com/go-linter-which-checks-for-dangerous-unicode-character-sequences/
# We use '\u' because it doesn't require a map lookup and is therefore faster
BIDI_UNICODE = [
    "\u202A",  # \N{LEFT-TO-RIGHT EMBEDDING}
    "\u202B",  # \N{RIGHT-TO-LEFT EMBEDDING}
    "\u202C",  # \N{POP DIRECTIONAL FORMATTING}
    "\u202D",  # \N{LEFT-TO-RIGHT OVERRIDE}
    "\u202E",  # \N{RIGHT-TO-LEFT OVERRIDE}
    "\u2066",  # \N{LEFT-TO-RIGHT ISOLATE}
    "\u2067",  # \N{RIGHT-TO-LEFT ISOLATE}
    "\u2068",  # \N{FIRST STRONG ISOLATE}
    "\u2069",  # \N{POP DIRECTIONAL ISOLATE}
    # The following was part of PEP 672:
    # https://www.python.org/dev/peps/pep-0672/
    # so the list above might not be complete
    "\u200F",  # \n{RIGHT-TO-LEFT MARK}
    # We don't use
    #   "\u200E" # \n{LEFT-TO-RIGHT MARK}
    # as this is the default for latin files and can't be used
    # to hide code
]


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013559.798">class _BadChar(NamedTuple):
    """Representation of an ASCII char considered bad."""

    @others
</t>
<t tx="ekr.20250131013559.799"># Based on https://www.python.org/dev/peps/pep-0672/
BAD_CHARS = [
    _BadChar(
        "backspace",
        "\b",
        "\\b",
        "E2510",
        (
            "Moves the cursor back, so the character after it will overwrite the "
            "character before."
        ),
    ),
    _BadChar(
        "carriage-return",
        "\r",
        "\\r",
        "E2511",
        (
            "Moves the cursor to the start of line, subsequent characters overwrite "
            "the start of the line."
        ),
    ),
    _BadChar(
        "sub",
        "\x1A",
        "\\x1A",
        "E2512",
        (
            'Ctrl+Z "End of text" on Windows. Some programs (such as type) ignore '
            "the rest of the file after it."
        ),
    ),
    _BadChar(
        "esc",
        "\x1B",
        "\\x1B",
        "E2513",
        (
            "Commonly initiates escape codes which allow arbitrary control "
            "of the terminal."
        ),
    ),
    _BadChar(
        "nul",
        "\0",
        "\\0",
        "E2514",
        "Mostly end of input for python.",
    ),
    _BadChar(
        # Zero Width with Space. At the time of writing not accepted by Python.
        # But used in Trojan Source Examples, so still included and tested for.
        "zero-width-space",
        "\u200B",  # \n{ZERO WIDTH SPACE}
        "\\u200B",
        "E2515",
        "Invisible space character could hide real code execution.",
    ),
]
BAD_ASCII_SEARCH_DICT = {char.unescaped: char for char in BAD_CHARS}


def _line_length(line: _StrLike, codec: str) -&gt; int:
    """Get the length of a string like line as displayed in an editor."""
    if isinstance(line, bytes):
        decoded = _remove_bom(line, codec).decode(codec, "replace")
    else:
        decoded = line

    stripped = decoded.rstrip("\n")

    if stripped != decoded:
        stripped = stripped.rstrip("\r")

    return len(stripped)


</t>
<t tx="ekr.20250131013559.800">def _map_positions_to_result(
    line: _StrLike,
    search_dict: dict[_StrLike, _BadChar],
    new_line: _StrLike,
    byte_str_length: int = 1,
) -&gt; dict[int, _BadChar]:
    """Get all occurrences of search dict keys within line.

    Ignores Windows end of line and can handle bytes as well as string.
    Also takes care of encodings for which the length of an encoded code point does not
    default to 8 Bit.
    """
    result: dict[int, _BadChar] = {}

    for search_for, char in search_dict.items():
        if search_for not in line:
            continue

        # Special Handling for Windows '\r\n'
        if char.unescaped == "\r" and line.endswith(new_line):
            ignore_pos = len(line) - 2 * byte_str_length
        else:
            ignore_pos = None

        start = 0
        pos = line.find(search_for, start)
        while pos &gt; 0:
            if pos != ignore_pos:
                # Calculate the column
                col = int(pos / byte_str_length)
                result[col] = char
            start = pos + 1
            pos = line.find(search_for, start)

    return result


</t>
<t tx="ekr.20250131013559.801">UNICODE_BOMS = {
    "utf-8": codecs.BOM_UTF8,
    "utf-16": codecs.BOM_UTF16,
    "utf-32": codecs.BOM_UTF32,
    "utf-16le": codecs.BOM_UTF16_LE,
    "utf-16be": codecs.BOM_UTF16_BE,
    "utf-32le": codecs.BOM_UTF32_LE,
    "utf-32be": codecs.BOM_UTF32_BE,
}
BOM_SORTED_TO_CODEC = OrderedDict(
    # Sorted by length of BOM of each codec
    (UNICODE_BOMS[codec], codec)
    for codec in ("utf-32le", "utf-32be", "utf-8", "utf-16le", "utf-16be")
)

UTF_NAME_REGEX_COMPILED = re.compile(
    "utf[ -]?(8|16|32)[ -]?(le|be|)?(sig)?", flags=re.IGNORECASE
)


def _normalize_codec_name(codec: str) -&gt; str:
    """Make sure the codec name is always given as defined in the BOM dict."""
    return UTF_NAME_REGEX_COMPILED.sub(r"utf-\1\2", codec).lower()


</t>
<t tx="ekr.20250131013559.802">def _remove_bom(encoded: bytes, encoding: str) -&gt; bytes:
    """Remove the bom if given from a line."""
    if encoding not in UNICODE_BOMS:
        return encoded
    bom = UNICODE_BOMS[encoding]
    if encoded.startswith(bom):
        return encoded[len(bom) :]
    return encoded


</t>
<t tx="ekr.20250131013559.803">def _encode_without_bom(string: str, encoding: str) -&gt; bytes:
    """Encode a string but remove the BOM."""
    return _remove_bom(string.encode(encoding), encoding)


</t>
<t tx="ekr.20250131013559.804">def _byte_to_str_length(codec: str) -&gt; int:
    """Return how many byte are usually(!) a character point."""
    if codec.startswith("utf-32"):
        return 4
    if codec.startswith("utf-16"):
        return 2

    return 1


</t>
<t tx="ekr.20250131013559.805">@lru_cache(maxsize=1000)
def _cached_encode_search(string: str, encoding: str) -&gt; bytes:
    """A cached version of encode used for search pattern."""
    return _encode_without_bom(string, encoding)


</t>
<t tx="ekr.20250131013559.806">def _fix_utf16_32_line_stream(steam: Iterable[bytes], codec: str) -&gt; Iterable[bytes]:
    r"""Handle line ending for UTF16 and UTF32 correctly.

    Currently, Python simply strips the required zeros after \n after the
    line ending. Leading to lines that can't be decoded properly
    """
    if not codec.startswith("utf-16") and not codec.startswith("utf-32"):
        yield from steam
    else:
        # First we get all the bytes in memory
        content = b"".join(line for line in steam)

        new_line = _cached_encode_search("\n", codec)

        # Now we split the line by the real new line in the correct encoding
        # we can't use split as it would strip the \n that we need
        start = 0
        while True:
            pos = content.find(new_line, start)
            if pos &gt;= 0:
                yield content[start : pos + len(new_line)]
            else:
                # Yield the rest and finish
                if content[start:]:
                    yield content[start:]
                break

            start = pos + len(new_line)


</t>
<t tx="ekr.20250131013559.807">def extract_codec_from_bom(first_line: bytes) -&gt; str:
    """Try to extract the codec (unicode only) by checking for the BOM.

    For details about BOM see https://unicode.org/faq/utf_bom.html#BOM

    Args:
        first_line: the first line of a file

    Returns:
        a codec name

    Raises:
        ValueError: if no codec was found
    """
    for bom, codec in BOM_SORTED_TO_CODEC.items():
        if first_line.startswith(bom):
            return codec

    raise ValueError("No BOM found. Could not detect Unicode codec.")


</t>
<t tx="ekr.20250131013559.808">class UnicodeChecker(checkers.BaseRawFileChecker):
    """Check characters that could be used to hide bad code to humans.

    This includes:

    - Bidirectional Unicode (see https://trojansource.codes/)

    - Bad ASCII characters (see PEP672)

        If a programmer requires to use such a character they should use the escaped
        version, that is also much easier to read and does not depend on the editor used.

    The Checker also includes a check that UTF-16 and UTF-32 are not used to encode
    Python files.

    At the time of writing Python supported only UTF-8. See
    https://stackoverflow.com/questions/69897842/ and https://bugs.python.org/issue1503789
    for background.
    """

    @others
</t>
<t tx="ekr.20250131013559.809">def register(linter: pylint.lint.PyLinter) -&gt; None:
    linter.register_checker(UnicodeChecker(linter))
</t>
<t tx="ekr.20250131013559.810">name: str
unescaped: str
escaped: str
code: str
help_text: str

def description(self) -&gt; str:
    """Used for the detailed error message description."""
    return (
        f"Invalid unescaped character {self.name}, "
        f'use "{self.escaped}" instead.'
    )

</t>
<t tx="ekr.20250131013559.811">def human_code(self) -&gt; str:
    """Used to generate the human readable error message."""
    return f"invalid-character-{self.name}"


</t>
<t tx="ekr.20250131013559.812">name = "unicode_checker"

msgs = {
    "E2501": (
        # This error will be only displayed to users once Python Supports
        # UTF-16/UTF-32 (if at all)
        "UTF-16 and UTF-32 aren't backward compatible. Use UTF-8 instead",
        "invalid-unicode-codec",
        (
            "For compatibility use UTF-8 instead of UTF-16/UTF-32. "
            "See also https://bugs.python.org/issue1503789 for a history "
            "of this issue. And "
            "https://softwareengineering.stackexchange.com/questions/102205/ "
            "for some possible problems when using UTF-16 for instance."
        ),
    ),
    "E2502": (
        (
            "Contains control characters that can permit obfuscated code "
            "executed differently than displayed"
        ),
        "bidirectional-unicode",
        (
            "bidirectional unicode are typically not displayed characters required "
            "to display right-to-left (RTL) script "
            "(i.e. Chinese, Japanese, Arabic, Hebrew, ...) correctly. "
            "So can you trust this code? "
            "Are you sure it displayed correctly in all editors? "
            "If you did not write it or your language is not RTL,"
            " remove the special characters, as they could be used to trick you into "
            "executing code, "
            "that does something else than what it looks like.\n"
            "More Information:\n"
            "https://en.wikipedia.org/wiki/Bidirectional_text\n"
            "https://trojansource.codes/"
        ),
    ),
    "C2503": (
        "PEP8 recommends UTF-8 as encoding for Python files",
        "bad-file-encoding",
        (
            "PEP8 recommends UTF-8 default encoding for Python files. See "
            "https://peps.python.org/pep-0008/#source-file-encoding"
        ),
    ),
    ** {
        bad_char.code: (
            bad_char.description(),
            bad_char.human_code(),
            bad_char.help_text,
        )
        for bad_char in BAD_CHARS
    },
}

@staticmethod
def _is_invalid_codec(codec: str) -&gt; bool:
    return codec.startswith(("utf-16", "utf-32"))

</t>
<t tx="ekr.20250131013559.813">@staticmethod
def _is_unicode(codec: str) -&gt; bool:
    return codec.startswith("utf")

</t>
<t tx="ekr.20250131013559.814">@classmethod
def _find_line_matches(cls, line: bytes, codec: str) -&gt; dict[int, _BadChar]:
    """Find all matches of BAD_CHARS within line.

    Args:
        line: the input
        codec: that will be used to convert line/or search string into

    Return:
        A dictionary with the column offset and the BadASCIIChar
    """
    # We try to decode in Unicode to get the correct column offset
    # if we would use bytes, it could be off because UTF-8 has no fixed length
    try:
        line_search = line.decode(codec, errors="strict")
        search_dict = BAD_ASCII_SEARCH_DICT
        return _map_positions_to_result(line_search, search_dict, "\n")
    except UnicodeDecodeError:
        # If we can't decode properly, we simply use bytes, even so the column offsets
        # might be wrong a bit, but it is still better then nothing
        line_search_byte = line
        search_dict_byte: dict[bytes, _BadChar] = {}
        for char in BAD_CHARS:
            # Some characters might not exist in all encodings
            with contextlib.suppress(UnicodeDecodeError):
                search_dict_byte[_cached_encode_search(char.unescaped, codec)] = (
                    char
                )

        return _map_positions_to_result(
            line_search_byte,
            search_dict_byte,
            _cached_encode_search("\n", codec),
            byte_str_length=_byte_to_str_length(codec),
        )

</t>
<t tx="ekr.20250131013559.815">@staticmethod
def _determine_codec(stream: io.BytesIO) -&gt; tuple[str, int]:
    """Determine the codec from the given stream.

    first tries https://www.python.org/dev/peps/pep-0263/
    and if this fails also checks for BOMs of UTF-16 and UTF-32
    to be future-proof.

    Args:
        stream: The byte stream to analyse

    Returns: A tuple consisting of:
              - normalized codec name
              - the line in which the codec was found

    Raises:
        SyntaxError: if failing to detect codec
    """
    try:
        # First try to detect encoding with PEP 263
        # Doesn't work with UTF-16/32 at the time of writing
        # see https://bugs.python.org/issue1503789
        codec, lines = detect_encoding(stream.readline)

        # lines are empty if UTF-8 BOM is found
        codec_definition_line = len(lines) or 1
    except SyntaxError as e:
        # Codec could not be detected by Python, we try manually to check for
        # UTF 16/32 BOMs, which aren't supported by Python at the time of writing.
        # This is only included to be future save and handle these codecs as well
        stream.seek(0)
        try:
            codec = extract_codec_from_bom(stream.readline())
            codec_definition_line = 1
        except ValueError as ve:
            # Failed to detect codec, so the syntax error originated not from
            # UTF16/32 codec usage. So simply raise the error again.
            raise e from ve

    return _normalize_codec_name(codec), codec_definition_line

</t>
<t tx="ekr.20250131013559.816">def _check_codec(self, codec: str, codec_definition_line: int) -&gt; None:
    """Check validity of the codec."""
    if codec != "utf-8":
        msg = "bad-file-encoding"
        if self._is_invalid_codec(codec):
            msg = "invalid-unicode-codec"
        self.add_message(
            msg,
            # Currently Nodes will lead to crashes of pylint
            # node=node,
            line=codec_definition_line,
            end_lineno=codec_definition_line,
            confidence=pylint.interfaces.HIGH,
            col_offset=None,
            end_col_offset=None,
        )

</t>
<t tx="ekr.20250131013559.817">def _check_invalid_chars(self, line: bytes, lineno: int, codec: str) -&gt; None:
    """Look for chars considered bad."""
    matches = self._find_line_matches(line, codec)
    for col, char in matches.items():
        self.add_message(
            char.human_code(),
            # Currently Nodes will lead to crashes of pylint
            # node=node,
            line=lineno,
            end_lineno=lineno,
            confidence=pylint.interfaces.HIGH,
            col_offset=col + 1,
            end_col_offset=col + len(char.unescaped) + 1,
        )

</t>
<t tx="ekr.20250131013559.818">def _check_bidi_chars(self, line: bytes, lineno: int, codec: str) -&gt; None:
    """Look for Bidirectional Unicode, if we use unicode."""
    if not self._is_unicode(codec):
        return
    for dangerous in BIDI_UNICODE:
        if _cached_encode_search(dangerous, codec) in line:
            # Note that we don't add a col_offset on purpose:
            #   Using these unicode characters it depends on the editor
            #   how it displays the location of characters in the line.
            #   So we mark the complete line.
            self.add_message(
                "bidirectional-unicode",
                # Currently Nodes will lead to crashes of pylint
                # node=node,
                line=lineno,
                end_lineno=lineno,
                # We mark the complete line, as bidi controls make it hard
                # to determine the correct cursor position within an editor
                col_offset=0,
                end_col_offset=_line_length(line, codec),
                confidence=pylint.interfaces.HIGH,
            )
            # We look for bidirectional unicode only once per line
            # as we mark the complete line anyway
            break

</t>
<t tx="ekr.20250131013559.819">def process_module(self, node: nodes.Module) -&gt; None:
    """Perform the actual check by checking module stream."""
    with node.stream() as stream:
        codec, codec_line = self._determine_codec(stream)
        self._check_codec(codec, codec_line)

        stream.seek(0)

        # Check for invalid content (controls/chars)
        for lineno, line in enumerate(
            _fix_utf16_32_line_stream(stream, codec), start=1
        ):
            if lineno == 1:
                line = _remove_bom(line, codec)
            self._check_bidi_chars(line, lineno, codec)
            self._check_invalid_chars(line, lineno, codec)


</t>
<t tx="ekr.20250131013559.820">@path pylint/checkers
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Checker for features used that are not supported by all python versions
indicated by the py-version setting.
"""

from __future__ import annotations

from typing import TYPE_CHECKING

from astroid import nodes

from pylint.checkers import BaseChecker
from pylint.checkers.utils import (
    only_required_for_messages,
    safe_infer,
    uninferable_final_decorators,
)
from pylint.interfaces import HIGH

if TYPE_CHECKING:
    from pylint.lint import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013559.821">class UnsupportedVersionChecker(BaseChecker):
    """Checker for features that are not supported by all python versions
    indicated by the py-version setting.
    """

    @others
</t>
<t tx="ekr.20250131013559.822">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(UnsupportedVersionChecker(linter))
</t>
<t tx="ekr.20250131013559.823">name = "unsupported_version"
msgs = {
    "W2601": (
        "F-strings are not supported by all versions included in the py-version setting",
        "using-f-string-in-unsupported-version",
        "Used when the py-version set by the user is lower than 3.6 and pylint encounters "
        "an f-string.",
    ),
    "W2602": (
        "typing.final is not supported by all versions included in the py-version setting",
        "using-final-decorator-in-unsupported-version",
        "Used when the py-version set by the user is lower than 3.8 and pylint encounters "
        "a ``typing.final`` decorator.",
    ),
    "W2603": (
        "Exception groups are not supported by all versions included in the py-version setting",
        "using-exception-groups-in-unsupported-version",
        "Used when the py-version set by the user is lower than 3.11 and pylint encounters "
        "``except*`` or `ExceptionGroup``.",
    ),
    "W2604": (
        "Generic type syntax (PEP 695) is not supported by all versions included in the py-version setting",
        "using-generic-type-syntax-in-unsupported-version",
        "Used when the py-version set by the user is lower than 3.12 and pylint encounters "
        "generic type syntax.",
    ),
    "W2605": (
        "Assignment expression is not supported by all versions included in the py-version setting",
        "using-assignment-expression-in-unsupported-version",
        "Used when the py-version set by the user is lower than 3.8 and pylint encounters "
        "an assignment expression (walrus) operator.",
    ),
    "W2606": (
        "Positional-only arguments are not supported by all versions included in the py-version setting",
        "using-positional-only-args-in-unsupported-version",
        "Used when the py-version set by the user is lower than 3.8 and pylint encounters "
        "positional-only arguments.",
    ),
}

def open(self) -&gt; None:
    """Initialize visit variables and statistics."""
    py_version = self.linter.config.py_version
    self._py36_plus = py_version &gt;= (3, 6)
    self._py38_plus = py_version &gt;= (3, 8)
    self._py311_plus = py_version &gt;= (3, 11)
    self._py312_plus = py_version &gt;= (3, 12)

</t>
<t tx="ekr.20250131013559.824">@only_required_for_messages("using-f-string-in-unsupported-version")
def visit_joinedstr(self, node: nodes.JoinedStr) -&gt; None:
    """Check f-strings."""
    if not self._py36_plus:
        self.add_message(
            "using-f-string-in-unsupported-version", node=node, confidence=HIGH
        )

</t>
<t tx="ekr.20250131013559.825">@only_required_for_messages("using-assignment-expression-in-unsupported-version")
def visit_namedexpr(self, node: nodes.JoinedStr) -&gt; None:
    if not self._py38_plus:
        self.add_message(
            "using-assignment-expression-in-unsupported-version",
            node=node,
            confidence=HIGH,
        )

</t>
<t tx="ekr.20250131013559.826">@only_required_for_messages("using-positional-only-args-in-unsupported-version")
def visit_arguments(self, node: nodes.Arguments) -&gt; None:
    if not self._py38_plus and node.posonlyargs:
        self.add_message(
            "using-positional-only-args-in-unsupported-version",
            node=node,
            confidence=HIGH,
        )

</t>
<t tx="ekr.20250131013559.827">@only_required_for_messages("using-final-decorator-in-unsupported-version")
def visit_decorators(self, node: nodes.Decorators) -&gt; None:
    """Check decorators."""
    self._check_typing_final(node)

</t>
<t tx="ekr.20250131013559.828">def _check_typing_final(self, node: nodes.Decorators) -&gt; None:
    """Add a message when the `typing.final` decorator is used and the
    py-version is lower than 3.8.
    """
    if self._py38_plus:
        return

    decorators = []
    for decorator in node.get_children():
        inferred = safe_infer(decorator)
        if inferred and inferred.qname() == "typing.final":
            decorators.append(decorator)

    for decorator in decorators or uninferable_final_decorators(node):
        self.add_message(
            "using-final-decorator-in-unsupported-version",
            node=decorator,
            confidence=HIGH,
        )

</t>
<t tx="ekr.20250131013559.829">@only_required_for_messages("using-exception-groups-in-unsupported-version")
def visit_trystar(self, node: nodes.TryStar) -&gt; None:
    if not self._py311_plus:
        self.add_message(
            "using-exception-groups-in-unsupported-version",
            node=node,
            confidence=HIGH,
        )

</t>
<t tx="ekr.20250131013559.830">@only_required_for_messages("using-exception-groups-in-unsupported-version")
def visit_excepthandler(self, node: nodes.ExceptHandler) -&gt; None:
    if (
        not self._py311_plus
        and isinstance(node.type, nodes.Name)
        and node.type.name == "ExceptionGroup"
    ):
        self.add_message(
            "using-exception-groups-in-unsupported-version",
            node=node,
            confidence=HIGH,
        )

</t>
<t tx="ekr.20250131013559.831">@only_required_for_messages("using-exception-groups-in-unsupported-version")
def visit_raise(self, node: nodes.Raise) -&gt; None:
    if (
        not self._py311_plus
        and isinstance(node.exc, nodes.Call)
        and isinstance(node.exc.func, nodes.Name)
        and node.exc.func.name == "ExceptionGroup"
    ):
        self.add_message(
            "using-exception-groups-in-unsupported-version",
            node=node,
            confidence=HIGH,
        )

</t>
<t tx="ekr.20250131013559.832">@only_required_for_messages("using-generic-type-syntax-in-unsupported-version")
def visit_typealias(self, node: nodes.TypeAlias) -&gt; None:
    if not self._py312_plus:
        self.add_message(
            "using-generic-type-syntax-in-unsupported-version",
            node=node,
            confidence=HIGH,
        )

</t>
<t tx="ekr.20250131013559.833">@only_required_for_messages("using-generic-type-syntax-in-unsupported-version")
def visit_typevar(self, node: nodes.TypeVar) -&gt; None:
    if not self._py312_plus:
        self.add_message(
            "using-generic-type-syntax-in-unsupported-version",
            node=node,
            confidence=HIGH,
        )

</t>
<t tx="ekr.20250131013559.834">@only_required_for_messages("using-generic-type-syntax-in-unsupported-version")
def visit_typevartuple(self, node: nodes.TypeVarTuple) -&gt; None:
    if not self._py312_plus:
        self.add_message(
            "using-generic-type-syntax-in-unsupported-version",
            node=node,
            confidence=HIGH,
        )


</t>
<t tx="ekr.20250131013559.835">@path pylint/checkers
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Some functions that may be useful for various checkers."""

from __future__ import annotations

import _string
import builtins
import fnmatch
import itertools
import numbers
import re
import string
from collections.abc import Callable, Iterable, Iterator
from functools import lru_cache, partial
from re import Match
from typing import TYPE_CHECKING, Any, TypeVar

import astroid.objects
from astroid import TooManyLevelsError, nodes, util
from astroid.context import InferenceContext
from astroid.exceptions import AstroidError
from astroid.nodes._base_nodes import ImportNode, Statement
from astroid.typing import InferenceResult, SuccessfulInferenceResult

from pylint.constants import TYPING_NEVER, TYPING_NORETURN

if TYPE_CHECKING:
    from functools import _lru_cache_wrapper

    from pylint.checkers import BaseChecker

_NodeT = TypeVar("_NodeT", bound=nodes.NodeNG)
_CheckerT = TypeVar("_CheckerT", bound="BaseChecker")
AstCallbackMethod = Callable[[_CheckerT, _NodeT], None]

COMP_NODE_TYPES = (
    nodes.ListComp,
    nodes.SetComp,
    nodes.DictComp,
    nodes.GeneratorExp,
)
EXCEPTIONS_MODULE = "builtins"
ABC_MODULES = {"abc", "_py_abc"}
ABC_METHODS = {
    "abc.abstractproperty",
    "abc.abstractmethod",
    "abc.abstractclassmethod",
    "abc.abstractstaticmethod",
}
TYPING_PROTOCOLS = frozenset(
    {"typing.Protocol", "typing_extensions.Protocol", ".Protocol"}
)
COMMUTATIVE_OPERATORS = frozenset({"*", "+", "^", "&amp;", "|"})
ITER_METHOD = "__iter__"
AITER_METHOD = "__aiter__"
NEXT_METHOD = "__next__"
GETITEM_METHOD = "__getitem__"
CLASS_GETITEM_METHOD = "__class_getitem__"
SETITEM_METHOD = "__setitem__"
DELITEM_METHOD = "__delitem__"
CONTAINS_METHOD = "__contains__"
KEYS_METHOD = "keys"

# Dictionary which maps the number of expected parameters a
# special method can have to a set of special methods.
# The following keys are used to denote the parameters restrictions:
#
# * None: variable number of parameters
# * number: exactly that number of parameters
# * tuple: these are the odd ones. Basically it means that the function
#          can work with any number of arguments from that tuple,
#          although it's best to implement it in order to accept
#          all of them.
_SPECIAL_METHODS_PARAMS = {
    None: ("__new__", "__init__", "__call__", "__init_subclass__"),
    0: (
        "__del__",
        "__repr__",
        "__str__",
        "__bytes__",
        "__hash__",
        "__bool__",
        "__dir__",
        "__len__",
        "__length_hint__",
        "__iter__",
        "__reversed__",
        "__neg__",
        "__pos__",
        "__abs__",
        "__invert__",
        "__complex__",
        "__int__",
        "__float__",
        "__index__",
        "__trunc__",
        "__floor__",
        "__ceil__",
        "__enter__",
        "__aenter__",
        "__getnewargs_ex__",
        "__getnewargs__",
        "__getstate__",
        "__reduce__",
        "__copy__",
        "__unicode__",
        "__nonzero__",
        "__await__",
        "__aiter__",
        "__anext__",
        "__fspath__",
        "__subclasses__",
    ),
    1: (
        "__format__",
        "__lt__",
        "__le__",
        "__eq__",
        "__ne__",
        "__gt__",
        "__ge__",
        "__getattr__",
        "__getattribute__",
        "__delattr__",
        "__delete__",
        "__instancecheck__",
        "__subclasscheck__",
        "__getitem__",
        "__missing__",
        "__delitem__",
        "__contains__",
        "__add__",
        "__sub__",
        "__mul__",
        "__truediv__",
        "__floordiv__",
        "__rfloordiv__",
        "__mod__",
        "__divmod__",
        "__lshift__",
        "__rshift__",
        "__and__",
        "__xor__",
        "__or__",
        "__radd__",
        "__rsub__",
        "__rmul__",
        "__rtruediv__",
        "__rmod__",
        "__rdivmod__",
        "__rpow__",
        "__rlshift__",
        "__rrshift__",
        "__rand__",
        "__rxor__",
        "__ror__",
        "__iadd__",
        "__isub__",
        "__imul__",
        "__itruediv__",
        "__ifloordiv__",
        "__imod__",
        "__ilshift__",
        "__irshift__",
        "__iand__",
        "__ixor__",
        "__ior__",
        "__ipow__",
        "__setstate__",
        "__reduce_ex__",
        "__deepcopy__",
        "__cmp__",
        "__matmul__",
        "__rmatmul__",
        "__imatmul__",
        "__div__",
    ),
    2: ("__setattr__", "__get__", "__set__", "__setitem__", "__set_name__"),
    3: ("__exit__", "__aexit__"),
    (0, 1): ("__round__",),
    (1, 2): ("__pow__",),
}

SPECIAL_METHODS_PARAMS = {
    name: params
    for params, methods in _SPECIAL_METHODS_PARAMS.items()
    for name in methods
}
PYMETHODS = set(SPECIAL_METHODS_PARAMS)

SUBSCRIPTABLE_CLASSES_PEP585 = frozenset(
    (
        "builtins.tuple",
        "builtins.list",
        "builtins.dict",
        "builtins.set",
        "builtins.frozenset",
        "builtins.type",
        "collections.deque",
        "collections.defaultdict",
        "collections.OrderedDict",
        "collections.Counter",
        "collections.ChainMap",
        "_collections_abc.Awaitable",
        "_collections_abc.Coroutine",
        "_collections_abc.AsyncIterable",
        "_collections_abc.AsyncIterator",
        "_collections_abc.AsyncGenerator",
        "_collections_abc.Iterable",
        "_collections_abc.Iterator",
        "_collections_abc.Generator",
        "_collections_abc.Reversible",
        "_collections_abc.Container",
        "_collections_abc.Collection",
        "_collections_abc.Callable",
        "_collections_abc.Set",
        "_collections_abc.MutableSet",
        "_collections_abc.Mapping",
        "_collections_abc.MutableMapping",
        "_collections_abc.Sequence",
        "_collections_abc.MutableSequence",
        "_collections_abc.ByteString",
        "_collections_abc.MappingView",
        "_collections_abc.KeysView",
        "_collections_abc.ItemsView",
        "_collections_abc.ValuesView",
        "contextlib.AbstractContextManager",
        "contextlib.AbstractAsyncContextManager",
        "re.Pattern",
        "re.Match",
    )
)

SINGLETON_VALUES = {True, False, None}

TERMINATING_FUNCS_QNAMES = frozenset(
    {"_sitebuiltins.Quitter", "sys.exit", "posix._exit", "nt._exit"}
)


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.1">class NoSuchArgumentError(Exception):
    pass


</t>
<t tx="ekr.20250131013600.10">def is_defined_before(var_node: nodes.Name) -&gt; bool:
    """Check if the given variable node is defined before.

    Verify that the variable node is defined by a parent node
    (e.g. if or with) earlier than `var_node`, or is defined by a
    (list, set, dict, or generator comprehension, lambda)
    or in a previous sibling node on the same line
    (statement_defining ; statement_using).
    """
    varname = var_node.name
    for parent in var_node.node_ancestors():
        defnode = defnode_in_scope(var_node, varname, parent)
        if defnode is None:
            continue
        defnode_scope = defnode.scope()
        if isinstance(
            defnode_scope, (*COMP_NODE_TYPES, nodes.Lambda, nodes.FunctionDef)
        ):
            # Avoid the case where var_node_scope is a nested function
            if isinstance(defnode_scope, nodes.FunctionDef):
                var_node_scope = var_node.scope()
                if var_node_scope is not defnode_scope and isinstance(
                    var_node_scope, nodes.FunctionDef
                ):
                    return False
            return True
        if defnode.lineno &lt; var_node.lineno:
            return True
        # `defnode` and `var_node` on the same line
        for defnode_anc in defnode.node_ancestors():
            if defnode_anc.lineno != var_node.lineno:
                continue
            if isinstance(
                defnode_anc,
                (
                    nodes.For,
                    nodes.While,
                    nodes.With,
                    nodes.Try,
                    nodes.ExceptHandler,
                ),
            ):
                return True
    # possibly multiple statements on the same line using semicolon separator
    stmt = var_node.statement()
    _node = stmt.previous_sibling()
    lineno = stmt.fromlineno
    while _node and _node.fromlineno == lineno:
        for assign_node in _node.nodes_of_class(nodes.AssignName):
            if assign_node.name == varname:
                return True
        for imp_node in _node.nodes_of_class((nodes.ImportFrom, nodes.Import)):
            if varname in [name[1] or name[0] for name in imp_node.names]:
                return True
        _node = _node.previous_sibling()
    return False


</t>
<t tx="ekr.20250131013600.100">def is_function_body_ellipsis(node: nodes.FunctionDef) -&gt; bool:
    """Checks whether a function body only consists of a single Ellipsis."""
    return (
        len(node.body) == 1
        and isinstance(node.body[0], nodes.Expr)
        and isinstance(node.body[0].value, nodes.Const)
        and node.body[0].value.value == Ellipsis
    )


</t>
<t tx="ekr.20250131013600.1000">def _check_in_comparison(self, comparator: nodes.NodeNG) -&gt; None:
    """Checks for membership comparisons with in-place container objects."""
    if not isinstance(comparator, nodes.BaseContainer) or isinstance(
        comparator, nodes.Set
    ):
        return

    # Heuristic - We need to be sure all items in set are hashable
    if all(isinstance(item, nodes.Const) for item in comparator.elts):
        self.add_message("use-set-for-membership", node=comparator)


</t>
<t tx="ekr.20250131013600.1001">@path pylint/extensions
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

from typing import TYPE_CHECKING, NamedTuple

import astroid.bases
from astroid import nodes

from pylint.checkers import BaseChecker
from pylint.checkers.utils import (
    in_type_checking_block,
    is_node_in_type_annotation_context,
    is_postponed_evaluation_enabled,
    only_required_for_messages,
    safe_infer,
)
from pylint.constants import TYPING_NORETURN
from pylint.interfaces import HIGH, INFERENCE

if TYPE_CHECKING:
    from pylint.lint import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.1002">class TypingAlias(NamedTuple):
    name: str
    name_collision: bool


</t>
<t tx="ekr.20250131013600.1003">DEPRECATED_TYPING_ALIASES: dict[str, TypingAlias] = {
    "typing.Tuple": TypingAlias("tuple", False),
    "typing.List": TypingAlias("list", False),
    "typing.Dict": TypingAlias("dict", False),
    "typing.Set": TypingAlias("set", False),
    "typing.FrozenSet": TypingAlias("frozenset", False),
    "typing.Type": TypingAlias("type", False),
    "typing.Deque": TypingAlias("collections.deque", True),
    "typing.DefaultDict": TypingAlias("collections.defaultdict", True),
    "typing.OrderedDict": TypingAlias("collections.OrderedDict", True),
    "typing.Counter": TypingAlias("collections.Counter", True),
    "typing.ChainMap": TypingAlias("collections.ChainMap", True),
    "typing.Awaitable": TypingAlias("collections.abc.Awaitable", True),
    "typing.Coroutine": TypingAlias("collections.abc.Coroutine", True),
    "typing.AsyncIterable": TypingAlias("collections.abc.AsyncIterable", True),
    "typing.AsyncIterator": TypingAlias("collections.abc.AsyncIterator", True),
    "typing.AsyncGenerator": TypingAlias("collections.abc.AsyncGenerator", True),
    "typing.Iterable": TypingAlias("collections.abc.Iterable", True),
    "typing.Iterator": TypingAlias("collections.abc.Iterator", True),
    "typing.Generator": TypingAlias("collections.abc.Generator", True),
    "typing.Reversible": TypingAlias("collections.abc.Reversible", True),
    "typing.Container": TypingAlias("collections.abc.Container", True),
    "typing.Collection": TypingAlias("collections.abc.Collection", True),
    "typing.Callable": TypingAlias("collections.abc.Callable", True),
    "typing.AbstractSet": TypingAlias("collections.abc.Set", False),
    "typing.MutableSet": TypingAlias("collections.abc.MutableSet", True),
    "typing.Mapping": TypingAlias("collections.abc.Mapping", True),
    "typing.MutableMapping": TypingAlias("collections.abc.MutableMapping", True),
    "typing.Sequence": TypingAlias("collections.abc.Sequence", True),
    "typing.MutableSequence": TypingAlias("collections.abc.MutableSequence", True),
    "typing.ByteString": TypingAlias("collections.abc.ByteString", True),
    "typing.MappingView": TypingAlias("collections.abc.MappingView", True),
    "typing.KeysView": TypingAlias("collections.abc.KeysView", True),
    "typing.ItemsView": TypingAlias("collections.abc.ItemsView", True),
    "typing.ValuesView": TypingAlias("collections.abc.ValuesView", True),
    "typing.ContextManager": TypingAlias("contextlib.AbstractContextManager", False),
    "typing.AsyncContextManager": TypingAlias(
        "contextlib.AbstractAsyncContextManager", False
    ),
    "typing.Pattern": TypingAlias("re.Pattern", True),
    "typing.Match": TypingAlias("re.Match", True),
    "typing.Hashable": TypingAlias("collections.abc.Hashable", True),
    "typing.Sized": TypingAlias("collections.abc.Sized", True),
}

ALIAS_NAMES = frozenset(key.split(".")[1] for key in DEPRECATED_TYPING_ALIASES)
UNION_NAMES = ("Optional", "Union")


class DeprecatedTypingAliasMsg(NamedTuple):
    node: nodes.Name | nodes.Attribute
    qname: str
    alias: str
    parent_subscript: bool = False


</t>
<t tx="ekr.20250131013600.1004"># pylint: disable-next=too-many-instance-attributes
class TypingChecker(BaseChecker):
    """Find issue specifically related to type annotations."""

    @others
</t>
<t tx="ekr.20250131013600.1005">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(TypingChecker(linter))
</t>
<t tx="ekr.20250131013600.1006">name = "typing"
msgs = {
    "W6001": (
        "'%s' is deprecated, use '%s' instead",
        "deprecated-typing-alias",
        "Emitted when a deprecated typing alias is used.",
    ),
    "R6002": (
        "'%s' will be deprecated with PY39, consider using '%s' instead%s",
        "consider-using-alias",
        "Only emitted if 'runtime-typing=no' and a deprecated "
        "typing alias is used in a type annotation context in "
        "Python 3.7 or 3.8.",
    ),
    "R6003": (
        "Consider using alternative union syntax instead of '%s'%s",
        "consider-alternative-union-syntax",
        "Emitted when ``typing.Union`` or ``typing.Optional`` is used "
        "instead of the shorthand union syntax. For example, "
        "``Union[int, float]`` instead of ``int | float``. Using "
        "the shorthand for unions aligns with Python typing "
        "recommendations, removes the need for imports, and avoids "
        "confusion in function signatures.",
    ),
    "E6004": (
        "'NoReturn' inside compound types is broken in 3.7.0 / 3.7.1",
        "broken-noreturn",
        "``typing.NoReturn`` inside compound types is broken in "
        "Python 3.7.0 and 3.7.1. If not dependent on runtime introspection, "
        "use string annotation instead. E.g. "
        "``Callable[..., 'NoReturn']``. https://bugs.python.org/issue34921",
    ),
    "E6005": (
        "'collections.abc.Callable' inside Optional and Union is broken in "
        "3.9.0 / 3.9.1 (use 'typing.Callable' instead)",
        "broken-collections-callable",
        "``collections.abc.Callable`` inside Optional and Union is broken in "
        "Python 3.9.0 and 3.9.1. Use ``typing.Callable`` for these cases instead. "
        "https://bugs.python.org/issue42965",
    ),
    "R6006": (
        "Type `%s` is used more than once in union type annotation. Remove redundant typehints.",
        "redundant-typehint-argument",
        "Duplicated type arguments will be skipped by `mypy` tool, therefore should be "
        "removed to avoid confusion.",
    ),
    "R6007": (
        "Type `%s` has unnecessary default type args. Change it to `%s`.",
        "unnecessary-default-type-args",
        "Emitted when types have default type args which can be omitted. "
        "Mainly used for `typing.Generator` and `typing.AsyncGenerator`.",
    ),
}
options = (
    (
        "runtime-typing",
        {
            "default": True,
            "type": "yn",
            "metavar": "&lt;y or n&gt;",
            "help": (
                "Set to ``no`` if the app / library does **NOT** need to "
                "support runtime introspection of type annotations. "
                "If you use type annotations **exclusively** for type checking "
                "of an application, you're probably fine. For libraries, "
                "evaluate if some users want to access the type hints "
                "at runtime first, e.g., through ``typing.get_type_hints``. "
                "Applies to Python versions 3.7 - 3.9"
            ),
        },
    ),
)

_should_check_typing_alias: bool
"""The use of type aliases (PEP 585) requires Python 3.9
or Python 3.7+ with postponed evaluation.
"""

_should_check_alternative_union_syntax: bool
"""The use of alternative union syntax (PEP 604) requires Python 3.10
or Python 3.7+ with postponed evaluation.
"""

def __init__(self, linter: PyLinter) -&gt; None:
    """Initialize checker instance."""
    super().__init__(linter=linter)
    self._found_broken_callable_location: bool = False
    self._alias_name_collisions: set[str] = set()
    self._deprecated_typing_alias_msgs: list[DeprecatedTypingAliasMsg] = []
    self._consider_using_alias_msgs: list[DeprecatedTypingAliasMsg] = []

</t>
<t tx="ekr.20250131013600.1007">def open(self) -&gt; None:
    py_version = self.linter.config.py_version
    self._py37_plus = py_version &gt;= (3, 7)
    self._py39_plus = py_version &gt;= (3, 9)
    self._py310_plus = py_version &gt;= (3, 10)
    self._py313_plus = py_version &gt;= (3, 13)

    self._should_check_typing_alias = self._py39_plus or (
        self._py37_plus and self.linter.config.runtime_typing is False
    )
    self._should_check_alternative_union_syntax = self._py310_plus or (
        self._py37_plus and self.linter.config.runtime_typing is False
    )

    self._should_check_noreturn = py_version &lt; (3, 7, 2)
    self._should_check_callable = py_version &lt; (3, 9, 2)

</t>
<t tx="ekr.20250131013600.1008">def _msg_postponed_eval_hint(self, node: nodes.NodeNG) -&gt; str:
    """Message hint if postponed evaluation isn't enabled."""
    if self._py310_plus or "annotations" in node.root().future_imports:
        return ""
    return ". Add 'from __future__ import annotations' as well"

</t>
<t tx="ekr.20250131013600.1009">@only_required_for_messages(
    "deprecated-typing-alias",
    "consider-using-alias",
    "consider-alternative-union-syntax",
    "broken-noreturn",
    "broken-collections-callable",
)
def visit_name(self, node: nodes.Name) -&gt; None:
    if self._should_check_typing_alias and node.name in ALIAS_NAMES:
        self._check_for_typing_alias(node)
    if self._should_check_alternative_union_syntax and node.name in UNION_NAMES:
        self._check_for_alternative_union_syntax(node, node.name)
    if self._should_check_noreturn and node.name == "NoReturn":
        self._check_broken_noreturn(node)
    if self._should_check_callable and node.name == "Callable":
        self._check_broken_callable(node)

</t>
<t tx="ekr.20250131013600.101">def is_base_container(node: nodes.NodeNG | None) -&gt; bool:
    return isinstance(node, nodes.BaseContainer) and not node.elts


</t>
<t tx="ekr.20250131013600.1010">@only_required_for_messages(
    "deprecated-typing-alias",
    "consider-using-alias",
    "consider-alternative-union-syntax",
    "broken-noreturn",
    "broken-collections-callable",
)
def visit_attribute(self, node: nodes.Attribute) -&gt; None:
    if self._should_check_typing_alias and node.attrname in ALIAS_NAMES:
        self._check_for_typing_alias(node)
    if self._should_check_alternative_union_syntax and node.attrname in UNION_NAMES:
        self._check_for_alternative_union_syntax(node, node.attrname)
    if self._should_check_noreturn and node.attrname == "NoReturn":
        self._check_broken_noreturn(node)
    if self._should_check_callable and node.attrname == "Callable":
        self._check_broken_callable(node)

</t>
<t tx="ekr.20250131013600.1011">@only_required_for_messages("redundant-typehint-argument")
def visit_annassign(self, node: nodes.AnnAssign) -&gt; None:
    annotation = node.annotation
    if self._is_deprecated_union_annotation(annotation, "Optional"):
        if self._is_optional_none_annotation(annotation):
            self.add_message(
                "redundant-typehint-argument",
                node=annotation,
                args="None",
                confidence=HIGH,
            )
        return
    if self._is_deprecated_union_annotation(annotation, "Union") and isinstance(
        annotation.slice, nodes.Tuple
    ):
        types = annotation.slice.elts
    elif self._is_binop_union_annotation(annotation):
        types = self._parse_binops_typehints(annotation)
    else:
        return

    self._check_union_types(types, node)

</t>
<t tx="ekr.20250131013600.1012">@only_required_for_messages("unnecessary-default-type-args")
def visit_subscript(self, node: nodes.Subscript) -&gt; None:
    inferred = safe_infer(node.value)
    if (  # pylint: disable=too-many-boolean-expressions
        isinstance(inferred, nodes.ClassDef)
        and (
            (
                inferred.qname() in {"typing.Generator", "typing.AsyncGenerator"}
                and self._py313_plus
            )
            or inferred.qname()
            in {"_collections_abc.Generator", "_collections_abc.AsyncGenerator"}
        )
        and isinstance(node.slice, nodes.Tuple)
        and all(
            (isinstance(el, nodes.Const) and el.value is None)
            for el in node.slice.elts[1:]
        )
    ):
        suggested_str = (
            f"{node.value.as_string()}[{node.slice.elts[0].as_string()}]"
        )
        self.add_message(
            "unnecessary-default-type-args",
            args=(node.as_string(), suggested_str),
            node=node,
            confidence=HIGH,
        )

</t>
<t tx="ekr.20250131013600.1013">@staticmethod
def _is_deprecated_union_annotation(
    annotation: nodes.NodeNG, union_name: str
) -&gt; bool:
    return (
        isinstance(annotation, nodes.Subscript)
        and isinstance(annotation.value, nodes.Name)
        and annotation.value.name == union_name
    )

</t>
<t tx="ekr.20250131013600.1014">def _is_binop_union_annotation(self, annotation: nodes.NodeNG) -&gt; bool:
    return self._should_check_alternative_union_syntax and isinstance(
        annotation, nodes.BinOp
    )

</t>
<t tx="ekr.20250131013600.1015">@staticmethod
def _is_optional_none_annotation(annotation: nodes.Subscript) -&gt; bool:
    return (
        isinstance(annotation.slice, nodes.Const) and annotation.slice.value is None
    )

</t>
<t tx="ekr.20250131013600.1016">def _parse_binops_typehints(
    self, binop_node: nodes.BinOp, typehints_list: list[nodes.NodeNG] | None = None
) -&gt; list[nodes.NodeNG]:
    typehints_list = typehints_list or []
    if isinstance(binop_node.left, nodes.BinOp):
        typehints_list.extend(
            self._parse_binops_typehints(binop_node.left, typehints_list)
        )
    else:
        typehints_list.append(binop_node.left)
    typehints_list.append(binop_node.right)
    return typehints_list

</t>
<t tx="ekr.20250131013600.1017">def _check_union_types(
    self, types: list[nodes.NodeNG], annotation: nodes.NodeNG
) -&gt; None:
    types_set = set()
    for typehint in types:
        typehint_str = typehint.as_string()
        if typehint_str in types_set:
            self.add_message(
                "redundant-typehint-argument",
                node=annotation,
                args=(typehint_str),
                confidence=HIGH,
            )
        else:
            types_set.add(typehint_str)

</t>
<t tx="ekr.20250131013600.1018">def _check_for_alternative_union_syntax(
    self,
    node: nodes.Name | nodes.Attribute,
    name: str,
) -&gt; None:
    """Check if alternative union syntax could be used.

    Requires
    - Python 3.10
    - OR: Python 3.7+ with postponed evaluation in
          a type annotation context
    """
    inferred = safe_infer(node)
    if not (
        (
            isinstance(inferred, nodes.FunctionDef)
            and inferred.qname() in {"typing.Optional", "typing.Union"}
        )
        or (
            isinstance(inferred, astroid.bases.Instance)
            and inferred.qname() == "typing._SpecialForm"
        )
    ):
        return
    if not (self._py310_plus or is_node_in_type_annotation_context(node)):
        return
    self.add_message(
        "consider-alternative-union-syntax",
        node=node,
        args=(name, self._msg_postponed_eval_hint(node)),
        confidence=INFERENCE,
    )

</t>
<t tx="ekr.20250131013600.1019">def _check_for_typing_alias(
    self,
    node: nodes.Name | nodes.Attribute,
) -&gt; None:
    """Check if typing alias is deprecated or could be replaced.

    Requires
    - Python 3.9
    - OR: Python 3.7+ with postponed evaluation in
          a type annotation context

    For Python 3.7+: Only emit message if change doesn't create
        any name collisions, only ever used in a type annotation
        context, and can safely be replaced.
    """
    inferred = safe_infer(node)
    if not isinstance(inferred, nodes.ClassDef):
        return
    alias = DEPRECATED_TYPING_ALIASES.get(inferred.qname(), None)
    if alias is None:
        return

    if self._py39_plus:
        if inferred.qname() == "typing.Callable" and self._broken_callable_location(
            node
        ):
            self._found_broken_callable_location = True
        self._deprecated_typing_alias_msgs.append(
            DeprecatedTypingAliasMsg(
                node,
                inferred.qname(),
                alias.name,
            )
        )
        return

    # For PY37+, check for type annotation context first
    if not is_node_in_type_annotation_context(node) and isinstance(
        node.parent, nodes.Subscript
    ):
        if alias.name_collision is True:
            self._alias_name_collisions.add(inferred.qname())
        return
    self._consider_using_alias_msgs.append(
        DeprecatedTypingAliasMsg(
            node,
            inferred.qname(),
            alias.name,
            isinstance(node.parent, nodes.Subscript),
        )
    )

</t>
<t tx="ekr.20250131013600.102">def is_empty_dict_literal(node: nodes.NodeNG | None) -&gt; bool:
    return isinstance(node, nodes.Dict) and not node.items


</t>
<t tx="ekr.20250131013600.1020">@only_required_for_messages("consider-using-alias", "deprecated-typing-alias")
def leave_module(self, node: nodes.Module) -&gt; None:
    """After parsing of module is complete, add messages for
    'consider-using-alias' check.

    Make sure results are safe to recommend / collision free.
    """
    if self._py39_plus:
        for msg in self._deprecated_typing_alias_msgs:
            if (
                self._found_broken_callable_location
                and msg.qname == "typing.Callable"
            ):
                continue
            self.add_message(
                "deprecated-typing-alias",
                node=msg.node,
                args=(msg.qname, msg.alias),
                confidence=INFERENCE,
            )

    elif self._py37_plus:
        msg_future_import = self._msg_postponed_eval_hint(node)
        for msg in self._consider_using_alias_msgs:
            if msg.qname in self._alias_name_collisions:
                continue
            self.add_message(
                "consider-using-alias",
                node=msg.node,
                args=(
                    msg.qname,
                    msg.alias,
                    msg_future_import if msg.parent_subscript else "",
                ),
                confidence=INFERENCE,
            )

    # Clear all module cache variables
    self._found_broken_callable_location = False
    self._deprecated_typing_alias_msgs.clear()
    self._alias_name_collisions.clear()
    self._consider_using_alias_msgs.clear()

</t>
<t tx="ekr.20250131013600.1021">def _check_broken_noreturn(self, node: nodes.Name | nodes.Attribute) -&gt; None:
    """Check for 'NoReturn' inside compound types."""
    if not isinstance(node.parent, nodes.BaseContainer):
        # NoReturn not part of a Union or Callable type
        return

    if in_type_checking_block(node) or (
        is_postponed_evaluation_enabled(node)
        and is_node_in_type_annotation_context(node)
    ):
        return

    for inferred in node.infer():
        # To deal with typing_extensions, don't use safe_infer
        if (
            (
                isinstance(inferred, (nodes.FunctionDef, nodes.ClassDef))
                and inferred.qname() in TYPING_NORETURN
            )
            # In Python 3.7 - 3.8, NoReturn is alias of '_SpecialForm'
            or (
                isinstance(inferred, astroid.bases.BaseInstance)
                and isinstance(inferred._proxied, nodes.ClassDef)
                and inferred._proxied.qname() == "typing._SpecialForm"
            )
        ):
            self.add_message("broken-noreturn", node=node, confidence=INFERENCE)
            break

</t>
<t tx="ekr.20250131013600.1022">def _check_broken_callable(self, node: nodes.Name | nodes.Attribute) -&gt; None:
    """Check for 'collections.abc.Callable' inside Optional and Union."""
    inferred = safe_infer(node)
    if not (
        isinstance(inferred, nodes.ClassDef)
        and inferred.qname() == "_collections_abc.Callable"
        and self._broken_callable_location(node)
    ):
        return

    self.add_message("broken-collections-callable", node=node, confidence=INFERENCE)

</t>
<t tx="ekr.20250131013600.1023">def _broken_callable_location(self, node: nodes.Name | nodes.Attribute) -&gt; bool:
    """Check if node would be a broken location for collections.abc.Callable."""
    if in_type_checking_block(node) or (
        is_postponed_evaluation_enabled(node)
        and is_node_in_type_annotation_context(node)
    ):
        return False

    # Check first Callable arg is a list of arguments -&gt; Callable[[int], None]
    if not (
        isinstance(node.parent, nodes.Subscript)
        and isinstance(node.parent.slice, nodes.Tuple)
        and len(node.parent.slice.elts) == 2
        and isinstance(node.parent.slice.elts[0], nodes.List)
    ):
        return False

    # Check nested inside Optional or Union
    parent_subscript = node.parent.parent
    if isinstance(parent_subscript, nodes.BaseContainer):
        parent_subscript = parent_subscript.parent
    if not (
        isinstance(parent_subscript, nodes.Subscript)
        and isinstance(parent_subscript.value, (nodes.Name, nodes.Attribute))
    ):
        return False

    inferred_parent = safe_infer(parent_subscript.value)
    if not (
        (
            isinstance(inferred_parent, nodes.FunctionDef)
            and inferred_parent.qname() in {"typing.Optional", "typing.Union"}
        )
        or (
            isinstance(inferred_parent, astroid.bases.Instance)
            and inferred_parent.qname() == "typing._SpecialForm"
        )
    ):
        return False

    return True


</t>
<t tx="ekr.20250131013600.1024">@path pylint/extensions
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Check for use of while loops."""

from __future__ import annotations

from typing import TYPE_CHECKING

from astroid import nodes

from pylint.checkers import BaseChecker
from pylint.checkers.utils import only_required_for_messages

if TYPE_CHECKING:
    from pylint.lint import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.1025">class WhileChecker(BaseChecker):
    @others
</t>
<t tx="ekr.20250131013600.1026">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(WhileChecker(linter))
</t>
<t tx="ekr.20250131013600.1027">name = "while_used"
msgs = {
    "W0149": (
        "Used `while` loop",
        "while-used",
        "Unbounded `while` loops can often be rewritten as bounded `for` loops. "
        "Exceptions can be made for cases such as event loops, listeners, etc.",
    )
}

@only_required_for_messages("while-used")
def visit_while(self, node: nodes.While) -&gt; None:
    self.add_message("while-used", node=node)


</t>
<t tx="ekr.20250131013600.1028"></t>
<t tx="ekr.20250131013600.1029">@path pylint/lint
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Pylint [options] modules_or_packages.

Check that module(s) satisfy a coding standard (and more !).

pylint --help

Display this help message and exit.

pylint --help-msg &lt;msg-id&gt;[,&lt;msg-id&gt;]

Display help messages about given message identifiers and exit.
"""
import sys

from pylint.config.exceptions import ArgumentPreprocessingError
from pylint.lint.caching import load_results, save_results
from pylint.lint.expand_modules import discover_package_path
from pylint.lint.parallel import check_parallel
from pylint.lint.pylinter import PyLinter
from pylint.lint.report_functions import (
    report_messages_by_module_stats,
    report_messages_stats,
    report_total_messages_stats,
)
from pylint.lint.run import Run
from pylint.lint.utils import _augment_sys_path, augmented_sys_path

__all__ = [
    "ArgumentPreprocessingError",
    "PyLinter",
    "Run",
    "_augment_sys_path",
    "augmented_sys_path",
    "check_parallel",
    "discover_package_path",
    "load_results",
    "report_messages_by_module_stats",
    "report_messages_stats",
    "report_total_messages_stats",
    "save_results",
]

if __name__ == "__main__":
    Run(sys.argv[1:])
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.103">def is_empty_str_literal(node: nodes.NodeNG | None) -&gt; bool:
    return (
        isinstance(node, nodes.Const) and isinstance(node.value, str) and not node.value
    )


</t>
<t tx="ekr.20250131013600.1030">@path pylint/lint
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Functions that creates the basic options for the Run and PyLinter classes."""

from __future__ import annotations

import re
import sys
from typing import TYPE_CHECKING

from pylint import constants, interfaces
from pylint.config.callback_actions import (
    _DisableAction,
    _DoNothingAction,
    _EnableAction,
    _ErrorsOnlyModeAction,
    _FullDocumentationAction,
    _GenerateConfigFileAction,
    _GenerateRCFileAction,
    _ListCheckGroupsAction,
    _ListConfidenceLevelsAction,
    _ListExtensionsAction,
    _ListMessagesAction,
    _ListMessagesEnabledAction,
    _LongHelpAction,
    _MessageHelpAction,
    _OutputFormatAction,
)
from pylint.typing import Options

if TYPE_CHECKING:
    from pylint.lint import PyLinter, Run


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.1031">def _make_linter_options(linter: PyLinter) -&gt; Options:
    """Return the options used in a PyLinter class."""
    return (
        (
            "ignore",
            {
                "type": "csv",
                "metavar": "&lt;file&gt;[,&lt;file&gt;...]",
                "dest": "black_list",
                "kwargs": {"old_names": ["black_list"]},
                "default": constants.DEFAULT_IGNORE_LIST,
                "help": "Files or directories to be skipped. "
                "They should be base names, not paths.",
            },
        ),
        (
            "ignore-patterns",
            {
                "type": "regexp_csv",
                "metavar": "&lt;pattern&gt;[,&lt;pattern&gt;...]",
                "dest": "black_list_re",
                "default": (re.compile(r"^\.#"),),
                "help": "Files or directories matching the regular expression patterns are"
                " skipped. The regex matches against base names, not paths. The default value "
                "ignores Emacs file locks",
            },
        ),
        (
            "ignore-paths",
            {
                "type": "regexp_paths_csv",
                "metavar": "&lt;pattern&gt;[,&lt;pattern&gt;...]",
                "default": [],
                "help": "Add files or directories matching the regular expressions patterns to the "
                "ignore-list. The regex matches against paths and can be in "
                "Posix or Windows format. Because '\\\\' represents the directory delimiter "
                "on Windows systems, it can't be used as an escape character.",
            },
        ),
        (
            "persistent",
            {
                "default": True,
                "type": "yn",
                "metavar": "&lt;y or n&gt;",
                "help": "Pickle collected data for later comparisons.",
            },
        ),
        (
            "load-plugins",
            {
                "type": "csv",
                "metavar": "&lt;modules&gt;",
                "default": (),
                "help": "List of plugins (as comma separated values of "
                "python module names) to load, usually to register "
                "additional checkers.",
            },
        ),
        (
            "output-format",
            {
                "default": "text",
                "action": _OutputFormatAction,
                "callback": lambda x: x,
                "metavar": "&lt;format&gt;",
                "short": "f",
                "group": "Reports",
                "help": "Set the output format. Available formats are: text, "
                "parseable, colorized, json2 (improved json format), json "
                "(old json format) and msvs (visual studio). "
                "You can also give a reporter class, e.g. mypackage.mymodule."
                "MyReporterClass.",
                "kwargs": {"linter": linter},
            },
        ),
        (
            "reports",
            {
                "default": False,
                "type": "yn",
                "metavar": "&lt;y or n&gt;",
                "short": "r",
                "group": "Reports",
                "help": "Tells whether to display a full report or only the "
                "messages.",
            },
        ),
        (
            "evaluation",
            {
                "type": "string",
                "metavar": "&lt;python_expression&gt;",
                "group": "Reports",
                "default": "max(0, 0 if fatal else 10.0 - ((float(5 * error + warning + refactor + "
                "convention) / statement) * 10))",
                "help": "Python expression which should return a score less "
                "than or equal to 10. You have access to the variables 'fatal', "
                "'error', 'warning', 'refactor', 'convention', and 'info' which "
                "contain the number of messages in each category, as well as "
                "'statement' which is the total number of statements "
                "analyzed. This score is used by the global "
                "evaluation report (RP0004).",
            },
        ),
        (
            "score",
            {
                "default": True,
                "type": "yn",
                "metavar": "&lt;y or n&gt;",
                "short": "s",
                "group": "Reports",
                "help": "Activate the evaluation score.",
            },
        ),
        (
            "fail-under",
            {
                "default": 10,
                "type": "float",
                "metavar": "&lt;score&gt;",
                "help": "Specify a score threshold under which the program will exit with error.",
            },
        ),
        (
            "fail-on",
            {
                "default": "",
                "type": "csv",
                "metavar": "&lt;msg ids&gt;",
                "help": "Return non-zero exit code if any of these messages/categories are detected,"
                " even if score is above --fail-under value. Syntax same as enable."
                " Messages specified are enabled, while categories only check already-enabled messages.",
            },
        ),
        (
            "confidence",
            {
                "type": "confidence",
                "metavar": "&lt;levels&gt;",
                "default": interfaces.CONFIDENCE_LEVEL_NAMES,
                "group": "Messages control",
                "help": "Only show warnings with the listed confidence levels."
                f" Leave empty to show all. Valid levels: {', '.join(interfaces.CONFIDENCE_LEVEL_NAMES)}.",
            },
        ),
        (
            "enable",
            {
                "action": _EnableAction,
                "callback": lambda x1, x2, x3, x4: x1,
                "default": (),
                "metavar": "&lt;msg ids&gt;",
                "short": "e",
                "group": "Messages control",
                "help": "Enable the message, report, category or checker with the "
                "given id(s). You can either give multiple identifier "
                "separated by comma (,) or put this option multiple time "
                "(only on the command line, not in the configuration file "
                "where it should appear only once). "
                'See also the "--disable" option for examples.',
                "kwargs": {"linter": linter},
            },
        ),
        (
            "disable",
            {
                "action": _DisableAction,
                "callback": lambda x1, x2, x3, x4: x1,
                "metavar": "&lt;msg ids&gt;",
                "default": (),
                "short": "d",
                "group": "Messages control",
                "help": "Disable the message, report, category or checker "
                "with the given id(s). You can either give multiple identifiers "
                "separated by comma (,) or put this option multiple times "
                "(only on the command line, not in the configuration file "
                "where it should appear only once). "
                'You can also use "--disable=all" to disable everything first '
                "and then re-enable specific checks. For example, if you want "
                "to run only the similarities checker, you can use "
                '"--disable=all --enable=similarities". '
                "If you want to run only the classes checker, but have no "
                "Warning level messages displayed, use "
                '"--disable=all --enable=classes --disable=W".',
                "kwargs": {"linter": linter},
            },
        ),
        (
            "msg-template",
            {
                "type": "string",
                "default": "",
                "metavar": "&lt;template&gt;",
                "group": "Reports",
                "help": (
                    "Template used to display messages. "
                    "This is a python new-style format string "
                    "used to format the message information. "
                    "See doc for all details."
                ),
            },
        ),
        (
            "jobs",
            {
                "type": "int",
                "metavar": "&lt;n-processes&gt;",
                "short": "j",
                "default": 1,
                "help": "Use multiple processes to speed up Pylint. Specifying 0 will "
                "auto-detect the number of processors available to use, and will cap "
                "the count on Windows to avoid hangs.",
            },
        ),
        (
            "unsafe-load-any-extension",
            {
                "type": "yn",
                "metavar": "&lt;y or n&gt;",
                "default": False,
                "hide": True,
                "help": (
                    "Allow loading of arbitrary C extensions. Extensions"
                    " are imported into the active Python interpreter and"
                    " may run arbitrary code."
                ),
            },
        ),
        (
            "limit-inference-results",
            {
                "type": "int",
                "metavar": "&lt;number-of-results&gt;",
                "default": 100,
                "help": (
                    "Control the amount of potential inferred values when inferring "
                    "a single object. This can help the performance when dealing with "
                    "large functions or complex, nested conditions."
                ),
            },
        ),
        (
            "extension-pkg-allow-list",
            {
                "type": "csv",
                "metavar": "&lt;pkg[,pkg]&gt;",
                "default": [],
                "help": (
                    "A comma-separated list of package or module names"
                    " from where C extensions may be loaded. Extensions are"
                    " loading into the active Python interpreter and may run"
                    " arbitrary code."
                ),
            },
        ),
        (
            "extension-pkg-whitelist",
            {
                "type": "csv",
                "metavar": "&lt;pkg[,pkg]&gt;",
                "default": [],
                "help": (
                    "A comma-separated list of package or module names"
                    " from where C extensions may be loaded. Extensions are"
                    " loading into the active Python interpreter and may run"
                    " arbitrary code. (This is an alternative name to"
                    " extension-pkg-allow-list for backward compatibility.)"
                ),
            },
        ),
        (
            "suggestion-mode",
            {
                "type": "yn",
                "metavar": "&lt;y or n&gt;",
                "default": True,
                "help": (
                    "When enabled, pylint would attempt to guess common "
                    "misconfiguration and emit user-friendly hints instead "
                    "of false-positive error messages."
                ),
            },
        ),
        (
            "exit-zero",
            {
                "action": "store_true",
                "default": False,
                "metavar": "&lt;flag&gt;",
                "help": (
                    "Always return a 0 (non-error) status code, even if "
                    "lint errors are found. This is primarily useful in "
                    "continuous integration scripts."
                ),
            },
        ),
        (
            "from-stdin",
            {
                "action": "store_true",
                "default": False,
                "metavar": "&lt;flag&gt;",
                "help": (
                    "Interpret the stdin as a python script, whose filename "
                    "needs to be passed as the module_or_package argument."
                ),
            },
        ),
        (
            "source-roots",
            {
                "type": "glob_paths_csv",
                "metavar": "&lt;path&gt;[,&lt;path&gt;...]",
                "default": (),
                "help": "Add paths to the list of the source roots. Supports globbing patterns. "
                "The source root is an absolute path or a path relative to the current working "
                "directory used to determine a package namespace for modules located under the "
                "source root.",
            },
        ),
        (
            "recursive",
            {
                "type": "yn",
                "metavar": "&lt;yn&gt;",
                "default": False,
                "help": "Discover python modules and packages in the file system subtree.",
            },
        ),
        (
            "py-version",
            {
                "default": sys.version_info[:2],
                "type": "py_version",
                "metavar": "&lt;py_version&gt;",
                "help": (
                    "Minimum Python version to use for version dependent checks. "
                    "Will default to the version used to run pylint."
                ),
            },
        ),
        (
            "ignored-modules",
            {
                "default": (),
                "type": "csv",
                "metavar": "&lt;module names&gt;",
                "help": "List of module names for which member attributes "
                "should not be checked and will not be imported "
                "(useful for modules/projects "
                "where namespaces are manipulated during runtime and "
                "thus existing member attributes cannot be "
                "deduced by static analysis). It supports qualified "
                "module names, as well as Unix pattern matching.",
            },
        ),
        (
            "analyse-fallback-blocks",
            {
                "default": False,
                "type": "yn",
                "metavar": "&lt;y or n&gt;",
                "help": "Analyse import fallback blocks. This can be used to "
                "support both Python 2 and 3 compatible code, which "
                "means that the block might have code that exists "
                "only in one or another interpreter, leading to false "
                "positives when analysed.",
            },
        ),
        (
            "clear-cache-post-run",
            {
                "default": False,
                "type": "yn",
                "metavar": "&lt;y or n&gt;",
                "help": "Clear in-memory caches upon conclusion of linting. "
                "Useful if running pylint in a server-like mode.",
            },
        ),
        (
            "prefer-stubs",
            {
                "default": False,
                "type": "yn",
                "metavar": "&lt;y or n&gt;",
                "help": "Resolve imports to .pyi stubs if available. May "
                "reduce no-member messages and increase not-an-iterable "
                "messages.",
            },
        ),
    )


</t>
<t tx="ekr.20250131013600.1032">def _make_run_options(self: Run) -&gt; Options:
    """Return the options used in a Run class."""
    return (
        (
            "rcfile",
            {
                "action": _DoNothingAction,
                "kwargs": {},
                "group": "Commands",
                "help": "Specify a configuration file to load.",
                "hide_from_config_file": True,
            },
        ),
        (
            "output",
            {
                "action": _DoNothingAction,
                "kwargs": {},
                "group": "Commands",
                "help": "Specify an output file.",
                "hide_from_config_file": True,
            },
        ),
        (
            "init-hook",
            {
                "action": _DoNothingAction,
                "kwargs": {},
                "help": "Python code to execute, usually for sys.path "
                "manipulation such as pygtk.require().",
            },
        ),
        (
            "help-msg",
            {
                "action": _MessageHelpAction,
                "kwargs": {"Run": self},
                "group": "Commands",
                "help": "Display a help message for the given message id and "
                "exit. The value may be a comma separated list of message ids.",
                "hide_from_config_file": True,
            },
        ),
        (
            "list-msgs",
            {
                "action": _ListMessagesAction,
                "kwargs": {"Run": self},
                "group": "Commands",
                "help": "Display a list of all pylint's messages divided by whether "
                "they are emittable with the given interpreter.",
                "hide_from_config_file": True,
            },
        ),
        (
            "list-msgs-enabled",
            {
                "action": _ListMessagesEnabledAction,
                "kwargs": {"Run": self},
                "group": "Commands",
                "help": "Display a list of what messages are enabled, "
                "disabled and non-emittable with the given configuration.",
                "hide_from_config_file": True,
            },
        ),
        (
            "list-groups",
            {
                "action": _ListCheckGroupsAction,
                "kwargs": {"Run": self},
                "group": "Commands",
                "help": "List pylint's message groups.",
                "hide_from_config_file": True,
            },
        ),
        (
            "list-conf-levels",
            {
                "action": _ListConfidenceLevelsAction,
                "kwargs": {"Run": self},
                "group": "Commands",
                "help": "Generate pylint's confidence levels.",
                "hide_from_config_file": True,
            },
        ),
        (
            "list-extensions",
            {
                "action": _ListExtensionsAction,
                "kwargs": {"Run": self},
                "group": "Commands",
                "help": "List available extensions.",
                "hide_from_config_file": True,
            },
        ),
        (
            "full-documentation",
            {
                "action": _FullDocumentationAction,
                "kwargs": {"Run": self},
                "group": "Commands",
                "help": "Generate pylint's full documentation.",
                "hide_from_config_file": True,
            },
        ),
        (
            "generate-rcfile",
            {
                "action": _GenerateRCFileAction,
                "kwargs": {"Run": self},
                "group": "Commands",
                "help": "Generate a sample configuration file according to "
                "the current configuration. You can put other options "
                "before this one to get them in the generated "
                "configuration.",
                "hide_from_config_file": True,
            },
        ),
        (
            "generate-toml-config",
            {
                "action": _GenerateConfigFileAction,
                "kwargs": {"Run": self},
                "group": "Commands",
                "help": "Generate a sample configuration file according to "
                "the current configuration. You can put other options "
                "before this one to get them in the generated "
                "configuration. The config is in the .toml format.",
                "hide_from_config_file": True,
            },
        ),
        (
            "errors-only",
            {
                "action": _ErrorsOnlyModeAction,
                "kwargs": {"Run": self},
                "short": "E",
                "help": "In error mode, messages with a category besides "
                "ERROR or FATAL are suppressed, and no reports are done by default. "
                "Error mode is compatible with disabling specific errors. ",
                "hide_from_config_file": True,
            },
        ),
        (
            "verbose",
            {
                "action": _DoNothingAction,
                "kwargs": {},
                "short": "v",
                "help": "In verbose mode, extra non-checker-related info "
                "will be displayed.",
                "hide_from_config_file": True,
                "metavar": "",
            },
        ),
        (
            "enable-all-extensions",
            {
                "action": _DoNothingAction,
                "kwargs": {},
                "help": "Load and enable all available extensions. "
                "Use --list-extensions to see a list all available extensions.",
                "hide_from_config_file": True,
                "metavar": "",
            },
        ),
        (
            "long-help",
            {
                "action": _LongHelpAction,
                "kwargs": {"Run": self},
                "help": "Show more verbose help.",
                "group": "Commands",
                "hide_from_config_file": True,
            },
        ),
    )
</t>
<t tx="ekr.20250131013600.1033">@path pylint/lint
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import pickle
import sys
import warnings
from pathlib import Path

from pylint.constants import PYLINT_HOME
from pylint.utils import LinterStats

PYLINT_HOME_AS_PATH = Path(PYLINT_HOME)


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.1034">def _get_pdata_path(
    base_name: Path, recurs: int, pylint_home: Path = PYLINT_HOME_AS_PATH
) -&gt; Path:
    # We strip all characters that can't be used in a filename. Also strip '/' and
    # '\\' because we want to create a single file, not sub-directories.
    underscored_name = "_".join(
        str(p.replace(":", "_").replace("/", "_").replace("\\", "_"))
        for p in base_name.parts
    )
    return pylint_home / f"{underscored_name}_{recurs}.stats"


</t>
<t tx="ekr.20250131013600.1035">def load_results(
    base: str | Path, pylint_home: str | Path = PYLINT_HOME
) -&gt; LinterStats | None:
    base = Path(base)
    pylint_home = Path(pylint_home)
    data_file = _get_pdata_path(base, 1, pylint_home)

    if not data_file.exists():
        return None

    try:
        with open(data_file, "rb") as stream:
            data = pickle.load(stream)
            if not isinstance(data, LinterStats):
                warnings.warn(
                    "You're using an old pylint cache with invalid data following "
                    f"an upgrade, please delete '{data_file}'.",
                    UserWarning,
                    stacklevel=2,
                )
                raise TypeError
            return data
    except Exception:  # pylint: disable=broad-except
        # There's an issue with the cache but we just continue as if it isn't there
        return None


</t>
<t tx="ekr.20250131013600.1036">def save_results(
    results: LinterStats, base: str | Path, pylint_home: str | Path = PYLINT_HOME
) -&gt; None:
    base = Path(base)
    pylint_home = Path(pylint_home)
    try:
        pylint_home.mkdir(parents=True, exist_ok=True)
    except OSError:  # pragma: no cover
        print(f"Unable to create directory {pylint_home}", file=sys.stderr)
    data_file = _get_pdata_path(base, 1)
    try:
        with open(data_file, "wb") as stream:
            pickle.dump(results, stream)
    except OSError as ex:  # pragma: no cover
        print(f"Unable to create file {data_file}: {ex}", file=sys.stderr)
</t>
<t tx="ekr.20250131013600.1037">@path pylint/lint
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import os
import sys
from collections.abc import Sequence
from pathlib import Path
from re import Pattern

from astroid import modutils

from pylint.typing import ErrorDescriptionDict, ModuleDescriptionDict


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.1038">def _modpath_from_file(filename: str, is_namespace: bool, path: list[str]) -&gt; list[str]:
    def _is_package_cb(inner_path: str, parts: list[str]) -&gt; bool:
        return modutils.check_modpath_has_init(inner_path, parts) or is_namespace

    return modutils.modpath_from_file_with_callback(  # type: ignore[no-any-return]
        filename, path=path, is_package_cb=_is_package_cb
    )


</t>
<t tx="ekr.20250131013600.1039">def discover_package_path(modulepath: str, source_roots: Sequence[str]) -&gt; str:
    """Discover package path from one its modules and source roots."""
    dirname = os.path.realpath(os.path.expanduser(modulepath))
    if not os.path.isdir(dirname):
        dirname = os.path.dirname(dirname)

    # Look for a source root that contains the module directory
    for source_root in source_roots:
        source_root = os.path.realpath(os.path.expanduser(source_root))
        if os.path.commonpath([source_root, dirname]) in [dirname, source_root]:
            return source_root

    # Fall back to legacy discovery by looking for __init__.py upwards as
    # it's the only way given that source root was not found or was not provided
    while True:
        if not os.path.exists(os.path.join(dirname, "__init__.py")):
            return dirname
        old_dirname = dirname
        dirname = os.path.dirname(dirname)
        if old_dirname == dirname:
            return os.getcwd()


</t>
<t tx="ekr.20250131013600.104">def returns_bool(node: nodes.NodeNG) -&gt; bool:
    """Returns true if a node is a nodes.Return that returns a constant boolean."""
    return (
        isinstance(node, nodes.Return)
        and isinstance(node.value, nodes.Const)
        and isinstance(node.value.value, bool)
    )


</t>
<t tx="ekr.20250131013600.1040">def _is_in_ignore_list_re(element: str, ignore_list_re: list[Pattern[str]]) -&gt; bool:
    """Determines if the element is matched in a regex ignore-list."""
    return any(file_pattern.match(element) for file_pattern in ignore_list_re)


</t>
<t tx="ekr.20250131013600.1041">def _is_ignored_file(
    element: str,
    ignore_list: list[str],
    ignore_list_re: list[Pattern[str]],
    ignore_list_paths_re: list[Pattern[str]],
) -&gt; bool:
    element = os.path.normpath(element)
    basename = Path(element).absolute().name
    return (
        basename in ignore_list
        or _is_in_ignore_list_re(basename, ignore_list_re)
        or _is_in_ignore_list_re(element, ignore_list_paths_re)
    )


</t>
<t tx="ekr.20250131013600.1042"># pylint: disable = too-many-locals, too-many-statements
def expand_modules(
    files_or_modules: Sequence[str],
    source_roots: Sequence[str],
    ignore_list: list[str],
    ignore_list_re: list[Pattern[str]],
    ignore_list_paths_re: list[Pattern[str]],
) -&gt; tuple[dict[str, ModuleDescriptionDict], list[ErrorDescriptionDict]]:
    """Take a list of files/modules/packages and return the list of tuple
    (file, module name) which have to be actually checked.
    """
    result: dict[str, ModuleDescriptionDict] = {}
    errors: list[ErrorDescriptionDict] = []
    path = sys.path.copy()

    for something in files_or_modules:
        basename = os.path.basename(something)
        if _is_ignored_file(
            something, ignore_list, ignore_list_re, ignore_list_paths_re
        ):
            result[something] = {
                "path": something,
                "name": "",
                "isarg": False,
                "basepath": something,
                "basename": "",
                "isignored": True,
            }
            continue
        module_package_path = discover_package_path(something, source_roots)
        additional_search_path = [".", module_package_path, * path]
        if os.path.exists(something):
            # this is a file or a directory
            try:
                modname = ".".join(
                    modutils.modpath_from_file(something, path=additional_search_path)
                )
            except ImportError:
                modname = os.path.splitext(basename)[0]
            if os.path.isdir(something):
                filepath = os.path.join(something, "__init__.py")
            else:
                filepath = something
        else:
            # suppose it's a module or package
            modname = something
            try:
                filepath = modutils.file_from_modpath(
                    modname.split("."), path=additional_search_path
                )
                if filepath is None:
                    continue
            except ImportError as ex:
                errors.append({"key": "fatal", "mod": modname, "ex": ex})
                continue
        filepath = os.path.normpath(filepath)
        modparts = (modname or something).split(".")
        try:
            spec = modutils.file_info_from_modpath(
                modparts, path=additional_search_path
            )
        except ImportError:
            # Might not be acceptable, don't crash.
            is_namespace = not os.path.exists(filepath)
            is_directory = os.path.isdir(something)
        else:
            is_namespace = modutils.is_namespace(spec)
            is_directory = modutils.is_directory(spec)
        if not is_namespace:
            if filepath in result:
                # Always set arg flag if module explicitly given.
                result[filepath]["isarg"] = True
            else:
                result[filepath] = {
                    "path": filepath,
                    "name": modname,
                    "isarg": True,
                    "basepath": filepath,
                    "basename": modname,
                    "isignored": False,
                }
        has_init = (
            not (modname.endswith(".__init__") or modname == "__init__")
            and os.path.basename(filepath) == "__init__.py"
        )
        if has_init or is_namespace or is_directory:
            for subfilepath in modutils.get_module_files(
                os.path.dirname(filepath) or ".", ignore_list, list_all=is_namespace
            ):
                subfilepath = os.path.normpath(subfilepath)
                if filepath == subfilepath:
                    continue
                if _is_in_ignore_list_re(
                    os.path.basename(subfilepath), ignore_list_re
                ) or _is_in_ignore_list_re(subfilepath, ignore_list_paths_re):
                    result[subfilepath] = {
                        "path": subfilepath,
                        "name": "",
                        "isarg": False,
                        "basepath": subfilepath,
                        "basename": "",
                        "isignored": True,
                    }
                    continue

                modpath = _modpath_from_file(
                    subfilepath, is_namespace, path=additional_search_path
                )
                submodname = ".".join(modpath)
                # Preserve arg flag if module is also explicitly given.
                isarg = subfilepath in result and result[subfilepath]["isarg"]
                result[subfilepath] = {
                    "path": subfilepath,
                    "name": submodname,
                    "isarg": isarg,
                    "basepath": filepath,
                    "basename": modname,
                    "isignored": False,
                }
    return result, errors
</t>
<t tx="ekr.20250131013600.1043">@path pylint/lint
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import tokenize
from collections import defaultdict
from typing import TYPE_CHECKING, Literal

from pylint import exceptions, interfaces
from pylint.constants import (
    MSG_STATE_CONFIDENCE,
    MSG_STATE_SCOPE_CONFIG,
    MSG_STATE_SCOPE_MODULE,
    MSG_TYPES,
    MSG_TYPES_LONG,
)
from pylint.interfaces import HIGH
from pylint.message import MessageDefinition
from pylint.typing import ManagedMessage, MessageDefinitionTuple
from pylint.utils.pragma_parser import (
    OPTION_PO,
    InvalidPragmaError,
    UnRecognizedOptionError,
    parse_pragma,
)

if TYPE_CHECKING:
    from pylint.lint.pylinter import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.1044">class _MessageStateHandler:
    """Class that handles message disabling &amp; enabling and processing of inline
    pragma's.
    """

    @others
</t>
<t tx="ekr.20250131013600.1045">def __init__(self, linter: PyLinter) -&gt; None:
    self.linter = linter
    self.default_enabled_messages: dict[str, MessageDefinitionTuple] = {
        k: v
        for k, v in self.linter.msgs.items()
        if len(v) == 3 or v[3].get("default_enabled", True)
    }
    self._msgs_state: dict[str, bool] = {}
    self._options_methods = {
        "enable": self.enable,
        "disable": self.disable,
        "disable-next": self.disable_next,
    }
    self._bw_options_methods = {
        "disable-msg": self._options_methods["disable"],
        "enable-msg": self._options_methods["enable"],
    }
    self._pragma_lineno: dict[str, int] = {}
    self._stashed_messages: defaultdict[
        tuple[str, str], list[tuple[str | None, str]]
    ] = defaultdict(list)
    """Some messages in the options (for --enable and --disable) are encountered
    too early to warn about them.

    i.e. before all option providers have been fully parsed. Thus, this dict stores
    option_value and msg_id needed to (later) emit the messages keyed on module names.
    """

</t>
<t tx="ekr.20250131013600.1046">def _set_one_msg_status(
    self, scope: str, msg: MessageDefinition, line: int | None, enable: bool
) -&gt; None:
    """Set the status of an individual message."""
    if scope in {"module", "line"}:
        assert isinstance(line, int)  # should always be int inside module scope

        self.linter.file_state.set_msg_status(msg, line, enable, scope)
        if not enable and msg.symbol != "locally-disabled":
            self.linter.add_message(
                "locally-disabled", line=line, args=(msg.symbol, msg.msgid)
            )
    else:
        msgs = self._msgs_state
        msgs[msg.msgid] = enable

</t>
<t tx="ekr.20250131013600.1047">def _get_messages_to_set(
    self, msgid: str, enable: bool, ignore_unknown: bool = False
) -&gt; list[MessageDefinition]:
    """Do some tests and find the actual messages of which the status should be set."""
    message_definitions: list[MessageDefinition] = []
    if msgid == "all":
        for _msgid in MSG_TYPES:
            message_definitions.extend(
                self._get_messages_to_set(_msgid, enable, ignore_unknown)
            )
        if not enable:
            # "all" should not disable pylint's own warnings
            message_definitions = list(
                filter(
                    lambda m: m.msgid not in self.default_enabled_messages,
                    message_definitions,
                )
            )
        return message_definitions

    # msgid is a category?
    category_id = msgid.upper()
    if category_id not in MSG_TYPES:
        category_id_formatted = MSG_TYPES_LONG.get(category_id)
    else:
        category_id_formatted = category_id
    if category_id_formatted is not None:
        for _msgid in self.linter.msgs_store._msgs_by_category[
            category_id_formatted
        ]:
            message_definitions.extend(
                self._get_messages_to_set(_msgid, enable, ignore_unknown)
            )
        return message_definitions

    # msgid is a checker name?
    if msgid.lower() in self.linter._checkers:
        for checker in self.linter._checkers[msgid.lower()]:
            for _msgid in checker.msgs:
                message_definitions.extend(
                    self._get_messages_to_set(_msgid, enable, ignore_unknown)
                )
        return message_definitions

    # msgid is report id?
    if msgid.lower().startswith("rp"):
        if enable:
            self.linter.enable_report(msgid)
        else:
            self.linter.disable_report(msgid)
        return message_definitions

    try:
        # msgid is a symbolic or numeric msgid.
        message_definitions = self.linter.msgs_store.get_message_definitions(msgid)
    except exceptions.UnknownMessageError:
        if not ignore_unknown:
            raise
    return message_definitions

</t>
<t tx="ekr.20250131013600.1048">def _set_msg_status(
    self,
    msgid: str,
    enable: bool,
    scope: str = "package",
    line: int | None = None,
    ignore_unknown: bool = False,
) -&gt; None:
    """Do some tests and then iterate over message definitions to set state."""
    assert scope in {"package", "module", "line"}

    message_definitions = self._get_messages_to_set(msgid, enable, ignore_unknown)

    for message_definition in message_definitions:
        self._set_one_msg_status(scope, message_definition, line, enable)

    # sync configuration object
    self.linter.config.enable = []
    self.linter.config.disable = []
    for msgid_or_symbol, is_enabled in self._msgs_state.items():
        symbols = [
            m.symbol
            for m in self.linter.msgs_store.get_message_definitions(msgid_or_symbol)
        ]
        if is_enabled:
            self.linter.config.enable += symbols
        else:
            self.linter.config.disable += symbols

</t>
<t tx="ekr.20250131013600.1049">def _register_by_id_managed_msg(
    self, msgid_or_symbol: str, line: int | None, is_disabled: bool = True
) -&gt; None:
    """If the msgid is a numeric one, then register it to inform the user
    it could furnish instead a symbolic msgid.
    """
    if msgid_or_symbol[1:].isdigit():
        try:
            symbol = self.linter.msgs_store.message_id_store.get_symbol(
                msgid=msgid_or_symbol
            )
        except exceptions.UnknownMessageError:
            return
        managed = ManagedMessage(
            self.linter.current_name, msgid_or_symbol, symbol, line, is_disabled
        )
        self.linter._by_id_managed_msgs.append(managed)

</t>
<t tx="ekr.20250131013600.105">def assigned_bool(node: nodes.NodeNG) -&gt; bool:
    """Returns true if a node is a nodes.Assign that returns a constant boolean."""
    return (
        isinstance(node, nodes.Assign)
        and isinstance(node.value, nodes.Const)
        and isinstance(node.value.value, bool)
    )


</t>
<t tx="ekr.20250131013600.1050">def disable(
    self,
    msgid: str,
    scope: str = "package",
    line: int | None = None,
    ignore_unknown: bool = False,
) -&gt; None:
    """Disable a message for a scope."""
    self._set_msg_status(
        msgid, enable=False, scope=scope, line=line, ignore_unknown=ignore_unknown
    )
    self._register_by_id_managed_msg(msgid, line)

</t>
<t tx="ekr.20250131013600.1051">def disable_next(
    self,
    msgid: str,
    _: str = "package",
    line: int | None = None,
    ignore_unknown: bool = False,
) -&gt; None:
    """Disable a message for the next line."""
    if not line:
        raise exceptions.NoLineSuppliedError
    self._set_msg_status(
        msgid,
        enable=False,
        scope="line",
        line=line + 1,
        ignore_unknown=ignore_unknown,
    )
    self._register_by_id_managed_msg(msgid, line + 1)

</t>
<t tx="ekr.20250131013600.1052">def enable(
    self,
    msgid: str,
    scope: str = "package",
    line: int | None = None,
    ignore_unknown: bool = False,
) -&gt; None:
    """Enable a message for a scope."""
    self._set_msg_status(
        msgid, enable=True, scope=scope, line=line, ignore_unknown=ignore_unknown
    )
    self._register_by_id_managed_msg(msgid, line, is_disabled=False)

</t>
<t tx="ekr.20250131013600.1053">def disable_noerror_messages(self) -&gt; None:
    """Disable message categories other than `error` and `fatal`."""
    for msgcat in self.linter.msgs_store._msgs_by_category:
        if msgcat in {"E", "F"}:
            continue
        self.disable(msgcat)

</t>
<t tx="ekr.20250131013600.1054">def list_messages_enabled(self) -&gt; None:
    emittable, non_emittable = self.linter.msgs_store.find_emittable_messages()
    enabled: list[str] = []
    disabled: list[str] = []
    for message in emittable:
        if self.is_message_enabled(message.msgid):
            enabled.append(f"  {message.symbol} ({message.msgid})")
        else:
            disabled.append(f"  {message.symbol} ({message.msgid})")
    print("Enabled messages:")
    for msg in enabled:
        print(msg)
    print("\nDisabled messages:")
    for msg in disabled:
        print(msg)
    print("\nNon-emittable messages with current interpreter:")
    for msg_def in non_emittable:
        print(f"  {msg_def.symbol} ({msg_def.msgid})")
    print("")

</t>
<t tx="ekr.20250131013600.1055">def _get_message_state_scope(
    self,
    msgid: str,
    line: int | None = None,
    confidence: interfaces.Confidence | None = None,
) -&gt; Literal[0, 1, 2] | None:
    """Returns the scope at which a message was enabled/disabled."""
    if confidence is None:
        confidence = interfaces.UNDEFINED
    if confidence.name not in self.linter.config.confidence:
        return MSG_STATE_CONFIDENCE  # type: ignore[return-value] # mypy does not infer Literal correctly
    try:
        if line in self.linter.file_state._module_msgs_state[msgid]:
            return MSG_STATE_SCOPE_MODULE  # type: ignore[return-value]
    except(KeyError, TypeError):
        return MSG_STATE_SCOPE_CONFIG  # type: ignore[return-value]
    return None

</t>
<t tx="ekr.20250131013600.1056">def _is_one_message_enabled(self, msgid: str, line: int | None) -&gt; bool:
    """Checks state of a single message for the current file.

    This function can't be cached as it depends on self.file_state which can
    change.
    """
    if line is None:
        return self._msgs_state.get(msgid, True)
    try:
        return self.linter.file_state._module_msgs_state[msgid][line]
    except KeyError:
        # Check if the message's line is after the maximum line existing in ast tree.
        # This line won't appear in the ast tree and won't be referred in
        # self.file_state._module_msgs_state
        # This happens for example with a commented line at the end of a module.
        max_line_number = self.linter.file_state.get_effective_max_line_number()
        if max_line_number and line &gt; max_line_number:
            fallback = True
            lines = self.linter.file_state._raw_module_msgs_state.get(msgid, {})

            # Doesn't consider scopes, as a 'disable' can be in a
            # different scope than that of the current line.
            closest_lines = reversed(
                [
                    (message_line, enable)
                    for message_line, enable in lines.items()
                    if message_line &lt;= line
                ]
            )
            _, fallback_iter = next(closest_lines, (None, None))
            if fallback_iter is not None:
                fallback = fallback_iter

            return self._msgs_state.get(msgid, fallback)
        return self._msgs_state.get(msgid, True)

</t>
<t tx="ekr.20250131013600.1057">def is_message_enabled(
    self,
    msg_descr: str,
    line: int | None = None,
    confidence: interfaces.Confidence | None = None,
) -&gt; bool:
    """Is this message enabled for the current file ?

    Optionally, is it enabled for this line and confidence level ?

    The current file is implicit and mandatory. As a result this function
    can't be cached right now as the line is the line of the currently
    analysed file (self.file_state), if it changes, then the result for
    the same msg_descr/line might need to change.

    :param msg_descr: Either the msgid or the symbol for a MessageDefinition
    :param line: The line of the currently analysed file
    :param confidence: The confidence of the message
    """
    if confidence and confidence.name not in self.linter.config.confidence:
        return False
    try:
        msgids = self.linter.msgs_store.message_id_store.get_active_msgids(
            msg_descr
        )
    except exceptions.UnknownMessageError:
        # The linter checks for messages that are not registered
        # due to version mismatch, just treat them as message IDs
        # for now.
        msgids = [msg_descr]
    return any(self._is_one_message_enabled(msgid, line) for msgid in msgids)

</t>
<t tx="ekr.20250131013600.1058">def process_tokens(self, tokens: list[tokenize.TokenInfo]) -&gt; None:
    """Process tokens from the current module to search for module/block level
    options.

    See func_block_disable_msg.py test case for expected behaviour.
    """
    control_pragmas = {"disable", "disable-next", "enable"}
    prev_line = None
    saw_newline = True
    seen_newline = True
    for tok_type, content, start, _, _ in tokens:
        if prev_line and prev_line != start[0]:
            saw_newline = seen_newline
            seen_newline = False

        prev_line = start[0]
        if tok_type in (tokenize.NL, tokenize.NEWLINE):
            seen_newline = True

        if tok_type != tokenize.COMMENT:
            continue
        match = OPTION_PO.search(content)
        if match is None:
            continue
        try:  # pylint: disable = too-many-try-statements
            for pragma_repr in parse_pragma(match.group(2)):
                if pragma_repr.action in {"disable-all", "skip-file"}:
                    if pragma_repr.action == "disable-all":
                        self.linter.add_message(
                            "deprecated-pragma",
                            line=start[0],
                            args=("disable-all", "skip-file"),
                        )
                    self.linter.add_message("file-ignored", line=start[0])
                    self._ignore_file = True
                    return
                try:
                    meth = self._options_methods[pragma_repr.action]
                except KeyError:
                    meth = self._bw_options_methods[pragma_repr.action]
                    # found a "(dis|en)able-msg" pragma deprecated suppression
                    self.linter.add_message(
                        "deprecated-pragma",
                        line=start[0],
                        args=(
                            pragma_repr.action,
                            pragma_repr.action.replace("-msg", ""),
                        ),
                    )
                for msgid in pragma_repr.messages:
                    # Add the line where a control pragma was encountered.
                    if pragma_repr.action in control_pragmas:
                        self._pragma_lineno[msgid] = start[0]

                    if (pragma_repr.action, msgid) == ("disable", "all"):
                        self.linter.add_message(
                            "deprecated-pragma",
                            line=start[0],
                            args=("disable=all", "skip-file"),
                        )
                        self.linter.add_message("file-ignored", line=start[0])
                        self._ignore_file = True
                        return
                        # If we did not see a newline between the previous line and now,
                        # we saw a backslash so treat the two lines as one.
                    l_start = start[0]
                    if not saw_newline:
                        l_start -= 1
                    try:
                        meth(msgid, "module", l_start)
                    except(
                        exceptions.DeletedMessageError,
                        exceptions.MessageBecameExtensionError,
                    ) as e:
                        self.linter.add_message(
                            "useless-option-value",
                            args=(pragma_repr.action, e),
                            line=start[0],
                            confidence=HIGH,
                        )
                    except exceptions.UnknownMessageError:
                        self.linter.add_message(
                            "unknown-option-value",
                            args=(pragma_repr.action, msgid),
                            line=start[0],
                            confidence=HIGH,
                        )

        except UnRecognizedOptionError as err:
            self.linter.add_message(
                "unrecognized-inline-option", args=err.token, line=start[0]
            )
            continue
        except InvalidPragmaError as err:
            self.linter.add_message(
                "bad-inline-option", args=err.token, line=start[0]
            )
            continue
</t>
<t tx="ekr.20250131013600.1059">@path pylint/lint
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import functools
from collections import defaultdict
from collections.abc import Iterable, Sequence
from typing import TYPE_CHECKING, Any

import dill

from pylint import reporters
from pylint.lint.utils import _augment_sys_path
from pylint.message import Message
from pylint.typing import FileItem
from pylint.utils import LinterStats, merge_stats

try:
    import multiprocessing
except ImportError:
    multiprocessing = None  # type: ignore[assignment]

try:
    from concurrent.futures import ProcessPoolExecutor
except ImportError:
    ProcessPoolExecutor = None  # type: ignore[assignment,misc]

if TYPE_CHECKING:
    from pylint.lint import PyLinter

# PyLinter object used by worker processes when checking files using parallel mode
# should only be used by the worker processes
_worker_linter: PyLinter | None = None


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.106">def get_node_first_ancestor_of_type(
    node: nodes.NodeNG, ancestor_type: type[_NodeT] | tuple[type[_NodeT], ...]
) -&gt; _NodeT | None:
    """Return the first parent node that is any of the provided types (or None)."""
    for ancestor in node.node_ancestors():
        if isinstance(ancestor, ancestor_type):
            return ancestor  # type: ignore[no-any-return]
    return None


</t>
<t tx="ekr.20250131013600.1060">def _worker_initialize(
    linter: bytes, extra_packages_paths: Sequence[str] | None = None
) -&gt; None:
    """Function called to initialize a worker for a Process within a concurrent Pool.

    :param linter: A linter-class (PyLinter) instance pickled with dill
    :param extra_packages_paths: Extra entries to be added to `sys.path`
    """
    global _worker_linter  # pylint: disable=global-statement
    _worker_linter = dill.loads(linter)
    assert _worker_linter

    # On the worker process side the messages are just collected and passed back to
    # parent process as _worker_check_file function's return value
    _worker_linter.set_reporter(reporters.CollectingReporter())
    _worker_linter.open()

    # Re-register dynamic plugins, since the pool does not have access to the
    # astroid module that existed when the linter was pickled.
    _worker_linter.load_plugin_modules(_worker_linter._dynamic_plugins, force=True)
    _worker_linter.load_plugin_configuration()

    if extra_packages_paths:
        _augment_sys_path(extra_packages_paths)


</t>
<t tx="ekr.20250131013600.1061">def _worker_check_single_file(
    file_item: FileItem,
) -&gt; tuple[
    int,
    str,
    str,
    str,
    list[Message],
    LinterStats,
    int,
    defaultdict[str, list[Any]],
</t>
<t tx="ekr.20250131013600.1062">]:
    if not _worker_linter:
        raise RuntimeError("Worker linter not yet initialised")
    _worker_linter.open()
    _worker_linter.check_single_file_item(file_item)
    mapreduce_data = defaultdict(list)
    for checker in _worker_linter.get_checkers():
        data = checker.get_map_data()
        if data is not None:
            mapreduce_data[checker.name].append(data)
    msgs = _worker_linter.reporter.messages
    assert isinstance(_worker_linter.reporter, reporters.CollectingReporter)
    _worker_linter.reporter.reset()
    return (
        id(multiprocessing.current_process()),
        _worker_linter.current_name,
        file_item.filepath,
        _worker_linter.file_state.base_name,
        msgs,
        _worker_linter.stats,
        _worker_linter.msg_status,
        mapreduce_data,
    )


def _merge_mapreduce_data(
    linter: PyLinter,
    all_mapreduce_data: defaultdict[int, list[defaultdict[str, list[Any]]]],
) -&gt; None:
    """Merges map/reduce data across workers, invoking relevant APIs on checkers."""
    # First collate the data and prepare it, so we can send it to the checkers for
    # validation. The intent here is to collect all the mapreduce data for all checker-
    # runs across processes - that will then be passed to a static method on the
    # checkers to be reduced and further processed.
    collated_map_reduce_data: defaultdict[str, list[Any]] = defaultdict(list)
    for linter_data in all_mapreduce_data.values():
        for run_data in linter_data:
            for checker_name, data in run_data.items():
                collated_map_reduce_data[checker_name].extend(data)

    # Send the data to checkers that support/require consolidated data
    original_checkers = linter.get_checkers()
    for checker in original_checkers:
        if checker.name in collated_map_reduce_data:
            # Assume that if the check has returned map/reduce data that it has the
            # reducer function
            checker.reduce_map_data(linter, collated_map_reduce_data[checker.name])


</t>
<t tx="ekr.20250131013600.1063">def check_parallel(
    linter: PyLinter,
    jobs: int,
    files: Iterable[FileItem],
    extra_packages_paths: Sequence[str] | None = None,
) -&gt; None:
    """Use the given linter to lint the files with given amount of workers (jobs).

    This splits the work filestream-by-filestream. If you need to do work across
    multiple files, as in the similarity-checker, then implement the map/reduce functionality.
    """
    # The linter is inherited by all the pool's workers, i.e. the linter
    # is identical to the linter object here. This is required so that
    # a custom PyLinter object can be used.
    initializer = functools.partial(
        _worker_initialize, extra_packages_paths=extra_packages_paths
    )
    with ProcessPoolExecutor(
        max_workers=jobs, initializer=initializer, initargs=(dill.dumps(linter),)
    ) as executor:
        linter.open()
        all_stats = []
        all_mapreduce_data: defaultdict[int, list[defaultdict[str, list[Any]]]] = (
            defaultdict(list)
        )

        # Maps each file to be worked on by a single _worker_check_single_file() call,
        # collecting any map/reduce data by checker module so that we can 'reduce' it
        # later.
        for (
            worker_idx,  # used to merge map/reduce data across workers
            module,
            file_path,
            base_name,
            messages,
            stats,
            msg_status,
            mapreduce_data,
        ) in executor.map(_worker_check_single_file, files):
            linter.file_state.base_name = base_name
            linter.file_state._is_base_filestate = False
            linter.set_current_module(module, file_path)
            for msg in messages:
                linter.reporter.handle_message(msg)
            all_stats.append(stats)
            all_mapreduce_data[worker_idx].append(mapreduce_data)
            linter.msg_status |= msg_status

    _merge_mapreduce_data(linter, all_mapreduce_data)
    linter.stats = merge_stats([linter.stats, * all_stats])
</t>
<t tx="ekr.20250131013600.1064">@path pylint/lint
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import argparse
import collections
import contextlib
import functools
import os
import sys
import tokenize
import traceback
from collections import defaultdict
from collections.abc import Callable, Iterable, Iterator, Sequence
from io import TextIOWrapper
from pathlib import Path
from re import Pattern
from types import ModuleType
from typing import Any, Protocol

import astroid
from astroid import nodes

from pylint import checkers, exceptions, interfaces, reporters
from pylint.checkers.base_checker import BaseChecker
from pylint.config.arguments_manager import _ArgumentsManager
from pylint.constants import (
    MAIN_CHECKER_NAME,
    MSG_TYPES,
    MSG_TYPES_STATUS,
    WarningScope,
)
from pylint.interfaces import HIGH
from pylint.lint.base_options import _make_linter_options
from pylint.lint.caching import load_results, save_results
from pylint.lint.expand_modules import (
    _is_ignored_file,
    discover_package_path,
    expand_modules,
)
from pylint.lint.message_state_handler import _MessageStateHandler
from pylint.lint.parallel import check_parallel
from pylint.lint.report_functions import (
    report_messages_by_module_stats,
    report_messages_stats,
    report_total_messages_stats,
)
from pylint.lint.utils import (
    augmented_sys_path,
    get_fatal_error_message,
    prepare_crash_report,
)
from pylint.message import Message, MessageDefinition, MessageDefinitionStore
from pylint.reporters.base_reporter import BaseReporter
from pylint.reporters.progress_reporters import ProgressReporter
from pylint.reporters.text import TextReporter
from pylint.reporters.ureports import nodes as report_nodes
from pylint.typing import (
    DirectoryNamespaceDict,
    FileItem,
    ManagedMessage,
    MessageDefinitionTuple,
    MessageLocationTuple,
    ModuleDescriptionDict,
    Options,
)
from pylint.utils import ASTWalker, FileState, LinterStats, utils

MANAGER = astroid.MANAGER


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.107">def get_node_first_ancestor_of_type_and_its_child(
    node: nodes.NodeNG, ancestor_type: type[_NodeT] | tuple[type[_NodeT], ...]
) -&gt; tuple[None, None] | tuple[_NodeT, nodes.NodeNG]:
    """Modified version of get_node_first_ancestor_of_type to also return the
    descendant visited directly before reaching the sought ancestor.

    Useful for extracting whether a statement is guarded by a try, except, or finally
    when searching for a Try ancestor.
    """
    child = node
    for ancestor in node.node_ancestors():
        if isinstance(ancestor, ancestor_type):
            return (ancestor, child)
        child = ancestor
    return None, None


</t>
<t tx="ekr.20250131013600.108">def in_type_checking_block(node: nodes.NodeNG) -&gt; bool:
    """Check if a node is guarded by a TYPE_CHECKING guard."""
    for ancestor in node.node_ancestors():
        if not isinstance(ancestor, nodes.If):
            continue
        if isinstance(ancestor.test, nodes.Name):
            if ancestor.test.name != "TYPE_CHECKING":
                continue
            lookup_result = ancestor.test.lookup(ancestor.test.name)[1]
            if not lookup_result:
                return False
            maybe_import_from = lookup_result[0]
            if (
                isinstance(maybe_import_from, nodes.ImportFrom)
                and maybe_import_from.modname == "typing"
            ):
                return True
            inferred = safe_infer(ancestor.test)
            if isinstance(inferred, nodes.Const) and inferred.value is False:
                return True
        elif isinstance(ancestor.test, nodes.Attribute):
            if ancestor.test.attrname != "TYPE_CHECKING":
                continue
            inferred_module = safe_infer(ancestor.test.expr)
            if (
                isinstance(inferred_module, nodes.Module)
                and inferred_module.name == "typing"
            ):
                return True

    return False


</t>
<t tx="ekr.20250131013600.109">def is_typing_member(node: nodes.NodeNG, names_to_check: tuple[str, ...]) -&gt; bool:
    """Check if `node` is a member of the `typing` module and has one of the names from
    `names_to_check`.
    """
    if isinstance(node, nodes.Name):
        try:
            import_from = node.lookup(node.name)[1][0]
        except IndexError:
            return False

        if isinstance(import_from, nodes.ImportFrom):
            return (
                import_from.modname == "typing"
                and import_from.real_name(node.name) in names_to_check
            )
    elif isinstance(node, nodes.Attribute):
        inferred_module = safe_infer(node.expr)
        return (
            isinstance(inferred_module, nodes.Module)
            and inferred_module.name == "typing"
            and node.attrname in names_to_check
        )
    return False


</t>
<t tx="ekr.20250131013600.11">def is_default_argument(node: nodes.NodeNG, scope: nodes.NodeNG | None = None) -&gt; bool:
    """Return true if the given Name node is used in function or lambda
    default argument's value.
    """
    if not scope:
        scope = node.scope()
    if isinstance(scope, (nodes.FunctionDef, nodes.Lambda)):
        all_defaults = itertools.chain(
            scope.args.defaults, (d for d in scope.args.kw_defaults if d is not None)
        )
        return any(
            default_name_node is node
            for default_node in all_defaults
            for default_name_node in default_node.nodes_of_class(nodes.Name)
        )

    return False


</t>
<t tx="ekr.20250131013600.110">@lru_cache
def in_for_else_branch(parent: nodes.NodeNG, stmt: Statement) -&gt; bool:
    """Returns True if stmt is inside the else branch for a parent For stmt."""
    return isinstance(parent, nodes.For) and any(
        else_stmt.parent_of(stmt) or else_stmt == stmt for else_stmt in parent.orelse
    )


</t>
<t tx="ekr.20250131013600.111">def find_assigned_names_recursive(
    target: nodes.AssignName | nodes.BaseContainer,
) -&gt; Iterator[str]:
    """Yield the names of assignment targets, accounting for nested ones."""
    if isinstance(target, nodes.AssignName):
        if target.name is not None:
            yield target.name
    elif isinstance(target, nodes.BaseContainer):
        for elt in target.elts:
            yield from find_assigned_names_recursive(elt)


</t>
<t tx="ekr.20250131013600.112">def has_starred_node_recursive(
    node: nodes.For | nodes.Comprehension | nodes.Set,
) -&gt; Iterator[bool]:
    """Yield ``True`` if a Starred node is found recursively."""
    if isinstance(node, nodes.Starred):
        yield True
    elif isinstance(node, nodes.Set):
        for elt in node.elts:
            yield from has_starred_node_recursive(elt)
    elif isinstance(node, (nodes.For, nodes.Comprehension)):
        for elt in node.iter.elts:
            yield from has_starred_node_recursive(elt)


</t>
<t tx="ekr.20250131013600.113">def is_hashable(node: nodes.NodeNG) -&gt; bool:
    """Return whether any inferred value of `node` is hashable.

    When finding ambiguity, return True.
    """
    # pylint: disable = too-many-try-statements
    try:
        for inferred in node.infer():
            if isinstance(inferred, (nodes.ClassDef, util.UninferableBase)):
                return True
            if not hasattr(inferred, "igetattr"):
                return True
            hash_fn = next(inferred.igetattr("__hash__"))
            if hash_fn.parent is inferred:
                return True
            if getattr(hash_fn, "value", True) is not None:
                return True
        return False
    except astroid.InferenceError:
        return True


</t>
<t tx="ekr.20250131013600.114">def subscript_chain_is_equal(left: nodes.Subscript, right: nodes.Subscript) -&gt; bool:
    while isinstance(left, nodes.Subscript) and isinstance(right, nodes.Subscript):
        try:
            if (
                get_subscript_const_value(left).value
                != get_subscript_const_value(right).value
            ):
                return False

            left = left.value
            right = right.value
        except InferredTypeError:
            return False

    return left.as_string() == right.as_string()  # type: ignore[no-any-return]


</t>
<t tx="ekr.20250131013600.115">def _is_target_name_in_binop_side(
    target: nodes.AssignName | nodes.AssignAttr, side: nodes.NodeNG | None
) -&gt; bool:
    """Determine whether the target name-like node is referenced in the side node."""
    if isinstance(side, nodes.Name):
        if isinstance(target, nodes.AssignName):
            return target.name == side.name  # type: ignore[no-any-return]
        return False
    if isinstance(side, nodes.Attribute) and isinstance(target, nodes.AssignAttr):
        return target.as_string() == side.as_string()  # type: ignore[no-any-return]
    if isinstance(side, nodes.Subscript) and isinstance(target, nodes.Subscript):
        return subscript_chain_is_equal(target, side)

    return False


</t>
<t tx="ekr.20250131013600.116">def is_augmented_assign(node: nodes.Assign) -&gt; tuple[bool, str]:
    """Determine if the node is assigning itself (with modifications) to itself.

    For example: x = 1 + x
    """
    if not isinstance(node.value, nodes.BinOp):
        return False, ""

    binop = node.value
    target = node.targets[0]

    if not isinstance(target, (nodes.AssignName, nodes.AssignAttr, nodes.Subscript)):
        return False, ""

    # We don't want to catch x = "1" + x or x = "%s" % x
    if isinstance(binop.left, nodes.Const) and isinstance(
        binop.left.value, (str, bytes)
    ):
        return False, ""

    # This could probably be improved but for now we disregard all assignments from calls
    if isinstance(binop.left, nodes.Call) or isinstance(binop.right, nodes.Call):
        return False, ""

    if _is_target_name_in_binop_side(target, binop.left):
        return True, binop.op
    if (
        # Unless an operator is commutative, we should not raise (i.e. x = 3/x)
        binop.op in COMMUTATIVE_OPERATORS
        and _is_target_name_in_binop_side(target, binop.right)
    ):
        inferred_left = safe_infer(binop.left)
        if isinstance(inferred_left, nodes.Const) and isinstance(
            inferred_left.value, int
        ):
            return True, binop.op
        return False, ""
    return False, ""


</t>
<t tx="ekr.20250131013600.117">def _qualified_name_parts(qualified_module_name: str) -&gt; list[str]:
    """Split the names of the given module into subparts.

    For example,
        _qualified_name_parts('pylint.checkers.ImportsChecker')
    returns
        ['pylint', 'pylint.checkers', 'pylint.checkers.ImportsChecker']
    """
    names = qualified_module_name.split(".")
    return [".".join(names[0 : i + 1]) for i in range(len(names))]


</t>
<t tx="ekr.20250131013600.118">def is_module_ignored(
    qualified_module_name: str, ignored_modules: Iterable[str]
) -&gt; bool:
    ignored_modules = set(ignored_modules)
    for current_module in _qualified_name_parts(qualified_module_name):
        # Try to match the module name directly
        if current_module in ignored_modules:
            return True
        for ignore in ignored_modules:
            # Try to see if the ignores pattern match against the module name.
            if fnmatch.fnmatch(current_module, ignore):
                return True
    return False


</t>
<t tx="ekr.20250131013600.119">def is_singleton_const(node: nodes.NodeNG) -&gt; bool:
    return isinstance(node, nodes.Const) and any(
        node.value is value for value in SINGLETON_VALUES
    )


</t>
<t tx="ekr.20250131013600.12">def is_func_decorator(node: nodes.NodeNG) -&gt; bool:
    """Return true if the name is used in function decorator."""
    for parent in node.node_ancestors():
        if isinstance(parent, nodes.Decorators):
            return True
        if parent.is_statement or isinstance(
            parent,
            (
                nodes.Lambda,
                nodes.ComprehensionScope,
                nodes.ListComp,
            ),
        ):
            break
    return False


</t>
<t tx="ekr.20250131013600.120">def is_terminating_func(node: nodes.Call) -&gt; bool:
    """Detect call to exit(), quit(), os._exit(), sys.exit(), or
    functions annotated with `typing.NoReturn` or `typing.Never`.
    """
    if (
        not isinstance(node.func, nodes.Attribute)
        and not (isinstance(node.func, nodes.Name))
    ) or isinstance(node.parent, nodes.Lambda):
        return False

    try:
        for inferred in node.func.infer():
            if (
                hasattr(inferred, "qname")
                and inferred.qname() in TERMINATING_FUNCS_QNAMES
            ):
                return True
            # Unwrap to get the actual function node object
            if isinstance(inferred, astroid.BoundMethod) and isinstance(
                inferred._proxied, astroid.UnboundMethod
            ):
                inferred = inferred._proxied._proxied
            if (  # pylint: disable=too-many-boolean-expressions
                isinstance(inferred, nodes.FunctionDef)
                and (
                    not isinstance(inferred, nodes.AsyncFunctionDef)
                    or isinstance(node.parent, nodes.Await)
                )
                and isinstance(inferred.returns, nodes.Name)
                and (inferred_func := safe_infer(inferred.returns))
                and hasattr(inferred_func, "qname")
                and inferred_func.qname()
                in (
                    * TYPING_NEVER,
                    * TYPING_NORETURN,
                    # In Python 3.7 - 3.8, NoReturn is alias of '_SpecialForm'
                    # "typing._SpecialForm",
                    # But 'typing.Any' also inherits _SpecialForm
                    # See #9751
                )
            ):
                return True
    except(StopIteration, astroid.InferenceError):
        pass

    return False


</t>
<t tx="ekr.20250131013600.121">def is_class_attr(name: str, klass: nodes.ClassDef) -&gt; bool:
    try:
        klass.getattr(name)
        return True
    except astroid.NotFoundError:
        return False


</t>
<t tx="ekr.20250131013600.122">def get_inverse_comparator(op: str) -&gt; str:
    """Returns the inverse comparator given a comparator.

    E.g. when given "==", returns "!="

    :param str op: the comparator to look up.

    :returns: The inverse of the comparator in string format
    :raises KeyError: if input is not recognized as a comparator
    """
    return {
        "==": "!=",
        "!=": "==",
        "&lt;": "&gt;=",
        "&gt;": "&lt;=",
        "&lt;=": "&gt;",
        "&gt;=": "&lt;",
        "in": "not in",
        "not in": "in",
        "is": "is not",
        "is not": "is",
    }[op]


</t>
<t tx="ekr.20250131013600.123">def not_condition_as_string(
    test_node: nodes.Compare | nodes.Name | nodes.UnaryOp | nodes.BoolOp | nodes.BinOp,
) -&gt; str:
    msg = f"not {test_node.as_string()}"
    if isinstance(test_node, nodes.UnaryOp):
        msg = test_node.operand.as_string()
    elif isinstance(test_node, nodes.BoolOp):
        msg = f"not ({test_node.as_string()})"
    elif isinstance(test_node, nodes.Compare):
        lhs = test_node.left
        ops, rhs = test_node.ops[0]
        lower_priority_expressions = (
            nodes.Lambda,
            nodes.UnaryOp,
            nodes.BoolOp,
            nodes.IfExp,
            nodes.NamedExpr,
        )
        lhs = (
            f"({lhs.as_string()})"
            if isinstance(lhs, lower_priority_expressions)
            else lhs.as_string()
        )
        rhs = (
            f"({rhs.as_string()})"
            if isinstance(rhs, lower_priority_expressions)
            else rhs.as_string()
        )
        msg = f"{lhs} {get_inverse_comparator(ops)} {rhs}"
    return msg


</t>
<t tx="ekr.20250131013600.124">@lru_cache(maxsize=1000)
def overridden_method(
    klass: nodes.LocalsDictNodeNG, name: str | None
) -&gt; nodes.FunctionDef | None:
    """Get overridden method if any."""
    try:
        parent = next(klass.local_attr_ancestors(name))
    except(StopIteration, KeyError):
        return None
    try:
        meth_node = parent[name]
    except KeyError:  # pragma: no cover
        # We have found an ancestor defining &lt;name&gt; but it's not in the local
        # dictionary. This may happen with astroid built from living objects.
        return None
    if isinstance(meth_node, nodes.FunctionDef):
        return meth_node
    return None  # pragma: no cover


</t>
<t tx="ekr.20250131013600.125">def clear_lru_caches() -&gt; None:
    """Clear caches holding references to AST nodes."""
    caches_holding_node_references: list[_lru_cache_wrapper[Any]] = [
        class_is_abstract,
        in_for_else_branch,
        infer_all,
        is_overload_stub,
        overridden_method,
        unimplemented_abstract_methods,
        safe_infer,
    ]
    for lru in caches_holding_node_references:
        lru.cache_clear()


</t>
<t tx="ekr.20250131013600.126">def is_enum_member(node: nodes.AssignName) -&gt; bool:
    """Return `True` if `node` is an Enum member (is an item of the
    `__members__` container).
    """
    frame = node.frame()
    if (
        not isinstance(frame, nodes.ClassDef)
        or not frame.is_subtype_of("enum.Enum")
        or frame.root().qname() == "enum"
    ):
        return False

    members = frame.locals.get("__members__")
    # A dataclass is one known case for when `members` can be `None`
    if members is None:
        return False
    return node.name in [name_obj.name for value, name_obj in members[0].items]
</t>
<t tx="ekr.20250131013600.127">def __init__(self, index: int) -&gt; None:
    super().__init__(index)
    self.index = index


</t>
<t tx="ekr.20250131013600.128">@path pylint/checkers
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Variables checkers for Python code."""

from __future__ import annotations

import copy
import itertools
import math
import os
import re
from collections import defaultdict
from enum import Enum
from functools import cached_property
from typing import TYPE_CHECKING

import astroid
import astroid.exceptions
from astroid import bases, extract_node, nodes, util

from pylint.checkers import BaseChecker, utils
from pylint.checkers.utils import (
    in_type_checking_block,
    is_module_ignored,
    is_postponed_evaluation_enabled,
    is_sys_guard,
    overridden_method,
)
from pylint.constants import TYPING_NEVER, TYPING_NORETURN
from pylint.interfaces import CONTROL_FLOW, HIGH, INFERENCE, INFERENCE_FAILURE

if TYPE_CHECKING:
    from collections.abc import Generator, Iterable, Iterator

    from astroid.nodes import _base_nodes
    from astroid.typing import InferenceResult

    from pylint.lint import PyLinter
    from pylint.typing import MessageDefinitionTuple

    Consumption = dict[str, list[nodes.NodeNG]]


SPECIAL_OBJ = re.compile("^_{2}[a-z]+_{2}$")
FUTURE = "__future__"
# regexp for ignored argument name
IGNORED_ARGUMENT_NAMES = re.compile("_.*|^ignored_|^unused_")
# In Python 3.7 abc has a Python implementation which is preferred
# by astroid. Unfortunately this also messes up our explicit checks
# for `abc`
METACLASS_NAME_TRANSFORMS = {"_py_abc": "abc"}
BUILTIN_RANGE = "builtins.range"
TYPING_MODULE = "typing"

DICT_TYPES = (
    astroid.objects.DictValues,
    astroid.objects.DictKeys,
    astroid.objects.DictItems,
    astroid.nodes.node_classes.Dict,
)

NODES_WITH_VALUE_ATTR = (
    nodes.Assign,
    nodes.AnnAssign,
    nodes.AugAssign,
    nodes.Expr,
    nodes.Return,
    nodes.Match,
    nodes.TypeAlias,
)


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.129">class VariableVisitConsumerAction(Enum):
    """Reported by _check_consumer() and its sub-methods to determine the
    subsequent action to take in _undefined_and_used_before_checker().

    Continue -&gt; continue loop to next consumer
    Return -&gt; return and thereby break the loop
    """

    CONTINUE = 0
    RETURN = 1


</t>
<t tx="ekr.20250131013600.13">def is_ancestor_name(frame: nodes.ClassDef, node: nodes.NodeNG) -&gt; bool:
    """Return whether `frame` is an astroid.Class node with `node` in the
    subtree of its bases attribute.
    """
    if not isinstance(frame, nodes.ClassDef):
        return False
    return any(node in base.nodes_of_class(nodes.Name) for base in frame.bases)


</t>
<t tx="ekr.20250131013600.130">def _is_from_future_import(stmt: nodes.ImportFrom, name: str) -&gt; bool | None:
    """Check if the name is a future import from another module."""
    try:
        module = stmt.do_import_module(stmt.modname)
    except astroid.AstroidBuildingError:
        return None

    for local_node in module.locals.get(name, []):
        if isinstance(local_node, nodes.ImportFrom) and local_node.modname == FUTURE:
            return True
    return None


</t>
<t tx="ekr.20250131013600.131">def _get_unpacking_extra_info(node: nodes.Assign, inferred: InferenceResult) -&gt; str:
    """Return extra information to add to the message for unpacking-non-sequence
    and unbalanced-tuple/dict-unpacking errors.
    """
    more = ""
    if isinstance(inferred, DICT_TYPES):
        if isinstance(node, nodes.Assign):
            more = node.value.as_string()
        elif isinstance(node, nodes.For):
            more = node.iter.as_string()
        return more

    inferred_module = inferred.root().name
    if node.root().name == inferred_module:
        if node.lineno == inferred.lineno:
            more = f"'{inferred.as_string()}'"
        elif inferred.lineno:
            more = f"defined at line {inferred.lineno}"
    elif inferred.lineno:
        more = f"defined at line {inferred.lineno} of {inferred_module}"
    return more


</t>
<t tx="ekr.20250131013600.132">def _detect_global_scope(
    node: nodes.Name,
    frame: nodes.LocalsDictNodeNG,
    defframe: nodes.LocalsDictNodeNG,
) -&gt; bool:
    """Detect that the given frames share a global scope.

    Two frames share a global scope when neither
    of them are hidden under a function scope, as well
    as any parent scope of them, until the root scope.
    In this case, depending from something defined later on
    will only work if guarded by a nested function definition.

    Example:
        class A:
            # B has the same global scope as `C`, leading to a NameError.
            # Return True to indicate a shared scope.
            class B(C): ...
        class C: ...

    Whereas this does not lead to a NameError:
        class A:
            def guard():
                # Return False to indicate no scope sharing.
                class B(C): ...
        class C: ...
    """
    def_scope = scope = None
    if frame and frame.parent:
        scope = frame.parent.scope()
    if defframe and defframe.parent:
        def_scope = defframe.parent.scope()
    if (
        isinstance(frame, nodes.ClassDef)
        and scope is not def_scope
        and scope is utils.get_node_first_ancestor_of_type(node, nodes.FunctionDef)
    ):
        # If the current node's scope is a class nested under a function,
        # and the def_scope is something else, then they aren't shared.
        return False
    if isinstance(frame, nodes.FunctionDef):
        # If the parent of the current node is a
        # function, then it can be under its scope (defined in); or
        # the `-&gt;` part of annotations. The same goes
        # for annotations of function arguments, they'll have
        # their parent the Arguments node.
        if frame.parent_of(defframe):
            return node.lineno &lt; defframe.lineno  # type: ignore[no-any-return]
        if not isinstance(node.parent, (nodes.FunctionDef, nodes.Arguments)):
            return False

    break_scopes = []
    for current_scope in (scope or frame, def_scope):
        # Look for parent scopes. If there is anything different
        # than a module or a class scope, then the frames don't
        # share a global scope.
        parent_scope = current_scope
        while parent_scope:
            if not isinstance(parent_scope, (nodes.ClassDef, nodes.Module)):
                break_scopes.append(parent_scope)
                break
            if parent_scope.parent:
                parent_scope = parent_scope.parent.scope()
            else:
                break
    if len(set(break_scopes)) &gt; 1:
        # Store different scopes than expected.
        # If the stored scopes are, in fact, the very same, then it means
        # that the two frames (frame and defframe) share the same scope,
        # and we could apply our lineno analysis over them.
        # For instance, this works when they are inside a function, the node
        # that uses a definition and the definition itself.
        return False
    # At this point, we are certain that frame and defframe share a scope
    # and the definition of the first depends on the second.
    return frame.lineno &lt; defframe.lineno  # type: ignore[no-any-return]


</t>
<t tx="ekr.20250131013600.133">def _infer_name_module(node: nodes.Import, name: str) -&gt; Generator[InferenceResult]:
    context = astroid.context.InferenceContext()
    context.lookupname = name
    return node.infer(context, asname=False)  # type: ignore[no-any-return]


</t>
<t tx="ekr.20250131013600.134">def _fix_dot_imports(
    not_consumed: Consumption,
) -&gt; list[tuple[str, _base_nodes.ImportNode]]:
    """Try to fix imports with multiple dots, by returning a dictionary
    with the import names expanded.

    The function unflattens root imports,
    like 'xml' (when we have both 'xml.etree' and 'xml.sax'), to 'xml.etree'
    and 'xml.sax' respectively.
    """
    names: dict[str, _base_nodes.ImportNode] = {}
    for name, stmts in not_consumed.items():
        if any(
            isinstance(stmt, nodes.AssignName)
            and isinstance(stmt.assign_type(), nodes.AugAssign)
            for stmt in stmts
        ):
            continue
        for stmt in stmts:
            if not isinstance(stmt, (nodes.ImportFrom, nodes.Import)):
                continue
            for imports in stmt.names:
                second_name = None
                import_module_name = imports[0]
                if import_module_name == "*":
                    # In case of wildcard imports,
                    # pick the name from inside the imported module.
                    second_name = name
                else:
                    name_matches_dotted_import = False
                    if (
                        import_module_name.startswith(name)
                        and import_module_name.find(".") &gt; -1
                    ):
                        name_matches_dotted_import = True

                    if name_matches_dotted_import or name in imports:
                        # Most likely something like 'xml.etree',
                        # which will appear in the .locals as 'xml'.
                        # Only pick the name if it wasn't consumed.
                        second_name = import_module_name
                if second_name and second_name not in names:
                    names[second_name] = stmt
    return sorted(names.items(), key=lambda a: a[1].fromlineno)


</t>
<t tx="ekr.20250131013600.135">def _find_frame_imports(name: str, frame: nodes.LocalsDictNodeNG) -&gt; bool:
    """Detect imports in the frame, with the required *name*.

    Such imports can be considered assignments if they are not globals.
    Returns True if an import for the given name was found.
    """
    if name in _flattened_scope_names(frame.nodes_of_class(nodes.Global)):
        return False

    imports = frame.nodes_of_class((nodes.Import, nodes.ImportFrom))
    for import_node in imports:
        for import_name, import_alias in import_node.names:
            # If the import uses an alias, check only that.
            # Otherwise, check only the import name.
            if import_alias:
                if import_alias == name:
                    return True
            elif import_name and import_name == name:
                return True
    return False


</t>
<t tx="ekr.20250131013600.136">def _import_name_is_global(
    stmt: nodes.Global | _base_nodes.ImportNode,
    global_names: set[str],
) -&gt; bool:
    for import_name, import_alias in stmt.names:
        # If the import uses an alias, check only that.
        # Otherwise, check only the import name.
        if import_alias:
            if import_alias in global_names:
                return True
        elif import_name in global_names:
            return True
    return False


</t>
<t tx="ekr.20250131013600.137">def _flattened_scope_names(
    iterator: Iterator[nodes.Global | nodes.Nonlocal],
) -&gt; set[str]:
    values = (set(stmt.names) for stmt in iterator)
    return set(itertools.chain.from_iterable(values))


</t>
<t tx="ekr.20250131013600.138">def _assigned_locally(name_node: nodes.Name) -&gt; bool:
    """Checks if name_node has corresponding assign statement in same scope."""
    name_node_scope = name_node.scope()
    assign_stmts = name_node_scope.nodes_of_class(nodes.AssignName)
    return any(a.name == name_node.name for a in assign_stmts) or _find_frame_imports(
        name_node.name, name_node_scope
    )


</t>
<t tx="ekr.20250131013600.139">def _is_before(node: nodes.NodeNG, reference_node: nodes.NodeNG) -&gt; bool:
    """Checks if node appears before reference_node."""
    if node.lineno &lt; reference_node.lineno:
        return True
    if (
        node.lineno == reference_node.lineno
        and node.col_offset &lt; reference_node.col_offset
    ):
        return True
    return False


</t>
<t tx="ekr.20250131013600.14">def is_being_called(node: nodes.NodeNG) -&gt; bool:
    """Return True if node is the function being called in a Call node."""
    return isinstance(node.parent, nodes.Call) and node.parent.func is node


</t>
<t tx="ekr.20250131013600.140">def _is_nonlocal_name(node: nodes.Name, frame: nodes.LocalsDictNodeNG) -&gt; bool:
    """Checks if name node has a nonlocal declaration in the given frame."""
    if not isinstance(frame, nodes.FunctionDef):
        return False

    return any(
        isinstance(stmt, nodes.Nonlocal)
        and node.name in stmt.names
        and _is_before(stmt, node)
        for stmt in frame.body
    )


</t>
<t tx="ekr.20250131013600.141">def _has_locals_call_after_node(stmt: nodes.NodeNG, scope: nodes.FunctionDef) -&gt; bool:
    skip_nodes = (
        nodes.FunctionDef,
        nodes.ClassDef,
        nodes.Import,
        nodes.ImportFrom,
    )
    for call in scope.nodes_of_class(nodes.Call, skip_klass=skip_nodes):
        inferred = utils.safe_infer(call.func)
        if (
            utils.is_builtin_object(inferred)
            and getattr(inferred, "name", None) == "locals"
        ):
            if stmt.lineno &lt; call.lineno:
                return True
    return False


</t>
<t tx="ekr.20250131013600.142">MSGS: dict[str, MessageDefinitionTuple] = {
    "E0601": (
        "Using variable %r before assignment",
        "used-before-assignment",
        "Emitted when a local variable is accessed before its assignment took place. "
        "Assignments in try blocks are assumed not to have occurred when evaluating "
        "associated except/finally blocks. Assignments in except blocks are assumed "
        "not to have occurred when evaluating statements outside the block, except "
        "when the associated try block contains a return statement.",
    ),
    "E0602": (
        "Undefined variable %r",
        "undefined-variable",
        "Used when an undefined variable is accessed.",
    ),
    "E0603": (
        "Undefined variable name %r in __all__",
        "undefined-all-variable",
        "Used when an undefined variable name is referenced in __all__.",
    ),
    "E0604": (
        "Invalid object %r in __all__, must contain only strings",
        "invalid-all-object",
        "Used when an invalid (non-string) object occurs in __all__.",
    ),
    "E0605": (
        "Invalid format for __all__, must be tuple or list",
        "invalid-all-format",
        "Used when __all__ has an invalid format.",
    ),
    "E0606": (
        "Possibly using variable %r before assignment",
        "possibly-used-before-assignment",
        "Emitted when a local variable is accessed before its assignment took place "
        "in both branches of an if/else switch.",
    ),
    "E0611": (
        "No name %r in module %r",
        "no-name-in-module",
        "Used when a name cannot be found in a module.",
    ),
    "W0601": (
        "Global variable %r undefined at the module level",
        "global-variable-undefined",
        'Used when a variable is defined through the "global" statement '
        "but the variable is not defined in the module scope.",
    ),
    "W0602": (
        "Using global for %r but no assignment is done",
        "global-variable-not-assigned",
        "When a variable defined in the global scope is modified in an inner scope, "
        "the 'global' keyword is required in the inner scope only if there is an "
        "assignment operation done in the inner scope.",
    ),
    "W0603": (
        "Using the global statement",  # W0121
        "global-statement",
        'Used when you use the "global" statement to update a global '
        "variable. Pylint discourages its usage. That doesn't mean you cannot "
        "use it!",
    ),
    "W0604": (
        "Using the global statement at the module level",  # W0103
        "global-at-module-level",
        'Used when you use the "global" statement at the module level '
        "since it has no effect.",
    ),
    "W0611": (
        "Unused %s",
        "unused-import",
        "Used when an imported module or variable is not used.",
    ),
    "W0612": (
        "Unused variable %r",
        "unused-variable",
        "Used when a variable is defined but not used.",
    ),
    "W0613": (
        "Unused argument %r",
        "unused-argument",
        "Used when a function or method argument is not used.",
    ),
    "W0614": (
        "Unused import(s) %s from wildcard import of %s",
        "unused-wildcard-import",
        "Used when an imported module or variable is not used from a "
        "`'from X import *'` style import.",
    ),
    "W0621": (
        "Redefining name %r from outer scope (line %s)",
        "redefined-outer-name",
        "Used when a variable's name hides a name defined in an outer scope or except handler.",
    ),
    "W0622": (
        "Redefining built-in %r",
        "redefined-builtin",
        "Used when a variable or function override a built-in.",
    ),
    "W0631": (
        "Using possibly undefined loop variable %r",
        "undefined-loop-variable",
        "Used when a loop variable (i.e. defined by a for loop or "
        "a list comprehension or a generator expression) is used outside "
        "the loop.",
    ),
    "W0632": (
        "Possible unbalanced tuple unpacking with sequence %s: left side has %d "
        "label%s, right side has %d value%s",
        "unbalanced-tuple-unpacking",
        "Used when there is an unbalanced tuple unpacking in assignment",
        {"old_names": [("E0632", "old-unbalanced-tuple-unpacking")]},
    ),
    "E0633": (
        "Attempting to unpack a non-sequence%s",
        "unpacking-non-sequence",
        "Used when something which is not a sequence is used in an unpack assignment",
        {"old_names": [("W0633", "old-unpacking-non-sequence")]},
    ),
    "W0640": (
        "Cell variable %s defined in loop",
        "cell-var-from-loop",
        "A variable used in a closure is defined in a loop. "
        "This will result in all closures using the same value for "
        "the closed-over variable.",
    ),
    "W0641": (
        "Possibly unused variable %r",
        "possibly-unused-variable",
        "Used when a variable is defined but might not be used. "
        "The possibility comes from the fact that locals() might be used, "
        "which could consume or not the said variable",
    ),
    "W0642": (
        "Invalid assignment to %s in method",
        "self-cls-assignment",
        "Invalid assignment to self or cls in instance or class method "
        "respectively.",
    ),
    "E0643": (
        "Invalid index for iterable length",
        "potential-index-error",
        "Emitted when an index used on an iterable goes beyond the length of that "
        "iterable.",
    ),
    "W0644": (
        "Possible unbalanced dict unpacking with %s: "
        "left side has %d label%s, right side has %d value%s",
        "unbalanced-dict-unpacking",
        "Used when there is an unbalanced dict unpacking in assignment or for loop",
    ),
}


class NamesConsumer:
    """A simple class to handle consumed, to consume and scope type info of node locals."""

@others
</t>
<t tx="ekr.20250131013600.143"># pylint: disable=too-many-public-methods
class VariablesChecker(BaseChecker):
    """BaseChecker for variables.

    Checks for
    * unused variables / imports
    * undefined variables
    * redefinition of variable from builtins or from an outer scope or except handler
    * use of variable before assignment
    * __all__ consistency
    * self/cls assignment
    """

    @others
</t>
<t tx="ekr.20250131013600.144">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(VariablesChecker(linter))
</t>
<t tx="ekr.20250131013600.145">    node: nodes.NodeNG
    scope_type: str

    to_consume: Consumption
    consumed: Consumption
    consumed_uncertain: Consumption
    """Retrieves nodes filtered out by get_next_to_consume() that may not
    have executed.

    These include nodes such as statements in except blocks, or statements
    in try blocks (when evaluating their corresponding except and finally
    blocks). Checkers that want to treat the statements as executed
    (e.g. for unused-variable) may need to add them back.
    """

    def __init__(self, node: nodes.NodeNG, scope_type: str):
        self.node = node
        self.scope_type = scope_type

        self.to_consume = copy.copy(node.locals)
        self.consumed = {}
        self.consumed_uncertain = defaultdict(list)

        self.names_under_always_false_test: set[str] = set()
        self.names_defined_under_one_branch_only: set[str] = set()

</t>
<t tx="ekr.20250131013600.146">    def __repr__(self) -&gt; str:
        _to_consumes = [f"{k}-&gt;{v}" for k, v in self.to_consume.items()]
        _consumed = [f"{k}-&gt;{v}" for k, v in self.consumed.items()]
        _consumed_uncertain = [f"{k}-&gt;{v}" for k, v in self.consumed_uncertain.items()]
        to_consumes = ", ".join(_to_consumes)
        consumed = ", ".join(_consumed)
        consumed_uncertain = ", ".join(_consumed_uncertain)
        return f"""
to_consume : {to_consumes}
consumed : {consumed}
consumed_uncertain: {consumed_uncertain}
scope_type : {self.scope_type}
"""

</t>
<t tx="ekr.20250131013600.147">    def mark_as_consumed(self, name: str, consumed_nodes: list[nodes.NodeNG]) -&gt; None:
        """Mark the given nodes as consumed for the name.

        If all of the nodes for the name were consumed, delete the name from
        the to_consume dictionary
        """
        unconsumed = [n for n in self.to_consume[name] if n not in set(consumed_nodes)]
        self.consumed[name] = consumed_nodes

        if unconsumed:
            self.to_consume[name] = unconsumed
        else:
            del self.to_consume[name]

</t>
<t tx="ekr.20250131013600.148">    def get_next_to_consume(self, node: nodes.Name) -&gt; list[nodes.NodeNG] | None:
        """Return a list of the nodes that define `node` from this scope.

        If it is uncertain whether a node will be consumed, such as for statements in
        except blocks, add it to self.consumed_uncertain instead of returning it.
        Return None to indicate a special case that needs to be handled by the caller.
        """
        name = node.name
        parent_node = node.parent
        found_nodes = self.to_consume.get(name)
        node_statement = node.statement()
        if (
            found_nodes
            and isinstance(parent_node, nodes.Assign)
            and parent_node == found_nodes[0].parent
        ):
            lhs = found_nodes[0].parent.targets[0]
            if (
                isinstance(lhs, nodes.AssignName) and lhs.name == name
            ):  # this name is defined in this very statement
                found_nodes = None

        if (
            found_nodes
            and isinstance(parent_node, nodes.For)
            and parent_node.iter == node
            and parent_node.target in found_nodes
        ):
            found_nodes = None

        # Before filtering, check that this node's name is not a nonlocal
        if _is_nonlocal_name(node, node.frame()):
            return found_nodes

        # And no comprehension is under the node's frame
        if VariablesChecker._comprehension_between_frame_and_node(node):
            return found_nodes

        # Filter out assignments in ExceptHandlers that node is not contained in
        if found_nodes:
            found_nodes = [
                n
                for n in found_nodes
                if not isinstance(n.statement(), nodes.ExceptHandler)
                or n.statement().parent_of(node)
            ]

        # Filter out assignments guarded by always false conditions
        if found_nodes:
            uncertain_nodes = self._uncertain_nodes_if_tests(found_nodes, node)
            self.consumed_uncertain[node.name] += uncertain_nodes
            uncertain_nodes_set = set(uncertain_nodes)
            found_nodes = [n for n in found_nodes if n not in uncertain_nodes_set]

        # Filter out assignments in an Except clause that the node is not
        # contained in, assuming they may fail
        if found_nodes:
            uncertain_nodes = self._uncertain_nodes_in_except_blocks(
                found_nodes, node, node_statement
            )
            self.consumed_uncertain[node.name] += uncertain_nodes
            uncertain_nodes_set = set(uncertain_nodes)
            found_nodes = [n for n in found_nodes if n not in uncertain_nodes_set]

        # If this node is in a Finally block of a Try/Finally,
        # filter out assignments in the try portion, assuming they may fail
        if found_nodes:
            uncertain_nodes = (
                self._uncertain_nodes_in_try_blocks_when_evaluating_finally_blocks(
                    found_nodes, node_statement, name
                )
            )
            self.consumed_uncertain[node.name] += uncertain_nodes
            uncertain_nodes_set = set(uncertain_nodes)
            found_nodes = [n for n in found_nodes if n not in uncertain_nodes_set]

        # If this node is in an ExceptHandler,
        # filter out assignments in the try portion, assuming they may fail
        if found_nodes:
            uncertain_nodes = (
                self._uncertain_nodes_in_try_blocks_when_evaluating_except_blocks(
                    found_nodes, node_statement
                )
            )
            self.consumed_uncertain[node.name] += uncertain_nodes
            uncertain_nodes_set = set(uncertain_nodes)
            found_nodes = [n for n in found_nodes if n not in uncertain_nodes_set]

        return found_nodes

</t>
<t tx="ekr.20250131013600.149">    def _inferred_to_define_name_raise_or_return(
        self,
        name: str,
        node: nodes.NodeNG,
    ) -&gt; bool:
        """Return True if there is a path under this `if_node`
        that is inferred to define `name`, raise, or return.
        """
        # Handle try and with
        if isinstance(node, nodes.Try):
            # Allow either a path through try/else/finally OR a path through ALL except handlers
            try_except_node = node
            if node.finalbody:
                try_except_node = next(
                    (child for child in node.nodes_of_class(nodes.Try)),
                    None,
                )
            handlers = try_except_node.handlers if try_except_node else []
            return NamesConsumer._defines_name_raises_or_returns_recursive(
                name, node
            ) or all(
                NamesConsumer._defines_name_raises_or_returns_recursive(name, handler)
                for handler in handlers
            )

        if isinstance(node, (nodes.With, nodes.For, nodes.While)):
            return NamesConsumer._defines_name_raises_or_returns_recursive(name, node)

        if not isinstance(node, nodes.If):
            return False

        # Be permissive if there is a break or a continue
        if any(node.nodes_of_class(nodes.Break, nodes.Continue)):
            return True

        # Is there an assignment in this node itself, e.g. in named expression?
        if NamesConsumer._defines_name_raises_or_returns(name, node):
            return True

        test = node.test.value if isinstance(node.test, nodes.NamedExpr) else node.test
        all_inferred = utils.infer_all(test)
        only_search_if = False
        only_search_else = True

        for inferred in all_inferred:
            if not isinstance(inferred, nodes.Const):
                only_search_else = False
                continue
            val = inferred.value
            only_search_if = only_search_if or (val != NotImplemented and val)
            only_search_else = only_search_else and not val

        # Only search else branch when test condition is inferred to be false
        if all_inferred and only_search_else:
            self.names_under_always_false_test.add(name)
            return self._branch_handles_name(name, node.orelse)
        # Search both if and else branches
        if_branch_handles = self._branch_handles_name(name, node.body)
        else_branch_handles = self._branch_handles_name(name, node.orelse)
        if if_branch_handles ^ else_branch_handles:
            self.names_defined_under_one_branch_only.add(name)
        elif name in self.names_defined_under_one_branch_only:
            self.names_defined_under_one_branch_only.remove(name)
        return if_branch_handles and else_branch_handles

</t>
<t tx="ekr.20250131013600.15">def assign_parent(node: nodes.NodeNG) -&gt; nodes.NodeNG:
    """Return the higher parent which is not an AssignName, Tuple or List node."""
    while node and isinstance(node, (nodes.AssignName, nodes.Tuple, nodes.List)):
        node = node.parent
    return node


</t>
<t tx="ekr.20250131013600.150">    def _branch_handles_name(self, name: str, body: Iterable[nodes.NodeNG]) -&gt; bool:
        return any(
            NamesConsumer._defines_name_raises_or_returns(name, if_body_stmt)
            or (
                isinstance(
                    if_body_stmt,
                    (
                        nodes.If,
                        nodes.Try,
                        nodes.With,
                        nodes.For,
                        nodes.While,
                    ),
                )
                and self._inferred_to_define_name_raise_or_return(name, if_body_stmt)
            )
            for if_body_stmt in body
        )

</t>
<t tx="ekr.20250131013600.151">    def _uncertain_nodes_if_tests(
        self,
        found_nodes: list[nodes.NodeNG],
        node: nodes.NodeNG,
    ) -&gt; list[nodes.NodeNG]:
        """Identify nodes of uncertain execution because they are defined under if
        tests.

        Don't identify a node if there is a path that is inferred to
        define the name, raise, or return (e.g. any executed if/elif/else branch).
        """
        uncertain_nodes = []
        for other_node in found_nodes:
            if isinstance(other_node, nodes.AssignName):
                name = other_node.name
            elif isinstance(other_node, (nodes.Import, nodes.ImportFrom)):
                name = node.name
            elif isinstance(other_node, (nodes.FunctionDef, nodes.ClassDef)):
                name = other_node.name
            else:
                continue

            all_if = [
                n
                for n in other_node.node_ancestors()
                if isinstance(n, nodes.If) and not n.parent_of(node)
            ]
            if not all_if:
                continue

            closest_if = all_if[0]
            if (
                isinstance(node, nodes.AssignName)
                and node.frame() is not closest_if.frame()
            ):
                continue
            if closest_if.parent_of(node):
                continue

            outer_if = all_if[-1]
            if NamesConsumer._node_guarded_by_same_test(node, outer_if):
                continue

            # Name defined in the if/else control flow
            if self._inferred_to_define_name_raise_or_return(name, outer_if):
                continue

            uncertain_nodes.append(other_node)

        return uncertain_nodes

</t>
<t tx="ekr.20250131013600.152">    @staticmethod
    def _node_guarded_by_same_test(node: nodes.NodeNG, other_if: nodes.If) -&gt; bool:
        """Identify if `node` is guarded by an equivalent test as `other_if`.

        Two tests are equivalent if their string representations are identical
        or if their inferred values consist only of constants and those constants
        are identical, and the if test guarding `node` is not a Name.
        """
        if isinstance(other_if.test, nodes.NamedExpr):
            other_if_test = other_if.test.target
        else:
            other_if_test = other_if.test
        other_if_test_as_string = other_if_test.as_string()
        other_if_test_all_inferred = utils.infer_all(other_if_test)
        for ancestor in node.node_ancestors():
            if not isinstance(ancestor, (nodes.If, nodes.IfExp)):
                continue
            if ancestor.test.as_string() == other_if_test_as_string:
                return True
            if isinstance(ancestor.test, nodes.Name):
                continue
            all_inferred = utils.infer_all(ancestor.test)
            if len(all_inferred) == len(other_if_test_all_inferred):
                if any(
                    not isinstance(test, nodes.Const)
                    for test in (* all_inferred, * other_if_test_all_inferred)
                ):
                    continue
                if {test.value for test in all_inferred} != {
                    test.value for test in other_if_test_all_inferred
                }:
                    continue
                return True

        return False

</t>
<t tx="ekr.20250131013600.153">    @staticmethod
    def _uncertain_nodes_in_except_blocks(
        found_nodes: list[nodes.NodeNG],
        node: nodes.NodeNG,
        node_statement: _base_nodes.Statement,
    ) -&gt; list[nodes.NodeNG]:
        """Return any nodes in ``found_nodes`` that should be treated as uncertain
        because they are in an except block.
        """
        uncertain_nodes = []
        for other_node in found_nodes:
            other_node_statement = other_node.statement()
            # Only testing for statements in the except block of Try
            closest_except_handler = utils.get_node_first_ancestor_of_type(
                other_node_statement, nodes.ExceptHandler
            )
            if not closest_except_handler:
                continue
            # If the other node is in the same scope as this node, assume it executes
            if closest_except_handler.parent_of(node):
                continue
            closest_try_except: nodes.Try = closest_except_handler.parent
            # If the try or else blocks return, assume the except blocks execute.
            try_block_returns = any(
                isinstance(try_statement, nodes.Return)
                for try_statement in closest_try_except.body
            )
            else_block_returns = any(
                isinstance(else_statement, nodes.Return)
                for else_statement in closest_try_except.orelse
            )
            else_block_exits = any(
                isinstance(else_statement, nodes.Expr)
                and isinstance(else_statement.value, nodes.Call)
                and utils.is_terminating_func(else_statement.value)
                for else_statement in closest_try_except.orelse
            )
            else_block_continues = any(
                isinstance(else_statement, nodes.Continue)
                for else_statement in closest_try_except.orelse
            )
            if (
                else_block_continues
                and isinstance(node_statement.parent, (nodes.For, nodes.While))
                and closest_try_except.parent.parent_of(node_statement)
            ):
                continue

            if try_block_returns or else_block_returns or else_block_exits:
                # Exception: if this node is in the final block of the other_node_statement,
                # it will execute before returning. Assume the except statements are uncertain.
                if (
                    isinstance(node_statement.parent, nodes.Try)
                    and node_statement in node_statement.parent.finalbody
                    and closest_try_except.parent.parent_of(node_statement)
                ):
                    uncertain_nodes.append(other_node)
                # Or the node_statement is in the else block of the relevant Try
                elif (
                    isinstance(node_statement.parent, nodes.Try)
                    and node_statement in node_statement.parent.orelse
                    and closest_try_except.parent.parent_of(node_statement)
                ):
                    uncertain_nodes.append(other_node)
                # Assume the except blocks execute, so long as each handler
                # defines the name, raises, or returns.
                elif all(
                    NamesConsumer._defines_name_raises_or_returns_recursive(
                        node.name, handler
                    )
                    for handler in closest_try_except.handlers
                ):
                    continue

            if NamesConsumer._check_loop_finishes_via_except(node, closest_try_except):
                continue

            # Passed all tests for uncertain execution
            uncertain_nodes.append(other_node)
        return uncertain_nodes

</t>
<t tx="ekr.20250131013600.154">    @staticmethod
    def _defines_name_raises_or_returns(name: str, node: nodes.NodeNG) -&gt; bool:
        if isinstance(node, (nodes.Raise, nodes.Assert, nodes.Return, nodes.Continue)):
            return True
        if isinstance(node, nodes.Expr) and isinstance(node.value, nodes.Call):
            if utils.is_terminating_func(node.value):
                return True
            if (
                isinstance(node.value.func, nodes.Name)
                and node.value.func.name == "assert_never"
            ):
                return True
        if (
            isinstance(node, nodes.AnnAssign)
            and node.value
            and isinstance(node.target, nodes.AssignName)
            and node.target.name == name
        ):
            return True
        if isinstance(node, nodes.Assign):
            for target in node.targets:
                for elt in utils.get_all_elements(target):
                    if isinstance(elt, nodes.Starred):
                        elt = elt.value
                    if isinstance(elt, nodes.AssignName) and elt.name == name:
                        return True
        if isinstance(node, nodes.If):
            if any(
                child_named_expr.target.name == name
                for child_named_expr in node.nodes_of_class(nodes.NamedExpr)
            ):
                return True
        if isinstance(node, (nodes.Import, nodes.ImportFrom)) and any(
            (node_name[1] and node_name[1] == name) or (node_name[0] == name)
            for node_name in node.names
        ):
            return True
        if isinstance(node, nodes.With) and any(
            isinstance(item[1], nodes.AssignName) and item[1].name == name
            for item in node.items
        ):
            return True
        if isinstance(node, (nodes.ClassDef, nodes.FunctionDef)) and node.name == name:
            return True
        if (
            isinstance(node, nodes.ExceptHandler)
            and node.name
            and node.name.name == name
        ):
            return True
        return False

</t>
<t tx="ekr.20250131013600.155">    @staticmethod
    def _defines_name_raises_or_returns_recursive(
        name: str,
        node: nodes.NodeNG,
    ) -&gt; bool:
        """Return True if some child of `node` defines the name `name`,
        raises, or returns.
        """
        for stmt in node.get_children():
            if NamesConsumer._defines_name_raises_or_returns(name, stmt):
                return True
            if isinstance(stmt, (nodes.If, nodes.With)):
                if any(
                    NamesConsumer._defines_name_raises_or_returns(name, nested_stmt)
                    for nested_stmt in stmt.get_children()
                ):
                    return True
            if (
                isinstance(stmt, nodes.Try)
                and not stmt.finalbody
                and NamesConsumer._defines_name_raises_or_returns_recursive(name, stmt)
            ):
                return True
        return False

</t>
<t tx="ekr.20250131013600.156">    @staticmethod
    def _check_loop_finishes_via_except(
        node: nodes.NodeNG,
        other_node_try_except: nodes.Try,
    ) -&gt; bool:
        """Check for a specific control flow scenario.

        Described in https://github.com/pylint-dev/pylint/issues/5683.

        A scenario where the only non-break exit from a loop consists of the very
        except handler we are examining, such that code in the `else` branch of
        the loop can depend on it being assigned.

        Example:
        for _ in range(3):
            try:
                do_something()
            except:
                name = 1  &lt;-- only non-break exit from loop
            else:
                break
        else:
            print(name)
        """
        if not other_node_try_except.orelse:
            return False
        closest_loop: None | (nodes.For | nodes.While) = (
            utils.get_node_first_ancestor_of_type(node, (nodes.For, nodes.While))
        )
        if closest_loop is None:
            return False
        if not any(
            else_statement is node or else_statement.parent_of(node)
            for else_statement in closest_loop.orelse
        ):
            # `node` not guarded by `else`
            return False
        for inner_else_statement in other_node_try_except.orelse:
            if isinstance(inner_else_statement, nodes.Break):
                break_stmt = inner_else_statement
                break
        else:
            # No break statement
            return False

        def _try_in_loop_body(
            other_node_try_except: nodes.Try,
            loop: nodes.For | nodes.While,
        ) -&gt; bool:
            """Return True if `other_node_try_except` is a descendant of `loop`."""
            return any(
                loop_body_statement is other_node_try_except
                or loop_body_statement.parent_of(other_node_try_except)
                for loop_body_statement in loop.body
            )

        if not _try_in_loop_body(other_node_try_except, closest_loop):
            for ancestor in closest_loop.node_ancestors():
                if isinstance(ancestor, (nodes.For, nodes.While)):
                    if _try_in_loop_body(other_node_try_except, ancestor):
                        break
            else:
                # `other_node_try_except` didn't have a shared ancestor loop
                return False

        for loop_stmt in closest_loop.body:
            if NamesConsumer._recursive_search_for_continue_before_break(
                loop_stmt, break_stmt
            ):
                break
        else:
            # No continue found, so we arrived at our special case!
            return True
        return False

</t>
<t tx="ekr.20250131013600.157">    @staticmethod
    def _recursive_search_for_continue_before_break(
        stmt: _base_nodes.Statement,
        break_stmt: nodes.Break,
    ) -&gt; bool:
        """Return True if any Continue node can be found in descendants of `stmt`
        before encountering `break_stmt`, ignoring any nested loops.
        """
        if stmt is break_stmt:
            return False
        if isinstance(stmt, nodes.Continue):
            return True
        for child in stmt.get_children():
            if isinstance(stmt, (nodes.For, nodes.While)):
                continue
            if NamesConsumer._recursive_search_for_continue_before_break(
                child, break_stmt
            ):
                return True
        return False

</t>
<t tx="ekr.20250131013600.158">    @staticmethod
    def _uncertain_nodes_in_try_blocks_when_evaluating_except_blocks(
        found_nodes: list[nodes.NodeNG],
        node_statement: _base_nodes.Statement,
    ) -&gt; list[nodes.NodeNG]:
        """Return any nodes in ``found_nodes`` that should be treated as uncertain.

        Nodes are uncertain when they are in a try block and the ``node_statement``
        being evaluated is in one of its except handlers.
        """
        uncertain_nodes: list[nodes.NodeNG] = []
        closest_except_handler = utils.get_node_first_ancestor_of_type(
            node_statement, nodes.ExceptHandler
        )
        if closest_except_handler is None:
            return uncertain_nodes
        for other_node in found_nodes:
            other_node_statement = other_node.statement()
            # If the other statement is the except handler guarding `node`, it executes
            if other_node_statement is closest_except_handler:
                continue
            # Ensure other_node is in a try block
            (
                other_node_try_ancestor,
                other_node_try_ancestor_visited_child,
            ) = utils.get_node_first_ancestor_of_type_and_its_child(
                other_node_statement, nodes.Try
            )
            if other_node_try_ancestor is None:
                continue
            if (
                other_node_try_ancestor_visited_child
                not in other_node_try_ancestor.body
            ):
                continue
            # Make sure nesting is correct -- there should be at least one
            # except handler that is a sibling attached to the try ancestor,
            # or is an ancestor of the try ancestor.
            if not any(
                closest_except_handler in other_node_try_ancestor.handlers
                or other_node_try_ancestor_except_handler
                in closest_except_handler.node_ancestors()
                for other_node_try_ancestor_except_handler in other_node_try_ancestor.handlers
            ):
                continue
            # Passed all tests for uncertain execution
            uncertain_nodes.append(other_node)
        return uncertain_nodes

</t>
<t tx="ekr.20250131013600.159">    @staticmethod
    def _uncertain_nodes_in_try_blocks_when_evaluating_finally_blocks(
        found_nodes: list[nodes.NodeNG],
        node_statement: _base_nodes.Statement,
        name: str,
    ) -&gt; list[nodes.NodeNG]:
        uncertain_nodes: list[nodes.NodeNG] = []
        (
            closest_try_finally_ancestor,
            child_of_closest_try_finally_ancestor,
        ) = utils.get_node_first_ancestor_of_type_and_its_child(
            node_statement, nodes.Try
        )
        if closest_try_finally_ancestor is None:
            return uncertain_nodes
        if (
            child_of_closest_try_finally_ancestor
            not in closest_try_finally_ancestor.finalbody
        ):
            return uncertain_nodes
        for other_node in found_nodes:
            other_node_statement = other_node.statement()
            (
                other_node_try_finally_ancestor,
                child_of_other_node_try_finally_ancestor,
            ) = utils.get_node_first_ancestor_of_type_and_its_child(
                other_node_statement, nodes.Try
            )
            if other_node_try_finally_ancestor is None:
                continue
            # other_node needs to descend from the try of a try/finally.
            if (
                child_of_other_node_try_finally_ancestor
                not in other_node_try_finally_ancestor.body
            ):
                continue
            # If the two try/finally ancestors are not the same, then
            # node_statement's closest try/finally ancestor needs to be in
            # the final body of other_node's try/finally ancestor, or
            # descend from one of the statements in that final body.
            if (
                other_node_try_finally_ancestor is not closest_try_finally_ancestor
                and not any(
                    other_node_final_statement is closest_try_finally_ancestor
                    or other_node_final_statement.parent_of(
                        closest_try_finally_ancestor
                    )
                    for other_node_final_statement in other_node_try_finally_ancestor.finalbody
                )
            ):
                continue
            # Is the name defined in all exception clauses?
            if other_node_try_finally_ancestor.handlers and all(
                NamesConsumer._defines_name_raises_or_returns_recursive(name, handler)
                for handler in other_node_try_finally_ancestor.handlers
            ):
                continue
            # Passed all tests for uncertain execution
            uncertain_nodes.append(other_node)
        return uncertain_nodes


</t>
<t tx="ekr.20250131013600.16">def overrides_a_method(class_node: nodes.ClassDef, name: str) -&gt; bool:
    """Return True if &lt;name&gt; is a method overridden from an ancestor
    which is not the base object class.
    """
    for ancestor in class_node.ancestors():
        if ancestor.name == "object":
            continue
        if name in ancestor and isinstance(ancestor[name], nodes.FunctionDef):
            return True
    return False


</t>
<t tx="ekr.20250131013600.160">name = "variables"
msgs = MSGS
options = (
    (
        "init-import",
        {
            "default": False,
            "type": "yn",
            "metavar": "&lt;y or n&gt;",
            "help": "Tells whether we should check for unused import in "
            "__init__ files.",
        },
    ),
    (
        "dummy-variables-rgx",
        {
            "default": "_+$|(_[a-zA-Z0-9_]*[a-zA-Z0-9]+?$)|dummy|^ignored_|^unused_",
            "type": "regexp",
            "metavar": "&lt;regexp&gt;",
            "help": "A regular expression matching the name of dummy "
            "variables (i.e. expected to not be used).",
        },
    ),
    (
        "additional-builtins",
        {
            "default": (),
            "type": "csv",
            "metavar": "&lt;comma separated list&gt;",
            "help": "List of additional names supposed to be defined in "
            "builtins. Remember that you should avoid defining new builtins "
            "when possible.",
        },
    ),
    (
        "callbacks",
        {
            "default": ("cb_", "_cb"),
            "type": "csv",
            "metavar": "&lt;callbacks&gt;",
            "help": "List of strings which can identify a callback "
            "function by name. A callback name must start or "
            "end with one of those strings.",
        },
    ),
    (
        "redefining-builtins-modules",
        {
            "default": (
                "six.moves",
                "past.builtins",
                "future.builtins",
                "builtins",
                "io",
            ),
            "type": "csv",
            "metavar": "&lt;comma separated list&gt;",
            "help": "List of qualified module names which can have objects "
            "that can redefine builtins.",
        },
    ),
    (
        "ignored-argument-names",
        {
            "default": IGNORED_ARGUMENT_NAMES,
            "type": "regexp",
            "metavar": "&lt;regexp&gt;",
            "help": "Argument names that match this expression will be ignored.",
        },
    ),
    (
        "allow-global-unused-variables",
        {
            "default": True,
            "type": "yn",
            "metavar": "&lt;y or n&gt;",
            "help": "Tells whether unused global variables should be treated as a violation.",
        },
    ),
    (
        "allowed-redefined-builtins",
        {
            "default": (),
            "type": "csv",
            "metavar": "&lt;comma separated list&gt;",
            "help": "List of names allowed to shadow builtins",
        },
    ),
)

def __init__(self, linter: PyLinter) -&gt; None:
    super().__init__(linter)
    self._to_consume: list[NamesConsumer] = []
    self._type_annotation_names: list[str] = []
    self._except_handler_names_queue: list[
        tuple[nodes.ExceptHandler, nodes.AssignName]
    ] = []
    """This is a queue, last in first out."""
    self._reported_type_checking_usage_scopes: dict[
        str, list[nodes.LocalsDictNodeNG]
    ] = {}
    self._postponed_evaluation_enabled = False

</t>
<t tx="ekr.20250131013600.161">@utils.only_required_for_messages(
    "unbalanced-dict-unpacking",
)
def visit_for(self, node: nodes.For) -&gt; None:
    if not isinstance(node.target, nodes.Tuple):
        return

    targets = node.target.elts

    inferred = utils.safe_infer(node.iter)
    if not isinstance(inferred, DICT_TYPES):
        return

    values = self._nodes_to_unpack(inferred)
    if not values:
        # no dict items returned
        return

    if isinstance(inferred, astroid.objects.DictItems):
        # dict.items() is a bit special because values will be a tuple
        # So as long as there are always 2 targets and values each are
        # a tuple with two items, this will unpack correctly.
        # Example: `for key, val in {1: 2, 3: 4}.items()`
        if len(targets) == 2 and all(len(x.elts) == 2 for x in values):
            return

        # Starred nodes indicate ambiguous unpacking
        # if `dict.items()` is used so we won't flag them.
        if any(isinstance(target, nodes.Starred) for target in targets):
            return

    if isinstance(inferred, nodes.Dict):
        if isinstance(node.iter, nodes.Name):
            # If this a case of 'dict-items-missing-iter', we don't want to
            # report it as an 'unbalanced-dict-unpacking' as well
            # TODO (performance), merging both checks would streamline this
            if len(targets) == 2:
                return

    else:
        is_starred_targets = any(
            isinstance(target, nodes.Starred) for target in targets
        )
        for value in values:
            value_length = self._get_value_length(value)
            is_valid_star_unpack = is_starred_targets and value_length &gt;= len(
                targets
            )
            if len(targets) != value_length and not is_valid_star_unpack:
                details = _get_unpacking_extra_info(node, inferred)
                self._report_unbalanced_unpacking(
                    node, inferred, targets, value_length, details
                )
                break

</t>
<t tx="ekr.20250131013600.162">def leave_for(self, node: nodes.For) -&gt; None:
    self._store_type_annotation_names(node)

</t>
<t tx="ekr.20250131013600.163">def visit_module(self, node: nodes.Module) -&gt; None:
    """Visit module : update consumption analysis variable
    checks globals doesn't overrides builtins.
    """
    self._to_consume = [NamesConsumer(node, "module")]
    self._postponed_evaluation_enabled = is_postponed_evaluation_enabled(node)

    for name, stmts in node.locals.items():
        if utils.is_builtin(name):
            if self._should_ignore_redefined_builtin(stmts[0]) or name == "__doc__":
                continue
            self.add_message("redefined-builtin", args=name, node=stmts[0])

</t>
<t tx="ekr.20250131013600.164">@utils.only_required_for_messages(
    "unused-import",
    "unused-wildcard-import",
    "redefined-builtin",
    "undefined-all-variable",
    "invalid-all-object",
    "invalid-all-format",
    "unused-variable",
    "undefined-variable",
)
def leave_module(self, node: nodes.Module) -&gt; None:
    """Leave module: check globals."""
    assert len(self._to_consume) == 1

    self._check_metaclasses(node)
    not_consumed = self._to_consume.pop().to_consume
    # attempt to check for __all__ if defined
    if "__all__" in node.locals:
        self._check_all(node, not_consumed)

    # check for unused globals
    self._check_globals(not_consumed)

    # don't check unused imports in __init__ files
    if not self.linter.config.init_import and node.package:
        return

    self._check_imports(not_consumed)
    self._type_annotation_names = []

</t>
<t tx="ekr.20250131013600.165">def visit_classdef(self, node: nodes.ClassDef) -&gt; None:
    """Visit class: update consumption analysis variable."""
    self._to_consume.append(NamesConsumer(node, "class"))

</t>
<t tx="ekr.20250131013600.166">def leave_classdef(self, node: nodes.ClassDef) -&gt; None:
    """Leave class: update consumption analysis variable."""
    # Check for hidden ancestor names
    # e.g. "six" in: Class X(six.with_metaclass(ABCMeta, object)):
    for name_node in node.nodes_of_class(nodes.Name):
        if (
            isinstance(name_node.parent, nodes.Call)
            and isinstance(name_node.parent.func, nodes.Attribute)
            and isinstance(name_node.parent.func.expr, nodes.Name)
        ):
            hidden_name_node = name_node.parent.func.expr
            for consumer in self._to_consume:
                if hidden_name_node.name in consumer.to_consume:
                    consumer.mark_as_consumed(
                        hidden_name_node.name,
                        consumer.to_consume[hidden_name_node.name],
                    )
                    break
    self._to_consume.pop()

</t>
<t tx="ekr.20250131013600.167">def visit_lambda(self, node: nodes.Lambda) -&gt; None:
    """Visit lambda: update consumption analysis variable."""
    self._to_consume.append(NamesConsumer(node, "lambda"))

</t>
<t tx="ekr.20250131013600.168">def leave_lambda(self, _: nodes.Lambda) -&gt; None:
    """Leave lambda: update consumption analysis variable."""
    # do not check for not used locals here
    self._to_consume.pop()

</t>
<t tx="ekr.20250131013600.169">def visit_generatorexp(self, node: nodes.GeneratorExp) -&gt; None:
    """Visit genexpr: update consumption analysis variable."""
    self._to_consume.append(NamesConsumer(node, "comprehension"))

</t>
<t tx="ekr.20250131013600.17">def only_required_for_messages(
    *messages: str,
) -&gt; Callable[
    [AstCallbackMethod[_CheckerT, _NodeT]], AstCallbackMethod[_CheckerT, _NodeT]
</t>
<t tx="ekr.20250131013600.170">def leave_generatorexp(self, _: nodes.GeneratorExp) -&gt; None:
    """Leave genexpr: update consumption analysis variable."""
    # do not check for not used locals here
    self._to_consume.pop()

</t>
<t tx="ekr.20250131013600.171">def visit_dictcomp(self, node: nodes.DictComp) -&gt; None:
    """Visit dictcomp: update consumption analysis variable."""
    self._to_consume.append(NamesConsumer(node, "comprehension"))

</t>
<t tx="ekr.20250131013600.172">def leave_dictcomp(self, _: nodes.DictComp) -&gt; None:
    """Leave dictcomp: update consumption analysis variable."""
    # do not check for not used locals here
    self._to_consume.pop()

</t>
<t tx="ekr.20250131013600.173">def visit_setcomp(self, node: nodes.SetComp) -&gt; None:
    """Visit setcomp: update consumption analysis variable."""
    self._to_consume.append(NamesConsumer(node, "comprehension"))

</t>
<t tx="ekr.20250131013600.174">def leave_setcomp(self, _: nodes.SetComp) -&gt; None:
    """Leave setcomp: update consumption analysis variable."""
    # do not check for not used locals here
    self._to_consume.pop()

</t>
<t tx="ekr.20250131013600.175">def visit_functiondef(self, node: nodes.FunctionDef) -&gt; None:
    """Visit function: update consumption analysis variable and check locals."""
    self._to_consume.append(NamesConsumer(node, "function"))
    if not (
        self.linter.is_message_enabled("redefined-outer-name")
        or self.linter.is_message_enabled("redefined-builtin")
    ):
        return
    globs = node.root().globals
    for name, stmt in node.items():
        if name in globs and not isinstance(stmt, nodes.Global):
            definition = globs[name][0]
            if (
                isinstance(definition, nodes.ImportFrom)
                and definition.modname == FUTURE
            ):
                # It is a __future__ directive, not a symbol.
                continue

            # Do not take in account redefined names for the purpose
            # of type checking.:
            if any(
                in_type_checking_block(definition) for definition in globs[name]
            ):
                continue

            # Suppress emitting the message if the outer name is in the
            # scope of an exception assignment.
            # For example: the `e` in `except ValueError as e`
            global_node = globs[name][0]
            if isinstance(global_node, nodes.AssignName) and isinstance(
                global_node.parent, nodes.ExceptHandler
            ):
                continue

            line = definition.fromlineno
            if not self._is_name_ignored(stmt, name):
                self.add_message(
                    "redefined-outer-name", args=(name, line), node=stmt
                )

        elif (
            utils.is_builtin(name)
            and not self._allowed_redefined_builtin(name)
            and not self._should_ignore_redefined_builtin(stmt)
        ):
            # do not print Redefining builtin for additional builtins
            self.add_message("redefined-builtin", args=name, node=stmt)

</t>
<t tx="ekr.20250131013600.176">def leave_functiondef(self, node: nodes.FunctionDef) -&gt; None:
    """Leave function: check function's locals are consumed."""
    self._check_metaclasses(node)

    if node.type_comment_returns:
        self._store_type_annotation_node(node.type_comment_returns)
    if node.type_comment_args:
        for argument_annotation in node.type_comment_args:
            self._store_type_annotation_node(argument_annotation)

    not_consumed = self._to_consume.pop().to_consume
    if not (
        self.linter.is_message_enabled("unused-variable")
        or self.linter.is_message_enabled("possibly-unused-variable")
        or self.linter.is_message_enabled("unused-argument")
    ):
        return

    # Don't check arguments of function which are only raising an exception.
    if utils.is_error(node):
        return

    # Don't check arguments of abstract methods or within an interface.
    is_method = node.is_method()
    if is_method and node.is_abstract():
        return

    global_names = _flattened_scope_names(node.nodes_of_class(nodes.Global))
    nonlocal_names = _flattened_scope_names(node.nodes_of_class(nodes.Nonlocal))
    comprehension_target_names: set[str] = set()

    for comprehension_scope in node.nodes_of_class(nodes.ComprehensionScope):
        for generator in comprehension_scope.generators:
            for name in utils.find_assigned_names_recursive(generator.target):
                comprehension_target_names.add(name)

    for name, stmts in not_consumed.items():
        self._check_is_unused(
            name,
            node,
            stmts[0],
            global_names,
            nonlocal_names,
            comprehension_target_names,
        )

</t>
<t tx="ekr.20250131013600.177">visit_asyncfunctiondef = visit_functiondef
leave_asyncfunctiondef = leave_functiondef

@utils.only_required_for_messages(
    "global-variable-undefined",
    "global-variable-not-assigned",
    "global-statement",
    "global-at-module-level",
    "redefined-builtin",
)
def visit_global(self, node: nodes.Global) -&gt; None:
    """Check names imported exists in the global scope."""
    frame = node.frame()
    if isinstance(frame, nodes.Module):
        self.add_message("global-at-module-level", node=node, confidence=HIGH)
        return

    module = frame.root()
    default_message = True
    locals_ = node.scope().locals
    for name in node.names:
        try:
            assign_nodes = module.getattr(name)
        except astroid.NotFoundError:
            # unassigned global, skip
            assign_nodes = []

        not_defined_locally_by_import = not any(
            isinstance(local, (nodes.Import, nodes.ImportFrom))
            for local in locals_.get(name, ())
        )
        if (
            not utils.is_reassigned_after_current(node, name)
            and not utils.is_deleted_after_current(node, name)
            and not_defined_locally_by_import
        ):
            self.add_message(
                "global-variable-not-assigned",
                args=name,
                node=node,
                confidence=HIGH,
            )
            default_message = False
            continue

        for anode in assign_nodes:
            if (
                isinstance(anode, nodes.AssignName)
                and anode.name in module.special_attributes
            ):
                self.add_message("redefined-builtin", args=name, node=node)
                break
            if anode.frame() is module:
                # module level assignment
                break
            if (
                isinstance(anode, (nodes.ClassDef, nodes.FunctionDef))
                and anode.parent is module
            ):
                # module level function assignment
                break
        else:
            if not_defined_locally_by_import:
                # global undefined at the module scope
                self.add_message(
                    "global-variable-undefined",
                    args=name,
                    node=node,
                    confidence=HIGH,
                )
                default_message = False

    if default_message:
        self.add_message("global-statement", node=node, confidence=HIGH)

</t>
<t tx="ekr.20250131013600.178">def visit_assignname(self, node: nodes.AssignName) -&gt; None:
    if isinstance(node.assign_type(), nodes.AugAssign):
        self.visit_name(node)

</t>
<t tx="ekr.20250131013600.179">def visit_delname(self, node: nodes.DelName) -&gt; None:
    self.visit_name(node)

</t>
<t tx="ekr.20250131013600.18">]:
    """Decorator to store messages that are handled by a checker method as an
    attribute of the function object.

    This information is used by ``ASTWalker`` to decide whether to call the decorated
    method or not. If none of the messages is enabled, the method will be skipped.
    Therefore, the list of messages must be well maintained at all times!
    This decorator only has an effect on ``visit_*`` and ``leave_*`` methods
    of a class inheriting from ``BaseChecker``.
    """

    def store_messages(
        func: AstCallbackMethod[_CheckerT, _NodeT]
    ) -&gt; AstCallbackMethod[_CheckerT, _NodeT]:
        func.checks_msgs = messages  # type: ignore[attr-defined]
        return func

</t>
<t tx="ekr.20250131013600.180">def visit_name(self, node: nodes.Name | nodes.AssignName | nodes.DelName) -&gt; None:
    """Don't add the 'utils.only_required_for_messages' decorator here!

    It's important that all 'Name' nodes are visited, otherwise the
    'NamesConsumers' won't be correct.
    """
    stmt = node.statement()
    if stmt.fromlineno is None:
        # name node from an astroid built from live code, skip
        assert not stmt.root().file.endswith(".py")
        return

    self._undefined_and_used_before_checker(node, stmt)
    self._loopvar_name(node)

</t>
<t tx="ekr.20250131013600.181">@utils.only_required_for_messages("redefined-outer-name")
def visit_excepthandler(self, node: nodes.ExceptHandler) -&gt; None:
    if not node.name or not isinstance(node.name, nodes.AssignName):
        return

    for outer_except, outer_except_assign_name in self._except_handler_names_queue:
        if node.name.name == outer_except_assign_name.name:
            self.add_message(
                "redefined-outer-name",
                args=(outer_except_assign_name.name, outer_except.fromlineno),
                node=node,
            )
            break

    self._except_handler_names_queue.append((node, node.name))

</t>
<t tx="ekr.20250131013600.182">@utils.only_required_for_messages("redefined-outer-name")
def leave_excepthandler(self, node: nodes.ExceptHandler) -&gt; None:
    if not node.name or not isinstance(node.name, nodes.AssignName):
        return
    self._except_handler_names_queue.pop()

</t>
<t tx="ekr.20250131013600.183">def _undefined_and_used_before_checker(
    self,
    node: nodes.Name,
    stmt: nodes.NodeNG,
) -&gt; None:
    frame = stmt.scope()
    start_index = len(self._to_consume) - 1

    # iterates through parent scopes, from the inner to the outer
    base_scope_type = self._to_consume[start_index].scope_type

    for i in range(start_index, -1, -1):
        current_consumer = self._to_consume[i]

        # Certain nodes shouldn't be checked as they get checked another time
        if self._should_node_be_skipped(node, current_consumer, i == start_index):
            continue

        action, nodes_to_consume = self._check_consumer(
            node, stmt, frame, current_consumer, base_scope_type
        )
        if nodes_to_consume:
            # Any nodes added to consumed_uncertain by get_next_to_consume()
            # should be added back so that they are marked as used.
            # They will have already had a chance to emit used-before-assignment.
            # We check here instead of before every single return in _check_consumer()
            nodes_to_consume += current_consumer.consumed_uncertain[node.name]
            current_consumer.mark_as_consumed(node.name, nodes_to_consume)
        if action is VariableVisitConsumerAction.CONTINUE:
            continue
        if action is VariableVisitConsumerAction.RETURN:
            return

    # we have not found the name, if it isn't a builtin, that's an
    # undefined name !
    if not (
        node.name in nodes.Module.scope_attrs
        or utils.is_builtin(node.name)
        or node.name in self.linter.config.additional_builtins
        or (
            node.name == "__class__"
            and any(
                i.is_method()
                for i in node.node_ancestors()
                if isinstance(i, nodes.FunctionDef)
            )
        )
    ) and not utils.node_ignores_exception(node, NameError):
        self.add_message("undefined-variable", args=node.name, node=node)

</t>
<t tx="ekr.20250131013600.184">def _should_node_be_skipped(
    self,
    node: nodes.Name,
    consumer: NamesConsumer,
    is_start_index: bool,
) -&gt; bool:
    """Tests a consumer and node for various conditions in which the node shouldn't
    be checked for the undefined-variable and used-before-assignment checks.
    """
    if consumer.scope_type == "class":
        # The list of base classes in the class definition is not part
        # of the class body.
        # If the current scope is a class scope but it's not the inner
        # scope, ignore it. This prevents to access this scope instead of
        # the globals one in function members when there are some common
        # names.
        if utils.is_ancestor_name(consumer.node, node) or (
            not is_start_index and self._ignore_class_scope(node)
        ):
            if any(
                node.name == param.name.name for param in consumer.node.type_params
            ):
                return False

            return True

        # Ignore inner class scope for keywords in class definition
        if isinstance(node.parent, nodes.Keyword) and isinstance(
            node.parent.parent, nodes.ClassDef
        ):
            return True

    elif consumer.scope_type == "function" and self._defined_in_function_definition(
        node, consumer.node
    ):
        if any(node.name == param.name.name for param in consumer.node.type_params):
            return False

        # If the name node is used as a function default argument's value or as
        # a decorator, then start from the parent frame of the function instead
        # of the function frame - and thus open an inner class scope
        return True

    elif consumer.scope_type == "lambda" and utils.is_default_argument(
        node, consumer.node
    ):
        return True

    return False

</t>
<t tx="ekr.20250131013600.185"># pylint: disable = too-many-return-statements, too-many-branches
def _check_consumer(
    self,
    node: nodes.Name,
    stmt: nodes.NodeNG,
    frame: nodes.LocalsDictNodeNG,
    current_consumer: NamesConsumer,
    base_scope_type: str,
) -&gt; tuple[VariableVisitConsumerAction, list[nodes.NodeNG] | None]:
    """Checks a consumer for conditions that should trigger messages."""
    # If the name has already been consumed, only check it's not a loop
    # variable used outside the loop.
    if node.name in current_consumer.consumed:
        # Avoid the case where there are homonyms inside function scope and
        # comprehension current scope (avoid bug #1731)
        if utils.is_func_decorator(current_consumer.node) or not isinstance(
            node, nodes.ComprehensionScope
        ):
            self._check_late_binding_closure(node)
            return (VariableVisitConsumerAction.RETURN, None)

    found_nodes = current_consumer.get_next_to_consume(node)
    if found_nodes is None:
        return (VariableVisitConsumerAction.CONTINUE, None)
    if not found_nodes:
        is_reported = self._report_unfound_name_definition(node, current_consumer)
        # Mark for consumption any nodes added to consumed_uncertain by
        # get_next_to_consume() because they might not have executed.
        nodes_to_consume = current_consumer.consumed_uncertain[node.name]
        nodes_to_consume = self._filter_type_checking_definitions_from_consumption(
            node, nodes_to_consume, is_reported
        )
        return (
            VariableVisitConsumerAction.RETURN,
            nodes_to_consume,
        )

    self._check_late_binding_closure(node)

    defnode = utils.assign_parent(found_nodes[0])
    defstmt = defnode.statement()
    defframe = defstmt.frame()

    # The class reuses itself in the class scope.
    is_recursive_klass: bool = (
        frame is defframe
        and defframe.parent_of(node)
        and isinstance(defframe, nodes.ClassDef)
        and node.name == defframe.name
    )

    if (
        is_recursive_klass
        and utils.get_node_first_ancestor_of_type(node, nodes.Lambda)
        and (
            not utils.is_default_argument(node)
            or node.scope().parent.scope() is not defframe
        )
    ):
        # Self-referential class references are fine in lambda's --
        # As long as they are not part of the default argument directly
        # under the scope of the parent self-referring class.
        # Example of valid default argument:
        # class MyName3:
        #     myattr = 1
        #     mylambda3 = lambda: lambda a=MyName3: a
        # Example of invalid default argument:
        # class MyName4:
        #     myattr = 1
        #     mylambda4 = lambda a=MyName4: lambda: a

        # If the above conditional is True,
        # there is no possibility of undefined-variable
        # Also do not consume class name
        # (since consuming blocks subsequent checks)
        # -- quit
        return (VariableVisitConsumerAction.RETURN, None)

    (
        maybe_before_assign,
        annotation_return,
        use_outer_definition,
    ) = self._is_variable_violation(
        node,
        defnode,
        stmt,
        defstmt,
        frame,
        defframe,
        base_scope_type,
        is_recursive_klass,
    )

    if use_outer_definition:
        return (VariableVisitConsumerAction.CONTINUE, None)

    if (
        maybe_before_assign
        and not utils.is_defined_before(node)
        and not astroid.are_exclusive(stmt, defstmt, ("NameError",))
    ):
        # Used and defined in the same place, e.g `x += 1` and `del x`
        defined_by_stmt = defstmt is stmt and isinstance(
            node, (nodes.DelName, nodes.AssignName)
        )
        if (
            is_recursive_klass
            or defined_by_stmt
            or annotation_return
            or isinstance(defstmt, nodes.Delete)
        ):
            if not utils.node_ignores_exception(node, NameError):
                # Handle postponed evaluation of annotations
                if not (
                    self._postponed_evaluation_enabled
                    and isinstance(
                        stmt,
                        (
                            nodes.AnnAssign,
                            nodes.FunctionDef,
                            nodes.Arguments,
                        ),
                    )
                    and node.name in node.root().locals
                ):
                    if defined_by_stmt:
                        return (VariableVisitConsumerAction.CONTINUE, [node])
                    return (VariableVisitConsumerAction.CONTINUE, None)

        elif base_scope_type != "lambda":
            # E0601 may *not* occurs in lambda scope.

            # Skip postponed evaluation of annotations
            # and unevaluated annotations inside a function body
            if not (
                self._postponed_evaluation_enabled
                and isinstance(stmt, (nodes.AnnAssign, nodes.FunctionDef))
            ) and not (
                isinstance(stmt, nodes.AnnAssign)
                and utils.get_node_first_ancestor_of_type(stmt, nodes.FunctionDef)
            ):
                self.add_message(
                    "used-before-assignment",
                    args=node.name,
                    node=node,
                    confidence=HIGH,
                )
                return (VariableVisitConsumerAction.RETURN, found_nodes)

        elif base_scope_type == "lambda":
            # E0601 can occur in class-level scope in lambdas, as in
            # the following example:
            #   class A:
            #      x = lambda attr: f + attr
            #      f = 42
            # We check lineno because doing the following is fine:
            #   class A:
            #      x = 42
            #      y = lambda attr: x + attr
            if (
                isinstance(frame, nodes.ClassDef)
                and node.name in frame.locals
                and stmt.fromlineno &lt;= defstmt.fromlineno
            ):
                self.add_message(
                    "used-before-assignment",
                    args=node.name,
                    node=node,
                    confidence=HIGH,
                )

    elif not self._is_builtin(node.name) and self._is_only_type_assignment(
        node, defstmt
    ):
        if node.scope().locals.get(node.name):
            self.add_message(
                "used-before-assignment", args=node.name, node=node, confidence=HIGH
            )
        else:
            self.add_message(
                "undefined-variable", args=node.name, node=node, confidence=HIGH
            )
        return (VariableVisitConsumerAction.RETURN, found_nodes)

    elif (
        isinstance(defstmt, nodes.ClassDef) and defnode not in defframe.type_params
    ):
        return self._is_first_level_self_reference(node, defstmt, found_nodes)

    elif isinstance(defnode, nodes.NamedExpr):
        if isinstance(defnode.parent, nodes.IfExp):
            if self._is_never_evaluated(defnode, defnode.parent):
                self.add_message(
                    "undefined-variable",
                    args=node.name,
                    node=node,
                    confidence=INFERENCE,
                )
                return (VariableVisitConsumerAction.RETURN, found_nodes)

    return (VariableVisitConsumerAction.RETURN, found_nodes)

</t>
<t tx="ekr.20250131013600.186">def _report_unfound_name_definition(
    self,
    node: nodes.Name,
    current_consumer: NamesConsumer,
) -&gt; bool:
    """Reports used-before-assignment error when all name definition nodes
    are filtered out by NamesConsumer.

    Returns True if an error is reported; otherwise, returns False.
    """
    if (
        self._postponed_evaluation_enabled
        and utils.is_node_in_type_annotation_context(node)
    ):
        return False
    if self._is_builtin(node.name):
        return False
    if self._is_variable_annotation_in_function(node):
        return False
    if self._has_nonlocal_in_enclosing_frame(
        node, current_consumer.consumed_uncertain.get(node.name, [])
    ):
        return False
    if (
        node.name in self._reported_type_checking_usage_scopes
        and node.scope() in self._reported_type_checking_usage_scopes[node.name]
    ):
        return False

    confidence = HIGH
    if node.name in current_consumer.names_under_always_false_test:
        confidence = INFERENCE
    elif node.name in current_consumer.consumed_uncertain:
        confidence = CONTROL_FLOW

    if node.name in current_consumer.names_defined_under_one_branch_only:
        msg = "possibly-used-before-assignment"
    else:
        msg = "used-before-assignment"

    self.add_message(
        msg,
        args=node.name,
        node=node,
        confidence=confidence,
    )

    return True

</t>
<t tx="ekr.20250131013600.187">def _filter_type_checking_definitions_from_consumption(
    self,
    node: nodes.NodeNG,
    nodes_to_consume: list[nodes.NodeNG],
    is_reported: bool,
) -&gt; list[nodes.NodeNG]:
    """Filters out type-checking definition nodes (e.g. imports, class definitions)
    from consumption, as used-before-assignment may invoke in a different context.

    If used-before-assignment is reported for the usage of a type-checking definition,
    track the scope of that usage for future evaluation.
    """
    type_checking_definitions = {
        n
        for n in nodes_to_consume
        if isinstance(n, (nodes.Import, nodes.ImportFrom, nodes.ClassDef))
        and in_type_checking_block(n)
    }

    if type_checking_definitions and is_reported:
        self._reported_type_checking_usage_scopes.setdefault(node.name, []).append(
            node.scope()
        )

    return [n for n in nodes_to_consume if n not in type_checking_definitions]

</t>
<t tx="ekr.20250131013600.188">@utils.only_required_for_messages("no-name-in-module")
def visit_import(self, node: nodes.Import) -&gt; None:
    """Check modules attribute accesses."""
    if not self._analyse_fallback_blocks and utils.is_from_fallback_block(node):
        # No need to verify this, since ImportError is already
        # handled by the client code.
        return
    # Don't verify import if part of guarded import block
    if in_type_checking_block(node):
        return
    if isinstance(node.parent, nodes.If) and is_sys_guard(node.parent):
        return

    for name, _ in node.names:
        parts = name.split(".")
        try:
            module = next(_infer_name_module(node, parts[0]))
        except astroid.ResolveError:
            continue
        if not isinstance(module, nodes.Module):
            continue
        self._check_module_attrs(node, module, parts[1:])

</t>
<t tx="ekr.20250131013600.189">@utils.only_required_for_messages("no-name-in-module")
def visit_importfrom(self, node: nodes.ImportFrom) -&gt; None:
    """Check modules attribute accesses."""
    if not self._analyse_fallback_blocks and utils.is_from_fallback_block(node):
        # No need to verify this, since ImportError is already
        # handled by the client code.
        return
    # Don't verify import if part of guarded import block
    # I.e. `sys.version_info` or `typing.TYPE_CHECKING`
    if in_type_checking_block(node):
        return
    if isinstance(node.parent, nodes.If) and is_sys_guard(node.parent):
        return

    name_parts = node.modname.split(".")
    try:
        module = node.do_import_module(name_parts[0])
    except astroid.AstroidBuildingError:
        return
    module = self._check_module_attrs(node, module, name_parts[1:])
    if not module:
        return
    for name, _ in node.names:
        if name == "*":
            continue
        self._check_module_attrs(node, module, name.split("."))

</t>
<t tx="ekr.20250131013600.19">    return store_messages


class IncompleteFormatString(Exception):
    """A format string ended in the middle of a format specifier."""


</t>
<t tx="ekr.20250131013600.190">@utils.only_required_for_messages(
    "unbalanced-tuple-unpacking",
    "unpacking-non-sequence",
    "self-cls-assignment",
    "unbalanced_dict_unpacking",
)
def visit_assign(self, node: nodes.Assign) -&gt; None:
    """Check unbalanced tuple unpacking for assignments and unpacking
    non-sequences as well as in case self/cls get assigned.
    """
    self._check_self_cls_assign(node)
    if not isinstance(node.targets[0], (nodes.Tuple, nodes.List)):
        return

    targets = node.targets[0].itered()

    # Check if we have starred nodes.
    if any(isinstance(target, nodes.Starred) for target in targets):
        return

    try:
        inferred = utils.safe_infer(node.value)
        if inferred is not None:
            self._check_unpacking(inferred, node, targets)
    except astroid.InferenceError:
        return

</t>
<t tx="ekr.20250131013600.191"># listcomp have now also their scope
def visit_listcomp(self, node: nodes.ListComp) -&gt; None:
    """Visit listcomp: update consumption analysis variable."""
    self._to_consume.append(NamesConsumer(node, "comprehension"))

</t>
<t tx="ekr.20250131013600.192">def leave_listcomp(self, _: nodes.ListComp) -&gt; None:
    """Leave listcomp: update consumption analysis variable."""
    # do not check for not used locals here
    self._to_consume.pop()

</t>
<t tx="ekr.20250131013600.193">def leave_assign(self, node: nodes.Assign) -&gt; None:
    self._store_type_annotation_names(node)

</t>
<t tx="ekr.20250131013600.194">def leave_with(self, node: nodes.With) -&gt; None:
    self._store_type_annotation_names(node)

</t>
<t tx="ekr.20250131013600.195">def visit_arguments(self, node: nodes.Arguments) -&gt; None:
    for annotation in node.type_comment_args:
        self._store_type_annotation_node(annotation)

</t>
<t tx="ekr.20250131013600.196"># Relying on other checker's options, which might not have been initialized yet.
@cached_property
def _analyse_fallback_blocks(self) -&gt; bool:
    return bool(self.linter.config.analyse_fallback_blocks)

</t>
<t tx="ekr.20250131013600.197">@cached_property
def _ignored_modules(self) -&gt; Iterable[str]:
    return self.linter.config.ignored_modules  # type: ignore[no-any-return]

</t>
<t tx="ekr.20250131013600.198">@cached_property
def _allow_global_unused_variables(self) -&gt; bool:
    return bool(self.linter.config.allow_global_unused_variables)

</t>
<t tx="ekr.20250131013600.199">@staticmethod
def _defined_in_function_definition(
    node: nodes.NodeNG,
    frame: nodes.NodeNG,
) -&gt; bool:
    in_annotation_or_default_or_decorator = False
    if isinstance(frame, nodes.FunctionDef) and node.statement() is frame:
        in_annotation_or_default_or_decorator = (
            (
                node in frame.args.annotations
                or node in frame.args.posonlyargs_annotations
                or node in frame.args.kwonlyargs_annotations
                or node is frame.args.varargannotation
                or node is frame.args.kwargannotation
            )
            or frame.args.parent_of(node)
            or (frame.decorators and frame.decorators.parent_of(node))
            or (
                frame.returns
                and (node is frame.returns or frame.returns.parent_of(node))
            )
        )
    return in_annotation_or_default_or_decorator

</t>
<t tx="ekr.20250131013600.2">class InferredTypeError(Exception):
    pass


</t>
<t tx="ekr.20250131013600.20">class UnsupportedFormatCharacter(Exception):
    """A format character in a format string is not one of the supported
    format characters.
    """

    @others
</t>
<t tx="ekr.20250131013600.200">@staticmethod
def _in_lambda_or_comprehension_body(
    node: nodes.NodeNG,
    frame: nodes.NodeNG,
) -&gt; bool:
    """Return True if node within a lambda/comprehension body (or similar) and thus
    should not have access to class attributes in frame.
    """
    child = node
    parent = node.parent
    while parent is not None:
        if parent is frame:
            return False
        if isinstance(parent, nodes.Lambda) and child is not parent.args:
            # Body of lambda should not have access to class attributes.
            return True
        if isinstance(parent, nodes.Comprehension) and child is not parent.iter:
            # Only iter of list/set/dict/generator comprehension should have access.
            return True
        if isinstance(parent, nodes.ComprehensionScope) and not (
            parent.generators and child is parent.generators[0]
        ):
            # Body of list/set/dict/generator comprehension should not have access to class attributes.
            # Furthermore, only the first generator (if multiple) in comprehension should have access.
            return True
        child = parent
        parent = parent.parent
    return False

</t>
<t tx="ekr.20250131013600.201">@staticmethod
def _is_variable_violation(
    node: nodes.Name,
    defnode: nodes.NodeNG,
    stmt: _base_nodes.Statement,
    defstmt: _base_nodes.Statement,
    frame: nodes.LocalsDictNodeNG,  # scope of statement of node
    defframe: nodes.LocalsDictNodeNG,
    base_scope_type: str,
    is_recursive_klass: bool,
) -&gt; tuple[bool, bool, bool]:
    maybe_before_assign = True
    annotation_return = False
    use_outer_definition = False
    if frame is not defframe:
        maybe_before_assign = _detect_global_scope(node, frame, defframe)
    elif defframe.parent is None:
        # we are at the module level, check the name is not
        # defined in builtins
        if (
            node.name in defframe.scope_attrs
            or astroid.builtin_lookup(node.name)[1]
        ):
            maybe_before_assign = False
    else:
        # we are in a local scope, check the name is not
        # defined in global or builtin scope
        # skip this lookup if name is assigned later in function scope/lambda
        # Note: the node.frame() is not the same as the `frame` argument which is
        # equivalent to frame.statement().scope()
        forbid_lookup = (
            isinstance(frame, nodes.FunctionDef)
            or isinstance(node.frame(), nodes.Lambda)
        ) and _assigned_locally(node)
        if not forbid_lookup and defframe.root().lookup(node.name)[1]:
            maybe_before_assign = False
            use_outer_definition = stmt == defstmt and not isinstance(
                defnode, nodes.Comprehension
            )
        # check if we have a nonlocal
        elif node.name in defframe.locals:
            maybe_before_assign = not _is_nonlocal_name(node, defframe)

    if (
        base_scope_type == "lambda"
        and isinstance(frame, nodes.ClassDef)
        and node.name in frame.locals
    ):
        # This rule verifies that if the definition node of the
        # checked name is an Arguments node and if the name
        # is used a default value in the arguments defaults
        # and the actual definition of the variable label
        # is happening before the Arguments definition.
        #
        # bar = None
        # foo = lambda bar=bar: bar
        #
        # In this case, maybe_before_assign should be False, otherwise
        # it should be True.
        maybe_before_assign = not (
            isinstance(defnode, nodes.Arguments)
            and node in defnode.defaults
            and frame.locals[node.name][0].fromlineno &lt; defstmt.fromlineno
        )
    elif isinstance(defframe, nodes.ClassDef) and isinstance(
        frame, nodes.FunctionDef
    ):
        # Special rule for function return annotations,
        # using a name defined earlier in the class containing the function.
        if node is frame.returns and defframe.parent_of(frame.returns):
            annotation_return = True
            if frame.returns.name in defframe.locals:
                definition = defframe.locals[node.name][0]
                if definition.lineno is None or definition.lineno &lt; frame.lineno:
                    # Detect class assignments with a name defined earlier in the
                    # class. In this case, no warning should be raised.
                    maybe_before_assign = False
                else:
                    maybe_before_assign = True
            else:
                maybe_before_assign = True
        if isinstance(node.parent, nodes.Arguments):
            maybe_before_assign = stmt.fromlineno &lt;= defstmt.fromlineno
    elif is_recursive_klass:
        maybe_before_assign = True
    else:
        maybe_before_assign = (
            maybe_before_assign and stmt.fromlineno &lt;= defstmt.fromlineno
        )
        if maybe_before_assign and stmt.fromlineno == defstmt.fromlineno:
            if (
                isinstance(defframe, nodes.FunctionDef)
                and frame is defframe
                and defframe.parent_of(node)
                and (
                    defnode in defframe.type_params
                    # Single statement function, with the statement on the
                    # same line as the function definition
                    or stmt is not defstmt
                )
            ):
                maybe_before_assign = False
            elif (
                isinstance(defstmt, NODES_WITH_VALUE_ATTR)
                and VariablesChecker._maybe_used_and_assigned_at_once(defstmt)
                and frame is defframe
                and defframe.parent_of(node)
                and stmt is defstmt
            ):
                # Single statement if, with assignment expression on same
                # line as assignment
                # x = b if (b := True) else False
                maybe_before_assign = False
            elif (
                isinstance(defnode, nodes.NamedExpr)
                and frame is defframe
                and defframe.parent_of(stmt)
                and stmt is defstmt
                and _is_before(defnode, node)
            ):
                # Relation of a name to the same name in a named expression
                # Could be used before assignment if self-referencing:
                # (b := b)
                # Otherwise, safe if used after assignment:
                # (b := 2) and b
                maybe_before_assign = defnode.value is node or any(
                    a is defnode.value for a in node.node_ancestors()
                )
            elif (
                isinstance(defframe, nodes.ClassDef)
                and defnode in defframe.type_params
            ):
                # Generic on parent class:
                # class Child[_T](Parent[_T])
                maybe_before_assign = False

    return maybe_before_assign, annotation_return, use_outer_definition

</t>
<t tx="ekr.20250131013600.202">@staticmethod
def _maybe_used_and_assigned_at_once(defstmt: _base_nodes.Statement) -&gt; bool:
    """Check if `defstmt` has the potential to use and assign a name in the
    same statement.
    """
    if isinstance(defstmt, nodes.Match):
        return any(case.guard for case in defstmt.cases)
    if isinstance(defstmt, nodes.IfExp):
        return True
    if isinstance(defstmt, nodes.TypeAlias):
        return True
    if isinstance(defstmt.value, nodes.BaseContainer):
        return any(
            VariablesChecker._maybe_used_and_assigned_at_once(elt)
            for elt in defstmt.value.elts
            if isinstance(elt, (*NODES_WITH_VALUE_ATTR, nodes.IfExp, nodes.Match))
        )
    value = defstmt.value
    if isinstance(value, nodes.IfExp):
        return True
    if isinstance(value, nodes.Lambda) and isinstance(value.body, nodes.IfExp):
        return True
    if isinstance(value, nodes.Dict) and any(
        isinstance(item[0], nodes.IfExp) or isinstance(item[1], nodes.IfExp)
        for item in value.items
    ):
        return True
    if not isinstance(value, nodes.Call):
        return False
    return any(
        any(isinstance(kwarg.value, nodes.IfExp) for kwarg in call.keywords)
        or any(isinstance(arg, nodes.IfExp) for arg in call.args)
        or (
            isinstance(call.func, nodes.Attribute)
            and isinstance(call.func.expr, nodes.IfExp)
        )
        for call in value.nodes_of_class(klass=nodes.Call)
    )

</t>
<t tx="ekr.20250131013600.203">def _is_builtin(self, name: str) -&gt; bool:
    return name in self.linter.config.additional_builtins or utils.is_builtin(name)

</t>
<t tx="ekr.20250131013600.204">def _has_nonlocal_in_enclosing_frame(
    self, node: nodes.Name, uncertain_definitions: list[nodes.NodeNG]
) -&gt; bool:
    """Check if there is a nonlocal declaration in the nearest frame that encloses
    both usage and definitions.
    """
    defining_frames = {definition.frame() for definition in uncertain_definitions}
    frame = node.frame()
    is_enclosing_frame = False
    while frame and not is_enclosing_frame:
        is_enclosing_frame = all(
            (frame is defining_frame) or frame.parent_of(defining_frame)
            for defining_frame in defining_frames
        )
        if is_enclosing_frame and _is_nonlocal_name(node, frame):
            return True
        frame = frame.parent.frame() if frame.parent else None
    return False

</t>
<t tx="ekr.20250131013600.205">@staticmethod
def _is_only_type_assignment(
    node: nodes.Name,
    defstmt: _base_nodes.Statement,
) -&gt; bool:
    """Check if variable only gets assigned a type and never a value."""
    if not isinstance(defstmt, nodes.AnnAssign) or defstmt.value:
        return False

    defstmt_frame = defstmt.frame()
    node_frame = node.frame()

    parent = node
    while parent is not defstmt_frame.parent:
        parent_scope = parent.scope()

        # Find out if any nonlocals receive values in nested functions
        for inner_func in parent_scope.nodes_of_class(nodes.FunctionDef):
            if inner_func is parent_scope:
                continue
            if any(
                node.name in nl.names
                for nl in inner_func.nodes_of_class(nodes.Nonlocal)
            ) and any(
                node.name == an.name
                for an in inner_func.nodes_of_class(nodes.AssignName)
            ):
                return False

        local_refs = parent_scope.locals.get(node.name, [])
        for ref_node in local_refs:
            # If local ref is in the same frame as our node, but on a later lineno
            # we don't actually care about this local ref.
            # Local refs are ordered, so we break.
            #     print(var)
            #     var = 1  # &lt;- irrelevant
            if defstmt_frame == node_frame and ref_node.lineno &gt; node.lineno:
                break

            # If the parent of the local reference is anything but an AnnAssign
            # Or if the AnnAssign adds a value the variable will now have a value
            #     var = 1  # OR
            #     var: int = 1
            if (
                not isinstance(ref_node.parent, nodes.AnnAssign)
                or ref_node.parent.value
            ) and not (
                # EXCEPTION: will not have a value if a self-referencing named expression
                # var: int
                # if (var := var * var)  &lt;-- "var" still undefined
                isinstance(ref_node.parent, nodes.NamedExpr)
                and any(a is ref_node.parent.value for a in node.node_ancestors())
            ):
                return False
        parent = parent_scope.parent
    return True

</t>
<t tx="ekr.20250131013600.206">@staticmethod
def _is_first_level_self_reference(
    node: nodes.Name,
    defstmt: nodes.ClassDef,
    found_nodes: list[nodes.NodeNG],
) -&gt; tuple[VariableVisitConsumerAction, list[nodes.NodeNG] | None]:
    """Check if a first level method's annotation or default values
    refers to its own class, and return a consumer action.
    """
    if node.frame().parent == defstmt and node.statement() == node.frame():
        # Check if used as type annotation
        # Break if postponed evaluation is enabled
        if utils.is_node_in_type_annotation_context(node):
            if not utils.is_postponed_evaluation_enabled(node):
                return (VariableVisitConsumerAction.CONTINUE, None)
            return (VariableVisitConsumerAction.RETURN, None)
        # Check if used as default value by calling the class
        if isinstance(node.parent, nodes.Call) and isinstance(
            node.parent.parent, nodes.Arguments
        ):
            return (VariableVisitConsumerAction.CONTINUE, None)
    return (VariableVisitConsumerAction.RETURN, found_nodes)

</t>
<t tx="ekr.20250131013600.207">@staticmethod
def _is_never_evaluated(
    defnode: nodes.NamedExpr,
    defnode_parent: nodes.IfExp,
) -&gt; bool:
    """Check if a NamedExpr is inside a side of if ... else that never
    gets evaluated.
    """
    inferred_test = utils.safe_infer(defnode_parent.test)
    if isinstance(inferred_test, nodes.Const):
        if inferred_test.value is True and defnode == defnode_parent.orelse:
            return True
        if inferred_test.value is False and defnode == defnode_parent.body:
            return True
    return False

</t>
<t tx="ekr.20250131013600.208">@staticmethod
def _is_variable_annotation_in_function(node: nodes.NodeNG) -&gt; bool:
    is_annotation = utils.get_node_first_ancestor_of_type(node, nodes.AnnAssign)
    return (
        is_annotation
        and utils.get_node_first_ancestor_of_type(  # type: ignore[return-value]
            is_annotation, nodes.FunctionDef
        )
    )

</t>
<t tx="ekr.20250131013600.209">def _ignore_class_scope(self, node: nodes.NodeNG) -&gt; bool:
    """Return True if the node is in a local class scope, as an assignment.

    Detect if we are in a local class scope, as an assignment.
    For example, the following is fair game.

    class A:
       b = 1
       c = lambda b=b: b * b

    class B:
       tp = 1
       def func(self, arg: tp):
           ...
    class C:
       tp = 2
       def func(self, arg=tp):
           ...
    class C:
       class Tp:
           pass
       class D(Tp):
           ...
    """
    name = node.name
    frame = node.statement().scope()
    in_annotation_or_default_or_decorator = self._defined_in_function_definition(
        node, frame
    )
    in_ancestor_list = utils.is_ancestor_name(frame, node)
    if in_annotation_or_default_or_decorator or in_ancestor_list:
        frame_locals = frame.parent.scope().locals
    else:
        frame_locals = frame.locals
    return not (
        (isinstance(frame, nodes.ClassDef) or in_annotation_or_default_or_decorator)
        and not self._in_lambda_or_comprehension_body(node, frame)
        and name in frame_locals
    )

</t>
<t tx="ekr.20250131013600.21">def parse_format_string(
    format_string: str,
) -&gt; tuple[set[str], int, dict[str, str], list[str]]:
    """Parses a format string, returning a tuple (keys, num_args).

    Where 'keys' is the set of mapping keys in the format string, and 'num_args' is the number
    of arguments required by the format string. Raises IncompleteFormatString or
    UnsupportedFormatCharacter if a parse error occurs.
    """
    keys = set()
    key_types = {}
    pos_types = []
    num_args = 0

    def next_char(i: int) -&gt; tuple[int, str]:
        i += 1
        if i == len(format_string):
            raise IncompleteFormatString
        return (i, format_string[i])

    i = 0
    while i &lt; len(format_string):
        char = format_string[i]
        if char == "%":
            i, char = next_char(i)
            # Parse the mapping key (optional).
            key = None
            if char == "(":
                depth = 1
                i, char = next_char(i)
                key_start = i
                while depth != 0:
                    if char == "(":
                        depth += 1
                    elif char == ")":
                        depth -= 1
                    i, char = next_char(i)
                key_end = i - 1
                key = format_string[key_start:key_end]

            # Parse the conversion flags (optional).
            while char in "#0- +":
                i, char = next_char(i)
            # Parse the minimum field width (optional).
            if char == "*":
                num_args += 1
                i, char = next_char(i)
            else:
                while char in string.digits:
                    i, char = next_char(i)
            # Parse the precision (optional).
            if char == ".":
                i, char = next_char(i)
                if char == "*":
                    num_args += 1
                    i, char = next_char(i)
                else:
                    while char in string.digits:
                        i, char = next_char(i)
            # Parse the length modifier (optional).
            if char in "hlL":
                i, char = next_char(i)
            # Parse the conversion type (mandatory).
            flags = "diouxXeEfFgGcrs%a"
            if char not in flags:
                raise UnsupportedFormatCharacter(i)
            if key:
                keys.add(key)
                key_types[key] = char
            elif char != "%":
                num_args += 1
                pos_types.append(char)
        i += 1
    return keys, num_args, key_types, pos_types


</t>
<t tx="ekr.20250131013600.210"># pylint: disable-next=too-many-branches,too-many-statements
def _loopvar_name(self, node: astroid.Name) -&gt; None:
    # filter variables according to node's scope
    astmts = [s for s in node.lookup(node.name)[1] if hasattr(s, "assign_type")]
    # If this variable usage exists inside a function definition
    # that exists in the same loop,
    # the usage is safe because the function will not be defined either if
    # the variable is not defined.
    scope = node.scope()
    if isinstance(scope, (nodes.Lambda, nodes.FunctionDef)) and any(
        asmt.scope().parent_of(scope) for asmt in astmts
    ):
        return
    # Filter variables according to their respective scope. Test parent
    # and statement to avoid #74747. This is not a total fix, which would
    # introduce a mechanism similar to special attribute lookup in
    # modules. Also, in order to get correct inference in this case, the
    # scope lookup rules would need to be changed to return the initial
    # assignment (which does not exist in code per se) as well as any later
    # modifications.
    if (
        not astmts  # pylint: disable=too-many-boolean-expressions
        or (
            astmts[0].parent == astmts[0].root()
            and astmts[0].parent.parent_of(node)
        )
        or (
            astmts[0].is_statement
            or (
                not isinstance(astmts[0].parent, nodes.Module)
                and astmts[0].statement().parent_of(node)
            )
        )
    ):
        _astmts = []
    else:
        _astmts = astmts[:1]
    for i, stmt in enumerate(astmts[1:]):
        try:
            astmt_statement = astmts[i].statement()
        except astroid.exceptions.ParentMissingError:
            continue
        if astmt_statement.parent_of(stmt) and not utils.in_for_else_branch(
            astmt_statement, stmt
        ):
            continue
        _astmts.append(stmt)
    astmts = _astmts
    if len(astmts) != 1:
        return

    assign = astmts[0].assign_type()
    if not (
        isinstance(assign, (nodes.For, nodes.Comprehension, nodes.GeneratorExp))
        and assign.statement() is not node.statement()
    ):
        return

    if not isinstance(assign, nodes.For):
        self.add_message("undefined-loop-variable", args=node.name, node=node)
        return
    for else_stmt in assign.orelse:
        if isinstance(
            else_stmt, (nodes.Return, nodes.Raise, nodes.Break, nodes.Continue)
        ):
            return
        # TODO: 4.0: Consider using utils.is_terminating_func
        # after merging it with RefactoringChecker._is_function_def_never_returning
        if isinstance(else_stmt, nodes.Expr) and isinstance(
            else_stmt.value, nodes.Call
        ):
            inferred_func = utils.safe_infer(else_stmt.value.func)
            if (
                isinstance(inferred_func, nodes.FunctionDef)
                and inferred_func.returns
            ):
                inferred_return = utils.safe_infer(inferred_func.returns)
                if isinstance(
                    inferred_return, nodes.FunctionDef
                ) and inferred_return.qname() in {
                    * TYPING_NORETURN,
                    * TYPING_NEVER,
                    "typing._SpecialForm",
                }:
                    return
                # typing_extensions.NoReturn returns a _SpecialForm
                if (
                    isinstance(inferred_return, bases.Instance)
                    and inferred_return.qname() == "typing._SpecialForm"
                ):
                    return

    maybe_walrus = utils.get_node_first_ancestor_of_type(node, nodes.NamedExpr)
    if maybe_walrus:
        maybe_comprehension = utils.get_node_first_ancestor_of_type(
            maybe_walrus, nodes.Comprehension
        )
        if maybe_comprehension:
            comprehension_scope = utils.get_node_first_ancestor_of_type(
                maybe_comprehension, nodes.ComprehensionScope
            )
            if comprehension_scope is None:
                # Should not be possible.
                pass
            elif (
                comprehension_scope.parent.scope() is scope
                and node.name in comprehension_scope.locals
            ):
                return

    # For functions we can do more by inferring the length of the itered object
    try:
        inferred = next(assign.iter.infer())
        # Prefer the target of enumerate() rather than the enumerate object itself
        if (
            isinstance(inferred, astroid.Instance)
            and inferred.qname() == "builtins.enumerate"
        ):
            likely_call = assign.iter
            if isinstance(assign.iter, nodes.IfExp):
                likely_call = assign.iter.body
            if isinstance(likely_call, nodes.Call) and likely_call.args:
                inferred = next(likely_call.args[0].infer())
    except astroid.InferenceError:
        self.add_message("undefined-loop-variable", args=node.name, node=node)
    else:
        if (
            isinstance(inferred, astroid.Instance)
            and inferred.qname() == BUILTIN_RANGE
        ):
            # Consider range() objects safe, even if they might not yield any results.
            return

        # Consider sequences.
        sequences = (
            nodes.List,
            nodes.Tuple,
            nodes.Dict,
            nodes.Set,
            astroid.objects.FrozenSet,
        )
        if not isinstance(inferred, sequences):
            self.add_message("undefined-loop-variable", args=node.name, node=node)
            return

        elements = getattr(inferred, "elts", getattr(inferred, "items", []))
        if not elements:
            self.add_message("undefined-loop-variable", args=node.name, node=node)

</t>
<t tx="ekr.20250131013600.211"># pylint: disable = too-many-branches
def _check_is_unused(
    self,
    name: str,
    node: nodes.FunctionDef,
    stmt: nodes.NodeNG,
    global_names: set[str],
    nonlocal_names: Iterable[str],
    comprehension_target_names: Iterable[str],
) -&gt; None:
    # Ignore some special names specified by user configuration.
    if self._is_name_ignored(stmt, name):
        return
    # Ignore names that were added dynamically to the Function scope
    if (
        isinstance(node, nodes.FunctionDef)
        and name == "__class__"
        and len(node.locals["__class__"]) == 1
        and isinstance(node.locals["__class__"][0], nodes.ClassDef)
    ):
        return

    # Ignore names imported by the global statement.
    if isinstance(stmt, (nodes.Global, nodes.Import, nodes.ImportFrom)):
        # Detect imports, assigned to global statements.
        if global_names and _import_name_is_global(stmt, global_names):
            return

    # Ignore names in comprehension targets
    if name in comprehension_target_names:
        return

    # Ignore names in string literal type annotation.
    if name in self._type_annotation_names:
        return

    argnames = node.argnames()
    # Care about functions with unknown argument (builtins)
    if name in argnames:
        if node.name == "__new__":
            is_init_def = False
            # Look for the `__init__` method in all the methods of the same class.
            for n in node.parent.get_children():
                is_init_def = hasattr(n, "name") and (n.name == "__init__")
                if is_init_def:
                    break
            # Ignore unused arguments check for `__new__` if `__init__` is defined.
            if is_init_def:
                return
        self._check_unused_arguments(name, node, stmt, argnames, nonlocal_names)
    else:
        if stmt.parent and isinstance(
            stmt.parent, (nodes.Assign, nodes.AnnAssign, nodes.Tuple, nodes.For)
        ):
            if name in nonlocal_names:
                return

        qname = asname = None
        if isinstance(stmt, (nodes.Import, nodes.ImportFrom)):
            # Need the complete name, which we don't have in .locals.
            if len(stmt.names) &gt; 1:
                import_names = next(
                    (names for names in stmt.names if name in names), None
                )
            else:
                import_names = stmt.names[0]
            if import_names:
                qname, asname = import_names
                name = asname or qname

        if _has_locals_call_after_node(stmt, node.scope()):
            message_name = "possibly-unused-variable"
        else:
            if isinstance(stmt, nodes.Import):
                if asname is not None:
                    msg = f"{qname} imported as {asname}"
                else:
                    msg = f"import {name}"
                self.add_message("unused-import", args=msg, node=stmt)
                return
            if isinstance(stmt, nodes.ImportFrom):
                if asname is not None:
                    msg = f"{qname} imported from {stmt.modname} as {asname}"
                else:
                    msg = f"{name} imported from {stmt.modname}"
                self.add_message("unused-import", args=msg, node=stmt)
                return
            message_name = "unused-variable"

        if isinstance(stmt, nodes.FunctionDef) and stmt.decorators:
            return

        # Don't check function stubs created only for type information
        if utils.is_overload_stub(node):
            return

        # Special case for exception variable
        if isinstance(stmt.parent, nodes.ExceptHandler) and any(
            n.name == name for n in stmt.parent.nodes_of_class(nodes.Name)
        ):
            return

        self.add_message(message_name, args=name, node=stmt)

</t>
<t tx="ekr.20250131013600.212">def _is_name_ignored(
    self,
    stmt: nodes.NodeNG,
    name: str,
) -&gt; re.Pattern[str] | re.Match[str] | None:
    authorized_rgx = self.linter.config.dummy_variables_rgx
    if (
        isinstance(stmt, nodes.AssignName)
        and isinstance(stmt.parent, nodes.Arguments)
    ) or isinstance(stmt, nodes.Arguments):
        regex: re.Pattern[str] = self.linter.config.ignored_argument_names
    else:
        regex = authorized_rgx
    # See https://stackoverflow.com/a/47007761/2519059 to
    # understand what this function return. Please do NOT use
    # this elsewhere, this is confusing for no benefit
    return regex and regex.match(name)

</t>
<t tx="ekr.20250131013600.213">def _check_unused_arguments(
    self,
    name: str,
    node: nodes.FunctionDef,
    stmt: nodes.NodeNG,
    argnames: list[str],
    nonlocal_names: Iterable[str],
) -&gt; None:
    is_method = node.is_method()
    klass = node.parent.frame()
    if is_method and isinstance(klass, nodes.ClassDef):
        confidence = (
            INFERENCE if utils.has_known_bases(klass) else INFERENCE_FAILURE
        )
    else:
        confidence = HIGH

    if is_method:
        # Don't warn for the first argument of a (non static) method
        if node.type != "staticmethod" and name == argnames[0]:
            return
        # Don't warn for argument of an overridden method
        overridden = overridden_method(klass, node.name)
        if overridden is not None and name in overridden.argnames():
            return
        if node.name in utils.PYMETHODS and node.name not in (
            "__init__",
            "__new__",
        ):
            return
    # Don't check callback arguments
    if any(
        node.name.startswith(cb) or node.name.endswith(cb)
        for cb in self.linter.config.callbacks
    ):
        return
    # Don't check arguments of singledispatch.register function.
    if utils.is_registered_in_singledispatch_function(node):
        return

    # Don't check function stubs created only for type information
    if utils.is_overload_stub(node):
        return

    # Don't check protocol classes
    if utils.is_protocol_class(klass):
        return

    if name in nonlocal_names:
        return

    self.add_message("unused-argument", args=name, node=stmt, confidence=confidence)

</t>
<t tx="ekr.20250131013600.214">def _check_late_binding_closure(self, node: nodes.Name) -&gt; None:
    """Check whether node is a cell var that is assigned within a containing loop.

    Special cases where we don't care about the error:
    1. When the node's function is immediately called, e.g. (lambda: i)()
    2. When the node's function is returned from within the loop, e.g. return lambda: i
    """
    if not self.linter.is_message_enabled("cell-var-from-loop"):
        return

    node_scope = node.frame()

    # If node appears in a default argument expression,
    # look at the next enclosing frame instead
    if utils.is_default_argument(node, node_scope):
        node_scope = node_scope.parent.frame()

    # Check if node is a cell var
    if (
        not isinstance(node_scope, (nodes.Lambda, nodes.FunctionDef))
        or node.name in node_scope.locals
    ):
        return

    assign_scope, stmts = node.lookup(node.name)
    if not stmts or not assign_scope.parent_of(node_scope):
        return

    if utils.is_comprehension(assign_scope):
        self.add_message("cell-var-from-loop", node=node, args=node.name)
    else:
        # Look for an enclosing For loop.
        # Currently, we only consider the first assignment
        assignment_node = stmts[0]

        maybe_for = assignment_node
        while maybe_for and not isinstance(maybe_for, nodes.For):
            if maybe_for is assign_scope:
                break
            maybe_for = maybe_for.parent
        else:
            if (
                maybe_for
                and maybe_for.parent_of(node_scope)
                and not utils.is_being_called(node_scope)
                and node_scope.parent
                and not isinstance(node_scope.statement(), nodes.Return)
            ):
                self.add_message("cell-var-from-loop", node=node, args=node.name)

</t>
<t tx="ekr.20250131013600.215">def _should_ignore_redefined_builtin(self, stmt: nodes.NodeNG) -&gt; bool:
    if not isinstance(stmt, nodes.ImportFrom):
        return False
    return stmt.modname in self.linter.config.redefining_builtins_modules

</t>
<t tx="ekr.20250131013600.216">def _allowed_redefined_builtin(self, name: str) -&gt; bool:
    return name in self.linter.config.allowed_redefined_builtins

</t>
<t tx="ekr.20250131013600.217">@staticmethod
def _comprehension_between_frame_and_node(node: nodes.Name) -&gt; bool:
    """Return True if a ComprehensionScope intervenes between `node` and its
    frame.
    """
    closest_comprehension_scope = utils.get_node_first_ancestor_of_type(
        node, nodes.ComprehensionScope
    )
    return closest_comprehension_scope is not None and node.frame().parent_of(
        closest_comprehension_scope
    )

</t>
<t tx="ekr.20250131013600.218">def _store_type_annotation_node(self, type_annotation: nodes.NodeNG) -&gt; None:
    """Given a type annotation, store all the name nodes it refers to."""
    if isinstance(type_annotation, nodes.Name):
        self._type_annotation_names.append(type_annotation.name)
        return

    if isinstance(type_annotation, nodes.Attribute):
        self._store_type_annotation_node(type_annotation.expr)
        return

    if not isinstance(type_annotation, nodes.Subscript):
        return

    if (
        isinstance(type_annotation.value, nodes.Attribute)
        and isinstance(type_annotation.value.expr, nodes.Name)
        and type_annotation.value.expr.name == TYPING_MODULE
    ):
        self._type_annotation_names.append(TYPING_MODULE)
        return

    self._type_annotation_names.extend(
        annotation.name for annotation in type_annotation.nodes_of_class(nodes.Name)
    )

</t>
<t tx="ekr.20250131013600.219">def _store_type_annotation_names(
    self,
    node: nodes.For | nodes.Assign | nodes.With,
) -&gt; None:
    type_annotation = node.type_annotation
    if not type_annotation:
        return
    self._store_type_annotation_node(node.type_annotation)

</t>
<t tx="ekr.20250131013600.22">def split_format_field_names(
    format_string: str,
) -&gt; tuple[str, Iterable[tuple[bool, str]]]:
    try:
        return _string.formatter_field_name_split(format_string)  # type: ignore[no-any-return]
    except ValueError as e:
        raise IncompleteFormatString() from e


</t>
<t tx="ekr.20250131013600.220">def _check_self_cls_assign(self, node: nodes.Assign) -&gt; None:
    """Check that self/cls don't get assigned."""
    assign_names: set[str | None] = set()
    for target in node.targets:
        if isinstance(target, nodes.AssignName):
            assign_names.add(target.name)
        elif isinstance(target, nodes.Tuple):
            assign_names.update(
                elt.name for elt in target.elts if isinstance(elt, nodes.AssignName)
            )
    scope = node.scope()
    nonlocals_with_same_name = node.scope().parent and any(
        child for child in scope.body if isinstance(child, nodes.Nonlocal)
    )
    if nonlocals_with_same_name:
        scope = node.scope().parent.scope()

    if not (
        isinstance(scope, nodes.FunctionDef)
        and scope.is_method()
        and "builtins.staticmethod" not in scope.decoratornames()
    ):
        return
    argument_names = scope.argnames()
    if not argument_names:
        return
    self_cls_name = argument_names[0]
    if self_cls_name in assign_names:
        self.add_message("self-cls-assignment", node=node, args=(self_cls_name,))

</t>
<t tx="ekr.20250131013600.221">def _check_unpacking(
    self,
    inferred: InferenceResult,
    node: nodes.Assign,
    targets: list[nodes.NodeNG],
) -&gt; None:
    """Check for unbalanced tuple unpacking
    and unpacking non sequences.
    """
    if utils.is_inside_abstract_class(node):
        return
    if utils.is_comprehension(node):
        return
    if isinstance(inferred, util.UninferableBase):
        return
    if (
        isinstance(inferred.parent, nodes.Arguments)
        and isinstance(node.value, nodes.Name)
        and node.value.name == inferred.parent.vararg
    ):
        # Variable-length argument, we can't determine the length.
        return

    # Attempt to check unpacking is properly balanced
    values = self._nodes_to_unpack(inferred)
    details = _get_unpacking_extra_info(node, inferred)

    if values is not None:
        if len(targets) != len(values):
            self._report_unbalanced_unpacking(
                node, inferred, targets, len(values), details
            )
    # attempt to check unpacking may be possible (i.e. RHS is iterable)
    elif not utils.is_iterable(inferred):
        self._report_unpacking_non_sequence(node, details)

</t>
<t tx="ekr.20250131013600.222">@staticmethod
def _get_value_length(value_node: nodes.NodeNG) -&gt; int:
    value_subnodes = VariablesChecker._nodes_to_unpack(value_node)
    if value_subnodes is not None:
        return len(value_subnodes)
    if isinstance(value_node, nodes.Const) and isinstance(
        value_node.value, (str, bytes)
    ):
        return len(value_node.value)
    if isinstance(value_node, nodes.Subscript):
        step = value_node.slice.step or 1
        splice_range = value_node.slice.upper.value - value_node.slice.lower.value
        splice_length = int(math.ceil(splice_range / step))
        return splice_length
    return 1

</t>
<t tx="ekr.20250131013600.223">@staticmethod
def _nodes_to_unpack(node: nodes.NodeNG) -&gt; list[nodes.NodeNG] | None:
    """Return the list of values of the `Assign` node."""
    if isinstance(node, (nodes.Tuple, nodes.List, nodes.Set, *DICT_TYPES)):
        return node.itered()  # type: ignore[no-any-return]
    if isinstance(node, astroid.Instance) and any(
        ancestor.qname() == "typing.NamedTuple" for ancestor in node.ancestors()
    ):
        return [i for i in node.values() if isinstance(i, nodes.AssignName)]
    return None

</t>
<t tx="ekr.20250131013600.224">def _report_unbalanced_unpacking(
    self,
    node: nodes.NodeNG,
    inferred: InferenceResult,
    targets: list[nodes.NodeNG],
    values_count: int,
    details: str,
) -&gt; None:
    args = (
        details,
        len(targets),
        "" if len(targets) == 1 else "s",
        values_count,
        "" if values_count == 1 else "s",
    )

    symbol = (
        "unbalanced-dict-unpacking"
        if isinstance(inferred, DICT_TYPES)
        else "unbalanced-tuple-unpacking"
    )
    self.add_message(symbol, node=node, args=args, confidence=INFERENCE)

</t>
<t tx="ekr.20250131013600.225">def _report_unpacking_non_sequence(self, node: nodes.NodeNG, details: str) -&gt; None:
    if details and not details.startswith(" "):
        details = f" {details}"
    self.add_message("unpacking-non-sequence", node=node, args=details)

</t>
<t tx="ekr.20250131013600.226">def _check_module_attrs(
    self,
    node: _base_nodes.ImportNode,
    module: nodes.Module,
    module_names: list[str],
) -&gt; nodes.Module | None:
    """Check that module_names (list of string) are accessible through the
    given module, if the latest access name corresponds to a module, return it.
    """
    while module_names:
        name = module_names.pop(0)
        if name == "__dict__":
            module = None
            break
        try:
            module = module.getattr(name)[0]
            if not isinstance(module, nodes.Module):
                module = next(module.infer())
                if not isinstance(module, nodes.Module):
                    return None
        except astroid.NotFoundError:
            # Unable to import `name` from `module`. Since `name` may itself be a
            # module, we first check if it matches the ignored modules.
            if is_module_ignored(f"{module.qname()}.{name}", self._ignored_modules):
                return None
            self.add_message(
                "no-name-in-module", args=(name, module.name), node=node
            )
            return None
        except astroid.InferenceError:
            return None
    if module_names:
        modname = module.name if module else "__dict__"
        self.add_message(
            "no-name-in-module", node=node, args=(".".join(module_names), modname)
        )
        return None
    if isinstance(module, nodes.Module):
        return module
    return None

</t>
<t tx="ekr.20250131013600.227">def _check_all(
    self,
    node: nodes.Module,
    not_consumed: Consumption,
) -&gt; None:
    try:
        assigned = next(node.igetattr("__all__"))
    except astroid.InferenceError:
        return
    if isinstance(assigned, util.UninferableBase):
        return
    if assigned.pytype() not in {"builtins.list", "builtins.tuple"}:
        line, col = assigned.tolineno, assigned.col_offset
        self.add_message("invalid-all-format", line=line, col_offset=col, node=node)
        return
    for elt in getattr(assigned, "elts", ()):
        try:
            elt_name = next(elt.infer())
        except astroid.InferenceError:
            continue
        if isinstance(elt_name, util.UninferableBase):
            continue
        if not elt_name.parent:
            continue

        if not isinstance(elt_name, nodes.Const) or not isinstance(
            elt_name.value, str
        ):
            self.add_message("invalid-all-object", args=elt.as_string(), node=elt)
            continue

        elt_name = elt_name.value
        # If elt is in not_consumed, remove it from not_consumed
        if elt_name in not_consumed:
            del not_consumed[elt_name]
            continue

        if elt_name not in node.locals:
            if not node.package:
                self.add_message(
                    "undefined-all-variable", args=(elt_name,), node=elt
                )
            else:
                basename = os.path.splitext(node.file)[0]
                if os.path.basename(basename) == "__init__":
                    name = node.name + "." + elt_name
                    try:
                        astroid.modutils.file_from_modpath(name.split("."))
                    except ImportError:
                        self.add_message(
                            "undefined-all-variable", args=(elt_name,), node=elt
                        )
                    except SyntaxError:
                        # don't yield a syntax-error warning,
                        # because it will be later yielded
                        # when the file will be checked
                        pass

</t>
<t tx="ekr.20250131013600.228">def _check_globals(self, not_consumed: Consumption) -&gt; None:
    if self._allow_global_unused_variables:
        return
    for name, node_lst in not_consumed.items():
        for node in node_lst:
            if in_type_checking_block(node):
                continue
            self.add_message("unused-variable", args=(name,), node=node)

</t>
<t tx="ekr.20250131013600.229"># pylint: disable = too-many-branches
def _check_imports(self, not_consumed: Consumption) -&gt; None:
    local_names = _fix_dot_imports(not_consumed)
    checked = set()
    unused_wildcard_imports: defaultdict[
        tuple[str, nodes.ImportFrom],
        list[str],
    ] = defaultdict(list)
    for name, stmt in local_names:
        for imports in stmt.names:
            real_name = imported_name = imports[0]
            if imported_name == "*":
                real_name = name
            as_name = imports[1]
            if real_name in checked:
                continue
            if name not in (real_name, as_name):
                continue
            checked.add(real_name)

            is_type_annotation_import = (
                imported_name in self._type_annotation_names
                or as_name in self._type_annotation_names
            )

            is_dummy_import = (
                as_name
                and self.linter.config.dummy_variables_rgx
                and self.linter.config.dummy_variables_rgx.match(as_name)
            )

            if isinstance(stmt, nodes.Import) or (
                isinstance(stmt, nodes.ImportFrom) and not stmt.modname
            ):
                if isinstance(stmt, nodes.ImportFrom) and SPECIAL_OBJ.search(
                    imported_name
                ):
                    # Filter special objects (__doc__, __all__) etc.,
                    # because they can be imported for exporting.
                    continue

                if is_type_annotation_import or is_dummy_import:
                    # Most likely a typing import if it wasn't used so far.
                    # Also filter dummy variables.
                    continue

                if as_name is None:
                    msg = f"import {imported_name}"
                else:
                    msg = f"{imported_name} imported as {as_name}"
                if not in_type_checking_block(stmt):
                    self.add_message("unused-import", args=msg, node=stmt)
            elif isinstance(stmt, nodes.ImportFrom) and stmt.modname != FUTURE:
                if SPECIAL_OBJ.search(imported_name):
                    # Filter special objects (__doc__, __all__) etc.,
                    # because they can be imported for exporting.
                    continue

                if _is_from_future_import(stmt, name):
                    # Check if the name is in fact loaded from a
                    # __future__ import in another module.
                    continue

                if is_type_annotation_import or is_dummy_import:
                    # Most likely a typing import if it wasn't used so far.
                    # Also filter dummy variables.
                    continue

                if imported_name == "*":
                    unused_wildcard_imports[(stmt.modname, stmt)].append(name)
                else:
                    if as_name is None:
                        msg = f"{imported_name} imported from {stmt.modname}"
                    else:
                        msg = f"{imported_name} imported from {stmt.modname} as {as_name}"
                    if not in_type_checking_block(stmt):
                        self.add_message("unused-import", args=msg, node=stmt)

    # Construct string for unused-wildcard-import message
    for module, unused_list in unused_wildcard_imports.items():
        if len(unused_list) == 1:
            arg_string = unused_list[0]
        else:
            arg_string = (
                f"{', '.join(i for i in unused_list[:-1])} and {unused_list[-1]}"
            )
        self.add_message(
            "unused-wildcard-import", args=(arg_string, module[0]), node=module[1]
        )
    del self._to_consume

</t>
<t tx="ekr.20250131013600.23">def collect_string_fields(format_string: str) -&gt; Iterable[str | None]:
    """Given a format string, return an iterator
    of all the valid format fields.

    It handles nested fields as well.
    """
    formatter = string.Formatter()
    # pylint: disable = too-many-try-statements
    try:
        parseiterator = formatter.parse(format_string)
        for result in parseiterator:
            if all(item is None for item in result[1:]):
                # not a replacement format
                continue
            name = result[1]
            nested = result[2]
            yield name
            if nested:
                yield from collect_string_fields(nested)
    except ValueError as exc:
        # Probably the format string is invalid.
        if exc.args[0].startswith("cannot switch from manual"):
            # On Jython, parsing a string with both manual
            # and automatic positions will fail with a ValueError,
            # while on CPython it will simply return the fields,
            # the validation being done in the interpreter (?).
            # We're just returning two mixed fields in order
            # to trigger the format-combined-specification check.
            yield ""
            yield "1"
            return
        raise IncompleteFormatString(format_string) from exc


</t>
<t tx="ekr.20250131013600.230">def _check_metaclasses(self, node: nodes.Module | nodes.FunctionDef) -&gt; None:
    """Update consumption analysis for metaclasses."""
    consumed: list[tuple[Consumption, str]] = []

    for child_node in node.get_children():
        if isinstance(child_node, nodes.ClassDef):
            consumed.extend(self._check_classdef_metaclasses(child_node, node))

    # Pop the consumed items, in order to avoid having
    # unused-import and unused-variable false positives
    for scope_locals, name in consumed:
        scope_locals.pop(name, None)

</t>
<t tx="ekr.20250131013600.231">def _check_classdef_metaclasses(
    self,
    klass: nodes.ClassDef,
    parent_node: nodes.Module | nodes.FunctionDef,
) -&gt; list[tuple[Consumption, str]]:
    if not klass._metaclass:
        # Skip if this class doesn't use explicitly a metaclass, but inherits it from ancestors
        return []

    consumed: list[tuple[Consumption, str]] = []
    metaclass = klass.metaclass()
    name = ""
    if isinstance(klass._metaclass, nodes.Name):
        name = klass._metaclass.name
    elif isinstance(klass._metaclass, nodes.Attribute) and klass._metaclass.expr:
        attr = klass._metaclass.expr
        while not isinstance(attr, nodes.Name):
            attr = attr.expr
        name = attr.name
    elif isinstance(klass._metaclass, nodes.Call) and isinstance(
        klass._metaclass.func, nodes.Name
    ):
        name = klass._metaclass.func.name
    elif metaclass:
        name = metaclass.root().name

    found = False
    name = METACLASS_NAME_TRANSFORMS.get(name, name)
    if name:
        # check enclosing scopes starting from most local
        for to_consume in self._to_consume[::-1]:
            scope_locals = to_consume.to_consume
            found_nodes = scope_locals.get(name, [])
            for found_node in found_nodes:
                if found_node.lineno &lt;= klass.lineno:
                    consumed.append((scope_locals, name))
                    found = True
                    break
        # Check parent scope
        nodes_in_parent_scope = parent_node.locals.get(name, [])
        for found_node_parent in nodes_in_parent_scope:
            if found_node_parent.lineno &lt;= klass.lineno:
                found = True
                break
    if (
        not found
        and not metaclass
        and not (
            name in nodes.Module.scope_attrs
            or utils.is_builtin(name)
            or name in self.linter.config.additional_builtins
        )
    ):
        self.add_message("undefined-variable", node=klass, args=(name,))

    return consumed

</t>
<t tx="ekr.20250131013600.232">def visit_subscript(self, node: nodes.Subscript) -&gt; None:
    inferred_slice = utils.safe_infer(node.slice)

    self._check_potential_index_error(node, inferred_slice)

</t>
<t tx="ekr.20250131013600.233">def _inferred_iterable_length(self, iterable: nodes.Tuple | nodes.List) -&gt; int:
    length = 0
    for elt in iterable.elts:
        if not isinstance(elt, nodes.Starred):
            length += 1
            continue
        unpacked = utils.safe_infer(elt.value)
        if isinstance(unpacked, nodes.BaseContainer):
            length += len(unpacked.elts)
        else:
            length += 1
    return length

</t>
<t tx="ekr.20250131013600.234">def _check_potential_index_error(
    self,
    node: nodes.Subscript,
    inferred_slice: nodes.NodeNG | None,
) -&gt; None:
    """Check for the potential-index-error message."""
    # Currently we only check simple slices of a single integer
    if not isinstance(inferred_slice, nodes.Const) or not isinstance(
        inferred_slice.value, int
    ):
        return

    # If the node.value is a Tuple or List without inference it is defined in place
    if isinstance(node.value, (nodes.Tuple, nodes.List)):
        # Add 1 because iterables are 0-indexed
        if self._inferred_iterable_length(node.value) &lt; inferred_slice.value + 1:
            self.add_message(
                "potential-index-error", node=node, confidence=INFERENCE
            )
        return

</t>
<t tx="ekr.20250131013600.235">@utils.only_required_for_messages(
    "unused-import",
    "unused-variable",
)
def visit_const(self, node: nodes.Const) -&gt; None:
    """Take note of names that appear inside string literal type annotations
    unless the string is a parameter to `typing.Literal` or `typing.Annotation`.
    """
    if node.pytype() != "builtins.str":
        return
    if not utils.is_node_in_type_annotation_context(node):
        return

    # Check if parent's or grandparent's first child is typing.Literal
    parent = node.parent
    if isinstance(parent, nodes.Tuple):
        parent = parent.parent
    if isinstance(parent, nodes.Subscript):
        origin = next(parent.get_children(), None)
        if origin is not None and utils.is_typing_member(
            origin, ("Annotated", "Literal")
        ):
            return

    try:
        annotation = extract_node(node.value)
        self._store_type_annotation_node(annotation)
    except ValueError:
        # e.g. node.value is white space
        pass
    except astroid.AstroidSyntaxError:
        # e.g. "?" or ":" in typing.Literal["?", ":"]
        pass


</t>
<t tx="ekr.20250131013600.236"></t>
<t tx="ekr.20250131013600.237">@path pylint/checkers/base
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

# pylint: disable=duplicate-code # This is similar to the __init__ of .name_checker

from __future__ import annotations

__all__ = [
    "KNOWN_NAME_TYPES_WITH_STYLE",
    "AnyStyle",
    "CamelCaseStyle",
    "NameChecker",
    "NamingStyle",
    "PascalCaseStyle",
    "SnakeCaseStyle",
    "UpperCaseStyle",
]

from typing import TYPE_CHECKING

from pylint.checkers.base.basic_checker import BasicChecker
from pylint.checkers.base.basic_error_checker import BasicErrorChecker
from pylint.checkers.base.comparison_checker import ComparisonChecker
from pylint.checkers.base.docstring_checker import DocStringChecker
from pylint.checkers.base.function_checker import FunctionChecker
from pylint.checkers.base.name_checker import (
    KNOWN_NAME_TYPES_WITH_STYLE,
    AnyStyle,
    CamelCaseStyle,
    NamingStyle,
    PascalCaseStyle,
    SnakeCaseStyle,
    UpperCaseStyle,
)
from pylint.checkers.base.name_checker.checker import NameChecker
from pylint.checkers.base.pass_checker import PassChecker

if TYPE_CHECKING:
    from pylint.lint import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.238">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(BasicErrorChecker(linter))
    linter.register_checker(BasicChecker(linter))
    linter.register_checker(NameChecker(linter))
    linter.register_checker(DocStringChecker(linter))
    linter.register_checker(PassChecker(linter))
    linter.register_checker(ComparisonChecker(linter))
    linter.register_checker(FunctionChecker(linter))
</t>
<t tx="ekr.20250131013600.239">@path pylint/checkers/base
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Basic checker for Python code."""

from __future__ import annotations

import collections
import itertools
from collections.abc import Iterator
from typing import TYPE_CHECKING, Literal, cast

import astroid
from astroid import nodes, objects, util

from pylint import utils as lint_utils
from pylint.checkers import BaseChecker, utils
from pylint.interfaces import HIGH, INFERENCE, Confidence
from pylint.reporters.ureports import nodes as reporter_nodes
from pylint.utils import LinterStats

if TYPE_CHECKING:
    from pylint.lint.pylinter import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.24">def parse_format_method_string(
    format_string: str,
) -&gt; tuple[list[tuple[str, list[tuple[bool, str]]]], int, int]:
    """Parses a PEP 3101 format string, returning a tuple of
    (keyword_arguments, implicit_pos_args_cnt, explicit_pos_args).

    keyword_arguments is the set of mapping keys in the format string, implicit_pos_args_cnt
    is the number of arguments required by the format string and
    explicit_pos_args is the number of arguments passed with the position.
    """
    keyword_arguments = []
    implicit_pos_args_cnt = 0
    explicit_pos_args = set()
    for name in collect_string_fields(format_string):
        if name and str(name).isdigit():
            explicit_pos_args.add(str(name))
        elif name:
            keyname, fielditerator = split_format_field_names(name)
            if isinstance(keyname, numbers.Number):
                explicit_pos_args.add(str(keyname))
            try:
                keyword_arguments.append((keyname, list(fielditerator)))
            except ValueError as e:
                raise IncompleteFormatString() from e
        else:
            implicit_pos_args_cnt += 1
    return keyword_arguments, implicit_pos_args_cnt, len(explicit_pos_args)


</t>
<t tx="ekr.20250131013600.240">class _BasicChecker(BaseChecker):
    """Permits separating multiple checks with the same checker name into
    classes/file.
    """

    name = "basic"


</t>
<t tx="ekr.20250131013600.241">REVERSED_PROTOCOL_METHOD = "__reversed__"
SEQUENCE_PROTOCOL_METHODS = ("__getitem__", "__len__")
REVERSED_METHODS = (SEQUENCE_PROTOCOL_METHODS, (REVERSED_PROTOCOL_METHOD,))
# A mapping from qname -&gt; symbol, to be used when generating messages
# about dangerous default values as arguments
DEFAULT_ARGUMENT_SYMBOLS = dict(
    zip(
        [".".join(["builtins", x]) for x in ("set", "dict", "list")],
        ["set()", "{}", "[]"],
    ),
    **{
        x: f"{x}()"
        for x in (
            "collections.deque",
            "collections.ChainMap",
            "collections.Counter",
            "collections.OrderedDict",
            "collections.defaultdict",
            "collections.UserDict",
            "collections.UserList",
        )
    },
)


def report_by_type_stats(
    sect: reporter_nodes.Section,
    stats: LinterStats,
    old_stats: LinterStats | None,
) -&gt; None:
    """Make a report of.

    * percentage of different types documented
    * percentage of different types with a bad name
    """
    # percentage of different types documented and/or with a bad name
    nice_stats: dict[str, dict[str, str]] = {}
    for node_type in ("module", "class", "method", "function"):
        node_type = cast(Literal["function", "class", "method", "module"], node_type)
        total = stats.get_node_count(node_type)
        nice_stats[node_type] = {}
        if total != 0:
            undocumented_node = stats.get_undocumented(node_type)
            documented = total - undocumented_node
            percent = (documented * 100.0) / total
            nice_stats[node_type]["percent_documented"] = f"{percent:.2f}"
            badname_node = stats.get_bad_names(node_type)
            percent = (badname_node * 100.0) / total
            nice_stats[node_type]["percent_badname"] = f"{percent:.2f}"
    lines = ["type", "number", "old number", "difference", "%documented", "%badname"]
    for node_type in ("module", "class", "method", "function"):
        node_type = cast(Literal["function", "class", "method", "module"], node_type)
        new = stats.get_node_count(node_type)
        old = old_stats.get_node_count(node_type) if old_stats else None
        diff_str = lint_utils.diff_string(old, new) if old else None
        lines += [
            node_type,
            str(new),
            str(old) if old else "NC",
            diff_str if diff_str else "NC",
            nice_stats[node_type].get("percent_documented", "0"),
            nice_stats[node_type].get("percent_badname", "0"),
        ]
    sect.append(reporter_nodes.Table(children=lines, cols=6, rheaders=1))


</t>
<t tx="ekr.20250131013600.242"># pylint: disable-next = too-many-public-methods
class BasicChecker(_BasicChecker):
    """Basic checker.

    Checks for :
    * doc strings
    * number of arguments, local variables, branches, returns and statements in
    functions, methods
    * required module attributes
    * dangerous default values as arguments
    * redefinition of function / method / class
    * uses of the global statement
    """

    @others
</t>
<t tx="ekr.20250131013600.243">name = "basic"
msgs = {
    "W0101": (
        "Unreachable code",
        "unreachable",
        'Used when there is some code behind a "return" or "raise" '
        "statement, which will never be accessed.",
    ),
    "W0102": (
        "Dangerous default value %s as argument",
        "dangerous-default-value",
        "Used when a mutable value as list or dictionary is detected in "
        "a default value for an argument.",
    ),
    "W0104": (
        "Statement seems to have no effect",
        "pointless-statement",
        "Used when a statement doesn't have (or at least seems to) any effect.",
    ),
    "W0105": (
        "String statement has no effect",
        "pointless-string-statement",
        "Used when a string is used as a statement (which of course "
        "has no effect). This is a particular case of W0104 with its "
        "own message so you can easily disable it if you're using "
        "those strings as documentation, instead of comments.",
    ),
    "W0106": (
        'Expression "%s" is assigned to nothing',
        "expression-not-assigned",
        "Used when an expression that is not a function call is assigned "
        "to nothing. Probably something else was intended.",
    ),
    "W0108": (
        "Lambda may not be necessary",
        "unnecessary-lambda",
        "Used when the body of a lambda expression is a function call "
        "on the same argument list as the lambda itself; such lambda "
        "expressions are in all but a few cases replaceable with the "
        "function being called in the body of the lambda.",
    ),
    "W0109": (
        "Duplicate key %r in dictionary",
        "duplicate-key",
        "Used when a dictionary expression binds the same key multiple times.",
    ),
    "W0122": (
        "Use of exec",
        "exec-used",
        "Raised when the 'exec' statement is used. It's dangerous to use this "
        "function for a user input, and it's also slower than actual code in "
        "general. This doesn't mean you should never use it, but you should "
        "consider alternatives first and restrict the functions available.",
    ),
    "W0123": (
        "Use of eval",
        "eval-used",
        'Used when you use the "eval" function, to discourage its '
        "usage. Consider using `ast.literal_eval` for safely evaluating "
        "strings containing Python expressions "
        "from untrusted sources.",
    ),
    "W0150": (
        "%s statement in finally block may swallow exception",
        "lost-exception",
        "Used when a break or a return statement is found inside the "
        "finally clause of a try...finally block: the exceptions raised "
        "in the try clause will be silently swallowed instead of being "
        "re-raised.",
    ),
    "W0199": (
        "Assert called on a populated tuple. Did you mean 'assert x,y'?",
        "assert-on-tuple",
        "A call of assert on a tuple will always evaluate to true if "
        "the tuple is not empty, and will always evaluate to false if "
        "it is.",
    ),
    "W0124": (
        'Following "as" with another context manager looks like a tuple.',
        "confusing-with-statement",
        "Emitted when a `with` statement component returns multiple values "
        "and uses name binding with `as` only for a part of those values, "
        "as in with ctx() as a, b. This can be misleading, since it's not "
        "clear if the context manager returns a tuple or if the node without "
        "a name binding is another context manager.",
    ),
    "W0125": (
        "Using a conditional statement with a constant value",
        "using-constant-test",
        "Emitted when a conditional statement (If or ternary if) "
        "uses a constant value for its test. This might not be what "
        "the user intended to do.",
    ),
    "W0126": (
        "Using a conditional statement with potentially wrong function or method call due to "
        "missing parentheses",
        "missing-parentheses-for-call-in-test",
        "Emitted when a conditional statement (If or ternary if) "
        "seems to wrongly call a function due to missing parentheses",
    ),
    "W0127": (
        "Assigning the same variable %r to itself",
        "self-assigning-variable",
        "Emitted when we detect that a variable is assigned to itself",
    ),
    "W0128": (
        "Redeclared variable %r in assignment",
        "redeclared-assigned-name",
        "Emitted when we detect that a variable was redeclared in the same assignment.",
    ),
    "E0111": (
        "The first reversed() argument is not a sequence",
        "bad-reversed-sequence",
        "Used when the first argument to reversed() builtin "
        "isn't a sequence (does not implement __reversed__, "
        "nor __getitem__ and __len__",
    ),
    "E0119": (
        "format function is not called on str",
        "misplaced-format-function",
        "Emitted when format function is not called on str object. "
        'e.g doing print("value: {}").format(123) instead of '
        'print("value: {}".format(123)). This might not be what the user '
        "intended to do.",
    ),
    "W0129": (
        "Assert statement has a string literal as its first argument. The assert will %s fail.",
        "assert-on-string-literal",
        "Used when an assert statement has a string literal as its first argument, which will "
        "cause the assert to always pass.",
    ),
    "W0130": (
        "Duplicate value %r in set",
        "duplicate-value",
        "This message is emitted when a set contains the same value two or more times.",
    ),
    "W0131": (
        "Named expression used without context",
        "named-expr-without-context",
        "Emitted if named expression is used to do a regular assignment "
        "outside a context like if, for, while, or a comprehension.",
    ),
    "W0133": (
        "Exception statement has no effect",
        "pointless-exception-statement",
        "Used when an exception is created without being assigned, raised or returned "
        "for subsequent use elsewhere.",
    ),
    "W0134": (
        "'return' shadowed by the 'finally' clause.",
        "return-in-finally",
        "Emitted when a 'return' statement is found in a 'finally' block. This will overwrite "
        "the return value of a function and should be avoided.",
    ),
}

reports = (("RP0101", "Statistics by type", report_by_type_stats),)

def __init__(self, linter: PyLinter) -&gt; None:
    super().__init__(linter)
    self._trys: list[nodes.Try]

</t>
<t tx="ekr.20250131013600.244">def open(self) -&gt; None:
    """Initialize visit variables and statistics."""
    py_version = self.linter.config.py_version
    self._py38_plus = py_version &gt;= (3, 8)
    self._trys = []
    self.linter.stats.reset_node_count()

</t>
<t tx="ekr.20250131013600.245">@utils.only_required_for_messages(
    "using-constant-test", "missing-parentheses-for-call-in-test"
)
def visit_if(self, node: nodes.If) -&gt; None:
    self._check_using_constant_test(node, node.test)

</t>
<t tx="ekr.20250131013600.246">@utils.only_required_for_messages(
    "using-constant-test", "missing-parentheses-for-call-in-test"
)
def visit_ifexp(self, node: nodes.IfExp) -&gt; None:
    self._check_using_constant_test(node, node.test)

</t>
<t tx="ekr.20250131013600.247">@utils.only_required_for_messages(
    "using-constant-test", "missing-parentheses-for-call-in-test"
)
def visit_comprehension(self, node: nodes.Comprehension) -&gt; None:
    if node.ifs:
        for if_test in node.ifs:
            self._check_using_constant_test(node, if_test)

</t>
<t tx="ekr.20250131013600.248">def _check_using_constant_test(
    self,
    node: nodes.If | nodes.IfExp | nodes.Comprehension,
    test: nodes.NodeNG | None,
) -&gt; None:
    const_nodes = (
        nodes.Module,
        nodes.GeneratorExp,
        nodes.Lambda,
        nodes.FunctionDef,
        nodes.ClassDef,
        astroid.bases.Generator,
        astroid.UnboundMethod,
        astroid.BoundMethod,
        nodes.Module,
    )
    structs = (nodes.Dict, nodes.Tuple, nodes.Set, nodes.List)

    # These nodes are excepted, since they are not constant
    # values, requiring a computation to happen.
    except_nodes = (
        nodes.Call,
        nodes.BinOp,
        nodes.BoolOp,
        nodes.UnaryOp,
        nodes.Subscript,
    )
    inferred = None
    emit = isinstance(test, (nodes.Const, *structs, *const_nodes))
    maybe_generator_call = None
    if not isinstance(test, except_nodes):
        inferred = utils.safe_infer(test)
        if isinstance(inferred, util.UninferableBase) and isinstance(
            test, nodes.Name
        ):
            emit, maybe_generator_call = BasicChecker._name_holds_generator(test)

    # Emit if calling a function that only returns GeneratorExp (always tests True)
    elif isinstance(test, nodes.Call):
        maybe_generator_call = test
    if maybe_generator_call:
        inferred_call = utils.safe_infer(maybe_generator_call.func)
        if isinstance(inferred_call, nodes.FunctionDef):
            # Can't use all(x) or not any(not x) for this condition, because it
            # will return True for empty generators, which is not what we want.
            all_returns_were_generator = None
            for return_node in inferred_call._get_return_nodes_skip_functions():
                if not isinstance(return_node.value, nodes.GeneratorExp):
                    all_returns_were_generator = False
                    break
                all_returns_were_generator = True
            if all_returns_were_generator:
                self.add_message(
                    "using-constant-test", node=node, confidence=INFERENCE
                )
                return

    if emit:
        self.add_message("using-constant-test", node=test, confidence=INFERENCE)
    elif isinstance(inferred, const_nodes):
        # If the constant node is a FunctionDef or Lambda then
        # it may be an illicit function call due to missing parentheses
        call_inferred = None
        try:
            # Just forcing the generator to infer all elements.
            # astroid.exceptions.InferenceError are false positives
            # see https://github.com/pylint-dev/pylint/pull/8185
            if isinstance(inferred, nodes.FunctionDef):
                call_inferred = list(inferred.infer_call_result(node))
            elif isinstance(inferred, nodes.Lambda):
                call_inferred = list(inferred.infer_call_result(node))
        except astroid.InferenceError:
            call_inferred = None
        if call_inferred:
            self.add_message(
                "missing-parentheses-for-call-in-test",
                node=test,
                confidence=INFERENCE,
            )
        self.add_message("using-constant-test", node=test, confidence=INFERENCE)

</t>
<t tx="ekr.20250131013600.249">@staticmethod
def _name_holds_generator(test: nodes.Name) -&gt; tuple[bool, nodes.Call | None]:
    """Return whether `test` tests a name certain to hold a generator, or optionally
    a call that should be then tested to see if *it* returns only generators.
    """
    assert isinstance(test, nodes.Name)
    emit = False
    maybe_generator_call = None
    lookup_result = test.frame().lookup(test.name)
    if not lookup_result:
        return emit, maybe_generator_call
    maybe_generator_assigned = (
        isinstance(assign_name.parent.value, nodes.GeneratorExp)
        for assign_name in lookup_result[1]
        if isinstance(assign_name.parent, nodes.Assign)
    )
    first_item = next(maybe_generator_assigned, None)
    if first_item is not None:
        # Emit if this variable is certain to hold a generator
        if all(itertools.chain((first_item,), maybe_generator_assigned)):
            emit = True
        # If this variable holds the result of a call, save it for next test
        elif (
            len(lookup_result[1]) == 1
            and isinstance(lookup_result[1][0].parent, nodes.Assign)
            and isinstance(lookup_result[1][0].parent.value, nodes.Call)
        ):
            maybe_generator_call = lookup_result[1][0].parent.value
    return emit, maybe_generator_call

</t>
<t tx="ekr.20250131013600.25">def is_attr_protected(attrname: str) -&gt; bool:
    """Return True if attribute name is protected (start with _ and some other
    details), False otherwise.
    """
    return (
        attrname[0] == "_"
        and attrname != "_"
        and not (attrname.startswith("__") and attrname.endswith("__"))
    )


</t>
<t tx="ekr.20250131013600.250">def visit_module(self, _: nodes.Module) -&gt; None:
    """Check module name, docstring and required arguments."""
    self.linter.stats.node_count["module"] += 1

</t>
<t tx="ekr.20250131013600.251">def visit_classdef(self, _: nodes.ClassDef) -&gt; None:
    """Check module name, docstring and redefinition
    increment branch counter.
    """
    self.linter.stats.node_count["klass"] += 1

</t>
<t tx="ekr.20250131013600.252">@utils.only_required_for_messages(
    "pointless-statement",
    "pointless-exception-statement",
    "pointless-string-statement",
    "expression-not-assigned",
    "named-expr-without-context",
)
def visit_expr(self, node: nodes.Expr) -&gt; None:
    """Check for various kind of statements without effect."""
    expr = node.value
    if isinstance(expr, nodes.Const) and isinstance(expr.value, str):
        # treat string statement in a separated message
        # Handle PEP-257 attribute docstrings.
        # An attribute docstring is defined as being a string right after
        # an assignment at the module level, class level or __init__ level.
        scope = expr.scope()
        if isinstance(scope, (nodes.ClassDef, nodes.Module, nodes.FunctionDef)):
            if isinstance(scope, nodes.FunctionDef) and scope.name != "__init__":
                pass
            else:
                sibling = expr.previous_sibling()
                if (
                    sibling is not None
                    and sibling.scope() is scope
                    and isinstance(
                        sibling, (nodes.Assign, nodes.AnnAssign, nodes.TypeAlias)
                    )
                ):
                    return
        self.add_message("pointless-string-statement", node=node)
        return

    # Warn W0133 for exceptions that are used as statements
    if isinstance(expr, nodes.Call):
        name = ""
        if isinstance(expr.func, nodes.Name):
            name = expr.func.name
        elif isinstance(expr.func, nodes.Attribute):
            name = expr.func.attrname

        # Heuristic: only run inference for names that begin with an uppercase char
        # This reduces W0133's coverage, but retains acceptable runtime performance
        # For more details, see: https://github.com/pylint-dev/pylint/issues/8073
        inferred = utils.safe_infer(expr) if name[:1].isupper() else None
        if isinstance(inferred, objects.ExceptionInstance):
            self.add_message(
                "pointless-exception-statement", node=node, confidence=INFERENCE
            )
        return

    # Ignore if this is :
    # * the unique child of a try/except body
    # * a yield statement
    # * an ellipsis (which can be used on Python 3 instead of pass)
    # warn W0106 if we have any underlying function call (we can't predict
    # side effects), else pointless-statement
    if (
        isinstance(expr, (nodes.Yield, nodes.Await))
        or (
            isinstance(node.parent, (nodes.Try, nodes.TryStar))
            and node.parent.body == [node]
        )
        or (isinstance(expr, nodes.Const) and expr.value is Ellipsis)
    ):
        return
    if isinstance(expr, nodes.NamedExpr):
        self.add_message("named-expr-without-context", node=node, confidence=HIGH)
    elif any(expr.nodes_of_class(nodes.Call)):
        self.add_message(
            "expression-not-assigned", node=node, args=expr.as_string()
        )
    else:
        self.add_message("pointless-statement", node=node)

</t>
<t tx="ekr.20250131013600.253">@staticmethod
def _filter_vararg(
    node: nodes.Lambda, call_args: list[nodes.NodeNG]
) -&gt; Iterator[nodes.NodeNG]:
    # Return the arguments for the given call which are
    # not passed as vararg.
    for arg in call_args:
        if isinstance(arg, nodes.Starred):
            if (
                isinstance(arg.value, nodes.Name)
                and arg.value.name != node.args.vararg
            ):
                yield arg
        else:
            yield arg

</t>
<t tx="ekr.20250131013600.254">@staticmethod
def _has_variadic_argument(
    args: list[nodes.Starred | nodes.Keyword], variadic_name: str
) -&gt; bool:
    return not args or any(
        (isinstance(a.value, nodes.Name) and a.value.name != variadic_name)
        or not isinstance(a.value, nodes.Name)
        for a in args
    )

</t>
<t tx="ekr.20250131013600.255">@utils.only_required_for_messages("unnecessary-lambda")
def visit_lambda(self, node: nodes.Lambda) -&gt; None:
    """Check whether the lambda is suspicious."""
    # if the body of the lambda is a call expression with the same
    # argument list as the lambda itself, then the lambda is
    # possibly unnecessary and at least suspicious.
    if node.args.defaults:
        # If the arguments of the lambda include defaults, then a
        # judgment cannot be made because there is no way to check
        # that the defaults defined by the lambda are the same as
        # the defaults defined by the function called in the body
        # of the lambda.
        return
    call = node.body
    if not isinstance(call, nodes.Call):
        # The body of the lambda must be a function call expression
        # for the lambda to be unnecessary.
        return
    if isinstance(node.body.func, nodes.Attribute) and isinstance(
        node.body.func.expr, nodes.Call
    ):
        # Chained call, the intermediate call might
        # return something else (but we don't check that, yet).
        return

    ordinary_args = list(node.args.args)
    new_call_args = list(self._filter_vararg(node, call.args))
    if node.args.kwarg:
        if self._has_variadic_argument(call.keywords, node.args.kwarg):
            return
    elif call.keywords:
        return

    if node.args.vararg:
        if self._has_variadic_argument(call.starargs, node.args.vararg):
            return
    elif call.starargs:
        return

    # The "ordinary" arguments must be in a correspondence such that:
    # ordinary_args[i].name == call.args[i].name.
    if len(ordinary_args) != len(new_call_args):
        return
    for arg, passed_arg in zip(ordinary_args, new_call_args):
        if not isinstance(passed_arg, nodes.Name):
            return
        if arg.name != passed_arg.name:
            return

    # The lambda is necessary if it uses its parameter in the function it is
    # calling in the lambda's body
    # e.g. lambda foo: (func1 if foo else func2)(foo)
    for name in call.func.nodes_of_class(nodes.Name):
        if name.lookup(name.name)[0] is node:
            return

    self.add_message("unnecessary-lambda", line=node.fromlineno, node=node)

</t>
<t tx="ekr.20250131013600.256">@utils.only_required_for_messages("dangerous-default-value")
def visit_functiondef(self, node: nodes.FunctionDef) -&gt; None:
    """Check function name, docstring, arguments, redefinition,
    variable names, max locals.
    """
    if node.is_method():
        self.linter.stats.node_count["method"] += 1
    else:
        self.linter.stats.node_count["function"] += 1
    self._check_dangerous_default(node)

</t>
<t tx="ekr.20250131013600.257">visit_asyncfunctiondef = visit_functiondef

def _check_dangerous_default(self, node: nodes.FunctionDef) -&gt; None:
    """Check for dangerous default values as arguments."""

    def is_iterable(internal_node: nodes.NodeNG) -&gt; bool:
        return isinstance(internal_node, (nodes.List, nodes.Set, nodes.Dict))

    defaults = (node.args.defaults or []) + (node.args.kw_defaults or [])
    for default in defaults:
        if not default:
            continue
        try:
            value = next(default.infer())
        except astroid.InferenceError:
            continue

        if (
            isinstance(value, astroid.Instance)
            and value.qname() in DEFAULT_ARGUMENT_SYMBOLS
        ):
            if value is default:
                msg = DEFAULT_ARGUMENT_SYMBOLS[value.qname()]
            elif isinstance(value, astroid.Instance) or is_iterable(value):
                # We are here in the following situation(s):
                #   * a dict/set/list/tuple call which wasn't inferred
                #     to a syntax node ({}, () etc.). This can happen
                #     when the arguments are invalid or unknown to
                #     the inference.
                #   * a variable from somewhere else, which turns out to be a list
                #     or a dict.
                if is_iterable(default):
                    msg = value.pytype()
                elif isinstance(default, nodes.Call):
                    msg = f"{value.name}() ({value.qname()})"
                else:
                    msg = f"{default.as_string()} ({value.qname()})"
            else:
                # this argument is a name
                msg = f"{default.as_string()} ({DEFAULT_ARGUMENT_SYMBOLS[value.qname()]})"
            self.add_message("dangerous-default-value", node=node, args=(msg,))

</t>
<t tx="ekr.20250131013600.258">@utils.only_required_for_messages("unreachable", "lost-exception")
def visit_return(self, node: nodes.Return) -&gt; None:
    """Return node visitor.

    1 - check if the node has a right sibling (if so, that's some
    unreachable code)
    2 - check if the node is inside the 'finally' clause of a 'try...finally'
    block
    """
    self._check_unreachable(node)
    # Is it inside final body of a try...finally block ?
    self._check_not_in_finally(node, "return", (nodes.FunctionDef,))

</t>
<t tx="ekr.20250131013600.259">@utils.only_required_for_messages("unreachable")
def visit_continue(self, node: nodes.Continue) -&gt; None:
    """Check is the node has a right sibling (if so, that's some unreachable
    code).
    """
    self._check_unreachable(node)

</t>
<t tx="ekr.20250131013600.26">def node_frame_class(node: nodes.NodeNG) -&gt; nodes.ClassDef | None:
    """Return the class that is wrapping the given node.

    The function returns a class for a method node (or a staticmethod or a
    classmethod), otherwise it returns `None`.
    """
    klass = node.frame()
    nodes_to_check = (
        nodes.NodeNG,
        astroid.UnboundMethod,
        astroid.BaseInstance,
    )
    while (
        klass
        and isinstance(klass, nodes_to_check)
        and not isinstance(klass, nodes.ClassDef)
    ):
        if klass.parent is None:
            return None

        klass = klass.parent.frame()

    return klass


</t>
<t tx="ekr.20250131013600.260">@utils.only_required_for_messages("unreachable", "lost-exception")
def visit_break(self, node: nodes.Break) -&gt; None:
    """Break node visitor.

    1 - check if the node has a right sibling (if so, that's some
    unreachable code)
    2 - check if the node is inside the 'finally' clause of a 'try...finally'
    block
    """
    # 1 - Is it right sibling ?
    self._check_unreachable(node)
    # 2 - Is it inside final body of a try...finally block ?
    self._check_not_in_finally(node, "break", (nodes.For, nodes.While))

</t>
<t tx="ekr.20250131013600.261">@utils.only_required_for_messages("unreachable")
def visit_raise(self, node: nodes.Raise) -&gt; None:
    """Check if the node has a right sibling (if so, that's some unreachable
    code).
    """
    self._check_unreachable(node)

</t>
<t tx="ekr.20250131013600.262">def _check_misplaced_format_function(self, call_node: nodes.Call) -&gt; None:
    if not isinstance(call_node.func, nodes.Attribute):
        return
    if call_node.func.attrname != "format":
        return

    expr = utils.safe_infer(call_node.func.expr)
    if isinstance(expr, util.UninferableBase):
        return
    if not expr:
        # we are doubtful on inferred type of node, so here just check if format
        # was called on print()
        call_expr = call_node.func.expr
        if not isinstance(call_expr, nodes.Call):
            return
        if (
            isinstance(call_expr.func, nodes.Name)
            and call_expr.func.name == "print"
        ):
            self.add_message("misplaced-format-function", node=call_node)

</t>
<t tx="ekr.20250131013600.263">@utils.only_required_for_messages(
    "eval-used",
    "exec-used",
    "bad-reversed-sequence",
    "misplaced-format-function",
    "unreachable",
)
def visit_call(self, node: nodes.Call) -&gt; None:
    """Visit a Call node."""
    if utils.is_terminating_func(node):
        self._check_unreachable(node, confidence=INFERENCE)
    self._check_misplaced_format_function(node)
    if isinstance(node.func, nodes.Name):
        name = node.func.name
        # ignore the name if it's not a builtin (i.e. not defined in the
        # locals nor globals scope)
        if not (name in node.frame() or name in node.root()):
            if name == "exec":
                self.add_message("exec-used", node=node)
            elif name == "reversed":
                self._check_reversed(node)
            elif name == "eval":
                self.add_message("eval-used", node=node)

</t>
<t tx="ekr.20250131013600.264">@utils.only_required_for_messages("assert-on-tuple", "assert-on-string-literal")
def visit_assert(self, node: nodes.Assert) -&gt; None:
    """Check whether assert is used on a tuple or string literal."""
    if isinstance(node.test, nodes.Tuple) and len(node.test.elts) &gt; 0:
        self.add_message("assert-on-tuple", node=node, confidence=HIGH)

    if isinstance(node.test, nodes.Const) and isinstance(node.test.value, str):
        if node.test.value:
            when = "never"
        else:
            when = "always"
        self.add_message("assert-on-string-literal", node=node, args=(when,))

</t>
<t tx="ekr.20250131013600.265">@utils.only_required_for_messages("duplicate-key")
def visit_dict(self, node: nodes.Dict) -&gt; None:
    """Check duplicate key in dictionary."""
    keys = set()
    for k, _ in node.items:
        if isinstance(k, nodes.Const):
            key = k.value
        elif isinstance(k, nodes.Attribute):
            key = k.as_string()
        else:
            continue
        if key in keys:
            self.add_message("duplicate-key", node=node, args=key)
        keys.add(key)

</t>
<t tx="ekr.20250131013600.266">@utils.only_required_for_messages("duplicate-value")
def visit_set(self, node: nodes.Set) -&gt; None:
    """Check duplicate value in set."""
    values = set()
    for v in node.elts:
        if isinstance(v, nodes.Const):
            value = v.value
        else:
            continue
        if value in values:
            self.add_message(
                "duplicate-value", node=node, args=value, confidence=HIGH
            )
        values.add(value)

</t>
<t tx="ekr.20250131013600.267">def visit_try(self, node: nodes.Try) -&gt; None:
    """Update try block flag."""
    self._trys.append(node)

    for final_node in node.finalbody:
        for return_node in final_node.nodes_of_class(nodes.Return):
            self.add_message("return-in-finally", node=return_node, confidence=HIGH)

</t>
<t tx="ekr.20250131013600.268">def leave_try(self, _: nodes.Try) -&gt; None:
    """Update try block flag."""
    self._trys.pop()

</t>
<t tx="ekr.20250131013600.269">def _check_unreachable(
    self,
    node: nodes.Return | nodes.Continue | nodes.Break | nodes.Raise | nodes.Call,
    confidence: Confidence = HIGH,
) -&gt; None:
    """Check unreachable code."""
    unreachable_statement = node.next_sibling()
    if unreachable_statement is not None:
        if (
            isinstance(node, nodes.Return)
            and isinstance(unreachable_statement, nodes.Expr)
            and isinstance(unreachable_statement.value, nodes.Yield)
        ):
            # Don't add 'unreachable' for empty generators.
            # Only add warning if 'yield' is followed by another node.
            unreachable_statement = unreachable_statement.next_sibling()
            if unreachable_statement is None:
                return
        self.add_message(
            "unreachable", node=unreachable_statement, confidence=confidence
        )

</t>
<t tx="ekr.20250131013600.27">def get_outer_class(class_node: astroid.ClassDef) -&gt; astroid.ClassDef | None:
    """Return the class that is the outer class of given (nested) class_node."""
    parent_klass = class_node.parent.frame()

    return parent_klass if isinstance(parent_klass, astroid.ClassDef) else None


</t>
<t tx="ekr.20250131013600.270">def _check_not_in_finally(
    self,
    node: nodes.Break | nodes.Return,
    node_name: str,
    breaker_classes: tuple[nodes.NodeNG, ...] = (),
</t>
<t tx="ekr.20250131013600.271">) -&gt; None:
    """Check that a node is not inside a 'finally' clause of a
    'try...finally' statement.

    If we find a parent which type is in breaker_classes before
    a 'try...finally' block we skip the whole check.
    """
    # if self._trys is empty, we're not an in try block
    if not self._trys:
        return
    # the node could be a grand-grand...-child of the 'try...finally'
    _parent = node.parent
    _node = node
    while _parent and not isinstance(_parent, breaker_classes):
        if hasattr(_parent, "finalbody") and _node in _parent.finalbody:
            self.add_message("lost-exception", node=node, args=node_name)
            return
        _node = _parent
        _parent = _node.parent

def _check_reversed(self, node: nodes.Call) -&gt; None:
    """Check that the argument to `reversed` is a sequence."""
    try:
        argument = utils.safe_infer(utils.get_argument_from_call(node, position=0))
    except utils.NoSuchArgumentError:
        pass
    else:
        if isinstance(argument, util.UninferableBase):
            return
        if argument is None:
            # Nothing was inferred.
            # Try to see if we have iter().
            if isinstance(node.args[0], nodes.Call):
                try:
                    func = next(node.args[0].func.infer())
                except astroid.InferenceError:
                    return
                if getattr(
                    func, "name", None
                ) == "iter" and utils.is_builtin_object(func):
                    self.add_message("bad-reversed-sequence", node=node)
            return

        if isinstance(argument, (nodes.List, nodes.Tuple)):
            return

        # dicts are reversible, but only from Python 3.8 onward. Prior to
        # that, any class based on dict must explicitly provide a
        # __reversed__ method
        if not self._py38_plus and isinstance(argument, astroid.Instance):
            if any(
                ancestor.name == "dict" and utils.is_builtin_object(ancestor)
                for ancestor in itertools.chain(
                    (argument._proxied,), argument._proxied.ancestors()
                )
            ):
                try:
                    argument.locals[REVERSED_PROTOCOL_METHOD]
                except KeyError:
                    self.add_message("bad-reversed-sequence", node=node)
                return

        if hasattr(argument, "getattr"):
            # everything else is not a proper sequence for reversed()
            for methods in REVERSED_METHODS:
                for meth in methods:
                    try:
                        argument.getattr(meth)
                    except astroid.NotFoundError:
                        break
                else:
                    break
            else:
                self.add_message("bad-reversed-sequence", node=node)
        else:
            self.add_message("bad-reversed-sequence", node=node)

</t>
<t tx="ekr.20250131013600.272">@utils.only_required_for_messages("confusing-with-statement")
def visit_with(self, node: nodes.With) -&gt; None:
    # a "with" statement with multiple managers corresponds
    # to one AST "With" node with multiple items
    pairs = node.items
    if pairs:
        for prev_pair, pair in zip(pairs, pairs[1:]):
            if isinstance(prev_pair[1], nodes.AssignName) and (
                pair[1] is None and not isinstance(pair[0], nodes.Call)
            ):
                # Don't emit a message if the second is a function call
                # there's no way that can be mistaken for a name assignment.
                # If the line number doesn't match
                # we assume it's a nested "with".
                self.add_message("confusing-with-statement", node=node)

</t>
<t tx="ekr.20250131013600.273">def _check_self_assigning_variable(self, node: nodes.Assign) -&gt; None:
    # Detect assigning to the same variable.

    scope = node.scope()
    scope_locals = scope.locals

    rhs_names = []
    targets = node.targets
    if isinstance(targets[0], nodes.Tuple):
        if len(targets) != 1:
            # A complex assignment, so bail out early.
            return
        targets = targets[0].elts
        if len(targets) == 1:
            # Unpacking a variable into the same name.
            return

    if isinstance(node.value, nodes.Name):
        if len(targets) != 1:
            return
        rhs_names = [node.value]
    elif isinstance(node.value, nodes.Tuple):
        rhs_count = len(node.value.elts)
        if len(targets) != rhs_count or rhs_count == 1:
            return
        rhs_names = node.value.elts

    for target, lhs_name in zip(targets, rhs_names):
        if not isinstance(lhs_name, nodes.Name):
            continue
        if not isinstance(target, nodes.AssignName):
            continue
        # Check that the scope is different from a class level, which is usually
        # a pattern to expose module level attributes as class level ones.
        if isinstance(scope, nodes.ClassDef) and target.name in scope_locals:
            continue
        if target.name == lhs_name.name:
            self.add_message(
                "self-assigning-variable", args=(target.name,), node=target
            )

</t>
<t tx="ekr.20250131013600.274">def _check_redeclared_assign_name(self, targets: list[nodes.NodeNG | None]) -&gt; None:
    dummy_variables_rgx = self.linter.config.dummy_variables_rgx

    for target in targets:
        if not isinstance(target, nodes.Tuple):
            continue

        found_names = []
        for element in target.elts:
            if isinstance(element, nodes.Tuple):
                self._check_redeclared_assign_name([element])
            elif isinstance(element, nodes.AssignName) and element.name != "_":
                if dummy_variables_rgx and dummy_variables_rgx.match(element.name):
                    return
                found_names.append(element.name)

        names = collections.Counter(found_names)
        for name, count in names.most_common():
            if count &gt; 1:
                self.add_message(
                    "redeclared-assigned-name", args=(name,), node=target
                )

</t>
<t tx="ekr.20250131013600.275">@utils.only_required_for_messages(
    "self-assigning-variable", "redeclared-assigned-name"
)
def visit_assign(self, node: nodes.Assign) -&gt; None:
    self._check_self_assigning_variable(node)
    self._check_redeclared_assign_name(node.targets)

</t>
<t tx="ekr.20250131013600.276">@utils.only_required_for_messages("redeclared-assigned-name")
def visit_for(self, node: nodes.For) -&gt; None:
    self._check_redeclared_assign_name([node.target])
</t>
<t tx="ekr.20250131013600.277">@path pylint/checkers/base
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Basic Error checker from the basic checker."""

from __future__ import annotations

import itertools

import astroid
from astroid import nodes
from astroid.typing import InferenceResult

from pylint.checkers import utils
from pylint.checkers.base.basic_checker import _BasicChecker
from pylint.checkers.utils import infer_all
from pylint.interfaces import HIGH

ABC_METACLASSES = {"_py_abc.ABCMeta", "abc.ABCMeta"}  # Python 3.7+,
# List of methods which can be redefined
REDEFINABLE_METHODS = frozenset(("__module__",))
TYPING_FORWARD_REF_QNAME = "typing.ForwardRef"


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.278">def _get_break_loop_node(break_node: nodes.Break) -&gt; nodes.For | nodes.While | None:
    """Returns the loop node that holds the break node in arguments.

    Args:
        break_node (astroid.Break): the break node of interest.

    Returns:
        astroid.For or astroid.While: the loop node holding the break node.
    """
    loop_nodes = (nodes.For, nodes.While)
    parent = break_node.parent
    while not isinstance(parent, loop_nodes) or break_node in getattr(
        parent, "orelse", []
    ):
        break_node = parent
        parent = parent.parent
        if parent is None:
            break
    return parent


</t>
<t tx="ekr.20250131013600.279">def _loop_exits_early(loop: nodes.For | nodes.While) -&gt; bool:
    """Returns true if a loop may end with a break statement.

    Args:
        loop (astroid.For, astroid.While): the loop node inspected.

    Returns:
        bool: True if the loop may end with a break statement, False otherwise.
    """
    loop_nodes = (nodes.For, nodes.While)
    definition_nodes = (nodes.FunctionDef, nodes.ClassDef)
    inner_loop_nodes: list[nodes.For | nodes.While] = [
        _node
        for _node in loop.nodes_of_class(loop_nodes, skip_klass=definition_nodes)
        if _node != loop
    ]
    return any(
        _node
        for _node in loop.nodes_of_class(nodes.Break, skip_klass=definition_nodes)
        if _get_break_loop_node(_node) not in inner_loop_nodes
    )


</t>
<t tx="ekr.20250131013600.28">def is_attr_private(attrname: str) -&gt; Match[str] | None:
    """Check that attribute name is private (at least two leading underscores,
    at most one trailing underscore).
    """
    regex = re.compile("^_{2,10}.*[^_]+_?$")
    return regex.match(attrname)


</t>
<t tx="ekr.20250131013600.280">def _has_abstract_methods(node: nodes.ClassDef) -&gt; bool:
    """Determine if the given `node` has abstract methods.

    The methods should be made abstract by decorating them
    with `abc` decorators.
    """
    return len(utils.unimplemented_abstract_methods(node)) &gt; 0


</t>
<t tx="ekr.20250131013600.281">def redefined_by_decorator(node: nodes.FunctionDef) -&gt; bool:
    """Return True if the object is a method redefined via decorator.

    For example:
        @property
        def x(self): return self._x
        @x.setter
        def x(self, value): self._x = value
    """
    if node.decorators:
        for decorator in node.decorators.nodes:
            if (
                isinstance(decorator, nodes.Attribute)
                and getattr(decorator.expr, "name", None) == node.name
            ):
                return True
    return False


</t>
<t tx="ekr.20250131013600.282">class BasicErrorChecker(_BasicChecker):
    @others
</t>
<t tx="ekr.20250131013600.283">msgs = {
    "E0100": (
        "__init__ method is a generator",
        "init-is-generator",
        "Used when the special class method __init__ is turned into a "
        "generator by a yield in its body.",
    ),
    "E0101": (
        "Explicit return in __init__",
        "return-in-init",
        "Used when the special class method __init__ has an explicit "
        "return value.",
    ),
    "E0102": (
        "%s already defined line %s",
        "function-redefined",
        "Used when a function / class / method is redefined.",
    ),
    "E0103": (
        "%r not properly in loop",
        "not-in-loop",
        "Used when break or continue keywords are used outside a loop.",
    ),
    "E0104": (
        "Return outside function",
        "return-outside-function",
        'Used when a "return" statement is found outside a function or method.',
    ),
    "E0105": (
        "Yield outside function",
        "yield-outside-function",
        'Used when a "yield" statement is found outside a function or method.',
    ),
    "E0106": (
        "Return with argument inside generator",
        "return-arg-in-generator",
        'Used when a "return" statement with an argument is found '
        'in a generator function or method (e.g. with some "yield" statements).',
        {"maxversion": (3, 3)},
    ),
    "E0107": (
        "Use of the non-existent %s operator",
        "nonexistent-operator",
        "Used when you attempt to use the C-style pre-increment or "
        "pre-decrement operator -- and ++, which doesn't exist in Python.",
    ),
    "E0108": (
        "Duplicate argument name %r in function definition",
        "duplicate-argument-name",
        "Duplicate argument names in function definitions are syntax errors.",
    ),
    "E0110": (
        "Abstract class %r with abstract methods instantiated",
        "abstract-class-instantiated",
        "Used when an abstract class with `abc.ABCMeta` as metaclass "
        "has abstract methods and is instantiated.",
    ),
    "W0120": (
        "Else clause on loop without a break statement, remove the else and"
        " de-indent all the code inside it",
        "useless-else-on-loop",
        "Loops should only have an else clause if they can exit early "
        "with a break statement, otherwise the statements under else "
        "should be on the same scope as the loop itself.",
    ),
    "E0112": (
        "More than one starred expression in assignment",
        "too-many-star-expressions",
        "Emitted when there are more than one starred "
        "expressions (`*x`) in an assignment. This is a SyntaxError.",
    ),
    "E0113": (
        "Starred assignment target must be in a list or tuple",
        "invalid-star-assignment-target",
        "Emitted when a star expression is used as a starred assignment target.",
    ),
    "E0114": (
        "Can use starred expression only in assignment target",
        "star-needs-assignment-target",
        "Emitted when a star expression is not used in an assignment target.",
    ),
    "E0115": (
        "Name %r is nonlocal and global",
        "nonlocal-and-global",
        "Emitted when a name is both nonlocal and global.",
    ),
    "E0116": (
        "'continue' not supported inside 'finally' clause",
        "continue-in-finally",
        "Emitted when the `continue` keyword is found "
        "inside a finally clause, which is a SyntaxError.",
    ),
    "E0117": (
        "nonlocal name %s found without binding",
        "nonlocal-without-binding",
        "Emitted when a nonlocal variable does not have an attached "
        "name somewhere in the parent scopes",
    ),
    "E0118": (
        "Name %r is used prior to global declaration",
        "used-prior-global-declaration",
        "Emitted when a name is used prior a global declaration, "
        "which results in an error since Python 3.6.",
        {"minversion": (3, 6)},
    ),
}

def open(self) -&gt; None:
    py_version = self.linter.config.py_version
    self._py38_plus = py_version &gt;= (3, 8)

</t>
<t tx="ekr.20250131013600.284">@utils.only_required_for_messages("function-redefined")
def visit_classdef(self, node: nodes.ClassDef) -&gt; None:
    self._check_redefinition("class", node)

</t>
<t tx="ekr.20250131013600.285">def _too_many_starred_for_tuple(self, assign_tuple: nodes.Tuple) -&gt; bool:
    starred_count = 0
    for elem in assign_tuple.itered():
        if isinstance(elem, nodes.Tuple):
            return self._too_many_starred_for_tuple(elem)
        if isinstance(elem, nodes.Starred):
            starred_count += 1
    return starred_count &gt; 1

</t>
<t tx="ekr.20250131013600.286">@utils.only_required_for_messages(
    "too-many-star-expressions", "invalid-star-assignment-target"
)
def visit_assign(self, node: nodes.Assign) -&gt; None:
    # Check *a, *b = ...
    assign_target = node.targets[0]
    # Check *a = b
    if isinstance(node.targets[0], nodes.Starred):
        self.add_message("invalid-star-assignment-target", node=node)

    if not isinstance(assign_target, nodes.Tuple):
        return
    if self._too_many_starred_for_tuple(assign_target):
        self.add_message("too-many-star-expressions", node=node)

</t>
<t tx="ekr.20250131013600.287">@utils.only_required_for_messages("star-needs-assignment-target")
def visit_starred(self, node: nodes.Starred) -&gt; None:
    """Check that a Starred expression is used in an assignment target."""
    if isinstance(node.parent, nodes.Call):
        # f(*args) is converted to Call(args=[Starred]), so ignore
        # them for this check.
        return
    if isinstance(node.parent, (nodes.List, nodes.Tuple, nodes.Set, nodes.Dict)):
        # PEP 448 unpacking.
        return

    stmt = node.statement()
    if not isinstance(stmt, nodes.Assign):
        return

    if stmt.value is node or stmt.value.parent_of(node):
        self.add_message("star-needs-assignment-target", node=node)

</t>
<t tx="ekr.20250131013600.288">@utils.only_required_for_messages(
    "init-is-generator",
    "return-in-init",
    "function-redefined",
    "return-arg-in-generator",
    "duplicate-argument-name",
    "nonlocal-and-global",
    "used-prior-global-declaration",
)
def visit_functiondef(self, node: nodes.FunctionDef) -&gt; None:
    self._check_nonlocal_and_global(node)
    self._check_name_used_prior_global(node)
    if not redefined_by_decorator(
        node
    ) and not utils.is_registered_in_singledispatch_function(node):
        self._check_redefinition(
            (node.is_method() and "method") or "function", node
        )
    # checks for max returns, branch, return in __init__
    returns = node.nodes_of_class(
        nodes.Return, skip_klass=(nodes.FunctionDef, nodes.ClassDef)
    )
    if node.is_method() and node.name == "__init__":
        if node.is_generator():
            self.add_message("init-is-generator", node=node)
        else:
            values = [r.value for r in returns]
            # Are we returning anything but None from constructors
            if any(v for v in values if not utils.is_none(v)):
                self.add_message("return-in-init", node=node)
    # Check for duplicate names by clustering args with same name for detailed report
    arg_clusters = {}
    for arg in node.args.arguments:
        if arg.name in arg_clusters:
            self.add_message(
                "duplicate-argument-name",
                node=arg,
                args=(arg.name,),
                confidence=HIGH,
            )
        else:
            arg_clusters[arg.name] = arg

</t>
<t tx="ekr.20250131013600.289">visit_asyncfunctiondef = visit_functiondef

def _check_name_used_prior_global(self, node: nodes.FunctionDef) -&gt; None:
    scope_globals = {
        name: child
        for child in node.nodes_of_class(nodes.Global)
        for name in child.names
        if child.scope() is node
    }

    if not scope_globals:
        return

    for node_name in node.nodes_of_class(nodes.Name):
        if node_name.scope() is not node:
            continue

        name = node_name.name
        corresponding_global = scope_globals.get(name)
        if not corresponding_global:
            continue

        global_lineno = corresponding_global.fromlineno
        if global_lineno and global_lineno &gt; node_name.fromlineno:
            self.add_message(
                "used-prior-global-declaration", node=node_name, args=(name,)
            )

</t>
<t tx="ekr.20250131013600.29">def get_argument_from_call(
    call_node: nodes.Call, position: int | None = None, keyword: str | None = None
) -&gt; nodes.Name:
    """Returns the specified argument from a function call.

    :param nodes.Call call_node: Node representing a function call to check.
    :param int position: position of the argument.
    :param str keyword: the keyword of the argument.

    :returns: The node representing the argument, None if the argument is not found.
    :rtype: nodes.Name
    :raises ValueError: if both position and keyword are None.
    :raises NoSuchArgumentError: if no argument at the provided position or with
    the provided keyword.
    """
    if position is None and keyword is None:
        raise ValueError("Must specify at least one of: position or keyword.")
    if position is not None:
        try:
            return call_node.args[position]
        except IndexError:
            pass
    if keyword and call_node.keywords:
        for arg in call_node.keywords:
            if arg.arg == keyword:
                return arg.value

    raise NoSuchArgumentError


</t>
<t tx="ekr.20250131013600.290">def _check_nonlocal_and_global(self, node: nodes.FunctionDef) -&gt; None:
    """Check that a name is both nonlocal and global."""

    def same_scope(current: nodes.Global | nodes.Nonlocal) -&gt; bool:
        return current.scope() is node

    from_iter = itertools.chain.from_iterable
    nonlocals = set(
        from_iter(
            child.names
            for child in node.nodes_of_class(nodes.Nonlocal)
            if same_scope(child)
        )
    )

    if not nonlocals:
        return

    global_vars = set(
        from_iter(
            child.names
            for child in node.nodes_of_class(nodes.Global)
            if same_scope(child)
        )
    )
    for name in nonlocals.intersection(global_vars):
        self.add_message("nonlocal-and-global", args=(name,), node=node)

</t>
<t tx="ekr.20250131013600.291">@utils.only_required_for_messages("return-outside-function")
def visit_return(self, node: nodes.Return) -&gt; None:
    if not isinstance(node.frame(), nodes.FunctionDef):
        self.add_message("return-outside-function", node=node)

</t>
<t tx="ekr.20250131013600.292">@utils.only_required_for_messages("yield-outside-function")
def visit_yield(self, node: nodes.Yield) -&gt; None:
    self._check_yield_outside_func(node)

</t>
<t tx="ekr.20250131013600.293">@utils.only_required_for_messages("yield-outside-function")
def visit_yieldfrom(self, node: nodes.YieldFrom) -&gt; None:
    self._check_yield_outside_func(node)

</t>
<t tx="ekr.20250131013600.294">@utils.only_required_for_messages("not-in-loop", "continue-in-finally")
def visit_continue(self, node: nodes.Continue) -&gt; None:
    self._check_in_loop(node, "continue")

</t>
<t tx="ekr.20250131013600.295">@utils.only_required_for_messages("not-in-loop")
def visit_break(self, node: nodes.Break) -&gt; None:
    self._check_in_loop(node, "break")

</t>
<t tx="ekr.20250131013600.296">@utils.only_required_for_messages("useless-else-on-loop")
def visit_for(self, node: nodes.For) -&gt; None:
    self._check_else_on_loop(node)

</t>
<t tx="ekr.20250131013600.297">@utils.only_required_for_messages("useless-else-on-loop")
def visit_while(self, node: nodes.While) -&gt; None:
    self._check_else_on_loop(node)

</t>
<t tx="ekr.20250131013600.298">@utils.only_required_for_messages("nonexistent-operator")
def visit_unaryop(self, node: nodes.UnaryOp) -&gt; None:
    """Check use of the non-existent ++ and -- operators."""
    if (
        (node.op in "+-")
        and isinstance(node.operand, nodes.UnaryOp)
        and (node.operand.op == node.op)
        and (node.col_offset + 1 == node.operand.col_offset)
    ):
        self.add_message("nonexistent-operator", node=node, args=node.op * 2)

</t>
<t tx="ekr.20250131013600.299">def _check_nonlocal_without_binding(self, node: nodes.Nonlocal, name: str) -&gt; None:
    current_scope = node.scope()
    while current_scope.parent is not None:
        if not isinstance(current_scope, (nodes.ClassDef, nodes.FunctionDef)):
            self.add_message("nonlocal-without-binding", args=(name,), node=node)
            return

        # Search for `name` in the parent scope if:
        #  `current_scope` is the same scope in which the `nonlocal` name is declared
        #  or `name` is not in `current_scope.locals`.
        if current_scope is node.scope() or name not in current_scope.locals:
            current_scope = current_scope.parent.scope()
            continue

        # Okay, found it.
        return

    if not isinstance(current_scope, nodes.FunctionDef):
        self.add_message(
            "nonlocal-without-binding", args=(name,), node=node, confidence=HIGH
        )

</t>
<t tx="ekr.20250131013600.3">def get_all_elements(
    node: nodes.NodeNG,
) -&gt; Iterable[nodes.NodeNG]:
    """Recursively returns all atoms in nested lists and tuples."""
    if isinstance(node, (nodes.Tuple, nodes.List)):
        for child in node.elts:
            yield from get_all_elements(child)
    else:
        yield node


</t>
<t tx="ekr.20250131013600.30">def infer_kwarg_from_call(call_node: nodes.Call, keyword: str) -&gt; nodes.Name | None:
    """Returns the specified argument from a function's kwargs.

    :param nodes.Call call_node: Node representing a function call to check.
    :param str keyword: Name of the argument to be extracted.

    :returns: The node representing the argument, None if the argument is not found.
    :rtype: nodes.Name
    """
    for arg in call_node.kwargs:
        inferred = safe_infer(arg.value)
        if isinstance(inferred, nodes.Dict):
            for item in inferred.items:
                if item[0].value == keyword:
                    return item[1]

    return None


</t>
<t tx="ekr.20250131013600.300">@utils.only_required_for_messages("nonlocal-without-binding")
def visit_nonlocal(self, node: nodes.Nonlocal) -&gt; None:
    for name in node.names:
        self._check_nonlocal_without_binding(node, name)

</t>
<t tx="ekr.20250131013600.301">@utils.only_required_for_messages("abstract-class-instantiated")
def visit_call(self, node: nodes.Call) -&gt; None:
    """Check instantiating abstract class with
    abc.ABCMeta as metaclass.
    """
    for inferred in infer_all(node.func):
        self._check_inferred_class_is_abstract(inferred, node)

</t>
<t tx="ekr.20250131013600.302">def _check_inferred_class_is_abstract(
    self, inferred: InferenceResult, node: nodes.Call
) -&gt; None:
    if not isinstance(inferred, nodes.ClassDef):
        return

    klass = utils.node_frame_class(node)
    if klass is inferred:
        # Don't emit the warning if the class is instantiated
        # in its own body or if the call is not an instance
        # creation. If the class is instantiated into its own
        # body, we're expecting that it knows what it is doing.
        return

    # __init__ was called
    abstract_methods = _has_abstract_methods(inferred)

    if not abstract_methods:
        return

    metaclass = inferred.metaclass()

    if metaclass is None:
        # Python 3.4 has `abc.ABC`, which won't be detected
        # by ClassNode.metaclass()
        for ancestor in inferred.ancestors():
            if ancestor.qname() == "abc.ABC":
                self.add_message(
                    "abstract-class-instantiated", args=(inferred.name,), node=node
                )
                break

        return

    if metaclass.qname() in ABC_METACLASSES:
        self.add_message(
            "abstract-class-instantiated", args=(inferred.name,), node=node
        )

</t>
<t tx="ekr.20250131013600.303">def _check_yield_outside_func(self, node: nodes.Yield) -&gt; None:
    if not isinstance(node.frame(), (nodes.FunctionDef, nodes.Lambda)):
        self.add_message("yield-outside-function", node=node)

</t>
<t tx="ekr.20250131013600.304">def _check_else_on_loop(self, node: nodes.For | nodes.While) -&gt; None:
    """Check that any loop with an else clause has a break statement."""
    if node.orelse and not _loop_exits_early(node):
        self.add_message(
            "useless-else-on-loop",
            node=node,
            # This is not optimal, but the line previous
            # to the first statement in the else clause
            # will usually be the one that contains the else:.
            line=node.orelse[0].lineno - 1,
        )

</t>
<t tx="ekr.20250131013600.305">def _check_in_loop(
    self, node: nodes.Continue | nodes.Break, node_name: str
) -&gt; None:
    """Check that a node is inside a for or while loop."""
    for parent in node.node_ancestors():
        if isinstance(parent, (nodes.For, nodes.While)):
            if node not in parent.orelse:
                return

        if isinstance(parent, (nodes.ClassDef, nodes.FunctionDef)):
            break
        if (
            isinstance(parent, nodes.Try)
            and node in parent.finalbody
            and isinstance(node, nodes.Continue)
            and not self._py38_plus
        ):
            self.add_message("continue-in-finally", node=node)

    self.add_message("not-in-loop", node=node, args=node_name)

</t>
<t tx="ekr.20250131013600.306">def _check_redefinition(
    self, redeftype: str, node: nodes.Call | nodes.FunctionDef
) -&gt; None:
    """Check for redefinition of a function / method / class name."""
    parent_frame = node.parent.frame()

    # Ignore function stubs created for type information
    redefinitions = [
        i
        for i in parent_frame.locals[node.name]
        if not (isinstance(i.parent, nodes.AnnAssign) and i.parent.simple)
    ]
    defined_self = next(
        (local for local in redefinitions if not utils.is_overload_stub(local)),
        node,
    )
    if defined_self is not node and not astroid.are_exclusive(node, defined_self):
        # Additional checks for methods which are not considered
        # redefined, since they are already part of the base API.
        if (
            isinstance(parent_frame, nodes.ClassDef)
            and node.name in REDEFINABLE_METHODS
        ):
            return

        # Skip typing.overload() functions.
        if utils.is_overload_stub(node):
            return

        # Exempt functions redefined on a condition.
        if isinstance(node.parent, nodes.If):
            # Exempt "if not &lt;func&gt;" cases
            if (
                isinstance(node.parent.test, nodes.UnaryOp)
                and node.parent.test.op == "not"
                and isinstance(node.parent.test.operand, nodes.Name)
                and node.parent.test.operand.name == node.name
            ):
                return

            # Exempt "if &lt;func&gt; is not None" cases
            # pylint: disable=too-many-boolean-expressions
            if (
                isinstance(node.parent.test, nodes.Compare)
                and isinstance(node.parent.test.left, nodes.Name)
                and node.parent.test.left.name == node.name
                and node.parent.test.ops[0][0] == "is"
                and isinstance(node.parent.test.ops[0][1], nodes.Const)
                and node.parent.test.ops[0][1].value is None
            ):
                return

        # Check if we have forward references for this node.
        try:
            redefinition_index = redefinitions.index(node)
        except ValueError:
            pass
        else:
            for redefinition in redefinitions[:redefinition_index]:
                inferred = utils.safe_infer(redefinition)
                if (
                    inferred
                    and isinstance(inferred, astroid.Instance)
                    and inferred.qname() == TYPING_FORWARD_REF_QNAME
                ):
                    return

        dummy_variables_rgx = self.linter.config.dummy_variables_rgx
        if dummy_variables_rgx and dummy_variables_rgx.match(node.name):
            return
        self.add_message(
            "function-redefined",
            node=node,
            args=(redeftype, defined_self.fromlineno),
        )
</t>
<t tx="ekr.20250131013600.307">@path pylint/checkers/base
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Comparison checker from the basic checker."""

import astroid
from astroid import nodes

from pylint.checkers import utils
from pylint.checkers.base.basic_checker import _BasicChecker
from pylint.interfaces import HIGH

LITERAL_NODE_TYPES = (nodes.Const, nodes.Dict, nodes.List, nodes.Set)
COMPARISON_OPERATORS = frozenset(("==", "!=", "&lt;", "&gt;", "&lt;=", "&gt;="))
TYPECHECK_COMPARISON_OPERATORS = frozenset(("is", "is not", "==", "!="))
TYPE_QNAME = "builtins.type"


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.308">def _is_one_arg_pos_call(call: nodes.NodeNG) -&gt; bool:
    """Is this a call with exactly 1 positional argument ?"""
    return isinstance(call, nodes.Call) and len(call.args) == 1 and not call.keywords


</t>
<t tx="ekr.20250131013600.309">class ComparisonChecker(_BasicChecker):
    """Checks for comparisons.

    - singleton comparison: 'expr == True', 'expr == False' and 'expr == None'
    - yoda condition: 'const "comp" right' where comp can be '==', '!=', '&lt;',
      '&lt;=', '&gt;' or '&gt;=', and right can be a variable, an attribute, a method or
      a function
    """

    @others
</t>
<t tx="ekr.20250131013600.31">def inherit_from_std_ex(node: nodes.NodeNG | astroid.Instance) -&gt; bool:
    """Return whether the given class node is subclass of
    exceptions.Exception.
    """
    ancestors = node.ancestors() if hasattr(node, "ancestors") else []
    return any(
        ancestor.name in {"Exception", "BaseException"}
        and ancestor.root().name == EXCEPTIONS_MODULE
        for ancestor in itertools.chain([node], ancestors)
    )


</t>
<t tx="ekr.20250131013600.310">msgs = {
    "C0121": (
        "Comparison %s should be %s",
        "singleton-comparison",
        "Used when an expression is compared to singleton "
        "values like True, False or None.",
    ),
    "C0123": (
        "Use isinstance() rather than type() for a typecheck.",
        "unidiomatic-typecheck",
        "The idiomatic way to perform an explicit typecheck in "
        "Python is to use isinstance(x, Y) rather than "
        "type(x) == Y, type(x) is Y. Though there are unusual "
        "situations where these give different results.",
        {"old_names": [("W0154", "old-unidiomatic-typecheck")]},
    ),
    "R0123": (
        "In '%s', use '%s' when comparing constant literals not '%s' ('%s')",
        "literal-comparison",
        "Used when comparing an object to a literal, which is usually "
        "what you do not want to do, since you can compare to a different "
        "literal than what was expected altogether.",
    ),
    "R0124": (
        "Redundant comparison - %s",
        "comparison-with-itself",
        "Used when something is compared against itself.",
    ),
    "R0133": (
        "Comparison between constants: '%s %s %s' has a constant value",
        "comparison-of-constants",
        "When two literals are compared with each other the result is a constant. "
        "Using the constant directly is both easier to read and more performant. "
        "Initializing 'True' and 'False' this way is not required since Python 2.3.",
    ),
    "W0143": (
        "Comparing against a callable, did you omit the parenthesis?",
        "comparison-with-callable",
        "This message is emitted when pylint detects that a comparison with a "
        "callable was made, which might suggest that some parenthesis were omitted, "
        "resulting in potential unwanted behaviour.",
    ),
    "W0177": (
        "Comparison %s should be %s",
        "nan-comparison",
        "Used when an expression is compared to NaN "
        "values like numpy.NaN and float('nan').",
    ),
}

def _check_singleton_comparison(
    self,
    left_value: nodes.NodeNG,
    right_value: nodes.NodeNG,
    root_node: nodes.Compare,
    checking_for_absence: bool = False,
) -&gt; None:
    """Check if == or != is being used to compare a singleton value."""
    if utils.is_singleton_const(left_value):
        singleton, other_value = left_value.value, right_value
    elif utils.is_singleton_const(right_value):
        singleton, other_value = right_value.value, left_value
    else:
        return

    singleton_comparison_example = {False: "'{} is {}'", True: "'{} is not {}'"}

    # True/False singletons have a special-cased message in case the user is
    # mistakenly using == or != to check for truthiness
    if singleton in {True, False}:
        suggestion_template = (
            "{} if checking for the singleton value {}, or {} if testing for {}"
        )
        truthiness_example = {False: "not {}", True: "{}"}
        truthiness_phrase = {True: "truthiness", False: "falsiness"}

        # Looks for comparisons like x == True or x != False
        checking_truthiness = singleton is not checking_for_absence

        suggestion = suggestion_template.format(
            singleton_comparison_example[checking_for_absence].format(
                left_value.as_string(), right_value.as_string()
            ),
            singleton,
            (
                "'bool({})'"
                if not utils.is_test_condition(root_node) and checking_truthiness
                else "'{}'"
            ).format(
                truthiness_example[checking_truthiness].format(
                    other_value.as_string()
                )
            ),
            truthiness_phrase[checking_truthiness],
        )
    else:
        suggestion = singleton_comparison_example[checking_for_absence].format(
            left_value.as_string(), right_value.as_string()
        )
    self.add_message(
        "singleton-comparison",
        node=root_node,
        args=(f"'{root_node.as_string()}'", suggestion),
    )

</t>
<t tx="ekr.20250131013600.311">def _check_nan_comparison(
    self,
    left_value: nodes.NodeNG,
    right_value: nodes.NodeNG,
    root_node: nodes.Compare,
    checking_for_absence: bool = False,
) -&gt; None:
    def _is_float_nan(node: nodes.NodeNG) -&gt; bool:
        try:
            if isinstance(node, nodes.Call) and len(node.args) == 1:
                if (
                    node.args[0].value.lower() == "nan"
                    and node.inferred()[0].pytype() == "builtins.float"
                ):
                    return True
            return False
        except AttributeError:
            return False

    def _is_numpy_nan(node: nodes.NodeNG) -&gt; bool:
        if isinstance(node, nodes.Attribute) and node.attrname == "NaN":
            if isinstance(node.expr, nodes.Name):
                return node.expr.name in {"numpy", "nmp", "np"}
        return False

    def _is_nan(node: nodes.NodeNG) -&gt; bool:
        return _is_float_nan(node) or _is_numpy_nan(node)

    nan_left = _is_nan(left_value)
    if not nan_left and not _is_nan(right_value):
        return

    absence_text = ""
    if checking_for_absence:
        absence_text = "not "
    if nan_left:
        suggestion = f"'{absence_text}math.isnan({right_value.as_string()})'"
    else:
        suggestion = f"'{absence_text}math.isnan({left_value.as_string()})'"
    self.add_message(
        "nan-comparison",
        node=root_node,
        args=(f"'{root_node.as_string()}'", suggestion),
    )

</t>
<t tx="ekr.20250131013600.312">def _check_literal_comparison(
    self, literal: nodes.NodeNG, node: nodes.Compare
) -&gt; None:
    """Check if we compare to a literal, which is usually what we do not want to do."""
    is_other_literal = isinstance(literal, (nodes.List, nodes.Dict, nodes.Set))
    is_const = False
    if isinstance(literal, nodes.Const):
        if isinstance(literal.value, bool) or literal.value is None:
            # Not interested in these values.
            return
        is_const = isinstance(literal.value, (bytes, str, int, float))

    if is_const or is_other_literal:
        incorrect_node_str = node.as_string()
        if "is not" in incorrect_node_str:
            equal_or_not_equal = "!="
            is_or_is_not = "is not"
        else:
            equal_or_not_equal = "=="
            is_or_is_not = "is"
        fixed_node_str = incorrect_node_str.replace(
            is_or_is_not, equal_or_not_equal
        )
        self.add_message(
            "literal-comparison",
            args=(
                incorrect_node_str,
                equal_or_not_equal,
                is_or_is_not,
                fixed_node_str,
            ),
            node=node,
            confidence=HIGH,
        )

</t>
<t tx="ekr.20250131013600.313">def _check_logical_tautology(self, node: nodes.Compare) -&gt; None:
    """Check if identifier is compared against itself.

    :param node: Compare node
    :Example:
    val = 786
    if val == val:  # [comparison-with-itself]
        pass
    """
    left_operand = node.left
    right_operand = node.ops[0][1]
    operator = node.ops[0][0]
    if isinstance(left_operand, nodes.Const) and isinstance(
        right_operand, nodes.Const
    ):
        left_operand = left_operand.value
        right_operand = right_operand.value
    elif isinstance(left_operand, nodes.Name) and isinstance(
        right_operand, nodes.Name
    ):
        left_operand = left_operand.name
        right_operand = right_operand.name

    if left_operand == right_operand:
        suggestion = f"{left_operand} {operator} {right_operand}"
        self.add_message("comparison-with-itself", node=node, args=(suggestion,))

</t>
<t tx="ekr.20250131013600.314">def _check_constants_comparison(self, node: nodes.Compare) -&gt; None:
    """When two constants are being compared it is always a logical tautology."""
    left_operand = node.left
    if not isinstance(left_operand, nodes.Const):
        return

    right_operand = node.ops[0][1]
    if not isinstance(right_operand, nodes.Const):
        return

    operator = node.ops[0][0]
    self.add_message(
        "comparison-of-constants",
        node=node,
        args=(left_operand.value, operator, right_operand.value),
        confidence=HIGH,
    )

</t>
<t tx="ekr.20250131013600.315">def _check_callable_comparison(self, node: nodes.Compare) -&gt; None:
    operator = node.ops[0][0]
    if operator not in COMPARISON_OPERATORS:
        return

    bare_callables = (nodes.FunctionDef, astroid.BoundMethod)
    left_operand, right_operand = node.left, node.ops[0][1]
    # this message should be emitted only when there is comparison of bare callable
    # with non bare callable.
    number_of_bare_callables = 0
    for operand in left_operand, right_operand:
        inferred = utils.safe_infer(operand)
        # Ignore callables that raise, as well as typing constants
        # implemented as functions (that raise via their decorator)
        if (
            isinstance(inferred, bare_callables)
            and "typing._SpecialForm" not in inferred.decoratornames()
            and not any(isinstance(x, nodes.Raise) for x in inferred.body)
        ):
            number_of_bare_callables += 1
    if number_of_bare_callables == 1:
        self.add_message("comparison-with-callable", node=node)

</t>
<t tx="ekr.20250131013600.316">@utils.only_required_for_messages(
    "singleton-comparison",
    "unidiomatic-typecheck",
    "literal-comparison",
    "comparison-with-itself",
    "comparison-of-constants",
    "comparison-with-callable",
    "nan-comparison",
)
def visit_compare(self, node: nodes.Compare) -&gt; None:
    self._check_callable_comparison(node)
    self._check_logical_tautology(node)
    self._check_unidiomatic_typecheck(node)
    self._check_constants_comparison(node)
    # NOTE: this checker only works with binary comparisons like 'x == 42'
    # but not 'x == y == 42'
    if len(node.ops) != 1:
        return

    left = node.left
    operator, right = node.ops[0]

    if operator in {"==", "!="}:
        self._check_singleton_comparison(
            left, right, node, checking_for_absence=operator == "!="
        )

    if operator in {"==", "!=", "is", "is not"}:
        self._check_nan_comparison(
            left, right, node, checking_for_absence=operator in {"!=", "is not"}
        )
    if operator in {"is", "is not"}:
        self._check_literal_comparison(right, node)

</t>
<t tx="ekr.20250131013600.317">def _check_unidiomatic_typecheck(self, node: nodes.Compare) -&gt; None:
    operator, right = node.ops[0]
    if operator in TYPECHECK_COMPARISON_OPERATORS:
        left = node.left
        if _is_one_arg_pos_call(left):
            self._check_type_x_is_y(node, left, operator, right)

</t>
<t tx="ekr.20250131013600.318">def _check_type_x_is_y(
    self,
    node: nodes.Compare,
    left: nodes.NodeNG,
    operator: str,
    right: nodes.NodeNG,
) -&gt; None:
    """Check for expressions like type(x) == Y."""
    left_func = utils.safe_infer(left.func)
    if not (
        isinstance(left_func, nodes.ClassDef) and left_func.qname() == TYPE_QNAME
    ):
        return

    if operator in {"is", "is not"} and _is_one_arg_pos_call(right):
        right_func = utils.safe_infer(right.func)
        if (
            isinstance(right_func, nodes.ClassDef)
            and right_func.qname() == TYPE_QNAME
        ):
            # type(x) == type(a)
            right_arg = utils.safe_infer(right.args[0])
            if not isinstance(right_arg, LITERAL_NODE_TYPES):
                # not e.g. type(x) == type([])
                return
    self.add_message("unidiomatic-typecheck", node=node)
</t>
<t tx="ekr.20250131013600.319">@path pylint/checkers/base
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Docstring checker from the basic checker."""

from __future__ import annotations

import re
from typing import Literal

import astroid
from astroid import nodes

from pylint import interfaces
from pylint.checkers import utils
from pylint.checkers.base.basic_checker import _BasicChecker
from pylint.checkers.utils import (
    is_overload_stub,
    is_property_deleter,
    is_property_setter,
)

# do not require a doc string on private/system methods
NO_REQUIRED_DOC_RGX = re.compile("^_")


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.32">def error_of_type(
    handler: nodes.ExceptHandler,
    error_type: str | type[Exception] | tuple[str | type[Exception], ...],
) -&gt; bool:
    """Check if the given exception handler catches
    the given error_type.

    The *handler* parameter is a node, representing an ExceptHandler node.
    The *error_type* can be an exception, such as AttributeError,
    the name of an exception, or it can be a tuple of errors.
    The function will return True if the handler catches any of the
    given errors.
    """

    def stringify_error(error: str | type[Exception]) -&gt; str:
        if not isinstance(error, str):
            return error.__name__
        return error

    if not isinstance(error_type, tuple):
        error_type = (error_type,)
    expected_errors = {stringify_error(error) for error in error_type}
    if not handler.type:
        return False
    return handler.catch(expected_errors)  # type: ignore[no-any-return]


</t>
<t tx="ekr.20250131013600.320">def _infer_dunder_doc_attribute(
    node: nodes.Module | nodes.ClassDef | nodes.FunctionDef,
) -&gt; str | None:
    # Try to see if we have a `__doc__` attribute.
    try:
        docstring = node["__doc__"]
    except KeyError:
        return None

    docstring = utils.safe_infer(docstring)
    if not docstring:
        return None
    if not isinstance(docstring, nodes.Const):
        return None
    return str(docstring.value)


</t>
<t tx="ekr.20250131013600.321">class DocStringChecker(_BasicChecker):
    @others
</t>
<t tx="ekr.20250131013600.322">msgs = {
    "C0112": (
        "Empty %s docstring",
        "empty-docstring",
        "Used when a module, function, class or method has an empty "
        "docstring (it would be too easy ;).",
        {"old_names": [("W0132", "old-empty-docstring")]},
    ),
    "C0114": (
        "Missing module docstring",
        "missing-module-docstring",
        "Used when a module has no docstring. "
        "Empty modules do not require a docstring.",
        {"old_names": [("C0111", "missing-docstring")]},
    ),
    "C0115": (
        "Missing class docstring",
        "missing-class-docstring",
        "Used when a class has no docstring. "
        "Even an empty class must have a docstring.",
        {"old_names": [("C0111", "missing-docstring")]},
    ),
    "C0116": (
        "Missing function or method docstring",
        "missing-function-docstring",
        "Used when a function or method has no docstring. "
        "Some special methods like __init__ do not require a "
        "docstring.",
        {"old_names": [("C0111", "missing-docstring")]},
    ),
}
options = (
    (
        "no-docstring-rgx",
        {
            "default": NO_REQUIRED_DOC_RGX,
            "type": "regexp",
            "metavar": "&lt;regexp&gt;",
            "help": "Regular expression which should only match "
            "function or class names that do not require a "
            "docstring.",
        },
    ),
    (
        "docstring-min-length",
        {
            "default": -1,
            "type": "int",
            "metavar": "&lt;int&gt;",
            "help": (
                "Minimum line length for functions/classes that"
                " require docstrings, shorter ones are exempt."
            ),
        },
    ),
)

def open(self) -&gt; None:
    self.linter.stats.reset_undocumented()

</t>
<t tx="ekr.20250131013600.323">@utils.only_required_for_messages("missing-module-docstring", "empty-docstring")
def visit_module(self, node: nodes.Module) -&gt; None:
    self._check_docstring("module", node)

</t>
<t tx="ekr.20250131013600.324">@utils.only_required_for_messages("missing-class-docstring", "empty-docstring")
def visit_classdef(self, node: nodes.ClassDef) -&gt; None:
    if self.linter.config.no_docstring_rgx.match(node.name) is None:
        self._check_docstring("class", node)

</t>
<t tx="ekr.20250131013600.325">@utils.only_required_for_messages("missing-function-docstring", "empty-docstring")
def visit_functiondef(self, node: nodes.FunctionDef) -&gt; None:
    if self.linter.config.no_docstring_rgx.match(node.name) is None:
        ftype = "method" if node.is_method() else "function"
        if (
            is_property_setter(node)
            or is_property_deleter(node)
            or is_overload_stub(node)
        ):
            return

        if isinstance(node.parent.frame(), nodes.ClassDef):
            overridden = False
            confidence = (
                interfaces.INFERENCE
                if utils.has_known_bases(node.parent.frame())
                else interfaces.INFERENCE_FAILURE
            )
            # check if node is from a method overridden by its ancestor
            for ancestor in node.parent.frame().ancestors():
                if ancestor.qname() == "builtins.object":
                    continue
                if node.name in ancestor and isinstance(
                    ancestor[node.name], nodes.FunctionDef
                ):
                    overridden = True
                    break
            self._check_docstring(
                ftype, node, report_missing=not overridden, confidence=confidence  # type: ignore[arg-type]
            )
        elif isinstance(node.parent.frame(), nodes.Module):
            self._check_docstring(ftype, node)  # type: ignore[arg-type]
        else:
            return

</t>
<t tx="ekr.20250131013600.326">visit_asyncfunctiondef = visit_functiondef

def _check_docstring(
    self,
    node_type: Literal["class", "function", "method", "module"],
    node: nodes.Module | nodes.ClassDef | nodes.FunctionDef,
    report_missing: bool = True,
    confidence: interfaces.Confidence = interfaces.HIGH,
) -&gt; None:
    """Check if the node has a non-empty docstring."""
    docstring = node.doc_node.value if node.doc_node else None
    if docstring is None:
        docstring = _infer_dunder_doc_attribute(node)

    if docstring is None:
        if not report_missing:
            return
        lines = utils.get_node_last_lineno(node) - node.lineno

        if node_type == "module" and not lines:
            # If the module does not have a body, there's no reason
            # to require a docstring.
            return
        max_lines = self.linter.config.docstring_min_length

        if node_type != "module" and max_lines &gt; -1 and lines &lt; max_lines:
            return
        if node_type == "class":
            self.linter.stats.undocumented["klass"] += 1
        else:
            self.linter.stats.undocumented[node_type] += 1
        if (
            node.body
            and isinstance(node.body[0], nodes.Expr)
            and isinstance(node.body[0].value, nodes.Call)
        ):
            # Most likely a string with a format call. Let's see.
            func = utils.safe_infer(node.body[0].value.func)
            if isinstance(func, astroid.BoundMethod) and isinstance(
                func.bound, astroid.Instance
            ):
                # Strings.
                if func.bound.name in {"str", "unicode", "bytes"}:
                    return
        if node_type == "module":
            message = "missing-module-docstring"
        elif node_type == "class":
            message = "missing-class-docstring"
        else:
            message = "missing-function-docstring"
        self.add_message(message, node=node, confidence=confidence)
    elif not docstring.strip():
        if node_type == "class":
            self.linter.stats.undocumented["klass"] += 1
        else:
            self.linter.stats.undocumented[node_type] += 1
        self.add_message(
            "empty-docstring", node=node, args=(node_type,), confidence=confidence
        )
</t>
<t tx="ekr.20250131013600.327">@path pylint/checkers/base
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Function checker for Python code."""

from __future__ import annotations

from itertools import chain

from astroid import nodes

from pylint.checkers import utils
from pylint.checkers.base.basic_checker import _BasicChecker


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.328">class FunctionChecker(_BasicChecker):
    """Check if a function definition handles possible side effects."""

    @others
</t>
<t tx="ekr.20250131013600.329">msgs = {
    "W0135": (
        "The context used in function %r will not be exited.",
        "contextmanager-generator-missing-cleanup",
        "Used when a contextmanager is used inside a generator function"
        " and the cleanup is not handled.",
    )
}

@utils.only_required_for_messages("contextmanager-generator-missing-cleanup")
def visit_functiondef(self, node: nodes.FunctionDef) -&gt; None:
    self._check_contextmanager_generator_missing_cleanup(node)

</t>
<t tx="ekr.20250131013600.33">def decorated_with_property(node: nodes.FunctionDef) -&gt; bool:
    """Detect if the given function node is decorated with a property."""
    if not node.decorators:
        return False
    for decorator in node.decorators.nodes:
        try:
            if _is_property_decorator(decorator):
                return True
        except astroid.InferenceError:
            pass
    return False


</t>
<t tx="ekr.20250131013600.330">@utils.only_required_for_messages("contextmanager-generator-missing-cleanup")
def visit_asyncfunctiondef(self, node: nodes.AsyncFunctionDef) -&gt; None:
    self._check_contextmanager_generator_missing_cleanup(node)

</t>
<t tx="ekr.20250131013600.331">def _check_contextmanager_generator_missing_cleanup(
    self, node: nodes.FunctionDef
) -&gt; None:
    """Check a FunctionDef to find if it is a generator
    that uses a contextmanager internally.

    If it is, check if the contextmanager is properly cleaned up. Otherwise, add message.

    :param node: FunctionDef node to check
    :type node: nodes.FunctionDef
    """
    # if function does not use a Yield statement, it can't be a generator
    with_nodes = list(node.nodes_of_class(nodes.With))
    if not with_nodes:
        return
    # check for Yield inside the With statement
    yield_nodes = list(
        chain.from_iterable(
            with_node.nodes_of_class(nodes.Yield) for with_node in with_nodes
        )
    )
    if not yield_nodes:
        return

    # infer the call that yields a value, and check if it is a contextmanager
    for with_node in with_nodes:
        for call, held in with_node.items:
            if held is None:
                # if we discard the value, then we can skip checking it
                continue

            # safe infer is a generator
            inferred_node = getattr(utils.safe_infer(call), "parent", None)
            if not isinstance(inferred_node, nodes.FunctionDef):
                continue
            if self._node_fails_contextmanager_cleanup(inferred_node, yield_nodes):
                self.add_message(
                    "contextmanager-generator-missing-cleanup",
                    node=with_node,
                    args=(node.name,),
                )

</t>
<t tx="ekr.20250131013600.332">@staticmethod
def _node_fails_contextmanager_cleanup(
    node: nodes.FunctionDef, yield_nodes: list[nodes.Yield]
) -&gt; bool:
    """Check if a node fails contextmanager cleanup.

    Current checks for a contextmanager:
        - only if the context manager yields a non-constant value
        - only if the context manager lacks a finally, or does not catch GeneratorExit
        - only if some statement follows the yield, some manually cleanup happens

    :param node: Node to check
    :type node: nodes.FunctionDef
    :return: True if fails, False otherwise
    :param yield_nodes: List of Yield nodes in the function body
    :type yield_nodes: list[nodes.Yield]
    :rtype: bool
    """

    def check_handles_generator_exceptions(try_node: nodes.Try) -&gt; bool:
        # needs to handle either GeneratorExit, Exception, or bare except
        for handler in try_node.handlers:
            if handler.type is None:
                # handles all exceptions (bare except)
                return True
            inferred = utils.safe_infer(handler.type)
            if inferred and inferred.qname() in {
                "builtins.GeneratorExit",
                "builtins.Exception",
            }:
                return True
        return False

    # if context manager yields a non-constant value, then continue checking
    if any(
        yield_node.value is None or isinstance(yield_node.value, nodes.Const)
        for yield_node in yield_nodes
    ):
        return False

    # Check if yield expression is last statement
    yield_nodes = list(node.nodes_of_class(nodes.Yield))
    if len(yield_nodes) == 1:
        n = yield_nodes[0].parent
        while n is not node:
            if n.next_sibling() is not None:
                break
            n = n.parent
        else:
            # No next statement found
            return False

    # if function body has multiple Try, filter down to the ones that have a yield node
    try_with_yield_nodes = [
        try_node
        for try_node in node.nodes_of_class(nodes.Try)
        if any(try_node.nodes_of_class(nodes.Yield))
    ]
    if not try_with_yield_nodes:
        # no try blocks at all, so checks after this line do not apply
        return True
    # if the contextmanager has a finally block, then it is fine
    if all(try_node.finalbody for try_node in try_with_yield_nodes):
        return False
    # if the contextmanager catches GeneratorExit, then it is fine
    if all(
        check_handles_generator_exceptions(try_node)
        for try_node in try_with_yield_nodes
    ):
        return False
    return True
</t>
<t tx="ekr.20250131013600.333">@path pylint/checkers/base
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from astroid import nodes

from pylint.checkers import utils
from pylint.checkers.base.basic_checker import _BasicChecker


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.334">class PassChecker(_BasicChecker):
    """Check if the pass statement is really necessary."""

    @others
</t>
<t tx="ekr.20250131013600.335">msgs = {
    "W0107": (
        "Unnecessary pass statement",
        "unnecessary-pass",
        'Used when a "pass" statement can be removed without affecting '
        "the behaviour of the code.",
    )
}

@utils.only_required_for_messages("unnecessary-pass")
def visit_pass(self, node: nodes.Pass) -&gt; None:
    if len(node.parent.child_sequence(node)) &gt; 1 or (
        isinstance(node.parent, (nodes.ClassDef, nodes.FunctionDef))
        and node.parent.doc_node
    ):
        self.add_message("unnecessary-pass", node=node)
</t>
<t tx="ekr.20250131013600.336"></t>
<t tx="ekr.20250131013600.337">@path pylint/checkers/base/name_checker
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

__all__ = [
    "KNOWN_NAME_TYPES_WITH_STYLE",
    "AnyStyle",
    "CamelCaseStyle",
    "NameChecker",
    "NamingStyle",
    "PascalCaseStyle",
    "SnakeCaseStyle",
    "UpperCaseStyle",
]

from pylint.checkers.base.name_checker.checker import NameChecker
from pylint.checkers.base.name_checker.naming_style import (
    KNOWN_NAME_TYPES_WITH_STYLE,
    AnyStyle,
    CamelCaseStyle,
    NamingStyle,
    PascalCaseStyle,
    SnakeCaseStyle,
    UpperCaseStyle,
)
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.338">@path pylint/checkers/base/name_checker
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Basic checker for Python code."""

from __future__ import annotations

import argparse
import collections
import itertools
import re
import sys
from collections.abc import Iterable
from enum import Enum, auto
from re import Pattern
from typing import TYPE_CHECKING

import astroid
from astroid import nodes

from pylint import constants, interfaces
from pylint.checkers import utils
from pylint.checkers.base.basic_checker import _BasicChecker
from pylint.checkers.base.name_checker.naming_style import (
    KNOWN_NAME_TYPES,
    KNOWN_NAME_TYPES_WITH_STYLE,
    NAMING_STYLES,
    _create_naming_options,
)
from pylint.checkers.utils import is_property_deleter, is_property_setter
from pylint.typing import Options

if TYPE_CHECKING:
    from pylint.lint.pylinter import PyLinter

_BadNamesTuple = tuple[nodes.NodeNG, str, str, interfaces.Confidence]

# Default patterns for name types that do not have styles
DEFAULT_PATTERNS = {
    "typevar": re.compile(
        r"^_{0,2}(?!T[A-Z])(?:[A-Z]+|(?:[A-Z]+[a-z]+)+T?(?&lt;!Type))(?:_co(?:ntra)?)?$"
    ),
    "typealias": re.compile(
        r"^_{0,2}(?!T[A-Z]|Type)[A-Z]+[a-z0-9]+(?:[A-Z][a-z0-9]+)*$"
    ),
}

BUILTIN_PROPERTY = "builtins.property"
TYPE_VAR_QNAME = frozenset(
    (
        "typing.TypeVar",
        "typing_extensions.TypeVar",
    )
)


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.339">class TypeVarVariance(Enum):
    invariant = auto()
    covariant = auto()
    contravariant = auto()
    double_variant = auto()
    inferred = auto()


</t>
<t tx="ekr.20250131013600.34">def _is_property_kind(node: nodes.NodeNG, *kinds: str) -&gt; bool:
    if not isinstance(node, (astroid.UnboundMethod, nodes.FunctionDef)):
        return False
    if node.decorators:
        for decorator in node.decorators.nodes:
            if isinstance(decorator, nodes.Attribute) and decorator.attrname in kinds:
                return True
    return False


</t>
<t tx="ekr.20250131013600.340">def _get_properties(config: argparse.Namespace) -&gt; tuple[set[str], set[str]]:
    """Returns a tuple of property classes and names.

    Property classes are fully qualified, such as 'abc.abstractproperty' and
    property names are the actual names, such as 'abstract_property'.
    """
    property_classes = {BUILTIN_PROPERTY}
    property_names: set[str] = set()  # Not returning 'property', it has its own check.
    if config is not None:
        property_classes.update(config.property_classes)
        property_names.update(
            prop.rsplit(".", 1)[-1] for prop in config.property_classes
        )
    return property_classes, property_names


</t>
<t tx="ekr.20250131013600.341">def _redefines_import(node: nodes.AssignName) -&gt; bool:
    """Detect that the given node (AssignName) is inside an
    exception handler and redefines an import from the tryexcept body.

    Returns True if the node redefines an import, False otherwise.
    """
    current = node
    while current and not isinstance(current.parent, nodes.ExceptHandler):
        current = current.parent
    if not current or not utils.error_of_type(current.parent, ImportError):
        return False
    try_block = current.parent.parent
    for import_node in try_block.nodes_of_class((nodes.ImportFrom, nodes.Import)):
        for name, alias in import_node.names:
            if alias:
                if alias == node.name:
                    return True
            elif name == node.name:
                return True
    return False


</t>
<t tx="ekr.20250131013600.342">def _determine_function_name_type(
    node: nodes.FunctionDef, config: argparse.Namespace
) -&gt; str:
    """Determine the name type whose regex the function's name should match.

    :param node: A function node.
    :param config: Configuration from which to pull additional property classes.

    :returns: One of ('function', 'method', 'attr')
    """
    property_classes, property_names = _get_properties(config)
    if not node.is_method():
        return "function"

    if is_property_setter(node) or is_property_deleter(node):
        # If the function is decorated using the prop_method.{setter,getter}
        # form, treat it like an attribute as well.
        return "attr"

    decorators = node.decorators.nodes if node.decorators else []
    for decorator in decorators:
        # If the function is a property (decorated with @property
        # or @abc.abstractproperty), the name type is 'attr'.
        if isinstance(decorator, nodes.Name) or (
            isinstance(decorator, nodes.Attribute)
            and decorator.attrname in property_names
        ):
            inferred = utils.safe_infer(decorator)
            if (
                inferred
                and hasattr(inferred, "qname")
                and inferred.qname() in property_classes
            ):
                return "attr"
    return "method"


</t>
<t tx="ekr.20250131013600.343"># Name categories that are always consistent with all naming conventions.
EXEMPT_NAME_CATEGORIES = {"exempt", "ignore"}


def _is_multi_naming_match(
    match: re.Match[str] | None, node_type: str, confidence: interfaces.Confidence
) -&gt; bool:
    return (
        match is not None
        and match.lastgroup is not None
        and match.lastgroup not in EXEMPT_NAME_CATEGORIES
        and (node_type != "method" or confidence != interfaces.INFERENCE_FAILURE)
    )


</t>
<t tx="ekr.20250131013600.344">class NameChecker(_BasicChecker):
    @others
</t>
<t tx="ekr.20250131013600.345">msgs = {
    "C0103": (
        '%s name "%s" doesn\'t conform to %s',
        "invalid-name",
        "Used when the name doesn't conform to naming rules "
        "associated to its type (constant, variable, class...).",
    ),
    "C0104": (
        'Disallowed name "%s"',
        "disallowed-name",
        "Used when the name matches bad-names or bad-names-rgxs- (unauthorized names).",
        {
            "old_names": [
                ("C0102", "blacklisted-name"),
            ]
        },
    ),
    "C0105": (
        "Type variable name does not reflect variance%s",
        "typevar-name-incorrect-variance",
        "Emitted when a TypeVar name doesn't reflect its type variance. "
        "According to PEP8, it is recommended to add suffixes '_co' and "
        "'_contra' to the variables used to declare covariant or "
        "contravariant behaviour respectively. Invariant (default) variables "
        "do not require a suffix. The message is also emitted when invariant "
        "variables do have a suffix.",
    ),
    "C0131": (
        "TypeVar cannot be both covariant and contravariant",
        "typevar-double-variance",
        'Emitted when both the "covariant" and "contravariant" '
        'keyword arguments are set to "True" in a TypeVar.',
    ),
    "C0132": (
        'TypeVar name "%s" does not match assigned variable name "%s"',
        "typevar-name-mismatch",
        "Emitted when a TypeVar is assigned to a variable "
        "that does not match its name argument.",
    ),
}

_options: Options = (
    (
        "good-names",
        {
            "default": ("i", "j", "k", "ex", "Run", "_"),
            "type": "csv",
            "metavar": "&lt;names&gt;",
            "help": "Good variable names which should always be accepted,"
            " separated by a comma.",
        },
    ),
    (
        "good-names-rgxs",
        {
            "default": "",
            "type": "regexp_csv",
            "metavar": "&lt;names&gt;",
            "help": "Good variable names regexes, separated by a comma. If names match any regex,"
            " they will always be accepted",
        },
    ),
    (
        "bad-names",
        {
            "default": ("foo", "bar", "baz", "toto", "tutu", "tata"),
            "type": "csv",
            "metavar": "&lt;names&gt;",
            "help": "Bad variable names which should always be refused, "
            "separated by a comma.",
        },
    ),
    (
        "bad-names-rgxs",
        {
            "default": "",
            "type": "regexp_csv",
            "metavar": "&lt;names&gt;",
            "help": "Bad variable names regexes, separated by a comma. If names match any regex,"
            " they will always be refused",
        },
    ),
    (
        "name-group",
        {
            "default": (),
            "type": "csv",
            "metavar": "&lt;name1:name2&gt;",
            "help": (
                "Colon-delimited sets of names that determine each"
                " other's naming style when the name regexes"
                " allow several styles."
            ),
        },
    ),
    (
        "include-naming-hint",
        {
            "default": False,
            "type": "yn",
            "metavar": "&lt;y or n&gt;",
            "help": "Include a hint for the correct naming format with invalid-name.",
        },
    ),
    (
        "property-classes",
        {
            "default": ("abc.abstractproperty",),
            "type": "csv",
            "metavar": "&lt;decorator names&gt;",
            "help": "List of decorators that produce properties, such as "
            "abc.abstractproperty. Add to this list to register "
            "other decorators that produce valid properties. "
            "These decorators are taken in consideration only for invalid-name.",
        },
    ),
)
options: Options = _options + _create_naming_options()

def __init__(self, linter: PyLinter) -&gt; None:
    super().__init__(linter)
    self._name_group: dict[str, str] = {}
    self._bad_names: dict[str, dict[str, list[_BadNamesTuple]]] = {}
    self._name_regexps: dict[str, re.Pattern[str]] = {}
    self._name_hints: dict[str, str] = {}
    self._good_names_rgxs_compiled: list[re.Pattern[str]] = []
    self._bad_names_rgxs_compiled: list[re.Pattern[str]] = []

</t>
<t tx="ekr.20250131013600.346">def open(self) -&gt; None:
    self.linter.stats.reset_bad_names()
    for group in self.linter.config.name_group:
        for name_type in group.split(":"):
            self._name_group[name_type] = f"group_{group}"

    regexps, hints = self._create_naming_rules()
    self._name_regexps = regexps
    self._name_hints = hints
    self._good_names_rgxs_compiled = [
        re.compile(rgxp) for rgxp in self.linter.config.good_names_rgxs
    ]
    self._bad_names_rgxs_compiled = [
        re.compile(rgxp) for rgxp in self.linter.config.bad_names_rgxs
    ]

</t>
<t tx="ekr.20250131013600.347">def _create_naming_rules(self) -&gt; tuple[dict[str, Pattern[str]], dict[str, str]]:
    regexps: dict[str, Pattern[str]] = {}
    hints: dict[str, str] = {}

    for name_type in KNOWN_NAME_TYPES:
        if name_type in KNOWN_NAME_TYPES_WITH_STYLE:
            naming_style_name = getattr(
                self.linter.config, f"{name_type}_naming_style"
            )
            regexps[name_type] = NAMING_STYLES[naming_style_name].get_regex(
                name_type
            )
        else:
            naming_style_name = "predefined"
            regexps[name_type] = DEFAULT_PATTERNS[name_type]

        custom_regex_setting_name = f"{name_type}_rgx"
        custom_regex = getattr(self.linter.config, custom_regex_setting_name, None)
        if custom_regex is not None:
            regexps[name_type] = custom_regex

        if custom_regex is not None:
            hints[name_type] = f"{custom_regex.pattern!r} pattern"
        else:
            hints[name_type] = f"{naming_style_name} naming style"

    return regexps, hints

</t>
<t tx="ekr.20250131013600.348">@utils.only_required_for_messages("disallowed-name", "invalid-name")
def visit_module(self, node: nodes.Module) -&gt; None:
    self._check_name("module", node.name.split(".")[-1], node)
    self._bad_names = {}

</t>
<t tx="ekr.20250131013600.349">def leave_module(self, _: nodes.Module) -&gt; None:
    for all_groups in self._bad_names.values():
        if len(all_groups) &lt; 2:
            continue
        groups: collections.defaultdict[int, list[list[_BadNamesTuple]]] = (
            collections.defaultdict(list)
        )
        min_warnings = sys.maxsize
        prevalent_group, _ = max(all_groups.items(), key=lambda item: len(item[1]))
        for group in all_groups.values():
            groups[len(group)].append(group)
            min_warnings = min(len(group), min_warnings)
        if len(groups[min_warnings]) &gt; 1:
            by_line = sorted(
                groups[min_warnings],
                key=lambda group: min(
                    warning[0].lineno
                    for warning in group
                    if warning[0].lineno is not None
                ),
            )
            warnings: Iterable[_BadNamesTuple] = itertools.chain(*by_line[1:])
        else:
            warnings = groups[min_warnings][0]
        for args in warnings:
            self._raise_name_warning(prevalent_group, *args)

</t>
<t tx="ekr.20250131013600.35">def is_property_setter(node: nodes.NodeNG) -&gt; bool:
    """Check if the given node is a property setter."""
    return _is_property_kind(node, "setter")


</t>
<t tx="ekr.20250131013600.350">@utils.only_required_for_messages("disallowed-name", "invalid-name")
def visit_classdef(self, node: nodes.ClassDef) -&gt; None:
    self._check_name("class", node.name, node)
    for attr, anodes in node.instance_attrs.items():
        if not any(node.instance_attr_ancestors(attr)):
            self._check_name("attr", attr, anodes[0])

</t>
<t tx="ekr.20250131013600.351">@utils.only_required_for_messages("disallowed-name", "invalid-name")
def visit_functiondef(self, node: nodes.FunctionDef) -&gt; None:
    # Do not emit any warnings if the method is just an implementation
    # of a base class method.
    confidence = interfaces.HIGH
    if node.is_method():
        if utils.overrides_a_method(node.parent.frame(), node.name):
            return
        confidence = (
            interfaces.INFERENCE
            if utils.has_known_bases(node.parent.frame())
            else interfaces.INFERENCE_FAILURE
        )

    self._check_name(
        _determine_function_name_type(node, config=self.linter.config),
        node.name,
        node,
        confidence,
    )
    # Check argument names
    args = node.args.args
    if args is not None:
        self._recursive_check_names(args)

</t>
<t tx="ekr.20250131013600.352">visit_asyncfunctiondef = visit_functiondef

@utils.only_required_for_messages(
    "disallowed-name",
    "invalid-name",
    "typevar-name-incorrect-variance",
    "typevar-double-variance",
    "typevar-name-mismatch",
)
def visit_assignname(  # pylint: disable=too-many-branches
    self, node: nodes.AssignName
) -&gt; None:
    """Check module level assigned names."""
    frame = node.frame()
    assign_type = node.assign_type()

    # Check names defined in comprehensions
    if isinstance(assign_type, nodes.Comprehension):
        self._check_name("inlinevar", node.name, node)

    elif isinstance(assign_type, nodes.TypeVar):
        self._check_name("typevar", node.name, node)

    elif isinstance(assign_type, nodes.TypeAlias):
        self._check_name("typealias", node.name, node)

    # Check names defined in module scope
    elif isinstance(frame, nodes.Module):
        # Check names defined in Assign nodes
        if isinstance(assign_type, nodes.Assign):
            inferred_assign_type = utils.safe_infer(assign_type.value)

            # Check TypeVar's and TypeAliases assigned alone or in tuple assignment
            if isinstance(node.parent, nodes.Assign):
                if self._assigns_typevar(assign_type.value):
                    self._check_name("typevar", assign_type.targets[0].name, node)
                    return
                if self._assigns_typealias(assign_type.value):
                    self._check_name("typealias", assign_type.targets[0].name, node)
                    return

            if (
                isinstance(node.parent, nodes.Tuple)
                and isinstance(assign_type.value, nodes.Tuple)
                # protect against unbalanced tuple unpacking
                and node.parent.elts.index(node) &lt; len(assign_type.value.elts)
            ):
                assigner = assign_type.value.elts[node.parent.elts.index(node)]
                if self._assigns_typevar(assigner):
                    self._check_name(
                        "typevar",
                        assign_type.targets[0]
                        .elts[node.parent.elts.index(node)]
                        .name,
                        node,
                    )
                    return
                if self._assigns_typealias(assigner):
                    self._check_name(
                        "typealias",
                        assign_type.targets[0]
                        .elts[node.parent.elts.index(node)]
                        .name,
                        node,
                    )
                    return

            # Check classes (TypeVar's are classes so they need to be excluded first)
            elif isinstance(inferred_assign_type, nodes.ClassDef):
                self._check_name("class", node.name, node)

            # Don't emit if the name redefines an import in an ImportError except handler.
            elif not _redefines_import(node) and isinstance(
                inferred_assign_type, nodes.Const
            ):
                self._check_name("const", node.name, node)
            else:
                self._check_name(
                    "variable", node.name, node, disallowed_check_only=True
                )

        # Check names defined in AnnAssign nodes
        elif isinstance(assign_type, nodes.AnnAssign):
            if utils.is_assign_name_annotated_with(node, "Final"):
                self._check_name("const", node.name, node)
            elif self._assigns_typealias(assign_type.annotation):
                self._check_name("typealias", node.name, node)

    # Check names defined in function scopes
    elif isinstance(frame, nodes.FunctionDef):
        # global introduced variable aren't in the function locals
        if node.name in frame and node.name not in frame.argnames():
            if not _redefines_import(node):
                if isinstance(
                    assign_type, nodes.AnnAssign
                ) and self._assigns_typealias(assign_type.annotation):
                    self._check_name("typealias", node.name, node)
                else:
                    self._check_name("variable", node.name, node)

    # Check names defined in class scopes
    elif isinstance(frame, nodes.ClassDef) and not any(
        frame.local_attr_ancestors(node.name)
    ):
        if utils.is_enum_member(node) or utils.is_assign_name_annotated_with(
            node, "Final"
        ):
            self._check_name("class_const", node.name, node)
        else:
            self._check_name("class_attribute", node.name, node)

</t>
<t tx="ekr.20250131013600.353">def _recursive_check_names(self, args: list[nodes.AssignName]) -&gt; None:
    """Check names in a possibly recursive list &lt;arg&gt;."""
    for arg in args:
        self._check_name("argument", arg.name, arg)

</t>
<t tx="ekr.20250131013600.354">def _find_name_group(self, node_type: str) -&gt; str:
    return self._name_group.get(node_type, node_type)

</t>
<t tx="ekr.20250131013600.355">def _raise_name_warning(
    self,
    prevalent_group: str | None,
    node: nodes.NodeNG,
    node_type: str,
    name: str,
    confidence: interfaces.Confidence,
    warning: str = "invalid-name",
) -&gt; None:
    type_label = constants.HUMAN_READABLE_TYPES[node_type]
    hint = self._name_hints[node_type]
    if prevalent_group:
        # This happens in the multi naming match case. The expected
        # prevalent group needs to be spelled out to make the message
        # correct.
        hint = f"the `{prevalent_group}` group in the {hint}"
    if self.linter.config.include_naming_hint:
        hint += f" ({self._name_regexps[node_type].pattern!r} pattern)"
    args = (
        (type_label.capitalize(), name, hint)
        if warning == "invalid-name"
        else (type_label.capitalize(), name)
    )

    self.add_message(warning, node=node, args=args, confidence=confidence)
    self.linter.stats.increase_bad_name(node_type, 1)

</t>
<t tx="ekr.20250131013600.356">def _name_allowed_by_regex(self, name: str) -&gt; bool:
    return name in self.linter.config.good_names or any(
        pattern.match(name) for pattern in self._good_names_rgxs_compiled
    )

</t>
<t tx="ekr.20250131013600.357">def _name_disallowed_by_regex(self, name: str) -&gt; bool:
    return name in self.linter.config.bad_names or any(
        pattern.match(name) for pattern in self._bad_names_rgxs_compiled
    )

</t>
<t tx="ekr.20250131013600.358">def _check_name(
    self,
    node_type: str,
    name: str,
    node: nodes.NodeNG,
    confidence: interfaces.Confidence = interfaces.HIGH,
    disallowed_check_only: bool = False,
) -&gt; None:
    """Check for a name using the type's regexp."""

    def _should_exempt_from_invalid_name(node: nodes.NodeNG) -&gt; bool:
        if node_type == "variable":
            inferred = utils.safe_infer(node)
            if isinstance(inferred, nodes.ClassDef):
                return True
        return False

    if self._name_allowed_by_regex(name=name):
        return
    if self._name_disallowed_by_regex(name=name):
        self.linter.stats.increase_bad_name(node_type, 1)
        self.add_message(
            "disallowed-name", node=node, args=name, confidence=interfaces.HIGH
        )
        return
    regexp = self._name_regexps[node_type]
    match = regexp.match(name)

    if _is_multi_naming_match(match, node_type, confidence):
        name_group = self._find_name_group(node_type)
        bad_name_group = self._bad_names.setdefault(name_group, {})
        # Ignored because this is checked by the if statement
        warnings = bad_name_group.setdefault(match.lastgroup, [])  # type: ignore[union-attr, arg-type]
        warnings.append((node, node_type, name, confidence))

    if (
        match is None
        and not disallowed_check_only
        and not _should_exempt_from_invalid_name(node)
    ):
        self._raise_name_warning(None, node, node_type, name, confidence)

    # Check TypeVar names for variance suffixes
    if node_type == "typevar":
        self._check_typevar(name, node)

</t>
<t tx="ekr.20250131013600.359">@staticmethod
def _assigns_typevar(node: nodes.NodeNG | None) -&gt; bool:
    """Check if a node is assigning a TypeVar."""
    if isinstance(node, astroid.Call):
        inferred = utils.safe_infer(node.func)
        if (
            isinstance(inferred, astroid.ClassDef)
            and inferred.qname() in TYPE_VAR_QNAME
        ):
            return True
    return False

</t>
<t tx="ekr.20250131013600.36">def is_property_deleter(node: nodes.NodeNG) -&gt; bool:
    """Check if the given node is a property deleter."""
    return _is_property_kind(node, "deleter")


</t>
<t tx="ekr.20250131013600.360">@staticmethod
def _assigns_typealias(node: nodes.NodeNG | None) -&gt; bool:
    """Check if a node is assigning a TypeAlias."""
    inferred = utils.safe_infer(node)
    if isinstance(inferred, nodes.ClassDef):
        qname = inferred.qname()
        if qname == "typing.TypeAlias":
            return True
        if qname == ".Union":
            # Union is a special case because it can be used as a type alias
            # or as a type annotation. We only want to check the former.
            assert node is not None
            return not isinstance(node.parent, nodes.AnnAssign)
    elif isinstance(inferred, nodes.FunctionDef):
        # TODO: when py3.12 is minimum, remove this condition
        # TypeAlias became a class in python 3.12
        if inferred.qname() == "typing.TypeAlias":
            return True
    return False

</t>
<t tx="ekr.20250131013600.361">def _check_typevar(self, name: str, node: nodes.AssignName) -&gt; None:
    """Check for TypeVar lint violations."""
    variance: TypeVarVariance = TypeVarVariance.invariant
    if isinstance(node.parent, nodes.Assign):
        keywords = node.assign_type().value.keywords
        args = node.assign_type().value.args
    elif isinstance(node.parent, nodes.Tuple):
        keywords = (
            node.assign_type().value.elts[node.parent.elts.index(node)].keywords
        )
        args = node.assign_type().value.elts[node.parent.elts.index(node)].args
    else:  # PEP 695 generic type nodes
        keywords = ()
        args = ()
        variance = TypeVarVariance.inferred

    name_arg = None
    for kw in keywords:
        if variance == TypeVarVariance.double_variant:
            pass
        elif kw.arg == "covariant" and kw.value.value:
            variance = (
                TypeVarVariance.covariant
                if variance != TypeVarVariance.contravariant
                else TypeVarVariance.double_variant
            )
        elif kw.arg == "contravariant" and kw.value.value:
            variance = (
                TypeVarVariance.contravariant
                if variance != TypeVarVariance.covariant
                else TypeVarVariance.double_variant
            )

        if kw.arg == "name" and isinstance(kw.value, nodes.Const):
            name_arg = kw.value.value

    if name_arg is None and args and isinstance(args[0], nodes.Const):
        name_arg = args[0].value

    if variance == TypeVarVariance.inferred:
        # Ignore variance check for PEP 695 type parameters.
        # The variance is inferred by the type checker.
        # Adding _co or _contra suffix can help to reason about TypeVar.
        pass
    elif variance == TypeVarVariance.double_variant:
        self.add_message(
            "typevar-double-variance",
            node=node,
            confidence=interfaces.INFERENCE,
        )
        self.add_message(
            "typevar-name-incorrect-variance",
            node=node,
            args=("",),
            confidence=interfaces.INFERENCE,
        )
    elif variance == TypeVarVariance.covariant and not name.endswith("_co"):
        suggest_name = f"{re.sub('_contra$', '', name)}_co"
        self.add_message(
            "typevar-name-incorrect-variance",
            node=node,
            args=(f'. "{name}" is covariant, use "{suggest_name}" instead'),
            confidence=interfaces.INFERENCE,
        )
    elif variance == TypeVarVariance.contravariant and not name.endswith("_contra"):
        suggest_name = f"{re.sub('_co$', '', name)}_contra"
        self.add_message(
            "typevar-name-incorrect-variance",
            node=node,
            args=(f'. "{name}" is contravariant, use "{suggest_name}" instead'),
            confidence=interfaces.INFERENCE,
        )
    elif variance == TypeVarVariance.invariant and (
        name.endswith(("_co", "_contra"))
    ):
        suggest_name = re.sub("_contra$|_co$", "", name)
        self.add_message(
            "typevar-name-incorrect-variance",
            node=node,
            args=(f'. "{name}" is invariant, use "{suggest_name}" instead'),
            confidence=interfaces.INFERENCE,
        )

    if name_arg is not None and name_arg != name:
        self.add_message(
            "typevar-name-mismatch",
            node=node,
            args=(name_arg, name),
            confidence=interfaces.INFERENCE,
        )
</t>
<t tx="ekr.20250131013600.362">@path pylint/checkers/base/name_checker
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import re
from re import Pattern

from pylint import constants
from pylint.typing import OptionDict, Options


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.363">class NamingStyle:
    """Class to register all accepted forms of a single naming style.

    It may seem counter-intuitive that single naming style has multiple "accepted"
    forms of regular expressions, but we need to special-case stuff like dunder
    names in method names.
    """

    @others
</t>
<t tx="ekr.20250131013600.364">class SnakeCaseStyle(NamingStyle):
    """Regex rules for snake_case naming style."""

    CLASS_NAME_RGX = re.compile(r"[^\W\dA-Z][^\WA-Z]*$")
    MOD_NAME_RGX = re.compile(r"[^\W\dA-Z][^\WA-Z]*$")
    CONST_NAME_RGX = re.compile(r"([^\W\dA-Z][^\WA-Z]*|__.*__)$")
    COMP_VAR_RGX = CLASS_NAME_RGX
    DEFAULT_NAME_RGX = re.compile(
        r"([^\W\dA-Z][^\WA-Z]*|_[^\WA-Z]*|__[^\WA-Z\d_][^\WA-Z]+__)$"
    )
    CLASS_ATTRIBUTE_RGX = re.compile(r"([^\W\dA-Z][^\WA-Z]*|__.*__)$")


</t>
<t tx="ekr.20250131013600.365">class CamelCaseStyle(NamingStyle):
    """Regex rules for camelCase naming style."""

    CLASS_NAME_RGX = re.compile(r"[^\W\dA-Z][^\W_]*$")
    MOD_NAME_RGX = re.compile(r"[^\W\dA-Z][^\W_]*$")
    CONST_NAME_RGX = re.compile(r"([^\W\dA-Z][^\W_]*|__.*__)$")
    COMP_VAR_RGX = MOD_NAME_RGX
    DEFAULT_NAME_RGX = re.compile(r"([^\W\dA-Z][^\W_]*|__[^\W\dA-Z_]\w+__)$")
    CLASS_ATTRIBUTE_RGX = re.compile(r"([^\W\dA-Z][^\W_]*|__.*__)$")


</t>
<t tx="ekr.20250131013600.366">class PascalCaseStyle(NamingStyle):
    """Regex rules for PascalCase naming style."""

    CLASS_NAME_RGX = re.compile(r"[^\W\da-z][^\W_]*$")
    MOD_NAME_RGX = CLASS_NAME_RGX
    CONST_NAME_RGX = re.compile(r"([^\W\da-z][^\W_]*|__.*__)$")
    COMP_VAR_RGX = CLASS_NAME_RGX
    DEFAULT_NAME_RGX = re.compile(r"([^\W\da-z][^\W_]*|__[^\W\dA-Z_]\w+__)$")
    CLASS_ATTRIBUTE_RGX = re.compile(r"[^\W\da-z][^\W_]*$")


</t>
<t tx="ekr.20250131013600.367">class UpperCaseStyle(NamingStyle):
    """Regex rules for UPPER_CASE naming style."""

    CLASS_NAME_RGX = re.compile(r"[^\W\da-z][^\Wa-z]*$")
    MOD_NAME_RGX = CLASS_NAME_RGX
    CONST_NAME_RGX = re.compile(r"([^\W\da-z][^\Wa-z]*|__.*__)$")
    COMP_VAR_RGX = CLASS_NAME_RGX
    DEFAULT_NAME_RGX = re.compile(r"([^\W\da-z][^\Wa-z]*|__[^\W\dA-Z_]\w+__)$")
    CLASS_ATTRIBUTE_RGX = re.compile(r"[^\W\da-z][^\Wa-z]*$")


</t>
<t tx="ekr.20250131013600.368">class AnyStyle(NamingStyle):
    pass


</t>
<t tx="ekr.20250131013600.369">NAMING_STYLES = {
    "snake_case": SnakeCaseStyle,
    "camelCase": CamelCaseStyle,
    "PascalCase": PascalCaseStyle,
    "UPPER_CASE": UpperCaseStyle,
    "any": AnyStyle,
}

# Name types that have a style option
KNOWN_NAME_TYPES_WITH_STYLE = {
    "module",
    "const",
    "class",
    "function",
    "method",
    "attr",
    "argument",
    "variable",
    "class_attribute",
    "class_const",
    "inlinevar",
}


DEFAULT_NAMING_STYLES = {
    "module": "snake_case",
    "const": "UPPER_CASE",
    "class": "PascalCase",
    "function": "snake_case",
    "method": "snake_case",
    "attr": "snake_case",
    "argument": "snake_case",
    "variable": "snake_case",
    "class_attribute": "any",
    "class_const": "UPPER_CASE",
    "inlinevar": "any",
}


# Name types that have a 'rgx' option
KNOWN_NAME_TYPES = {
    * KNOWN_NAME_TYPES_WITH_STYLE,
    "typevar",
    "typealias",
}


def _create_naming_options() -&gt; Options:
    name_options: list[tuple[str, OptionDict]] = []
    for name_type in sorted(KNOWN_NAME_TYPES):
        human_readable_name = constants.HUMAN_READABLE_TYPES[name_type]
        name_type_hyphened = name_type.replace("_", "-")

        help_msg = f"Regular expression matching correct {human_readable_name} names. "
        if name_type in KNOWN_NAME_TYPES_WITH_STYLE:
            help_msg += f"Overrides {name_type_hyphened}-naming-style. "
        help_msg += (
            f"If left empty, {human_readable_name} names will be checked "
            "with the set naming style."
        )

        # Add style option for names that support it
        if name_type in KNOWN_NAME_TYPES_WITH_STYLE:
            default_style = DEFAULT_NAMING_STYLES[name_type]
            name_options.append(
                (
                    f"{name_type_hyphened}-naming-style",
                    {
                        "default": default_style,
                        "type": "choice",
                        "choices": list(NAMING_STYLES.keys()),
                        "metavar": "&lt;style&gt;",
                        "help": f"Naming style matching correct {human_readable_name} names.",
                    },
                )
            )

        name_options.append(
            (
                f"{name_type_hyphened}-rgx",
                {
                    "default": None,
                    "type": "regexp",
                    "metavar": "&lt;regexp&gt;",
                    "help": help_msg,
                },
            )
        )
    return tuple(name_options)
</t>
<t tx="ekr.20250131013600.37">def is_property_setter_or_deleter(node: nodes.NodeNG) -&gt; bool:
    """Check if the given node is either a property setter or a deleter."""
    return _is_property_kind(node, "setter", "deleter")


</t>
<t tx="ekr.20250131013600.370">ANY: Pattern[str] = re.compile(".*")
CLASS_NAME_RGX: Pattern[str] = ANY
MOD_NAME_RGX: Pattern[str] = ANY
CONST_NAME_RGX: Pattern[str] = ANY
COMP_VAR_RGX: Pattern[str] = ANY
DEFAULT_NAME_RGX: Pattern[str] = ANY
CLASS_ATTRIBUTE_RGX: Pattern[str] = ANY

@classmethod
def get_regex(cls, name_type: str) -&gt; Pattern[str]:
    return {
        "module": cls.MOD_NAME_RGX,
        "const": cls.CONST_NAME_RGX,
        "class": cls.CLASS_NAME_RGX,
        "function": cls.DEFAULT_NAME_RGX,
        "method": cls.DEFAULT_NAME_RGX,
        "attr": cls.DEFAULT_NAME_RGX,
        "argument": cls.DEFAULT_NAME_RGX,
        "variable": cls.DEFAULT_NAME_RGX,
        "class_attribute": cls.CLASS_ATTRIBUTE_RGX,
        "class_const": cls.CONST_NAME_RGX,
        "inlinevar": cls.COMP_VAR_RGX,
    }[name_type]


</t>
<t tx="ekr.20250131013600.371"></t>
<t tx="ekr.20250131013600.372">@path pylint/checkers/classes
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

from typing import TYPE_CHECKING

from pylint.checkers.classes.class_checker import ClassChecker
from pylint.checkers.classes.special_methods_checker import SpecialMethodsChecker

if TYPE_CHECKING:
    from pylint.lint import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.373">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(ClassChecker(linter))
    linter.register_checker(SpecialMethodsChecker(linter))
</t>
<t tx="ekr.20250131013600.374">@path pylint/checkers/classes
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Classes checker for Python code."""

from __future__ import annotations

from collections import defaultdict
from collections.abc import Callable, Sequence
from functools import cached_property
from itertools import chain, zip_longest
from re import Pattern
from typing import TYPE_CHECKING, Any, NamedTuple, Union

import astroid
from astroid import bases, nodes, util
from astroid.nodes import LocalsDictNodeNG
from astroid.typing import SuccessfulInferenceResult

from pylint.checkers import BaseChecker, utils
from pylint.checkers.utils import (
    PYMETHODS,
    class_is_abstract,
    decorated_with,
    decorated_with_property,
    get_outer_class,
    has_known_bases,
    is_attr_private,
    is_attr_protected,
    is_builtin_object,
    is_comprehension,
    is_iterable,
    is_property_setter,
    is_property_setter_or_deleter,
    node_frame_class,
    only_required_for_messages,
    safe_infer,
    unimplemented_abstract_methods,
    uninferable_final_decorators,
)
from pylint.interfaces import HIGH, INFERENCE
from pylint.typing import MessageDefinitionTuple

if TYPE_CHECKING:
    from pylint.lint.pylinter import PyLinter


_AccessNodes = Union[nodes.Attribute, nodes.AssignAttr]

INVALID_BASE_CLASSES = {"bool", "range", "slice", "memoryview"}
ALLOWED_PROPERTIES = {"bultins.property", "functools.cached_property"}
BUILTIN_DECORATORS = {"builtins.property", "builtins.classmethod"}
ASTROID_TYPE_COMPARATORS = {
    nodes.Const: lambda a, b: a.value == b.value,
    nodes.ClassDef: lambda a, b: a.qname == b.qname,
    nodes.Tuple: lambda a, b: a.elts == b.elts,
    nodes.List: lambda a, b: a.elts == b.elts,
    nodes.Dict: lambda a, b: a.items == b.items,
    nodes.Name: lambda a, b: set(a.infer()) == set(b.infer()),
}

# Dealing with useless override detection, with regard
# to parameters vs arguments


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.375">class _CallSignature(NamedTuple):
    args: list[str | None]
    kws: dict[str | None, str | None]
    starred_args: list[str]
    starred_kws: list[str]


</t>
<t tx="ekr.20250131013600.376">class _ParameterSignature(NamedTuple):
    args: list[str]
    kwonlyargs: list[str]
    varargs: str
    kwargs: str


</t>
<t tx="ekr.20250131013600.377">def _signature_from_call(call: nodes.Call) -&gt; _CallSignature:
    kws = {}
    args = []
    starred_kws = []
    starred_args = []
    for keyword in call.keywords or []:
        arg, value = keyword.arg, keyword.value
        if arg is None and isinstance(value, nodes.Name):
            # Starred node, and we are interested only in names,
            # otherwise some transformation might occur for the parameter.
            starred_kws.append(value.name)
        elif isinstance(value, nodes.Name):
            kws[arg] = value.name
        else:
            kws[arg] = None

    for arg in call.args:
        if isinstance(arg, nodes.Starred) and isinstance(arg.value, nodes.Name):
            # Positional variadic and a name, otherwise some transformation
            # might have occurred.
            starred_args.append(arg.value.name)
        elif isinstance(arg, nodes.Name):
            args.append(arg.name)
        else:
            args.append(None)

    return _CallSignature(args, kws, starred_args, starred_kws)


</t>
<t tx="ekr.20250131013600.378">def _signature_from_arguments(arguments: nodes.Arguments) -&gt; _ParameterSignature:
    kwarg = arguments.kwarg
    vararg = arguments.vararg
    args = [
        arg.name
        for arg in chain(arguments.posonlyargs, arguments.args)
        if arg.name != "self"
    ]
    kwonlyargs = [arg.name for arg in arguments.kwonlyargs]
    return _ParameterSignature(args, kwonlyargs, vararg, kwarg)


</t>
<t tx="ekr.20250131013600.379">def _definition_equivalent_to_call(
    definition: _ParameterSignature, call: _CallSignature
) -&gt; bool:
    """Check if a definition signature is equivalent to a call."""
    if definition.kwargs:
        if definition.kwargs not in call.starred_kws:
            return False
    elif call.starred_kws:
        return False
    if definition.varargs:
        if definition.varargs not in call.starred_args:
            return False
    elif call.starred_args:
        return False
    if any(kw not in call.kws for kw in definition.kwonlyargs):
        return False
    if definition.args != call.args:
        return False

    # No extra kwargs in call.
    return all(kw in call.args or kw in definition.kwonlyargs for kw in call.kws)


</t>
<t tx="ekr.20250131013600.38">def _is_property_decorator(decorator: nodes.Name) -&gt; bool:
    for inferred in decorator.infer():
        if isinstance(inferred, nodes.ClassDef):
            if inferred.qname() in {"builtins.property", "functools.cached_property"}:
                return True
            for ancestor in inferred.ancestors():
                if ancestor.name == "property" and ancestor.root().name == "builtins":
                    return True
        elif isinstance(inferred, nodes.FunctionDef):
            # If decorator is function, check if it has exactly one return
            # and the return is itself a function decorated with property
            returns: list[nodes.Return] = list(
                inferred._get_return_nodes_skip_functions()
            )
            if len(returns) == 1 and isinstance(
                returns[0].value, (nodes.Name, nodes.Attribute)
            ):
                inferred = safe_infer(returns[0].value)
                if (
                    inferred
                    and isinstance(inferred, astroid.objects.Property)
                    and isinstance(inferred.function, nodes.FunctionDef)
                ):
                    return decorated_with_property(inferred.function)
    return False


</t>
<t tx="ekr.20250131013600.380">def _is_trivial_super_delegation(function: nodes.FunctionDef) -&gt; bool:
    """Check whether a function definition is a method consisting only of a
    call to the same function on the superclass.
    """
    if (
        not function.is_method()
        # Adding decorators to a function changes behavior and
        # constitutes a non-trivial change.
        or function.decorators
    ):
        return False

    body = function.body
    if len(body) != 1:
        # Multiple statements, which means this overridden method
        # could do multiple things we are not aware of.
        return False

    statement = body[0]
    if not isinstance(statement, (nodes.Expr, nodes.Return)):
        # Doing something else than what we are interested in.
        return False

    call = statement.value
    if (
        not isinstance(call, nodes.Call)
        # Not a super() attribute access.
        or not isinstance(call.func, nodes.Attribute)
    ):
        return False

    # Anything other than a super call is non-trivial.
    super_call = safe_infer(call.func.expr)
    if not isinstance(super_call, astroid.objects.Super):
        return False

    # The name should be the same.
    if call.func.attrname != function.name:
        return False

    # Should be a super call with the MRO pointer being the
    # current class and the type being the current instance.
    current_scope = function.parent.scope()
    if (
        super_call.mro_pointer != current_scope
        or not isinstance(super_call.type, astroid.Instance)
        or super_call.type.name != current_scope.name
    ):
        return False

    return True


</t>
<t tx="ekr.20250131013600.381"># Deal with parameters overriding in two methods.


def _positional_parameters(method: nodes.FunctionDef) -&gt; list[nodes.AssignName]:
    positional = method.args.args
    if method.is_bound() and method.type in {"classmethod", "method"}:
        positional = positional[1:]
    return positional  # type: ignore[no-any-return]


</t>
<t tx="ekr.20250131013600.382">class _DefaultMissing:
    """Sentinel value for missing arg default, use _DEFAULT_MISSING."""


</t>
<t tx="ekr.20250131013600.383">_DEFAULT_MISSING = _DefaultMissing()


def _has_different_parameters_default_value(
    original: nodes.Arguments, overridden: nodes.Arguments
) -&gt; bool:
    """Check if original and overridden methods arguments have different default values.

    Return True if one of the overridden arguments has a default
    value different from the default value of the original argument
    If one of the method doesn't have argument (.args is None)
    return False
    """
    if original.args is None or overridden.args is None:
        return False

    for param in chain(original.args, original.kwonlyargs):
        try:
            original_default = original.default_value(param.name)
        except astroid.exceptions.NoDefault:
            original_default = _DEFAULT_MISSING
        try:
            overridden_default = overridden.default_value(param.name)
            if original_default is _DEFAULT_MISSING:
                # Only the original has a default.
                return True
        except astroid.exceptions.NoDefault:
            if original_default is _DEFAULT_MISSING:
                # Both have a default, no difference
                continue
            # Only the override has a default.
            return True

        original_type = type(original_default)
        if not isinstance(overridden_default, original_type):
            # Two args with same name but different types
            return True
        is_same_fn: Callable[[Any, Any], bool] | None = ASTROID_TYPE_COMPARATORS.get(
            original_type
        )
        if is_same_fn is None:
            # If the default value comparison is unhandled, assume the value is different
            return True
        if not is_same_fn(original_default, overridden_default):
            # Two args with same type but different values
            return True
    return False


</t>
<t tx="ekr.20250131013600.384">def _has_different_parameters(
    original: list[nodes.AssignName],
    overridden: list[nodes.AssignName],
    dummy_parameter_regex: Pattern[str],
) -&gt; list[str]:
    result: list[str] = []
    zipped = zip_longest(original, overridden)
    for original_param, overridden_param in zipped:
        if not overridden_param:
            return ["Number of parameters "]

        if not original_param:
            try:
                overridden_param.parent.default_value(overridden_param.name)
                continue
            except astroid.NoDefault:
                return ["Number of parameters "]

        # check for the arguments' name
        names = [param.name for param in (original_param, overridden_param)]
        if any(dummy_parameter_regex.match(name) for name in names):
            continue
        if original_param.name != overridden_param.name:
            result.append(
                f"Parameter '{original_param.name}' has been renamed "
                f"to '{overridden_param.name}' in"
            )

    return result


</t>
<t tx="ekr.20250131013600.385">def _has_different_keyword_only_parameters(
    original: list[nodes.AssignName],
    overridden: list[nodes.AssignName],
) -&gt; list[str]:
    """Determine if the two methods have different keyword only parameters."""
    original_names = [i.name for i in original]
    overridden_names = [i.name for i in overridden]

    if any(name not in overridden_names for name in original_names):
        return ["Number of parameters "]

    for name in overridden_names:
        if name in original_names:
            continue

        try:
            overridden[0].parent.default_value(name)
        except astroid.NoDefault:
            return ["Number of parameters "]

    return []


</t>
<t tx="ekr.20250131013600.386">def _different_parameters(
    original: nodes.FunctionDef,
    overridden: nodes.FunctionDef,
    dummy_parameter_regex: Pattern[str],
) -&gt; list[str]:
    """Determine if the two methods have different parameters.

    They are considered to have different parameters if:

       * they have different positional parameters, including different names

       * one of the methods is having variadics, while the other is not

       * they have different keyword only parameters.
    """
    output_messages = []
    original_parameters = _positional_parameters(original)
    overridden_parameters = _positional_parameters(overridden)

    # Copy kwonlyargs list so that we don't affect later function linting
    original_kwonlyargs = original.args.kwonlyargs

    # Allow positional/keyword variadic in overridden to match against any
    # positional/keyword argument in original.
    # Keep any arguments that are found separately in overridden to satisfy
    # later tests
    if overridden.args.vararg:
        overridden_names = [v.name for v in overridden_parameters]
        original_parameters = [
            v for v in original_parameters if v.name in overridden_names
        ]

    if overridden.args.kwarg:
        overridden_names = [v.name for v in overridden.args.kwonlyargs]
        original_kwonlyargs = [
            v for v in original.args.kwonlyargs if v.name in overridden_names
        ]

    different_positional = _has_different_parameters(
        original_parameters, overridden_parameters, dummy_parameter_regex
    )
    different_kwonly = _has_different_keyword_only_parameters(
        original_kwonlyargs, overridden.args.kwonlyargs
    )
    if different_kwonly and different_positional:
        if "Number " in different_positional[0] and "Number " in different_kwonly[0]:
            output_messages.append("Number of parameters ")
            output_messages += different_positional[1:]
            output_messages += different_kwonly[1:]
        else:
            output_messages += different_positional
            output_messages += different_kwonly
    else:
        if different_positional:
            output_messages += different_positional
        if different_kwonly:
            output_messages += different_kwonly

    # Arguments will only violate LSP if there are variadics in the original
    # that are then removed from the overridden
    kwarg_lost = original.args.kwarg and not overridden.args.kwarg
    vararg_lost = original.args.vararg and not overridden.args.vararg

    if kwarg_lost or vararg_lost:
        output_messages += ["Variadics removed in"]

    if original.name in PYMETHODS:
        # Ignore the difference for special methods. If the parameter
        # numbers are different, then that is going to be caught by
        # unexpected-special-method-signature.
        # If the names are different, it doesn't matter, since they can't
        # be used as keyword arguments anyway.
        output_messages.clear()

    return output_messages


</t>
<t tx="ekr.20250131013600.387">def _is_invalid_base_class(cls: nodes.ClassDef) -&gt; bool:
    return cls.name in INVALID_BASE_CLASSES and is_builtin_object(cls)


</t>
<t tx="ekr.20250131013600.388">def _has_data_descriptor(cls: nodes.ClassDef, attr: str) -&gt; bool:
    attributes = cls.getattr(attr)
    for attribute in attributes:
        try:
            for inferred in attribute.infer():
                if isinstance(inferred, astroid.Instance):
                    try:
                        inferred.getattr("__get__")
                        inferred.getattr("__set__")
                    except astroid.NotFoundError:
                        continue
                    else:
                        return True
        except astroid.InferenceError:
            # Can't infer, avoid emitting a false positive in this case.
            return True
    return False


</t>
<t tx="ekr.20250131013600.389">def _called_in_methods(
    func: LocalsDictNodeNG,
    klass: nodes.ClassDef,
    methods: Sequence[str],
) -&gt; bool:
    """Check if the func was called in any of the given methods,
    belonging to the *klass*.

    Returns True if so, False otherwise.
    """
    if not isinstance(func, nodes.FunctionDef):
        return False
    for method in methods:
        try:
            inferred = klass.getattr(method)
        except astroid.NotFoundError:
            continue
        for infer_method in inferred:
            for call in infer_method.nodes_of_class(nodes.Call):
                try:
                    bound = next(call.func.infer())
                except(astroid.InferenceError, StopIteration):
                    continue
                if not isinstance(bound, astroid.BoundMethod):
                    continue
                func_obj = bound._proxied
                if isinstance(func_obj, astroid.UnboundMethod):
                    func_obj = func_obj._proxied
                if func_obj.name == func.name:
                    return True
    return False


</t>
<t tx="ekr.20250131013600.39">def decorated_with(
    func: (
        nodes.ClassDef | nodes.FunctionDef | astroid.BoundMethod | astroid.UnboundMethod
    ),
    qnames: Iterable[str],
</t>
<t tx="ekr.20250131013600.390">def _is_attribute_property(name: str, klass: nodes.ClassDef) -&gt; bool:
    """Check if the given attribute *name* is a property in the given *klass*.

    It will look for `property` calls or for functions
    with the given name, decorated by `property` or `property`
    subclasses.
    Returns ``True`` if the name is a property in the given klass,
    ``False`` otherwise.
    """
    try:
        attributes = klass.getattr(name)
    except astroid.NotFoundError:
        return False
    property_name = "builtins.property"
    for attr in attributes:
        if isinstance(attr, util.UninferableBase):
            continue
        try:
            inferred = next(attr.infer())
        except astroid.InferenceError:
            continue
        if isinstance(inferred, nodes.FunctionDef) and decorated_with_property(
            inferred
        ):
            return True
        if inferred.pytype() == property_name:
            return True
    return False


</t>
<t tx="ekr.20250131013600.391">def _has_same_layout_slots(
    slots: list[nodes.Const | None], assigned_value: nodes.Name
) -&gt; bool:
    inferred = next(assigned_value.infer())
    if isinstance(inferred, nodes.ClassDef):
        other_slots = inferred.slots()
        if all(
            first_slot and second_slot and first_slot.value == second_slot.value
            for (first_slot, second_slot) in zip_longest(slots, other_slots)
        ):
            return True
    return False


</t>
<t tx="ekr.20250131013600.392">MSGS: dict[str, MessageDefinitionTuple] = {
    "F0202": (
        "Unable to check methods signature (%s / %s)",
        "method-check-failed",
        "Used when Pylint has been unable to check methods signature "
        "compatibility for an unexpected reason. Please report this kind "
        "if you don't make sense of it.",
    ),
    "E0202": (
        "An attribute defined in %s line %s hides this method",
        "method-hidden",
        "Used when a class defines a method which is hidden by an "
        "instance attribute from an ancestor class or set by some "
        "client code.",
    ),
    "E0203": (
        "Access to member %r before its definition line %s",
        "access-member-before-definition",
        "Used when an instance member is accessed before it's actually assigned.",
    ),
    "W0201": (
        "Attribute %r defined outside __init__",
        "attribute-defined-outside-init",
        "Used when an instance attribute is defined outside the __init__ method.",
    ),
    "W0212": (
        "Access to a protected member %s of a client class",  # E0214
        "protected-access",
        "Used when a protected member (i.e. class member with a name "
        "beginning with an underscore) is accessed outside the class or a "
        "descendant of the class where it's defined.",
    ),
    "W0213": (
        "Flag member %(overlap)s shares bit positions with %(sources)s",
        "implicit-flag-alias",
        "Used when multiple integer values declared within an enum.IntFlag "
        "class share a common bit position.",
    ),
    "E0211": (
        "Method %r has no argument",
        "no-method-argument",
        "Used when a method which should have the bound instance as "
        "first argument has no argument defined.",
    ),
    "E0213": (
        'Method %r should have "self" as first argument',
        "no-self-argument",
        'Used when a method has an attribute different the "self" as '
        "first argument. This is considered as an error since this is "
        "a so common convention that you shouldn't break it!",
    ),
    "C0202": (
        "Class method %s should have %s as first argument",
        "bad-classmethod-argument",
        "Used when a class method has a first argument named differently "
        "than the value specified in valid-classmethod-first-arg option "
        '(default to "cls"), recommended to easily differentiate them '
        "from regular instance methods.",
    ),
    "C0203": (
        "Metaclass method %s should have %s as first argument",
        "bad-mcs-method-argument",
        "Used when a metaclass method has a first argument named "
        "differently than the value specified in valid-classmethod-first"
        '-arg option (default to "cls"), recommended to easily '
        "differentiate them from regular instance methods.",
    ),
    "C0204": (
        "Metaclass class method %s should have %s as first argument",
        "bad-mcs-classmethod-argument",
        "Used when a metaclass class method has a first argument named "
        "differently than the value specified in valid-metaclass-"
        'classmethod-first-arg option (default to "mcs"), recommended to '
        "easily differentiate them from regular instance methods.",
    ),
    "W0211": (
        "Static method with %r as first argument",
        "bad-staticmethod-argument",
        'Used when a static method has "self" or a value specified in '
        "valid-classmethod-first-arg option or "
        "valid-metaclass-classmethod-first-arg option as first argument.",
    ),
    "W0221": (
        "%s %s %r method",
        "arguments-differ",
        "Used when a method has a different number of arguments than in "
        "the implemented interface or in an overridden method. Extra arguments "
        "with default values are ignored.",
    ),
    "W0222": (
        "Signature differs from %s %r method",
        "signature-differs",
        "Used when a method signature is different than in the "
        "implemented interface or in an overridden method.",
    ),
    "W0223": (
        "Method %r is abstract in class %r but is not overridden in child class %r",
        "abstract-method",
        "Used when an abstract method (i.e. raise NotImplementedError) is "
        "not overridden in concrete class.",
    ),
    "W0231": (
        "__init__ method from base class %r is not called",
        "super-init-not-called",
        "Used when an ancestor class method has an __init__ method "
        "which is not called by a derived class.",
    ),
    "W0233": (
        "__init__ method from a non direct base class %r is called",
        "non-parent-init-called",
        "Used when an __init__ method is called on a class which is not "
        "in the direct ancestors for the analysed class.",
    ),
    "W0246": (
        "Useless parent or super() delegation in method %r",
        "useless-parent-delegation",
        "Used whenever we can detect that an overridden method is useless, "
        "relying on parent or super() delegation to do the same thing as another method "
        "from the MRO.",
        {"old_names": [("W0235", "useless-super-delegation")]},
    ),
    "W0236": (
        "Method %r was expected to be %r, found it instead as %r",
        "invalid-overridden-method",
        "Used when we detect that a method was overridden in a way "
        "that does not match its base class "
        "which could result in potential bugs at runtime.",
    ),
    "W0237": (
        "%s %s %r method",
        "arguments-renamed",
        "Used when a method parameter has a different name than in "
        "the implemented interface or in an overridden method.",
    ),
    "W0238": (
        "Unused private member `%s.%s`",
        "unused-private-member",
        "Emitted when a private member of a class is defined but not used.",
    ),
    "W0239": (
        "Method %r overrides a method decorated with typing.final which is defined in class %r",
        "overridden-final-method",
        "Used when a method decorated with typing.final has been overridden.",
    ),
    "W0240": (
        "Class %r is a subclass of a class decorated with typing.final: %r",
        "subclassed-final-class",
        "Used when a class decorated with typing.final has been subclassed.",
    ),
    "W0244": (
        "Redefined slots %r in subclass",
        "redefined-slots-in-subclass",
        "Used when a slot is re-defined in a subclass.",
    ),
    "W0245": (
        "Super call without brackets",
        "super-without-brackets",
        "Used when a call to super does not have brackets and thus is not an actual "
        "call and does not work as expected.",
    ),
    "E0236": (
        "Invalid object %r in __slots__, must contain only non empty strings",
        "invalid-slots-object",
        "Used when an invalid (non-string) object occurs in __slots__.",
    ),
    "E0237": (
        "Assigning to attribute %r not defined in class slots",
        "assigning-non-slot",
        "Used when assigning to an attribute not defined in the class slots.",
    ),
    "E0238": (
        "Invalid __slots__ object",
        "invalid-slots",
        "Used when an invalid __slots__ is found in class. "
        "Only a string, an iterable or a sequence is permitted.",
    ),
    "E0239": (
        "Inheriting %r, which is not a class.",
        "inherit-non-class",
        "Used when a class inherits from something which is not a class.",
    ),
    "E0240": (
        "Inconsistent method resolution order for class %r",
        "inconsistent-mro",
        "Used when a class has an inconsistent method resolution order.",
    ),
    "E0241": (
        "Duplicate bases for class %r",
        "duplicate-bases",
        "Duplicate use of base classes in derived classes raise TypeErrors.",
    ),
    "E0242": (
        "Value %r in slots conflicts with class variable",
        "class-variable-slots-conflict",
        "Used when a value in __slots__ conflicts with a class variable, property or method.",
    ),
    "E0243": (
        "Invalid assignment to '__class__'. Should be a class definition but got a '%s'",
        "invalid-class-object",
        "Used when an invalid object is assigned to a __class__ property. "
        "Only a class is permitted.",
    ),
    "E0244": (
        'Extending inherited Enum class "%s"',
        "invalid-enum-extension",
        "Used when a class tries to extend an inherited Enum class. "
        "Doing so will raise a TypeError at runtime.",
    ),
    "E0245": (
        "No such name %r in __slots__",
        "declare-non-slot",
        "Raised when a type annotation on a class is absent from the list of names in __slots__, "
        "and __slots__ does not contain a __dict__ entry.",
    ),
    "R0202": (
        "Consider using a decorator instead of calling classmethod",
        "no-classmethod-decorator",
        "Used when a class method is defined without using the decorator syntax.",
    ),
    "R0203": (
        "Consider using a decorator instead of calling staticmethod",
        "no-staticmethod-decorator",
        "Used when a static method is defined without using the decorator syntax.",
    ),
    "C0205": (
        "Class __slots__ should be a non-string iterable",
        "single-string-used-for-slots",
        "Used when a class __slots__ is a simple string, rather than an iterable.",
    ),
    "R0205": (
        "Class %r inherits from object, can be safely removed from bases in python3",
        "useless-object-inheritance",
        "Used when a class inherit from object, which under python3 is implicit, "
        "hence can be safely removed from bases.",
    ),
    "R0206": (
        "Cannot have defined parameters for properties",
        "property-with-parameters",
        "Used when we detect that a property also has parameters, which are useless, "
        "given that properties cannot be called with additional arguments.",
    ),
}


def _scope_default() -&gt; defaultdict[str, list[_AccessNodes]]:
    # It's impossible to nest defaultdicts so we must use a function
    return defaultdict(list)


</t>
<t tx="ekr.20250131013600.393">class ScopeAccessMap:
    """Store the accessed variables per scope."""

    @others
</t>
<t tx="ekr.20250131013600.394">class ClassChecker(BaseChecker):
    """Checker for class nodes.

    Checks for :
    * methods without self as first argument
    * overridden methods signature
    * access only to existent members via self
    * attributes not defined in the __init__ method
    * unreachable code
    """

@others
</t>
<t tx="ekr.20250131013600.395">def _ancestors_to_call(
    klass_node: nodes.ClassDef, method_name: str = "__init__"
) -&gt; dict[nodes.ClassDef, bases.UnboundMethod]:
    """Return a dictionary where keys are the list of base classes providing
    the queried method, and so that should/may be called from the method node.
    """
    to_call: dict[nodes.ClassDef, bases.UnboundMethod] = {}
    for base_node in klass_node.ancestors(recurs=False):
        try:
            init_node = next(base_node.igetattr(method_name))
            if not isinstance(init_node, astroid.UnboundMethod):
                continue
            if init_node.is_abstract():
                continue
            to_call[base_node] = init_node
        except astroid.InferenceError:
            continue
    return to_call
</t>
<t tx="ekr.20250131013600.396">def __init__(self) -&gt; None:
    self._scopes: defaultdict[
        nodes.ClassDef, defaultdict[str, list[_AccessNodes]]
    ] = defaultdict(_scope_default)

</t>
<t tx="ekr.20250131013600.397">def set_accessed(self, node: _AccessNodes) -&gt; None:
    """Set the given node as accessed."""
    frame = node_frame_class(node)
    if frame is None:
        # The node does not live in a class.
        return
    self._scopes[frame][node.attrname].append(node)

</t>
<t tx="ekr.20250131013600.398">def accessed(self, scope: nodes.ClassDef) -&gt; dict[str, list[_AccessNodes]]:
    """Get the accessed variables for the given scope."""
    return self._scopes.get(scope, {})


</t>
<t tx="ekr.20250131013600.399">    # configuration section name
    name = "classes"
    # messages
    msgs = MSGS
    # configuration options
    options = (
        (
            "defining-attr-methods",
            {
                "default": (
                    "__init__",
                    "__new__",
                    "setUp",
                    "asyncSetUp",
                    "__post_init__",
                ),
                "type": "csv",
                "metavar": "&lt;method names&gt;",
                "help": "List of method names used to declare (i.e. assign) \
instance attributes.",
            },
        ),
        (
            "valid-classmethod-first-arg",
            {
                "default": ("cls",),
                "type": "csv",
                "metavar": "&lt;argument names&gt;",
                "help": "List of valid names for the first argument in \
a class method.",
            },
        ),
        (
            "valid-metaclass-classmethod-first-arg",
            {
                "default": ("mcs",),
                "type": "csv",
                "metavar": "&lt;argument names&gt;",
                "help": "List of valid names for the first argument in \
a metaclass class method.",
            },
        ),
        (
            "exclude-protected",
            {
                "default": (
                    # namedtuple public API.
                    "_asdict",
                    "_fields",
                    "_replace",
                    "_source",
                    "_make",
                    "os._exit",
                ),
                "type": "csv",
                "metavar": "&lt;protected access exclusions&gt;",
                "help": (
                    "List of member names, which should be excluded "
                    "from the protected access warning."
                ),
            },
        ),
        (
            "check-protected-access-in-special-methods",
            {
                "default": False,
                "type": "yn",
                "metavar": "&lt;y or n&gt;",
                "help": "Warn about protected attribute access inside special methods",
            },
        ),
    )

    def __init__(self, linter: PyLinter) -&gt; None:
        super().__init__(linter)
        self._accessed = ScopeAccessMap()
        self._first_attrs: list[str | None] = []

</t>
<t tx="ekr.20250131013600.4">def is_super(node: nodes.NodeNG) -&gt; bool:
    """Return True if the node is referencing the "super" builtin function."""
    if getattr(node, "name", None) == "super" and node.root().name == "builtins":
        return True
    return False


</t>
<t tx="ekr.20250131013600.40">) -&gt; bool:
    """Determine if the `func` node has a decorator with the qualified name `qname`."""
    decorators = func.decorators.nodes if func.decorators else []
    for decorator_node in decorators:
        if isinstance(decorator_node, nodes.Call):
            # We only want to infer the function name
            decorator_node = decorator_node.func
        try:
            if any(
                i.name in qnames or i.qname() in qnames
                for i in decorator_node.infer()
                if i is not None and not isinstance(i, util.UninferableBase)
            ):
                return True
        except astroid.InferenceError:
            continue
    return False


def uninferable_final_decorators(
    node: nodes.Decorators,
) -&gt; list[nodes.Attribute | nodes.Name | None]:
    """Return a list of uninferable `typing.final` decorators in `node`.

    This function is used to determine if the `typing.final` decorator is used
    with an unsupported Python version; the decorator cannot be inferred when
    using a Python version lower than 3.8.
    """
    decorators = []
    for decorator in getattr(node, "nodes", []):
        import_nodes: tuple[nodes.Import | nodes.ImportFrom] | None = None

        # Get the `Import` node. The decorator is of the form: @module.name
        if isinstance(decorator, nodes.Attribute):
            inferred = safe_infer(decorator.expr)
            if isinstance(inferred, nodes.Module) and inferred.qname() == "typing":
                _, import_nodes = decorator.expr.lookup(decorator.expr.name)

        # Get the `ImportFrom` node. The decorator is of the form: @name
        elif isinstance(decorator, nodes.Name):
            _, import_nodes = decorator.lookup(decorator.name)

        # The `final` decorator is expected to be found in the
        # import_nodes. Continue if we don't find any `Import` or `ImportFrom`
        # nodes for this decorator.
        if not import_nodes:
            continue
        import_node = import_nodes[0]

        if not isinstance(import_node, (astroid.Import, astroid.ImportFrom)):
            continue

        import_names = dict(import_node.names)

        # Check if the import is of the form: `from typing import final`
        is_from_import = ("final" in import_names) and import_node.modname == "typing"

        # Check if the import is of the form: `import typing`
        is_import = ("typing" in import_names) and getattr(
            decorator, "attrname", None
        ) == "final"

        if is_from_import or is_import:
            inferred = safe_infer(decorator)
            if inferred is None or isinstance(inferred, util.UninferableBase):
                decorators.append(decorator)
    return decorators


</t>
<t tx="ekr.20250131013600.400">    def open(self) -&gt; None:
        self._mixin_class_rgx = self.linter.config.mixin_class_rgx
        py_version = self.linter.config.py_version
        self._py38_plus = py_version &gt;= (3, 8)

</t>
<t tx="ekr.20250131013600.401">    @cached_property
    def _dummy_rgx(self) -&gt; Pattern[str]:
        return self.linter.config.dummy_variables_rgx  # type: ignore[no-any-return]

</t>
<t tx="ekr.20250131013600.402">    @only_required_for_messages(
        "abstract-method",
        "invalid-slots",
        "single-string-used-for-slots",
        "invalid-slots-object",
        "class-variable-slots-conflict",
        "inherit-non-class",
        "useless-object-inheritance",
        "inconsistent-mro",
        "duplicate-bases",
        "redefined-slots-in-subclass",
        "invalid-enum-extension",
        "subclassed-final-class",
        "implicit-flag-alias",
        "declare-non-slot",
    )
    def visit_classdef(self, node: nodes.ClassDef) -&gt; None:
        """Init visit variable _accessed."""
        self._check_bases_classes(node)
        self._check_slots(node)
        self._check_proper_bases(node)
        self._check_typing_final(node)
        self._check_consistent_mro(node)
        self._check_declare_non_slot(node)

</t>
<t tx="ekr.20250131013600.403">    def _check_declare_non_slot(self, node: nodes.ClassDef) -&gt; None:
        if not self._has_valid_slots(node):
            return

        slot_names = self._get_classdef_slots_names(node)

        # Stop if empty __slots__ in the class body, this likely indicates that
        # this class takes part in multiple inheritance with other slotted classes.
        if not slot_names:
            return

        # Stop if we find __dict__, since this means attributes can be set
        # dynamically
        if "__dict__" in slot_names:
            return

        for base in node.bases:
            ancestor = safe_infer(base)
            if not isinstance(ancestor, nodes.ClassDef):
                continue
            # if any base doesn't have __slots__, attributes can be set dynamically, so stop
            if not self._has_valid_slots(ancestor):
                return
            for slot_name in self._get_classdef_slots_names(ancestor):
                if slot_name == "__dict__":
                    return
                slot_names.append(slot_name)

        # Every class in bases has __slots__, our __slots__ is non-empty and there is no __dict__

        for child in node.body:
            if isinstance(child, nodes.AnnAssign):
                if child.value is not None:
                    continue
                if isinstance(child.target, nodes.AssignName):
                    if child.target.name not in slot_names:
                        self.add_message(
                            "declare-non-slot",
                            args=child.target.name,
                            node=child.target,
                            confidence=INFERENCE,
                        )

</t>
<t tx="ekr.20250131013600.404">    def _check_consistent_mro(self, node: nodes.ClassDef) -&gt; None:
        """Detect that a class has a consistent mro or duplicate bases."""
        try:
            node.mro()
        except astroid.InconsistentMroError:
            self.add_message("inconsistent-mro", args=node.name, node=node)
        except astroid.DuplicateBasesError:
            self.add_message("duplicate-bases", args=node.name, node=node)

</t>
<t tx="ekr.20250131013600.405">    def _check_enum_base(self, node: nodes.ClassDef, ancestor: nodes.ClassDef) -&gt; None:
        members = ancestor.getattr("__members__")
        if members and isinstance(members[0], nodes.Dict) and members[0].items:
            for _, name_node in members[0].items:
                # Exempt type annotations without value assignments
                if all(
                    isinstance(item.parent, nodes.AnnAssign)
                    and item.parent.value is None
                    for item in ancestor.getattr(name_node.name)
                ):
                    continue
                self.add_message(
                    "invalid-enum-extension",
                    args=ancestor.name,
                    node=node,
                    confidence=INFERENCE,
                )
                break

        if ancestor.is_subtype_of("enum.IntFlag"):
            # Collect integer flag assignments present on the class
            assignments = defaultdict(list)
            for assign_name in node.nodes_of_class(nodes.AssignName):
                if isinstance(assign_name.parent, nodes.Assign):
                    value = getattr(assign_name.parent.value, "value", None)
                    if isinstance(value, int):
                        assignments[value].append(assign_name)

            # For each bit position, collect all the flags that set the bit
            bit_flags = defaultdict(set)
            for flag in assignments:
                flag_bits = (i for i, c in enumerate(reversed(bin(flag))) if c == "1")
                for bit in flag_bits:
                    bit_flags[bit].add(flag)

            # Collect the minimum, unique values that each flag overlaps with
            overlaps = defaultdict(list)
            for flags in bit_flags.values():
                source, * conflicts = sorted(flags)
                for conflict in conflicts:
                    overlaps[conflict].append(source)

            # Report the overlapping values
            for overlap in overlaps:
                for assignment_node in assignments[overlap]:
                    self.add_message(
                        "implicit-flag-alias",
                        node=assignment_node,
                        args={
                            "overlap": f"&lt;{node.name}.{assignment_node.name}: {overlap}&gt;",
                            "sources": ", ".join(
                                f"&lt;{node.name}.{assignments[source][0].name}: {source}&gt; "
                                f"({overlap} &amp; {source} = {overlap &amp; source})"
                                for source in overlaps[overlap]
                            ),
                        },
                        confidence=INFERENCE,
                    )

</t>
<t tx="ekr.20250131013600.406">    def _check_proper_bases(self, node: nodes.ClassDef) -&gt; None:
        """Detect that a class inherits something which is not
        a class or a type.
        """
        for base in node.bases:
            ancestor = safe_infer(base)
            if not ancestor:
                continue
            if isinstance(ancestor, astroid.Instance) and (
                ancestor.is_subtype_of("builtins.type")
                or ancestor.is_subtype_of(".Protocol")
            ):
                continue

            if not isinstance(ancestor, nodes.ClassDef) or _is_invalid_base_class(
                ancestor
            ):
                self.add_message("inherit-non-class", args=base.as_string(), node=node)

            if isinstance(ancestor, nodes.ClassDef) and ancestor.is_subtype_of(
                "enum.Enum"
            ):
                self._check_enum_base(node, ancestor)

            if ancestor.name == object.__name__:
                self.add_message(
                    "useless-object-inheritance", args=node.name, node=node
                )

</t>
<t tx="ekr.20250131013600.407">    def _check_typing_final(self, node: nodes.ClassDef) -&gt; None:
        """Detect that a class does not subclass a class decorated with
        `typing.final`.
        """
        if not self._py38_plus:
            return
        for base in node.bases:
            ancestor = safe_infer(base)
            if not ancestor:
                continue

            if isinstance(ancestor, nodes.ClassDef) and (
                decorated_with(ancestor, ["typing.final"])
                or uninferable_final_decorators(ancestor.decorators)
            ):
                self.add_message(
                    "subclassed-final-class",
                    args=(node.name, ancestor.name),
                    node=node,
                )

</t>
<t tx="ekr.20250131013600.408">    @only_required_for_messages(
        "unused-private-member",
        "attribute-defined-outside-init",
        "access-member-before-definition",
    )
    def leave_classdef(self, node: nodes.ClassDef) -&gt; None:
        """Checker for Class nodes.

        check that instance attributes are defined in __init__ and check
        access to existent members
        """
        self._check_unused_private_functions(node)
        self._check_unused_private_variables(node)
        self._check_unused_private_attributes(node)
        self._check_attribute_defined_outside_init(node)

</t>
<t tx="ekr.20250131013600.409">    def _check_unused_private_functions(self, node: nodes.ClassDef) -&gt; None:
        for function_def in node.nodes_of_class(nodes.FunctionDef):
            if not is_attr_private(function_def.name):
                continue
            parent_scope = function_def.parent.scope()
            if isinstance(parent_scope, nodes.FunctionDef):
                # Handle nested functions
                if function_def.name in (
                    n.name for n in parent_scope.nodes_of_class(nodes.Name)
                ):
                    continue
            for child in node.nodes_of_class((nodes.Name, nodes.Attribute)):
                # Check for cases where the functions are used as a variable instead of as a
                # method call
                if isinstance(child, nodes.Name) and child.name == function_def.name:
                    break
                if isinstance(child, nodes.Attribute):
                    # Ignore recursive calls
                    if (
                        child.attrname != function_def.name
                        or child.scope() == function_def
                    ):
                        continue

                    # Check self.__attrname, cls.__attrname, node_name.__attrname
                    if isinstance(child.expr, nodes.Name) and child.expr.name in {
                        "self",
                        "cls",
                        node.name,
                    }:
                        break

                    # Check type(self).__attrname
                    if isinstance(child.expr, nodes.Call):
                        inferred = safe_infer(child.expr)
                        if (
                            isinstance(inferred, nodes.ClassDef)
                            and inferred.name == node.name
                        ):
                            break
            else:
                name_stack = []
                curr = parent_scope
                # Generate proper names for nested functions
                while curr != node:
                    name_stack.append(curr.name)
                    curr = curr.parent.scope()

                outer_level_names = f"{'.'.join(reversed(name_stack))}"
                function_repr = f"{outer_level_names}.{function_def.name}({function_def.args.as_string()})"
                self.add_message(
                    "unused-private-member",
                    node=function_def,
                    args=(node.name, function_repr.lstrip(".")),
                )

</t>
<t tx="ekr.20250131013600.41">@lru_cache(maxsize=1024)
def unimplemented_abstract_methods(
    node: nodes.ClassDef, is_abstract_cb: nodes.FunctionDef | None = None
) -&gt; dict[str, nodes.FunctionDef]:
    """Get the unimplemented abstract methods for the given *node*.

    A method can be considered abstract if the callback *is_abstract_cb*
    returns a ``True`` value. The check defaults to verifying that
    a method is decorated with abstract methods.
    It will return a dictionary of abstract method
    names and their inferred objects.
    """
    if is_abstract_cb is None:
        is_abstract_cb = partial(decorated_with, qnames=ABC_METHODS)
    visited: dict[str, nodes.FunctionDef] = {}
    try:
        mro = reversed(node.mro())
    except astroid.ResolveError:
        # Probably inconsistent hierarchy, don't try to figure this out here.
        return {}
    for ancestor in mro:
        for obj in ancestor.values():
            inferred = obj
            if isinstance(obj, nodes.AssignName):
                inferred = safe_infer(obj)
                if not inferred:
                    # Might be an abstract function,
                    # but since we don't have enough information
                    # in order to take this decision, we're taking
                    # the *safe* decision instead.
                    if obj.name in visited:
                        del visited[obj.name]
                    continue
                if not isinstance(inferred, nodes.FunctionDef):
                    if obj.name in visited:
                        del visited[obj.name]
            if isinstance(inferred, nodes.FunctionDef):
                # It's critical to use the original name,
                # since after inferring, an object can be something
                # else than expected, as in the case of the
                # following assignment.
                #
                # class A:
                #     def keys(self): pass
                #     __iter__ = keys
                abstract = is_abstract_cb(inferred)
                if abstract:
                    visited[obj.name] = inferred
                elif not abstract and obj.name in visited:
                    del visited[obj.name]
    return visited


</t>
<t tx="ekr.20250131013600.410">    def _check_unused_private_variables(self, node: nodes.ClassDef) -&gt; None:
        """Check if private variables are never used within a class."""
        for assign_name in node.nodes_of_class(nodes.AssignName):
            if isinstance(assign_name.parent, nodes.Arguments):
                continue  # Ignore function arguments
            if not is_attr_private(assign_name.name):
                continue
            for child in node.nodes_of_class((nodes.Name, nodes.Attribute)):
                if isinstance(child, nodes.Name) and child.name == assign_name.name:
                    break
                if isinstance(child, nodes.Attribute):
                    if not isinstance(child.expr, nodes.Name):
                        break
                    if child.attrname == assign_name.name and child.expr.name in (
                        "self",
                        "cls",
                        node.name,
                    ):
                        break
            else:
                args = (node.name, assign_name.name)
                self.add_message("unused-private-member", node=assign_name, args=args)

</t>
<t tx="ekr.20250131013600.411">    def _check_unused_private_attributes(self, node: nodes.ClassDef) -&gt; None:
        for assign_attr in node.nodes_of_class(nodes.AssignAttr):
            if not is_attr_private(assign_attr.attrname) or not isinstance(
                assign_attr.expr, nodes.Name
            ):
                continue

            # Logic for checking false positive when using __new__,
            # Get the returned object names of the __new__ magic function
            # Then check if the attribute was consumed in other instance methods
            acceptable_obj_names: list[str] = ["self"]
            scope = assign_attr.scope()
            if isinstance(scope, nodes.FunctionDef) and scope.name == "__new__":
                acceptable_obj_names.extend(
                    [
                        return_node.value.name
                        for return_node in scope.nodes_of_class(nodes.Return)
                        if isinstance(return_node.value, nodes.Name)
                    ]
                )

            for attribute in node.nodes_of_class(nodes.Attribute):
                if attribute.attrname != assign_attr.attrname:
                    continue

                if not isinstance(attribute.expr, nodes.Name):
                    continue

                if assign_attr.expr.name in {
                    "cls",
                    node.name,
                } and attribute.expr.name in {"cls", "self", node.name}:
                    # If assigned to cls or class name, can be accessed by cls/self/class name
                    break

                if (
                    assign_attr.expr.name in acceptable_obj_names
                    and attribute.expr.name == "self"
                ):
                    # If assigned to self.attrib, can only be accessed by self
                    # Or if __new__ was used, the returned object names are acceptable
                    break

                if assign_attr.expr.name == attribute.expr.name == node.name:
                    # Recognise attributes which are accessed via the class name
                    break

            else:
                args = (node.name, assign_attr.attrname)
                self.add_message("unused-private-member", node=assign_attr, args=args)

</t>
<t tx="ekr.20250131013600.412">    def _check_attribute_defined_outside_init(self, cnode: nodes.ClassDef) -&gt; None:
        # check access to existent members on non metaclass classes
        if (
            "attribute-defined-outside-init"
            in self.linter.config.ignored_checks_for_mixins
            and self._mixin_class_rgx.match(cnode.name)
        ):
            # We are in a mixin class. No need to try to figure out if
            # something is missing, since it is most likely that it will
            # miss.
            return

        accessed = self._accessed.accessed(cnode)
        if cnode.type != "metaclass":
            self._check_accessed_members(cnode, accessed)
        # checks attributes are defined in an allowed method such as __init__
        if not self.linter.is_message_enabled("attribute-defined-outside-init"):
            return
        defining_methods = self.linter.config.defining_attr_methods
        current_module = cnode.root()
        for attr, nodes_lst in cnode.instance_attrs.items():
            # Exclude `__dict__` as it is already defined.
            if attr == "__dict__":
                continue

            # Skip nodes which are not in the current module and it may screw up
            # the output, while it's not worth it
            nodes_lst = [
                n
                for n in nodes_lst
                if not isinstance(n.statement(), (nodes.Delete, nodes.AugAssign))
                and n.root() is current_module
            ]
            if not nodes_lst:
                continue  # error detected by typechecking

            # Check if any method attr is defined in is a defining method
            # or if we have the attribute defined in a setter.
            frames = (node.frame() for node in nodes_lst)
            if any(
                frame.name in defining_methods or is_property_setter(frame)
                for frame in frames
            ):
                continue

            # check attribute is defined in a parent's __init__
            for parent in cnode.instance_attr_ancestors(attr):
                attr_defined = False
                # check if any parent method attr is defined in is a defining method
                for node in parent.instance_attrs[attr]:
                    if node.frame().name in defining_methods:
                        attr_defined = True
                if attr_defined:
                    # we're done :)
                    break
            else:
                # check attribute is defined as a class attribute
                try:
                    cnode.local_attr(attr)
                except astroid.NotFoundError:
                    for node in nodes_lst:
                        if node.frame().name not in defining_methods:
                            # If the attribute was set by a call in any
                            # of the defining methods, then don't emit
                            # the warning.
                            if _called_in_methods(
                                node.frame(), cnode, defining_methods
                            ):
                                continue
                            self.add_message(
                                "attribute-defined-outside-init", args=attr, node=node
                            )

</t>
<t tx="ekr.20250131013600.413">    # pylint: disable = too-many-branches
    def visit_functiondef(self, node: nodes.FunctionDef) -&gt; None:
        """Check method arguments, overriding."""
        # ignore actual functions
        if not node.is_method():
            return

        self._check_useless_super_delegation(node)
        self._check_property_with_parameters(node)

        # 'is_method()' is called and makes sure that this is a 'nodes.ClassDef'
        klass: nodes.ClassDef = node.parent.frame()
        # check first argument is self if this is actually a method
        self._check_first_arg_for_type(node, klass.type == "metaclass")
        if node.name == "__init__":
            self._check_init(node, klass)
            return
        # check signature if the method overloads inherited method
        for overridden in klass.local_attr_ancestors(node.name):
            # get astroid for the searched method
            try:
                parent_function = overridden[node.name]
            except KeyError:
                # we have found the method but it's not in the local
                # dictionary.
                # This may happen with astroid build from living objects
                continue
            if not isinstance(parent_function, nodes.FunctionDef):
                continue
            self._check_signature(node, parent_function, klass)
            self._check_invalid_overridden_method(node, parent_function)
            break

        if node.decorators:
            for decorator in node.decorators.nodes:
                if isinstance(decorator, nodes.Attribute) and decorator.attrname in {
                    "getter",
                    "setter",
                    "deleter",
                }:
                    # attribute affectation will call this method, not hiding it
                    return
                if isinstance(decorator, nodes.Name):
                    if decorator.name in ALLOWED_PROPERTIES:
                        # attribute affectation will either call a setter or raise
                        # an attribute error, anyway not hiding the function
                        return

                if isinstance(decorator, nodes.Attribute):
                    if self._check_functools_or_not(decorator):
                        return

                # Infer the decorator and see if it returns something useful
                inferred = safe_infer(decorator)
                if not inferred:
                    return
                if isinstance(inferred, nodes.FunctionDef):
                    # Okay, it's a decorator, let's see what it can infer.
                    try:
                        inferred = next(inferred.infer_call_result(inferred))
                    except astroid.InferenceError:
                        return
                try:
                    if (
                        isinstance(inferred, (astroid.Instance, nodes.ClassDef))
                        and inferred.getattr("__get__")
                        and inferred.getattr("__set__")
                    ):
                        return
                except astroid.AttributeInferenceError:
                    pass

        # check if the method is hidden by an attribute
        # pylint: disable = too-many-try-statements
        try:
            overridden = klass.instance_attr(node.name)[0]
            overridden_frame = overridden.frame()
            if (
                isinstance(overridden_frame, nodes.FunctionDef)
                and overridden_frame.type == "method"
            ):
                overridden_frame = overridden_frame.parent.frame()
            if not (
                isinstance(overridden_frame, nodes.ClassDef)
                and klass.is_subtype_of(overridden_frame.qname())
            ):
                return

            # If a subclass defined the method then it's not our fault.
            for ancestor in klass.ancestors():
                if node.name in ancestor.instance_attrs and is_attr_private(node.name):
                    return
                for obj in ancestor.lookup(node.name)[1]:
                    if isinstance(obj, nodes.FunctionDef):
                        return
            args = (overridden.root().name, overridden.fromlineno)
            self.add_message("method-hidden", args=args, node=node)
        except astroid.NotFoundError:
            pass

</t>
<t tx="ekr.20250131013600.414">    visit_asyncfunctiondef = visit_functiondef

    def _check_useless_super_delegation(self, function: nodes.FunctionDef) -&gt; None:
        """Check if the given function node is an useless method override.

        We consider it *useless* if it uses the super() builtin, but having
        nothing additional whatsoever than not implementing the method at all.
        If the method uses super() to delegate an operation to the rest of the MRO,
        and if the method called is the same as the current one, the arguments
        passed to super() are the same as the parameters that were passed to
        this method, then the method could be removed altogether, by letting
        other implementation to take precedence.
        """
        if not _is_trivial_super_delegation(function):
            return

        call: nodes.Call = function.body[0].value

        # Classes that override __eq__ should also override
        # __hash__, even a trivial override is meaningful
        if function.name == "__hash__":
            for other_method in function.parent.mymethods():
                if other_method.name == "__eq__":
                    return

        # Check values of default args
        klass = function.parent.frame()
        meth_node = None
        for overridden in klass.local_attr_ancestors(function.name):
            # get astroid for the searched method
            try:
                meth_node = overridden[function.name]
            except KeyError:
                # we have found the method but it's not in the local
                # dictionary.
                # This may happen with astroid build from living objects
                continue
            if (
                not isinstance(meth_node, nodes.FunctionDef)
                # If the method have an ancestor which is not a
                # function then it is legitimate to redefine it
                or _has_different_parameters_default_value(
                    meth_node.args, function.args
                )
                # arguments to builtins such as Exception.__init__() cannot be inspected
                or (meth_node.args.args is None and function.argnames() != ["self"])
            ):
                return
            break

        # Detect if the parameters are the same as the call's arguments.
        params = _signature_from_arguments(function.args)
        args = _signature_from_call(call)

        if meth_node is not None:
            # Detect if the super method uses varargs and the function doesn't or makes some of those explicit
            if meth_node.args.vararg and (
                not function.args.vararg
                or len(function.args.args) &gt; len(meth_node.args.args)
            ):
                return

            def form_annotations(arguments: nodes.Arguments) -&gt; list[str]:
                annotations = chain(
                    (arguments.posonlyargs_annotations or []), arguments.annotations
                )
                return [ann.as_string() for ann in annotations if ann is not None]

            called_annotations = form_annotations(function.args)
            overridden_annotations = form_annotations(meth_node.args)
            if called_annotations and overridden_annotations:
                if called_annotations != overridden_annotations:
                    return

            if (
                function.returns is not None
                and meth_node.returns is not None
                and meth_node.returns.as_string() != function.returns.as_string()
            ):
                # Override adds typing information to the return type
                return

        if _definition_equivalent_to_call(params, args):
            self.add_message(
                "useless-parent-delegation",
                node=function,
                args=(function.name,),
                confidence=INFERENCE,
            )

</t>
<t tx="ekr.20250131013600.415">    def _check_property_with_parameters(self, node: nodes.FunctionDef) -&gt; None:
        if (
            len(node.args.arguments) &gt; 1
            and decorated_with_property(node)
            and not is_property_setter(node)
        ):
            self.add_message("property-with-parameters", node=node, confidence=HIGH)

</t>
<t tx="ekr.20250131013600.416">    def _check_invalid_overridden_method(
        self,
        function_node: nodes.FunctionDef,
        parent_function_node: nodes.FunctionDef,
    ) -&gt; None:
        parent_is_property = decorated_with_property(
            parent_function_node
        ) or is_property_setter_or_deleter(parent_function_node)
        current_is_property = decorated_with_property(
            function_node
        ) or is_property_setter_or_deleter(function_node)
        if parent_is_property and not current_is_property:
            self.add_message(
                "invalid-overridden-method",
                args=(function_node.name, "property", function_node.type),
                node=function_node,
            )
        elif not parent_is_property and current_is_property:
            self.add_message(
                "invalid-overridden-method",
                args=(function_node.name, "method", "property"),
                node=function_node,
            )

        parent_is_async = isinstance(parent_function_node, nodes.AsyncFunctionDef)
        current_is_async = isinstance(function_node, nodes.AsyncFunctionDef)

        if parent_is_async and not current_is_async:
            self.add_message(
                "invalid-overridden-method",
                args=(function_node.name, "async", "non-async"),
                node=function_node,
            )

        elif not parent_is_async and current_is_async:
            self.add_message(
                "invalid-overridden-method",
                args=(function_node.name, "non-async", "async"),
                node=function_node,
            )
        if (
            decorated_with(parent_function_node, ["typing.final"])
            or uninferable_final_decorators(parent_function_node.decorators)
        ) and self._py38_plus:
            self.add_message(
                "overridden-final-method",
                args=(function_node.name, parent_function_node.parent.frame().name),
                node=function_node,
            )

</t>
<t tx="ekr.20250131013600.417">    def _check_functools_or_not(self, decorator: nodes.Attribute) -&gt; bool:
        if decorator.attrname != "cached_property":
            return False

        if not isinstance(decorator.expr, nodes.Name):
            return False

        _, import_nodes = decorator.expr.lookup(decorator.expr.name)

        if not import_nodes:
            return False
        import_node = import_nodes[0]

        if not isinstance(import_node, (astroid.Import, astroid.ImportFrom)):
            return False

        return "functools" in dict(import_node.names)

</t>
<t tx="ekr.20250131013600.418">    def _has_valid_slots(self, node: nodes.ClassDef) -&gt; bool:
        if "__slots__" not in node.locals:
            return False

        try:
            inferred_slots = tuple(node.ilookup("__slots__"))
        except astroid.InferenceError:
            return False
        for slots in inferred_slots:
            # check if __slots__ is a valid type
            if isinstance(slots, util.UninferableBase):
                return False
            if not is_iterable(slots) and not is_comprehension(slots):
                return False
            if isinstance(slots, nodes.Const):
                return False
            if not hasattr(slots, "itered"):
                # we can't obtain the values, maybe a .deque?
                return False

        return True

</t>
<t tx="ekr.20250131013600.419">    def _check_slots(self, node: nodes.ClassDef) -&gt; None:
        if "__slots__" not in node.locals:
            return

        try:
            inferred_slots = tuple(node.ilookup("__slots__"))
        except astroid.InferenceError:
            return
        for slots in inferred_slots:
            # check if __slots__ is a valid type
            if isinstance(slots, util.UninferableBase):
                continue
            if not is_iterable(slots) and not is_comprehension(slots):
                self.add_message("invalid-slots", node=node)
                continue

            if isinstance(slots, nodes.Const):
                # a string, ignore the following checks
                self.add_message("single-string-used-for-slots", node=node)
                continue
            if not hasattr(slots, "itered"):
                # we can't obtain the values, maybe a .deque?
                continue

            if isinstance(slots, nodes.Dict):
                values = [item[0] for item in slots.items]
            else:
                values = slots.itered()
            if isinstance(values, util.UninferableBase):
                continue
            for elt in values:
                try:
                    self._check_slots_elt(elt, node)
                except astroid.InferenceError:
                    continue
            self._check_redefined_slots(node, slots, values)

</t>
<t tx="ekr.20250131013600.42">def find_try_except_wrapper_node(
    node: nodes.NodeNG,
) -&gt; nodes.ExceptHandler | nodes.Try | None:
    """Return the ExceptHandler or the Try node in which the node is."""
    current = node
    ignores = (nodes.ExceptHandler, nodes.Try)
    while current and not isinstance(current.parent, ignores):
        current = current.parent

    if current and isinstance(current.parent, ignores):
        return current.parent
    return None


</t>
<t tx="ekr.20250131013600.420">    def _get_classdef_slots_names(self, node: nodes.ClassDef) -&gt; list[str]:

        slots_names: list[str] = []
        try:
            inferred_slots = tuple(node.ilookup("__slots__"))
        except astroid.InferenceError:  # pragma: no cover
            return slots_names
        for slots in inferred_slots:
            if isinstance(slots, nodes.Dict):
                values = [item[0] for item in slots.items]
            else:
                values = slots.itered()
            slots_names.extend(self._get_slots_names(values))

        return slots_names

</t>
<t tx="ekr.20250131013600.421">    def _get_slots_names(self, slots_list: list[nodes.NodeNG]) -&gt; list[str]:
        slots_names: list[str] = []
        for slot in slots_list:
            if isinstance(slot, nodes.Const):
                slots_names.append(slot.value)
            else:
                inferred_slot = safe_infer(slot)
                inferred_slot_value = getattr(inferred_slot, "value", None)
                if isinstance(inferred_slot_value, str):
                    slots_names.append(inferred_slot_value)
        return slots_names

</t>
<t tx="ekr.20250131013600.422">    def _check_redefined_slots(
        self,
        node: nodes.ClassDef,
        slots_node: nodes.NodeNG,
        slots_list: list[nodes.NodeNG],
    ) -&gt; None:
        """Check if `node` redefines a slot which is defined in an ancestor class."""
        slots_names: list[str] = self._get_slots_names(slots_list)

        # Slots of all parent classes
        ancestors_slots_names = {
            slot.value
            for ancestor in node.local_attr_ancestors("__slots__")
            for slot in ancestor.slots() or []
        }

        # Slots which are common to `node` and its parent classes
        redefined_slots = ancestors_slots_names.intersection(slots_names)

        if redefined_slots:
            self.add_message(
                "redefined-slots-in-subclass",
                args=([name for name in slots_names if name in redefined_slots],),
                node=slots_node,
            )

</t>
<t tx="ekr.20250131013600.423">    def _check_slots_elt(
        self, elt: SuccessfulInferenceResult, node: nodes.ClassDef
    ) -&gt; None:
        for inferred in elt.infer():
            if isinstance(inferred, util.UninferableBase):
                continue
            if not isinstance(inferred, nodes.Const) or not isinstance(
                inferred.value, str
            ):
                self.add_message(
                    "invalid-slots-object",
                    args=elt.as_string(),
                    node=elt,
                    confidence=INFERENCE,
                )
                continue
            if not inferred.value:
                self.add_message(
                    "invalid-slots-object",
                    args=elt.as_string(),
                    node=elt,
                    confidence=INFERENCE,
                )

            # Check if we have a conflict with a class variable.
            class_variable = node.locals.get(inferred.value)
            if class_variable:
                # Skip annotated assignments which don't conflict at all with slots.
                if len(class_variable) == 1:
                    parent = class_variable[0].parent
                    if isinstance(parent, nodes.AnnAssign) and parent.value is None:
                        return
                self.add_message(
                    "class-variable-slots-conflict", args=(inferred.value,), node=elt
                )

</t>
<t tx="ekr.20250131013600.424">    def leave_functiondef(self, node: nodes.FunctionDef) -&gt; None:
        """On method node, check if this method couldn't be a function.

        ignore class, static and abstract methods, initializer,
        methods overridden from a parent class.
        """
        if node.is_method():
            if node.args.args is not None:
                self._first_attrs.pop()

</t>
<t tx="ekr.20250131013600.425">    leave_asyncfunctiondef = leave_functiondef

    def visit_attribute(self, node: nodes.Attribute) -&gt; None:
        """Check if the getattr is an access to a class member
        if so, register it.

        Also check for access to protected
        class member from outside its class (but ignore __special__
        methods)
        """
        self._check_super_without_brackets(node)

        # Check self
        if self._uses_mandatory_method_param(node):
            self._accessed.set_accessed(node)
            return
        if not self.linter.is_message_enabled("protected-access"):
            return

        self._check_protected_attribute_access(node)

</t>
<t tx="ekr.20250131013600.426">    def _check_super_without_brackets(self, node: nodes.Attribute) -&gt; None:
        """Check if there is a function call on a super call without brackets."""
        # Check if attribute call is in frame definition in class definition
        frame = node.frame()
        if not isinstance(frame, nodes.FunctionDef):
            return
        if not isinstance(frame.parent.frame(), nodes.ClassDef):
            return
        if not isinstance(node.parent, nodes.Call):
            return
        if not isinstance(node.expr, nodes.Name):
            return
        if node.expr.name == "super":
            self.add_message("super-without-brackets", node=node.expr, confidence=HIGH)

</t>
<t tx="ekr.20250131013600.427">    @only_required_for_messages(
        "assigning-non-slot", "invalid-class-object", "access-member-before-definition"
    )
    def visit_assignattr(self, node: nodes.AssignAttr) -&gt; None:
        if isinstance(
            node.assign_type(), nodes.AugAssign
        ) and self._uses_mandatory_method_param(node):
            self._accessed.set_accessed(node)
        self._check_in_slots(node)
        self._check_invalid_class_object(node)

</t>
<t tx="ekr.20250131013600.428">    def _check_invalid_class_object(self, node: nodes.AssignAttr) -&gt; None:
        if not node.attrname == "__class__":
            return
        if isinstance(node.parent, nodes.Tuple):
            class_index = -1
            for i, elt in enumerate(node.parent.elts):
                if hasattr(elt, "attrname") and elt.attrname == "__class__":
                    class_index = i
            if class_index == -1:
                # This should not happen because we checked that the node name
                # is '__class__' earlier, but let's not be too confident here
                return  # pragma: no cover
            inferred = safe_infer(node.parent.parent.value.elts[class_index])
        else:
            inferred = safe_infer(node.parent.value)
        if (
            isinstance(inferred, (nodes.ClassDef, util.UninferableBase))
            or inferred is None
        ):
            # If is uninferable, we allow it to prevent false positives
            return
        self.add_message(
            "invalid-class-object",
            node=node,
            args=inferred.__class__.__name__,
            confidence=INFERENCE,
        )

</t>
<t tx="ekr.20250131013600.429">    def _check_in_slots(self, node: nodes.AssignAttr) -&gt; None:
        """Check that the given AssignAttr node
        is defined in the class slots.
        """
        inferred = safe_infer(node.expr)
        if not isinstance(inferred, astroid.Instance):
            return

        klass = inferred._proxied
        if not has_known_bases(klass):
            return
        if "__slots__" not in klass.locals:
            return
        # If `__setattr__` is defined on the class, then we can't reason about
        # what will happen when assigning to an attribute.
        if any(
            base.locals.get("__setattr__")
            for base in klass.mro()
            if base.qname() != "builtins.object"
        ):
            return

        # If 'typing.Generic' is a base of bases of klass, the cached version
        # of 'slots()' might have been evaluated incorrectly, thus deleted cache entry.
        if any(base.qname() == "typing.Generic" for base in klass.mro()):
            cache = getattr(klass, "__cache", None)
            if cache and cache.get(klass.slots) is not None:
                del cache[klass.slots]

        slots = klass.slots()
        if slots is None:
            return
        # If any ancestor doesn't use slots, the slots
        # defined for this class are superfluous.
        if any(
            "__slots__" not in ancestor.locals
            and ancestor.name not in ("Generic", "object")
            for ancestor in klass.ancestors()
        ):
            return

        if not any(slot.value == node.attrname for slot in slots):
            # If we have a '__dict__' in slots, then
            # assigning any name is valid.
            if not any(slot.value == "__dict__" for slot in slots):
                if _is_attribute_property(node.attrname, klass):
                    # Properties circumvent the slots mechanism,
                    # so we should not emit a warning for them.
                    return
                if node.attrname != "__class__" and utils.is_class_attr(
                    node.attrname, klass
                ):
                    return
                if node.attrname in klass.locals:
                    for local_name in klass.locals.get(node.attrname):
                        statement = local_name.statement()
                        if (
                            isinstance(statement, nodes.AnnAssign)
                            and not statement.value
                        ):
                            return
                    if _has_data_descriptor(klass, node.attrname):
                        # Descriptors circumvent the slots mechanism as well.
                        return
                if node.attrname == "__class__" and _has_same_layout_slots(
                    slots, node.parent.value
                ):
                    return
                self.add_message(
                    "assigning-non-slot",
                    args=(node.attrname,),
                    node=node,
                    confidence=INFERENCE,
                )

</t>
<t tx="ekr.20250131013600.43">def find_except_wrapper_node_in_scope(
    node: nodes.NodeNG,
) -&gt; nodes.ExceptHandler | None:
    """Return the ExceptHandler in which the node is, without going out of scope."""
    for current in node.node_ancestors():
        if isinstance(current, astroid.scoped_nodes.LocalsDictNodeNG):
            # If we're inside a function/class definition, we don't want to keep checking
            # higher ancestors for `except` clauses, because if these exist, it means our
            # function/class was defined in an `except` clause, rather than the current code
            # actually running in an `except` clause.
            return None
        if isinstance(current, nodes.ExceptHandler):
            return current
    return None


</t>
<t tx="ekr.20250131013600.430">    @only_required_for_messages(
        "protected-access", "no-classmethod-decorator", "no-staticmethod-decorator"
    )
    def visit_assign(self, assign_node: nodes.Assign) -&gt; None:
        self._check_classmethod_declaration(assign_node)
        node = assign_node.targets[0]
        if not isinstance(node, nodes.AssignAttr):
            return

        if self._uses_mandatory_method_param(node):
            return
        self._check_protected_attribute_access(node)

</t>
<t tx="ekr.20250131013600.431">    def _check_classmethod_declaration(self, node: nodes.Assign) -&gt; None:
        """Checks for uses of classmethod() or staticmethod().

        When a @classmethod or @staticmethod decorator should be used instead.
        A message will be emitted only if the assignment is at a class scope
        and only if the classmethod's argument belongs to the class where it
        is defined.
        `node` is an assign node.
        """
        if not isinstance(node.value, nodes.Call):
            return

        # check the function called is "classmethod" or "staticmethod"
        func = node.value.func
        if not isinstance(func, nodes.Name) or func.name not in (
            "classmethod",
            "staticmethod",
        ):
            return

        msg = (
            "no-classmethod-decorator"
            if func.name == "classmethod"
            else "no-staticmethod-decorator"
        )
        # assignment must be at a class scope
        parent_class = node.scope()
        if not isinstance(parent_class, nodes.ClassDef):
            return

        # Check if the arg passed to classmethod is a class member
        classmeth_arg = node.value.args[0]
        if not isinstance(classmeth_arg, nodes.Name):
            return

        method_name = classmeth_arg.name
        if any(method_name == member.name for member in parent_class.mymethods()):
            self.add_message(msg, node=node.targets[0])

</t>
<t tx="ekr.20250131013600.432">    def _check_protected_attribute_access(
        self, node: nodes.Attribute | nodes.AssignAttr
    ) -&gt; None:
        """Given an attribute access node (set or get), check if attribute
        access is legitimate.

        Call _check_first_attr with node before calling
        this method. Valid cases are:
        * self._attr in a method or cls._attr in a classmethod. Checked by
        _check_first_attr.
        * Klass._attr inside "Klass" class.
        * Klass2._attr inside "Klass" class when Klass2 is a base class of
            Klass.
        """
        attrname = node.attrname

        if (
            not is_attr_protected(attrname)
            or attrname in self.linter.config.exclude_protected
        ):
            return

        # Typing annotations in function definitions can include protected members
        if utils.is_node_in_type_annotation_context(node):
            return

        # Return if `attrname` is defined at the module-level or as a class attribute
        # and is listed in `exclude-protected`.
        inferred = safe_infer(node.expr)
        if (
            inferred
            and isinstance(inferred, (nodes.ClassDef, nodes.Module))
            and f"{inferred.name}.{attrname}" in self.linter.config.exclude_protected
        ):
            return

        klass = node_frame_class(node)
        if klass is None:
            # We are not in a class, no remaining valid case
            self.add_message("protected-access", node=node, args=attrname)
            return

        # In classes, check we are not getting a parent method
        # through the class object or through super

        # If the expression begins with a call to super, that's ok.
        if (
            isinstance(node.expr, nodes.Call)
            and isinstance(node.expr.func, nodes.Name)
            and node.expr.func.name == "super"
        ):
            return

        # If the expression begins with a call to type(self), that's ok.
        if self._is_type_self_call(node.expr):
            return

        # Check if we are inside the scope of a class or nested inner class
        inside_klass = True
        outer_klass = klass
        callee = node.expr.as_string()
        parents_callee = callee.split(".")
        parents_callee.reverse()
        for callee in parents_callee:
            if not outer_klass or callee != outer_klass.name:
                inside_klass = False
                break

            # Move up one level within the nested classes
            outer_klass = get_outer_class(outer_klass)

        # We are in a class, one remaining valid cases, Klass._attr inside
        # Klass
        if not (inside_klass or callee in klass.basenames):
            # Detect property assignments in the body of the class.
            # This is acceptable:
            #
            # class A:
            #     b = property(lambda: self._b)

            stmt = node.parent.statement()
            if (
                isinstance(stmt, nodes.Assign)
                and len(stmt.targets) == 1
                and isinstance(stmt.targets[0], nodes.AssignName)
            ):
                name = stmt.targets[0].name
                if _is_attribute_property(name, klass):
                    return

            if (
                self._is_classmethod(node.frame())
                and self._is_inferred_instance(node.expr, klass)
                and self._is_class_or_instance_attribute(attrname, klass)
            ):
                return

            licit_protected_member = not attrname.startswith("__")
            if (
                not self.linter.config.check_protected_access_in_special_methods
                and licit_protected_member
                and self._is_called_inside_special_method(node)
            ):
                return

            self.add_message("protected-access", node=node, args=attrname)

</t>
<t tx="ekr.20250131013600.433">    @staticmethod
    def _is_called_inside_special_method(node: nodes.NodeNG) -&gt; bool:
        """Returns true if the node is located inside a special (aka dunder) method."""
        frame_name = node.frame().name
        return frame_name and frame_name in PYMETHODS

</t>
<t tx="ekr.20250131013600.434">    def _is_type_self_call(self, expr: nodes.NodeNG) -&gt; bool:
        return (
            isinstance(expr, nodes.Call)
            and isinstance(expr.func, nodes.Name)
            and expr.func.name == "type"
            and len(expr.args) == 1
            and self._is_mandatory_method_param(expr.args[0])
        )

</t>
<t tx="ekr.20250131013600.435">    @staticmethod
    def _is_classmethod(func: LocalsDictNodeNG) -&gt; bool:
        """Check if the given *func* node is a class method."""
        return isinstance(func, nodes.FunctionDef) and (
            func.type == "classmethod" or func.name == "__class_getitem__"
        )

</t>
<t tx="ekr.20250131013600.436">    @staticmethod
    def _is_inferred_instance(expr: nodes.NodeNG, klass: nodes.ClassDef) -&gt; bool:
        """Check if the inferred value of the given *expr* is an instance of
        *klass*.
        """
        inferred = safe_infer(expr)
        if not isinstance(inferred, astroid.Instance):
            return False
        return inferred._proxied is klass

</t>
<t tx="ekr.20250131013600.437">    @staticmethod
    def _is_class_or_instance_attribute(name: str, klass: nodes.ClassDef) -&gt; bool:
        """Check if the given attribute *name* is a class or instance member of the
        given *klass*.

        Returns ``True`` if the name is a property in the given klass,
        ``False`` otherwise.
        """
        if utils.is_class_attr(name, klass):
            return True

        try:
            klass.instance_attr(name)
            return True
        except astroid.NotFoundError:
            return False

</t>
<t tx="ekr.20250131013600.438">    def _check_accessed_members(
        self, node: nodes.ClassDef, accessed: dict[str, list[_AccessNodes]]
    ) -&gt; None:
        """Check that accessed members are defined."""
        excs = ("AttributeError", "Exception", "BaseException")
        for attr, nodes_lst in accessed.items():
            try:
                # is it a class attribute ?
                node.local_attr(attr)
                # yes, stop here
                continue
            except astroid.NotFoundError:
                pass
            # is it an instance attribute of a parent class ?
            try:
                next(node.instance_attr_ancestors(attr))
                # yes, stop here
                continue
            except StopIteration:
                pass
            # is it an instance attribute ?
            try:
                defstmts = node.instance_attr(attr)
            except astroid.NotFoundError:
                pass
            else:
                # filter out augment assignment nodes
                defstmts = [stmt for stmt in defstmts if stmt not in nodes_lst]
                if not defstmts:
                    # only augment assignment for this node, no-member should be
                    # triggered by the typecheck checker
                    continue
                # filter defstmts to only pick the first one when there are
                # several assignments in the same scope
                scope = defstmts[0].scope()
                defstmts = [
                    stmt
                    for i, stmt in enumerate(defstmts)
                    if i == 0 or stmt.scope() is not scope
                ]
                # if there are still more than one, don't attempt to be smarter
                # than we can be
                if len(defstmts) == 1:
                    defstmt = defstmts[0]
                    # check that if the node is accessed in the same method as
                    # it's defined, it's accessed after the initial assignment
                    frame = defstmt.frame()
                    lno = defstmt.fromlineno
                    for _node in nodes_lst:
                        if (
                            _node.frame() is frame
                            and _node.fromlineno &lt; lno
                            and not astroid.are_exclusive(
                                _node.statement(), defstmt, excs
                            )
                        ):
                            self.add_message(
                                "access-member-before-definition",
                                node=_node,
                                args=(attr, lno),
                            )

</t>
<t tx="ekr.20250131013600.439">    def _check_first_arg_for_type(
        self, node: nodes.FunctionDef, metaclass: bool
    ) -&gt; None:
        """Check the name of first argument, expect:.

        * 'self' for a regular method
        * 'cls' for a class method or a metaclass regular method (actually
          valid-classmethod-first-arg value)
        * 'mcs' for a metaclass class method (actually
          valid-metaclass-classmethod-first-arg)
        * not one of the above for a static method
        """
        # don't care about functions with unknown argument (builtins)
        if node.args.args is None:
            return
        if node.args.posonlyargs:
            first_arg = node.args.posonlyargs[0].name
        elif node.args.args:
            first_arg = node.argnames()[0]
        else:
            first_arg = None
        self._first_attrs.append(first_arg)
        first = self._first_attrs[-1]
        # static method
        if node.type == "staticmethod":
            if (
                first_arg == "self"
                or first_arg in self.linter.config.valid_classmethod_first_arg
                or first_arg in self.linter.config.valid_metaclass_classmethod_first_arg
            ):
                self.add_message("bad-staticmethod-argument", args=first, node=node)
                return
            self._first_attrs[-1] = None
        elif "builtins.staticmethod" in node.decoratornames():
            # Check if there is a decorator which is not named `staticmethod`
            # but is assigned to one.
            return
        # class / regular method with no args
        elif not (
            node.args.args
            or node.args.posonlyargs
            or node.args.vararg
            or node.args.kwarg
        ):
            self.add_message("no-method-argument", node=node, args=node.name)
        # metaclass
        elif metaclass:
            # metaclass __new__ or classmethod
            if node.type == "classmethod":
                self._check_first_arg_config(
                    first,
                    self.linter.config.valid_metaclass_classmethod_first_arg,
                    node,
                    "bad-mcs-classmethod-argument",
                    node.name,
                )
            # metaclass regular method
            else:
                self._check_first_arg_config(
                    first,
                    self.linter.config.valid_classmethod_first_arg,
                    node,
                    "bad-mcs-method-argument",
                    node.name,
                )
        # regular class with class method
        elif node.type == "classmethod" or node.name == "__class_getitem__":
            self._check_first_arg_config(
                first,
                self.linter.config.valid_classmethod_first_arg,
                node,
                "bad-classmethod-argument",
                node.name,
            )
        # regular class with regular method without self as argument
        elif first != "self":
            self.add_message("no-self-argument", node=node, args=node.name)

</t>
<t tx="ekr.20250131013600.44">def is_from_fallback_block(node: nodes.NodeNG) -&gt; bool:
    """Check if the given node is from a fallback import block."""
    context = find_try_except_wrapper_node(node)
    if not context:
        return False

    if isinstance(context, nodes.ExceptHandler):
        other_body = context.parent.body
        handlers = context.parent.handlers
    else:
        other_body = itertools.chain.from_iterable(
            handler.body for handler in context.handlers
        )
        handlers = context.handlers

    has_fallback_imports = any(
        isinstance(import_node, (nodes.ImportFrom, nodes.Import))
        for import_node in other_body
    )
    ignores_import_error = _except_handlers_ignores_exceptions(
        handlers, (ImportError, ModuleNotFoundError)
    )
    return ignores_import_error or has_fallback_imports


</t>
<t tx="ekr.20250131013600.440">    def _check_first_arg_config(
        self,
        first: str | None,
        config: Sequence[str],
        node: nodes.FunctionDef,
        message: str,
        method_name: str,
    ) -&gt; None:
        if first not in config:
            if len(config) == 1:
                valid = repr(config[0])
            else:
                valid = ", ".join(repr(v) for v in config[:-1])
                valid = f"{valid} or {config[-1]!r}"
            self.add_message(message, args=(method_name, valid), node=node)

</t>
<t tx="ekr.20250131013600.441">    def _check_bases_classes(self, node: nodes.ClassDef) -&gt; None:
        """Check that the given class node implements abstract methods from
        base classes.
        """

        def is_abstract(method: nodes.FunctionDef) -&gt; bool:
            return method.is_abstract(pass_is_abstract=False)  # type: ignore[no-any-return]

        # check if this class abstract
        if class_is_abstract(node):
            return

        methods = sorted(
            unimplemented_abstract_methods(node, is_abstract).items(),
            key=lambda item: item[0],
        )
        for name, method in methods:
            owner = method.parent.frame()
            if owner is node:
                continue
            # owner is not this class, it must be a parent class
            # check that the ancestor's method is not abstract
            if name in node.locals:
                # it is redefined as an attribute or with a descriptor
                continue

            self.add_message(
                "abstract-method",
                node=node,
                args=(name, owner.name, node.name),
                confidence=INFERENCE,
            )

</t>
<t tx="ekr.20250131013600.442">    def _check_init(self, node: nodes.FunctionDef, klass_node: nodes.ClassDef) -&gt; None:
        """Check that the __init__ method call super or ancestors'__init__
        method (unless it is used for type hinting with `typing.overload`).
        """
        if not self.linter.is_message_enabled(
            "super-init-not-called"
        ) and not self.linter.is_message_enabled("non-parent-init-called"):
            return
        to_call = _ancestors_to_call(klass_node)
        not_called_yet = dict(to_call)
        parents_with_called_inits: set[bases.UnboundMethod] = set()
        for stmt in node.nodes_of_class(nodes.Call):
            expr = stmt.func
            if not isinstance(expr, nodes.Attribute) or expr.attrname != "__init__":
                continue
            # skip the test if using super
            if (
                isinstance(expr.expr, nodes.Call)
                and isinstance(expr.expr.func, nodes.Name)
                and expr.expr.func.name == "super"
            ):
                return
            # pylint: disable = too-many-try-statements
            try:
                for klass in expr.expr.infer():
                    if isinstance(klass, util.UninferableBase):
                        continue
                    # The inferred klass can be super(), which was
                    # assigned to a variable and the `__init__`
                    # was called later.
                    #
                    # base = super()
                    # base.__init__(...)

                    if (
                        isinstance(klass, astroid.Instance)
                        and isinstance(klass._proxied, nodes.ClassDef)
                        and is_builtin_object(klass._proxied)
                        and klass._proxied.name == "super"
                    ):
                        return
                    if isinstance(klass, astroid.objects.Super):
                        return
                    try:
                        method = not_called_yet.pop(klass)
                        # Record that the class' init has been called
                        parents_with_called_inits.add(node_frame_class(method))
                    except KeyError:
                        if klass not in klass_node.ancestors(recurs=False):
                            self.add_message(
                                "non-parent-init-called", node=expr, args=klass.name
                            )
            except astroid.InferenceError:
                continue
        for klass, method in not_called_yet.items():
            # Check if the init of the class that defines this init has already
            # been called.
            if node_frame_class(method) in parents_with_called_inits:
                return

            if utils.is_protocol_class(klass):
                return

            if decorated_with(node, ["typing.overload"]):
                continue
            self.add_message(
                "super-init-not-called",
                args=klass.name,
                node=node,
                confidence=INFERENCE,
            )

</t>
<t tx="ekr.20250131013600.443">    def _check_signature(
        self,
        method1: nodes.FunctionDef,
        refmethod: nodes.FunctionDef,
        cls: nodes.ClassDef,
    ) -&gt; None:
        """Check that the signature of the two given methods match."""
        if not (
            isinstance(method1, nodes.FunctionDef)
            and isinstance(refmethod, nodes.FunctionDef)
        ):
            self.add_message(
                "method-check-failed", args=(method1, refmethod), node=method1
            )
            return

        instance = cls.instantiate_class()
        method1 = astroid.scoped_nodes.function_to_method(method1, instance)
        refmethod = astroid.scoped_nodes.function_to_method(refmethod, instance)

        # Don't care about functions with unknown argument (builtins).
        if method1.args.args is None or refmethod.args.args is None:
            return

        # Ignore private to class methods.
        if is_attr_private(method1.name):
            return
        # Ignore setters, they have an implicit extra argument,
        # which shouldn't be taken in consideration.
        if is_property_setter(method1):
            return

        arg_differ_output = _different_parameters(
            refmethod, method1, dummy_parameter_regex=self._dummy_rgx
        )

        class_type = "overriding"

        if len(arg_differ_output) &gt; 0:
            for msg in arg_differ_output:
                if "Number" in msg:
                    total_args_method1 = len(method1.args.args)
                    if method1.args.vararg:
                        total_args_method1 += 1
                    if method1.args.kwarg:
                        total_args_method1 += 1
                    if method1.args.kwonlyargs:
                        total_args_method1 += len(method1.args.kwonlyargs)
                    total_args_refmethod = len(refmethod.args.args)
                    if refmethod.args.vararg:
                        total_args_refmethod += 1
                    if refmethod.args.kwarg:
                        total_args_refmethod += 1
                    if refmethod.args.kwonlyargs:
                        total_args_refmethod += len(refmethod.args.kwonlyargs)
                    error_type = "arguments-differ"
                    msg_args = (
                        msg
                        + f"was {total_args_refmethod} in '{refmethod.parent.frame().name}.{refmethod.name}' and "
                        f"is now {total_args_method1} in",
                        class_type,
                        f"{method1.parent.frame().name}.{method1.name}",
                    )
                elif "renamed" in msg:
                    error_type = "arguments-renamed"
                    msg_args = (
                        msg,
                        class_type,
                        f"{method1.parent.frame().name}.{method1.name}",
                    )
                else:
                    error_type = "arguments-differ"
                    msg_args = (
                        msg,
                        class_type,
                        f"{method1.parent.frame().name}.{method1.name}",
                    )
                self.add_message(error_type, args=msg_args, node=method1)
        elif (
            len(method1.args.defaults) &lt; len(refmethod.args.defaults)
            and not method1.args.vararg
        ):
            class_type = "overridden"
            self.add_message(
                "signature-differs", args=(class_type, method1.name), node=method1
            )

</t>
<t tx="ekr.20250131013600.444">    def _uses_mandatory_method_param(
        self, node: nodes.Attribute | nodes.Assign | nodes.AssignAttr
    ) -&gt; bool:
        """Check that attribute lookup name use first attribute variable name.

        Name is `self` for method, `cls` for classmethod and `mcs` for metaclass.
        """
        return self._is_mandatory_method_param(node.expr)

</t>
<t tx="ekr.20250131013600.445">    def _is_mandatory_method_param(self, node: nodes.NodeNG) -&gt; bool:
        """Check if nodes.Name corresponds to first attribute variable name.

        Name is `self` for method, `cls` for classmethod and `mcs` for metaclass.
        Static methods return False.
        """
        if self._first_attrs:
            first_attr = self._first_attrs[-1]
        else:
            # It's possible the function was already unregistered.
            closest_func = utils.get_node_first_ancestor_of_type(
                node, nodes.FunctionDef
            )
            if closest_func is None:
                return False
            if not closest_func.is_bound():
                return False
            if not closest_func.args.args:
                return False
            first_attr = closest_func.args.args[0].name
        return isinstance(node, nodes.Name) and node.name == first_attr


</t>
<t tx="ekr.20250131013600.446">@path pylint/checkers/classes
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Special methods checker and helper function's module."""

from __future__ import annotations

from collections.abc import Callable

import astroid
from astroid import bases, nodes, util
from astroid.context import InferenceContext
from astroid.typing import InferenceResult

from pylint.checkers import BaseChecker
from pylint.checkers.utils import (
    PYMETHODS,
    SPECIAL_METHODS_PARAMS,
    decorated_with,
    is_function_body_ellipsis,
    only_required_for_messages,
    safe_infer,
)
from pylint.lint.pylinter import PyLinter

NEXT_METHOD = "__next__"


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.447">def _safe_infer_call_result(
    node: nodes.FunctionDef,
    caller: nodes.FunctionDef,
    context: InferenceContext | None = None,
) -&gt; InferenceResult | None:
    """Safely infer the return value of a function.

    Returns None if inference failed or if there is some ambiguity (more than
    one node has been inferred). Otherwise, returns inferred value.
    """
    try:
        inferit = node.infer_call_result(caller, context=context)
        value = next(inferit)
    except astroid.InferenceError:
        return None  # inference failed
    except StopIteration:
        return None  # no values inferred
    try:
        next(inferit)
        return None  # there is ambiguity on the inferred node
    except astroid.InferenceError:
        return None  # there is some kind of ambiguity
    except StopIteration:
        return value


</t>
<t tx="ekr.20250131013600.448">class SpecialMethodsChecker(BaseChecker):
    """Checker which verifies that special methods
    are implemented correctly.
    """

    @others
</t>
<t tx="ekr.20250131013600.449">name = "classes"
msgs = {
    "E0301": (
        "__iter__ returns non-iterator",
        "non-iterator-returned",
        "Used when an __iter__ method returns something which is not an "
        f"iterable (i.e. has no `{NEXT_METHOD}` method)",
        {
            "old_names": [
                ("W0234", "old-non-iterator-returned-1"),
                ("E0234", "old-non-iterator-returned-2"),
            ]
        },
    ),
    "E0302": (
        "The special method %r expects %s param(s), %d %s given",
        "unexpected-special-method-signature",
        "Emitted when a special method was defined with an "
        "invalid number of parameters. If it has too few or "
        "too many, it might not work at all.",
        {"old_names": [("E0235", "bad-context-manager")]},
    ),
    "E0303": (
        "__len__ does not return non-negative integer",
        "invalid-length-returned",
        "Used when a __len__ method returns something which is not a "
        "non-negative integer",
    ),
    "E0304": (
        "__bool__ does not return bool",
        "invalid-bool-returned",
        "Used when a __bool__ method returns something which is not a bool",
    ),
    "E0305": (
        "__index__ does not return int",
        "invalid-index-returned",
        "Used when an __index__ method returns something which is not "
        "an integer",
    ),
    "E0306": (
        "__repr__ does not return str",
        "invalid-repr-returned",
        "Used when a __repr__ method returns something which is not a string",
    ),
    "E0307": (
        "__str__ does not return str",
        "invalid-str-returned",
        "Used when a __str__ method returns something which is not a string",
    ),
    "E0308": (
        "__bytes__ does not return bytes",
        "invalid-bytes-returned",
        "Used when a __bytes__ method returns something which is not bytes",
    ),
    "E0309": (
        "__hash__ does not return int",
        "invalid-hash-returned",
        "Used when a __hash__ method returns something which is not an integer",
    ),
    "E0310": (
        "__length_hint__ does not return non-negative integer",
        "invalid-length-hint-returned",
        "Used when a __length_hint__ method returns something which is not a "
        "non-negative integer",
    ),
    "E0311": (
        "__format__ does not return str",
        "invalid-format-returned",
        "Used when a __format__ method returns something which is not a string",
    ),
    "E0312": (
        "__getnewargs__ does not return a tuple",
        "invalid-getnewargs-returned",
        "Used when a __getnewargs__ method returns something which is not "
        "a tuple",
    ),
    "E0313": (
        "__getnewargs_ex__ does not return a tuple containing (tuple, dict)",
        "invalid-getnewargs-ex-returned",
        "Used when a __getnewargs_ex__ method returns something which is not "
        "of the form tuple(tuple, dict)",
    ),
}

def __init__(self, linter: PyLinter) -&gt; None:
    super().__init__(linter)
    self._protocol_map: dict[
        str, Callable[[nodes.FunctionDef, InferenceResult], None]
    ] = {
        "__iter__": self._check_iter,
        "__len__": self._check_len,
        "__bool__": self._check_bool,
        "__index__": self._check_index,
        "__repr__": self._check_repr,
        "__str__": self._check_str,
        "__bytes__": self._check_bytes,
        "__hash__": self._check_hash,
        "__length_hint__": self._check_length_hint,
        "__format__": self._check_format,
        "__getnewargs__": self._check_getnewargs,
        "__getnewargs_ex__": self._check_getnewargs_ex,
    }

</t>
<t tx="ekr.20250131013600.45">def _except_handlers_ignores_exceptions(
    handlers: nodes.ExceptHandler,
    exceptions: tuple[type[ImportError], type[ModuleNotFoundError]],
) -&gt; bool:
    func = partial(error_of_type, error_type=exceptions)
    return any(func(handler) for handler in handlers)


</t>
<t tx="ekr.20250131013600.450">@only_required_for_messages(
    "unexpected-special-method-signature",
    "non-iterator-returned",
    "invalid-length-returned",
    "invalid-bool-returned",
    "invalid-index-returned",
    "invalid-repr-returned",
    "invalid-str-returned",
    "invalid-bytes-returned",
    "invalid-hash-returned",
    "invalid-length-hint-returned",
    "invalid-format-returned",
    "invalid-getnewargs-returned",
    "invalid-getnewargs-ex-returned",
)
def visit_functiondef(self, node: nodes.FunctionDef) -&gt; None:
    if not node.is_method():
        return

    inferred = _safe_infer_call_result(node, node)
    # Only want to check types that we are able to infer
    if (
        inferred
        and node.name in self._protocol_map
        and not is_function_body_ellipsis(node)
    ):
        self._protocol_map[node.name](node, inferred)

    if node.name in PYMETHODS:
        self._check_unexpected_method_signature(node)

</t>
<t tx="ekr.20250131013600.451">visit_asyncfunctiondef = visit_functiondef

def _check_unexpected_method_signature(self, node: nodes.FunctionDef) -&gt; None:
    expected_params = SPECIAL_METHODS_PARAMS[node.name]

    if expected_params is None:
        # This can support a variable number of parameters.
        return
    if not node.args.args and not node.args.vararg:
        # Method has no parameter, will be caught
        # by no-method-argument.
        return

    if decorated_with(node, ["builtins.staticmethod"]):
        # We expect to not take in consideration self.
        all_args = node.args.args
    else:
        all_args = node.args.args[1:]
    mandatory = len(all_args) - len(node.args.defaults)
    optional = len(node.args.defaults)
    current_params = mandatory + optional

    emit = False  # If we don't know we choose a false negative
    if isinstance(expected_params, tuple):
        # The expected number of parameters can be any value from this
        # tuple, although the user should implement the method
        # to take all of them in consideration.
        emit = mandatory not in expected_params
        # mypy thinks that expected_params has type tuple[int, int] | int | None
        # But at this point it must be 'tuple[int, int]' because of the type check
        expected_params = f"between {expected_params[0]} or {expected_params[1]}"  # type: ignore[assignment]
    else:
        # If the number of mandatory parameters doesn't
        # suffice, the expected parameters for this
        # function will be deduced from the optional
        # parameters.
        rest = expected_params - mandatory
        if rest == 0:
            emit = False
        elif rest &lt; 0:
            emit = True
        elif rest &gt; 0:
            emit = not ((optional - rest) &gt;= 0 or node.args.vararg)

    if emit:
        verb = "was" if current_params &lt;= 1 else "were"
        self.add_message(
            "unexpected-special-method-signature",
            args=(node.name, expected_params, current_params, verb),
            node=node,
        )

</t>
<t tx="ekr.20250131013600.452">@staticmethod
def _is_wrapped_type(node: InferenceResult, type_: str) -&gt; bool:
    return (
        isinstance(node, bases.Instance)
        and node.name == type_
        and not isinstance(node, nodes.Const)
    )

</t>
<t tx="ekr.20250131013600.453">@staticmethod
def _is_int(node: InferenceResult) -&gt; bool:
    if SpecialMethodsChecker._is_wrapped_type(node, "int"):
        return True

    return isinstance(node, nodes.Const) and isinstance(node.value, int)

</t>
<t tx="ekr.20250131013600.454">@staticmethod
def _is_str(node: InferenceResult) -&gt; bool:
    if SpecialMethodsChecker._is_wrapped_type(node, "str"):
        return True

    return isinstance(node, nodes.Const) and isinstance(node.value, str)

</t>
<t tx="ekr.20250131013600.455">@staticmethod
def _is_bool(node: InferenceResult) -&gt; bool:
    if SpecialMethodsChecker._is_wrapped_type(node, "bool"):
        return True

    return isinstance(node, nodes.Const) and isinstance(node.value, bool)

</t>
<t tx="ekr.20250131013600.456">@staticmethod
def _is_bytes(node: InferenceResult) -&gt; bool:
    if SpecialMethodsChecker._is_wrapped_type(node, "bytes"):
        return True

    return isinstance(node, nodes.Const) and isinstance(node.value, bytes)

</t>
<t tx="ekr.20250131013600.457">@staticmethod
def _is_tuple(node: InferenceResult) -&gt; bool:
    if SpecialMethodsChecker._is_wrapped_type(node, "tuple"):
        return True

    return isinstance(node, nodes.Const) and isinstance(node.value, tuple)

</t>
<t tx="ekr.20250131013600.458">@staticmethod
def _is_dict(node: InferenceResult) -&gt; bool:
    if SpecialMethodsChecker._is_wrapped_type(node, "dict"):
        return True

    return isinstance(node, nodes.Const) and isinstance(node.value, dict)

</t>
<t tx="ekr.20250131013600.459">@staticmethod
def _is_iterator(node: InferenceResult) -&gt; bool:
    if isinstance(node, bases.Generator):
        # Generators can be iterated.
        return True
    if isinstance(node, nodes.ComprehensionScope):
        # Comprehensions can be iterated.
        return True

    if isinstance(node, bases.Instance):
        try:
            node.local_attr(NEXT_METHOD)
            return True
        except astroid.NotFoundError:
            pass
    elif isinstance(node, nodes.ClassDef):
        metaclass = node.metaclass()
        if metaclass and isinstance(metaclass, nodes.ClassDef):
            try:
                metaclass.local_attr(NEXT_METHOD)
                return True
            except astroid.NotFoundError:
                pass
    return False

</t>
<t tx="ekr.20250131013600.46">def get_exception_handlers(
    node: nodes.NodeNG, exception: type[Exception] | str = Exception
) -&gt; list[nodes.ExceptHandler] | None:
    """Return the collections of handlers handling the exception in arguments.

    Args:
        node (nodes.NodeNG): A node that is potentially wrapped in a try except.
        exception (builtin.Exception or str): exception or name of the exception.

    Returns:
        list: the collection of handlers that are handling the exception or None.
    """
    context = find_try_except_wrapper_node(node)
    if isinstance(context, nodes.Try):
        return [
            handler for handler in context.handlers if error_of_type(handler, exception)
        ]
    return []


</t>
<t tx="ekr.20250131013600.460">def _check_iter(self, node: nodes.FunctionDef, inferred: InferenceResult) -&gt; None:
    if not self._is_iterator(inferred):
        self.add_message("non-iterator-returned", node=node)

</t>
<t tx="ekr.20250131013600.461">def _check_len(self, node: nodes.FunctionDef, inferred: InferenceResult) -&gt; None:
    if not self._is_int(inferred):
        self.add_message("invalid-length-returned", node=node)
    elif isinstance(inferred, nodes.Const) and inferred.value &lt; 0:
        self.add_message("invalid-length-returned", node=node)

</t>
<t tx="ekr.20250131013600.462">def _check_bool(self, node: nodes.FunctionDef, inferred: InferenceResult) -&gt; None:
    if not self._is_bool(inferred):
        self.add_message("invalid-bool-returned", node=node)

</t>
<t tx="ekr.20250131013600.463">def _check_index(self, node: nodes.FunctionDef, inferred: InferenceResult) -&gt; None:
    if not self._is_int(inferred):
        self.add_message("invalid-index-returned", node=node)

</t>
<t tx="ekr.20250131013600.464">def _check_repr(self, node: nodes.FunctionDef, inferred: InferenceResult) -&gt; None:
    if not self._is_str(inferred):
        self.add_message("invalid-repr-returned", node=node)

</t>
<t tx="ekr.20250131013600.465">def _check_str(self, node: nodes.FunctionDef, inferred: InferenceResult) -&gt; None:
    if not self._is_str(inferred):
        self.add_message("invalid-str-returned", node=node)

</t>
<t tx="ekr.20250131013600.466">def _check_bytes(self, node: nodes.FunctionDef, inferred: InferenceResult) -&gt; None:
    if not self._is_bytes(inferred):
        self.add_message("invalid-bytes-returned", node=node)

</t>
<t tx="ekr.20250131013600.467">def _check_hash(self, node: nodes.FunctionDef, inferred: InferenceResult) -&gt; None:
    if not self._is_int(inferred):
        self.add_message("invalid-hash-returned", node=node)

</t>
<t tx="ekr.20250131013600.468">def _check_length_hint(
    self, node: nodes.FunctionDef, inferred: InferenceResult
) -&gt; None:
    if not self._is_int(inferred):
        self.add_message("invalid-length-hint-returned", node=node)
    elif isinstance(inferred, nodes.Const) and inferred.value &lt; 0:
        self.add_message("invalid-length-hint-returned", node=node)

</t>
<t tx="ekr.20250131013600.469">def _check_format(self, node: nodes.FunctionDef, inferred: InferenceResult) -&gt; None:
    if not self._is_str(inferred):
        self.add_message("invalid-format-returned", node=node)

</t>
<t tx="ekr.20250131013600.47">def get_contextlib_with_statements(node: nodes.NodeNG) -&gt; Iterator[nodes.With]:
    """Get all contextlib.with statements in the ancestors of the given node."""
    for with_node in node.node_ancestors():
        if isinstance(with_node, nodes.With):
            yield with_node


</t>
<t tx="ekr.20250131013600.470">def _check_getnewargs(
    self, node: nodes.FunctionDef, inferred: InferenceResult
) -&gt; None:
    if not self._is_tuple(inferred):
        self.add_message("invalid-getnewargs-returned", node=node)

</t>
<t tx="ekr.20250131013600.471">def _check_getnewargs_ex(
    self, node: nodes.FunctionDef, inferred: InferenceResult
) -&gt; None:
    if not self._is_tuple(inferred):
        self.add_message("invalid-getnewargs-ex-returned", node=node)
        return

    if not isinstance(inferred, nodes.Tuple):
        # If it's not an astroid.Tuple we can't analyze it further
        return

    found_error = False

    if len(inferred.elts) != 2:
        found_error = True
    else:
        for arg, check in (
            (inferred.elts[0], self._is_tuple),
            (inferred.elts[1], self._is_dict),
        ):
            if isinstance(arg, (nodes.Call, nodes.Name)):
                arg = safe_infer(arg)

            if arg and not isinstance(arg, util.UninferableBase):
                if not check(arg):
                    found_error = True
                    break

    if found_error:
        self.add_message("invalid-getnewargs-ex-returned", node=node)
</t>
<t tx="ekr.20250131013600.472"></t>
<t tx="ekr.20250131013600.473">@path pylint/checkers/refactoring
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Looks for code which can be refactored."""

from __future__ import annotations

from typing import TYPE_CHECKING

from pylint.checkers.refactoring.implicit_booleaness_checker import (
    ImplicitBooleanessChecker,
)
from pylint.checkers.refactoring.not_checker import NotChecker
from pylint.checkers.refactoring.recommendation_checker import RecommendationChecker
from pylint.checkers.refactoring.refactoring_checker import RefactoringChecker

if TYPE_CHECKING:
    from pylint.lint import PyLinter

__all__ = [
    "ImplicitBooleanessChecker",
    "NotChecker",
    "RecommendationChecker",
    "RefactoringChecker",
]


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.474">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(RefactoringChecker(linter))
    linter.register_checker(NotChecker(linter))
    linter.register_checker(RecommendationChecker(linter))
    linter.register_checker(ImplicitBooleanessChecker(linter))
</t>
<t tx="ekr.20250131013600.475">@path pylint/checkers/refactoring
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import itertools

import astroid
from astroid import bases, nodes, util

from pylint import checkers
from pylint.checkers import utils
from pylint.interfaces import HIGH, INFERENCE


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.476">def _is_constant_zero(node: str | nodes.NodeNG) -&gt; bool:
    # We have to check that node.value is not False because node.value == 0 is True
    # when node.value is False
    return (
        isinstance(node, astroid.Const) and node.value == 0 and node.value is not False
    )


</t>
<t tx="ekr.20250131013600.477">class ImplicitBooleanessChecker(checkers.BaseChecker):
    """Checks for incorrect usage of comparisons or len() inside conditions.

    Incorrect usage of len()
    Pep8 states:
    For sequences, (strings, lists, tuples), use the fact that empty sequences are false.

        Yes: if not seq:
             if seq:

        No: if len(seq):
            if not len(seq):

    Problems detected:
    * if len(sequence):
    * if not len(sequence):
    * elif len(sequence):
    * elif not len(sequence):
    * while len(sequence):
    * while not len(sequence):
    * assert len(sequence):
    * assert not len(sequence):
    * bool(len(sequence))

    Incorrect usage of empty literal sequences; (), [], {},

    For empty sequences, (dicts, lists, tuples), use the fact that empty sequences are false.

        Yes: if variable:
             if not variable

        No: if variable == empty_literal:
            if variable != empty_literal:

    Problems detected:
    * comparison such as variable == empty_literal:
    * comparison such as variable != empty_literal:
    """

    @others
</t>
<t tx="ekr.20250131013600.478">name = "refactoring"
msgs = {
    "C1802": (
        "Do not use `len(SEQUENCE)` without comparison to determine if a sequence is empty",
        "use-implicit-booleaness-not-len",
        "Empty sequences are considered false in a boolean context. You can either"
        " remove the call to 'len' (``if not x``) or compare the length against a"
        " scalar (``if len(x) &gt; 1``).",
        {"old_names": [("C1801", "len-as-condition")]},
    ),
    "C1803": (
        '"%s" can be simplified to "%s", if it is strictly a sequence, as an empty %s is falsey',
        "use-implicit-booleaness-not-comparison",
        "Empty sequences are considered false in a boolean context. Following this"
        " check blindly in weakly typed code base can create hard to debug issues."
        " If the value can be something else that is falsey but not a sequence (for"
        " example ``None``, an empty string, or ``0``) the code will not be "
        "equivalent.",
    ),
    "C1804": (
        '"%s" can be simplified to "%s", if it is strictly a string, as an empty string is falsey',
        "use-implicit-booleaness-not-comparison-to-string",
        "Empty string are considered false in a boolean context. Following this"
        " check blindly in weakly typed code base can create hard to debug issues."
        " If the value can be something else that is falsey but not a string (for"
        " example ``None``, an empty sequence, or ``0``) the code will not be "
        "equivalent.",
        {
            "default_enabled": False,
            "old_names": [("C1901", "compare-to-empty-string")],
        },
    ),
    "C1805": (
        '"%s" can be simplified to "%s", if it is strictly an int, as 0 is falsey',
        "use-implicit-booleaness-not-comparison-to-zero",
        "0 is considered false in a boolean context. Following this"
        " check blindly in weakly typed code base can create hard to debug issues."
        " If the value can be something else that is falsey but not an int (for"
        " example ``None``, an empty string, or an empty sequence) the code will not be "
        "equivalent.",
        {"default_enabled": False, "old_names": [("C2001", "compare-to-zero")]},
    ),
}

options = ()
_operators = {"!=", "==", "is not", "is"}

@utils.only_required_for_messages("use-implicit-booleaness-not-len")
def visit_call(self, node: nodes.Call) -&gt; None:
    # a len(S) call is used inside a test condition
    # could be if, while, assert or if expression statement
    # e.g. `if len(S):`
    if not utils.is_call_of_name(node, "len"):
        return
    # the len() call could also be nested together with other
    # boolean operations, e.g. `if z or len(x):`
    parent = node.parent
    while isinstance(parent, nodes.BoolOp):
        parent = parent.parent
    # we're finally out of any nested boolean operations so check if
    # this len() call is part of a test condition
    if not utils.is_test_condition(node, parent):
        return
    len_arg = node.args[0]
    if isinstance(len_arg, (nodes.ListComp, nodes.SetComp, nodes.DictComp)):
        # The node is a comprehension as in len([x for x in ...])
        self.add_message(
            "use-implicit-booleaness-not-len",
            node=node,
            confidence=HIGH,
        )
        return
    try:
        instance = next(len_arg.infer())
    except astroid.InferenceError:
        # Probably undefined-variable, abort check
        return
    mother_classes = self.base_names_of_instance(instance)
    affected_by_pep8 = any(
        t in mother_classes for t in ("str", "tuple", "list", "set")
    )
    if "range" in mother_classes or (
        affected_by_pep8 and not self.instance_has_bool(instance)
    ):
        self.add_message(
            "use-implicit-booleaness-not-len",
            node=node,
            confidence=INFERENCE,
        )

</t>
<t tx="ekr.20250131013600.479">@staticmethod
def instance_has_bool(class_def: nodes.ClassDef) -&gt; bool:
    try:
        class_def.getattr("__bool__")
        return True
    except astroid.AttributeInferenceError:
        ...
    return False

</t>
<t tx="ekr.20250131013600.48">def _suppresses_exception(
    call: nodes.Call, exception: type[Exception] | str = Exception
) -&gt; bool:
    """Check if the given node suppresses the given exception."""
    if not isinstance(exception, str):
        exception = exception.__name__
    for arg in call.args:
        inferred = safe_infer(arg)
        if isinstance(inferred, nodes.ClassDef):
            if inferred.name == exception:
                return True
        elif isinstance(inferred, nodes.Tuple):
            for elt in inferred.elts:
                inferred_elt = safe_infer(elt)
                if (
                    isinstance(inferred_elt, nodes.ClassDef)
                    and inferred_elt.name == exception
                ):
                    return True
    return False


</t>
<t tx="ekr.20250131013600.480">@utils.only_required_for_messages("use-implicit-booleaness-not-len")
def visit_unaryop(self, node: nodes.UnaryOp) -&gt; None:
    """`not len(S)` must become `not S` regardless if the parent block is a test
    condition or something else (boolean expression) e.g. `if not len(S):`.
    """
    if (
        isinstance(node, nodes.UnaryOp)
        and node.op == "not"
        and utils.is_call_of_name(node.operand, "len")
    ):
        self.add_message(
            "use-implicit-booleaness-not-len", node=node, confidence=HIGH
        )

</t>
<t tx="ekr.20250131013600.481">@utils.only_required_for_messages(
    "use-implicit-booleaness-not-comparison",
    "use-implicit-booleaness-not-comparison-to-string",
    "use-implicit-booleaness-not-comparison-to-zero",
)
def visit_compare(self, node: nodes.Compare) -&gt; None:
    if self.linter.is_message_enabled("use-implicit-booleaness-not-comparison"):
        self._check_use_implicit_booleaness_not_comparison(node)
    if self.linter.is_message_enabled(
        "use-implicit-booleaness-not-comparison-to-zero"
    ) or self.linter.is_message_enabled(
        "use-implicit-booleaness-not-comparison-to-str"
    ):
        self._check_compare_to_str_or_zero(node)

</t>
<t tx="ekr.20250131013600.482">def _check_compare_to_str_or_zero(self, node: nodes.Compare) -&gt; None:
    # note: astroid.Compare has the left most operand in node.left
    # while the rest are a list of tuples in node.ops
    # the format of the tuple is ('compare operator sign', node)
    # here we squash everything into `ops` to make it easier for processing later
    ops: list[tuple[str, nodes.NodeNG]] = [("", node.left), * node.ops]
    iter_ops = iter(ops)
    all_ops = list(itertools.chain(*iter_ops))
    for ops_idx in range(len(all_ops) - 2):
        op_2 = all_ops[ops_idx + 1]
        if op_2 not in self._operators:
            continue
        op_1 = all_ops[ops_idx]
        op_3 = all_ops[ops_idx + 2]
        if self.linter.is_message_enabled(
            "use-implicit-booleaness-not-comparison-to-zero"
        ):
            op = None
            # 0 ?? X
            if _is_constant_zero(op_1):
                op = op_3
            # X ?? 0
            elif _is_constant_zero(op_3):
                op = op_1
            if op is not None:
                original = f"{op_1.as_string()} {op_2} {op_3.as_string()}"
                suggestion = (
                    op.as_string()
                    if op_2 in {"!=", "is not"}
                    else f"not {op.as_string()}"
                )
                self.add_message(
                    "use-implicit-booleaness-not-comparison-to-zero",
                    args=(original, suggestion),
                    node=node,
                    confidence=HIGH,
                )
        if self.linter.is_message_enabled(
            "use-implicit-booleaness-not-comparison-to-str"
        ):
            node_name = None
            # x ?? ""
            if utils.is_empty_str_literal(op_1):
                node_name = op_3.as_string()
            # '' ?? X
            elif utils.is_empty_str_literal(op_3):
                node_name = op_1.as_string()
            if node_name is not None:
                suggestion = (
                    f"not {node_name}" if op_2 in {"==", "is"} else node_name
                )
                self.add_message(
                    "use-implicit-booleaness-not-comparison-to-string",
                    args=(node.as_string(), suggestion),
                    node=node,
                    confidence=HIGH,
                )

</t>
<t tx="ekr.20250131013600.483">def _check_use_implicit_booleaness_not_comparison(
    self, node: nodes.Compare
) -&gt; None:
    """Check for left side and right side of the node for empty literals."""
    is_left_empty_literal = utils.is_base_container(
        node.left
    ) or utils.is_empty_dict_literal(node.left)

    # Check both left-hand side and right-hand side for literals
    for operator, comparator in node.ops:
        is_right_empty_literal = utils.is_base_container(
            comparator
        ) or utils.is_empty_dict_literal(comparator)
        # Using Exclusive OR (XOR) to compare between two side.
        # If two sides are both literal, it should be different error.
        if is_right_empty_literal ^ is_left_empty_literal:
            # set target_node to opposite side of literal
            target_node = node.left if is_right_empty_literal else comparator
            literal_node = comparator if is_right_empty_literal else node.left
            # Infer node to check
            target_instance = utils.safe_infer(target_node)
            if target_instance is None:
                continue
            mother_classes = self.base_names_of_instance(target_instance)
            is_base_comprehension_type = any(
                t in mother_classes for t in ("tuple", "list", "dict", "set")
            )

            # Only time we bypass check is when target_node is not inherited by
            # collection literals and have its own __bool__ implementation.
            if not is_base_comprehension_type and self.instance_has_bool(
                target_instance
            ):
                continue

            # No need to check for operator when visiting compare node
            if operator in {"==", "!=", "&gt;=", "&gt;", "&lt;=", "&lt;"}:
                self.add_message(
                    "use-implicit-booleaness-not-comparison",
                    args=self._implicit_booleaness_message_args(
                        literal_node, operator, target_node
                    ),
                    node=node,
                    confidence=HIGH,
                )

</t>
<t tx="ekr.20250131013600.484">def _get_node_description(self, node: nodes.NodeNG) -&gt; str:
    return {
        nodes.List: "list",
        nodes.Tuple: "tuple",
        nodes.Dict: "dict",
        nodes.Const: "str",
    }.get(type(node), "iterable")

</t>
<t tx="ekr.20250131013600.485">def _implicit_booleaness_message_args(
    self, literal_node: nodes.NodeNG, operator: str, target_node: nodes.NodeNG
) -&gt; tuple[str, str, str]:
    """Helper to get the right message for "use-implicit-booleaness-not-comparison"."""
    description = self._get_node_description(literal_node)
    collection_literal = {
        "list": "[]",
        "tuple": "()",
        "dict": "{}",
    }.get(description, "iterable")
    instance_name = "x"
    if isinstance(target_node, nodes.Call) and target_node.func:
        instance_name = f"{target_node.func.as_string()}(...)"
    elif isinstance(target_node, (nodes.Attribute, nodes.Name)):
        instance_name = target_node.as_string()
    original_comparison = f"{instance_name} {operator} {collection_literal}"
    suggestion = f"{instance_name}" if operator == "!=" else f"not {instance_name}"
    return original_comparison, suggestion, description

</t>
<t tx="ekr.20250131013600.486">@staticmethod
def base_names_of_instance(
    node: util.UninferableBase | bases.Instance,
) -&gt; list[str]:
    """Return all names inherited by a class instance or those returned by a
    function.

    The inherited names include 'object'.
    """
    if isinstance(node, bases.Instance):
        return [node.name] + [x.name for x in node.ancestors()]
    return []
</t>
<t tx="ekr.20250131013600.487">@path pylint/checkers/refactoring
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

import astroid
from astroid import nodes

from pylint import checkers
from pylint.checkers import utils


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.488">class NotChecker(checkers.BaseChecker):
    """Checks for too many not in comparison expressions.

    - "not not" should trigger a warning
    - "not" followed by a comparison should trigger a warning
    """

    @others
</t>
<t tx="ekr.20250131013600.489">msgs = {
    "C0117": (
        'Consider changing "%s" to "%s"',
        "unnecessary-negation",
        "Used when a boolean expression contains an unneeded negation, "
        "e.g. when two negation operators cancel each other out.",
        {"old_names": [("C0113", "unneeded-not")]},
    )
}
name = "refactoring"
reverse_op = {
    "&lt;": "&gt;=",
    "&lt;=": "&gt;",
    "&gt;": "&lt;=",
    "&gt;=": "&lt;",
    "==": "!=",
    "!=": "==",
    "in": "not in",
    "is": "is not",
}
# sets are not ordered, so for example "not set(LEFT_VALS) &lt;= set(RIGHT_VALS)" is
# not equivalent to "set(LEFT_VALS) &gt; set(RIGHT_VALS)"
skipped_nodes = (nodes.Set,)
# 'builtins' py3, '__builtin__' py2
skipped_classnames = [f"builtins.{qname}" for qname in ("set", "frozenset")]

@utils.only_required_for_messages("unnecessary-negation")
def visit_unaryop(self, node: nodes.UnaryOp) -&gt; None:
    if node.op != "not":
        return
    operand = node.operand

    if isinstance(operand, nodes.UnaryOp) and operand.op == "not":
        self.add_message(
            "unnecessary-negation",
            node=node,
            args=(node.as_string(), operand.operand.as_string()),
        )
    elif isinstance(operand, nodes.Compare):
        left = operand.left
        # ignore multiple comparisons
        if len(operand.ops) &gt; 1:
            return
        operator, right = operand.ops[0]
        if operator not in self.reverse_op:
            return
        # Ignore __ne__ as function of __eq__
        frame = node.frame()
        if frame.name == "__ne__" and operator == "==":
            return
        for _type in (utils.node_type(left), utils.node_type(right)):
            if not _type:
                return
            if isinstance(_type, self.skipped_nodes):
                return
            if (
                isinstance(_type, astroid.Instance)
                and _type.qname() in self.skipped_classnames
            ):
                return
        suggestion = (
            f"{left.as_string()} {self.reverse_op[operator]} {right.as_string()}"
        )
        self.add_message(
            "unnecessary-negation", node=node, args=(node.as_string(), suggestion)
        )
</t>
<t tx="ekr.20250131013600.49">def get_contextlib_suppressors(
    node: nodes.NodeNG, exception: type[Exception] | str = Exception
) -&gt; Iterator[nodes.With]:
    """Return the contextlib suppressors handling the exception.

    Args:
        node (nodes.NodeNG): A node that is potentially wrapped in a contextlib.suppress.
        exception (builtin.Exception): exception or name of the exception.

    Yields:
        nodes.With: A with node that is suppressing the exception.
    """
    for with_node in get_contextlib_with_statements(node):
        for item, _ in with_node.items:
            if isinstance(item, nodes.Call):
                inferred = safe_infer(item.func)
                if (
                    isinstance(inferred, nodes.ClassDef)
                    and inferred.qname() == "contextlib.suppress"
                ):
                    if _suppresses_exception(item, exception):
                        yield with_node


</t>
<t tx="ekr.20250131013600.490">@path pylint/checkers/refactoring
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import astroid
from astroid import nodes

from pylint import checkers
from pylint.checkers import utils
from pylint.interfaces import HIGH, INFERENCE


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.491">class RecommendationChecker(checkers.BaseChecker):
    @others
</t>
<t tx="ekr.20250131013600.492">name = "refactoring"
msgs = {
    "C0200": (
        "Consider using enumerate instead of iterating with range and len",
        "consider-using-enumerate",
        "Emitted when code that iterates with range and len is "
        "encountered. Such code can be simplified by using the "
        "enumerate builtin.",
    ),
    "C0201": (
        "Consider iterating the dictionary directly instead of calling .keys()",
        "consider-iterating-dictionary",
        "Emitted when the keys of a dictionary are iterated through the ``.keys()`` "
        "method or when ``.keys()`` is used for a membership check. "
        "It is enough to iterate through the dictionary itself, "
        "``for key in dictionary``. For membership checks, "
        "``if key in dictionary`` is faster.",
    ),
    "C0206": (
        "Consider iterating with .items()",
        "consider-using-dict-items",
        "Emitted when iterating over the keys of a dictionary and accessing the "
        "value by index lookup. "
        "Both the key and value can be accessed by iterating using the .items() "
        "method of the dictionary instead.",
    ),
    "C0207": (
        "Use %s instead",
        "use-maxsplit-arg",
        "Emitted when accessing only the first or last element of str.split(). "
        "The first and last element can be accessed by using "
        "str.split(sep, maxsplit=1)[0] or str.rsplit(sep, maxsplit=1)[-1] "
        "instead.",
    ),
    "C0208": (
        "Use a sequence type when iterating over values",
        "use-sequence-for-iteration",
        "When iterating over values, sequence types (e.g., ``lists``, ``tuples``, ``ranges``) "
        "are more efficient than ``sets``.",
    ),
    "C0209": (
        "Formatting a regular string which could be an f-string",
        "consider-using-f-string",
        "Used when we detect a string that is being formatted with format() or % "
        "which could potentially be an f-string. The use of f-strings is preferred. "
        "Requires Python 3.6 and ``py-version &gt;= 3.6``.",
    ),
}

def open(self) -&gt; None:
    py_version = self.linter.config.py_version
    self._py36_plus = py_version &gt;= (3, 6)

</t>
<t tx="ekr.20250131013600.493">@staticmethod
def _is_builtin(node: nodes.NodeNG, function: str) -&gt; bool:
    inferred = utils.safe_infer(node)
    if not inferred:
        return False
    return utils.is_builtin_object(inferred) and inferred.name == function

</t>
<t tx="ekr.20250131013600.494">@utils.only_required_for_messages(
    "consider-iterating-dictionary", "use-maxsplit-arg"
)
def visit_call(self, node: nodes.Call) -&gt; None:
    self._check_consider_iterating_dictionary(node)
    self._check_use_maxsplit_arg(node)

</t>
<t tx="ekr.20250131013600.495">def _check_consider_iterating_dictionary(self, node: nodes.Call) -&gt; None:
    if not isinstance(node.func, nodes.Attribute):
        return
    if node.func.attrname != "keys":
        return

    if isinstance(node.parent, nodes.BinOp) and node.parent.op in {"&amp;", "|", "^"}:
        return

    comp_ancestor = utils.get_node_first_ancestor_of_type(node, nodes.Compare)
    if isinstance(node.parent, (nodes.For, nodes.Comprehension)) or (
        comp_ancestor
        and any(
            op
            for op, comparator in comp_ancestor.ops
            if op in {"in", "not in"}
            and (comparator in node.node_ancestors() or comparator is node)
        )
    ):
        inferred = utils.safe_infer(node.func)
        if not isinstance(inferred, astroid.BoundMethod) or not isinstance(
            inferred.bound, nodes.Dict
        ):
            return
        self.add_message(
            "consider-iterating-dictionary", node=node, confidence=INFERENCE
        )

</t>
<t tx="ekr.20250131013600.496">def _check_use_maxsplit_arg(self, node: nodes.Call) -&gt; None:
    """Add message when accessing first or last elements of a str.split() or
    str.rsplit().
    """
    # Check if call is split() or rsplit()
    if not (
        isinstance(node.func, nodes.Attribute)
        and node.func.attrname in {"split", "rsplit"}
        and isinstance(utils.safe_infer(node.func), astroid.BoundMethod)
    ):
        return
    inferred_expr = utils.safe_infer(node.func.expr)
    if isinstance(inferred_expr, astroid.Instance) and any(
        inferred_expr.nodes_of_class(nodes.ClassDef)
    ):
        return

    confidence = HIGH
    try:
        sep = utils.get_argument_from_call(node, 0, "sep")
    except utils.NoSuchArgumentError:
        sep = utils.infer_kwarg_from_call(node, keyword="sep")
        confidence = INFERENCE
        if not sep:
            return

    try:
        # Ignore if maxsplit arg has been set
        utils.get_argument_from_call(node, 1, "maxsplit")
        return
    except utils.NoSuchArgumentError:
        if utils.infer_kwarg_from_call(node, keyword="maxsplit"):
            return

    if isinstance(node.parent, nodes.Subscript):
        try:
            subscript_value = utils.get_subscript_const_value(node.parent).value
        except utils.InferredTypeError:
            return

        # Check for cases where variable (Name) subscripts may be mutated within a loop
        if isinstance(node.parent.slice, nodes.Name):
            # Check if loop present within the scope of the node
            scope = node.scope()
            for loop_node in scope.nodes_of_class((nodes.For, nodes.While)):
                if not loop_node.parent_of(node):
                    continue

                # Check if var is mutated within loop (Assign/AugAssign)
                for assignment_node in loop_node.nodes_of_class(nodes.AugAssign):
                    if node.parent.slice.name == assignment_node.target.name:
                        return
                for assignment_node in loop_node.nodes_of_class(nodes.Assign):
                    if node.parent.slice.name in [
                        n.name for n in assignment_node.targets
                    ]:
                        return

        if subscript_value in (-1, 0):
            fn_name = node.func.attrname
            new_fn = "rsplit" if subscript_value == -1 else "split"
            new_name = (
                node.func.as_string().rsplit(fn_name, maxsplit=1)[0]
                + new_fn
                + f"({sep.as_string()}, maxsplit=1)[{subscript_value}]"
            )
            self.add_message(
                "use-maxsplit-arg",
                node=node,
                args=(new_name,),
                confidence=confidence,
            )

</t>
<t tx="ekr.20250131013600.497">@utils.only_required_for_messages(
    "consider-using-enumerate",
    "consider-using-dict-items",
    "use-sequence-for-iteration",
)
def visit_for(self, node: nodes.For) -&gt; None:
    self._check_consider_using_enumerate(node)
    self._check_consider_using_dict_items(node)
    self._check_use_sequence_for_iteration(node)

</t>
<t tx="ekr.20250131013600.498">def _check_consider_using_enumerate(self, node: nodes.For) -&gt; None:
    """Emit a convention whenever range and len are used for indexing."""
    # Verify that we have a `range([start], len(...), [stop])` call and
    # that the object which is iterated is used as a subscript in the
    # body of the for.

    # Is it a proper range call?
    if not isinstance(node.iter, nodes.Call):
        return
    if not self._is_builtin(node.iter.func, "range"):
        return
    if not node.iter.args:
        return
    is_constant_zero = (
        isinstance(node.iter.args[0], nodes.Const) and node.iter.args[0].value == 0
    )
    if len(node.iter.args) == 2 and not is_constant_zero:
        return
    if len(node.iter.args) &gt; 2:
        return

    # Is it a proper len call?
    if not isinstance(node.iter.args[-1], nodes.Call):
        return
    second_func = node.iter.args[-1].func
    if not self._is_builtin(second_func, "len"):
        return
    len_args = node.iter.args[-1].args
    if not len_args or len(len_args) != 1:
        return
    iterating_object = len_args[0]
    if isinstance(iterating_object, nodes.Name):
        expected_subscript_val_type = nodes.Name
    elif isinstance(iterating_object, nodes.Attribute):
        expected_subscript_val_type = nodes.Attribute
    else:
        return
    # If we're defining __iter__ on self, enumerate won't work
    scope = node.scope()
    if (
        isinstance(iterating_object, nodes.Name)
        and iterating_object.name == "self"
        and scope.name == "__iter__"
    ):
        return

    # Verify that the body of the for loop uses a subscript
    # with the object that was iterated. This uses some heuristics
    # in order to make sure that the same object is used in the
    # for body.
    for child in node.body:
        for subscript in child.nodes_of_class(nodes.Subscript):
            if not isinstance(subscript.value, expected_subscript_val_type):
                continue

            value = subscript.slice
            if not isinstance(value, nodes.Name):
                continue
            if subscript.value.scope() != node.scope():
                # Ignore this subscript if it's not in the same
                # scope. This means that in the body of the for
                # loop, another scope was created, where the same
                # name for the iterating object was used.
                continue
            if value.name == node.target.name and (
                (
                    isinstance(subscript.value, nodes.Name)
                    and iterating_object.name == subscript.value.name
                )
                or (
                    isinstance(subscript.value, nodes.Attribute)
                    and iterating_object.attrname == subscript.value.attrname
                )
            ):
                self.add_message("consider-using-enumerate", node=node)
                return

</t>
<t tx="ekr.20250131013600.499">def _check_consider_using_dict_items(self, node: nodes.For) -&gt; None:
    """Add message when accessing dict values by index lookup."""
    # Verify that we have a .keys() call and
    # that the object which is iterated is used as a subscript in the
    # body of the for.

    iterating_object_name = utils.get_iterating_dictionary_name(node)
    if iterating_object_name is None:
        return

    # Verify that the body of the for loop uses a subscript
    # with the object that was iterated. This uses some heuristics
    # in order to make sure that the same object is used in the
    # for body.
    for child in node.body:
        for subscript in child.nodes_of_class(nodes.Subscript):
            if not isinstance(subscript.value, (nodes.Name, nodes.Attribute)):
                continue

            value = subscript.slice
            if (
                not isinstance(value, nodes.Name)
                or value.name != node.target.name
                or iterating_object_name != subscript.value.as_string()
            ):
                continue
            last_definition_lineno = value.lookup(value.name)[1][-1].lineno
            if last_definition_lineno &gt; node.lineno:
                # Ignore this subscript if it has been redefined after
                # the for loop. This checks for the line number using .lookup()
                # to get the line number where the iterating object was last
                # defined and compare that to the for loop's line number
                continue
            if (
                isinstance(subscript.parent, nodes.Assign)
                and subscript in subscript.parent.targets
            ) or (
                isinstance(subscript.parent, nodes.AugAssign)
                and subscript == subscript.parent.target
            ):
                # Ignore this subscript if it is the target of an assignment
                # Early termination as dict index lookup is necessary
                return
            if isinstance(subscript.parent, nodes.Delete):
                # Ignore this subscript if the index is used to delete a
                # dictionary item.
                return

            self.add_message("consider-using-dict-items", node=node)
            return

</t>
<t tx="ekr.20250131013600.5">def is_error(node: nodes.FunctionDef) -&gt; bool:
    """Return true if the given function node only raises an exception."""
    return len(node.body) == 1 and isinstance(node.body[0], nodes.Raise)


</t>
<t tx="ekr.20250131013600.50">def is_node_inside_try_except(node: nodes.Raise) -&gt; bool:
    """Check if the node is directly under a Try/Except statement
    (but not under an ExceptHandler!).

    Args:
        node (nodes.Raise): the node raising the exception.

    Returns:
        bool: True if the node is inside a try/except statement, False otherwise.
    """
    context = find_try_except_wrapper_node(node)
    return isinstance(context, nodes.Try)


</t>
<t tx="ekr.20250131013600.500">@utils.only_required_for_messages(
    "consider-using-dict-items",
    "use-sequence-for-iteration",
)
def visit_comprehension(self, node: nodes.Comprehension) -&gt; None:
    self._check_consider_using_dict_items_comprehension(node)
    self._check_use_sequence_for_iteration(node)

</t>
<t tx="ekr.20250131013600.501">def _check_consider_using_dict_items_comprehension(
    self, node: nodes.Comprehension
) -&gt; None:
    """Add message when accessing dict values by index lookup."""
    iterating_object_name = utils.get_iterating_dictionary_name(node)
    if iterating_object_name is None:
        return

    for child in node.parent.get_children():
        for subscript in child.nodes_of_class(nodes.Subscript):
            if not isinstance(subscript.value, (nodes.Name, nodes.Attribute)):
                continue

            value = subscript.slice
            if (
                not isinstance(value, nodes.Name)
                or value.name != node.target.name
                or iterating_object_name != subscript.value.as_string()
            ):
                continue

            self.add_message("consider-using-dict-items", node=node)
            return

</t>
<t tx="ekr.20250131013600.502">def _check_use_sequence_for_iteration(
    self, node: nodes.For | nodes.Comprehension
) -&gt; None:
    """Check if code iterates over an in-place defined set.

    Sets using `*` are not considered in-place.
    """
    if isinstance(node.iter, nodes.Set) and not any(
        utils.has_starred_node_recursive(node)
    ):
        self.add_message(
            "use-sequence-for-iteration", node=node.iter, confidence=HIGH
        )

</t>
<t tx="ekr.20250131013600.503">@utils.only_required_for_messages("consider-using-f-string")
def visit_const(self, node: nodes.Const) -&gt; None:
    if self._py36_plus:
        # f-strings require Python 3.6
        if node.pytype() == "builtins.str" and not isinstance(
            node.parent, nodes.JoinedStr
        ):
            self._detect_replacable_format_call(node)

</t>
<t tx="ekr.20250131013600.504">def _detect_replacable_format_call(self, node: nodes.Const) -&gt; None:
    """Check whether a string is used in a call to format() or '%' and whether it
    can be replaced by an f-string.
    """
    if (
        isinstance(node.parent, nodes.Attribute)
        and node.parent.attrname == "format"
    ):
        # Don't warn on referencing / assigning .format without calling it
        if not isinstance(node.parent.parent, nodes.Call):
            return

        if node.parent.parent.args:
            for arg in node.parent.parent.args:
                # If star expressions with more than 1 element are being used
                if isinstance(arg, nodes.Starred):
                    inferred = utils.safe_infer(arg.value)
                    if (
                        isinstance(inferred, astroid.List)
                        and len(inferred.elts) &gt; 1
                    ):
                        return
                # Backslashes can't be in f-string expressions
                if "\\" in arg.as_string():
                    return

        elif node.parent.parent.keywords:
            keyword_args = [
                i[0] for i in utils.parse_format_method_string(node.value)[0]
            ]
            for keyword in node.parent.parent.keywords:
                # If keyword is used multiple times
                if keyword_args.count(keyword.arg) &gt; 1:
                    return

                keyword = utils.safe_infer(keyword.value)

                # If lists of more than one element are being unpacked
                if isinstance(keyword, nodes.Dict):
                    if len(keyword.items) &gt; 1 and len(keyword_args) &gt; 1:
                        return

        # If all tests pass, then raise message
        self.add_message(
            "consider-using-f-string",
            node=node,
            line=node.lineno,
            col_offset=node.col_offset,
        )

    elif isinstance(node.parent, nodes.BinOp) and node.parent.op == "%":
        # Backslashes can't be in f-string expressions
        if "\\" in node.parent.right.as_string():
            return

        # If % applied to another type than str, it's modulo and can't be replaced by formatting
        if not hasattr(node.parent.left, "value") or not isinstance(
            node.parent.left.value, str
        ):
            return

        # Brackets can be inconvenient in f-string expressions
        if "{" in node.parent.left.value or "}" in node.parent.left.value:
            return

        inferred_right = utils.safe_infer(node.parent.right)

        # If dicts or lists of length &gt; 1 are used
        if isinstance(inferred_right, nodes.Dict):
            if len(inferred_right.items) &gt; 1:
                return
        elif isinstance(inferred_right, nodes.List):
            if len(inferred_right.elts) &gt; 1:
                return

        # If all tests pass, then raise message
        self.add_message(
            "consider-using-f-string",
            node=node,
            line=node.lineno,
            col_offset=node.col_offset,
        )
</t>
<t tx="ekr.20250131013600.505">@path pylint/checkers/refactoring
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import collections
import copy
import itertools
import tokenize
from collections.abc import Iterator
from functools import cached_property, reduce
from re import Pattern
from typing import TYPE_CHECKING, Any, NamedTuple, Union, cast

import astroid
from astroid import bases, nodes
from astroid.util import UninferableBase

from pylint import checkers
from pylint.checkers import utils
from pylint.checkers.base.basic_error_checker import _loop_exits_early
from pylint.checkers.utils import node_frame_class
from pylint.interfaces import HIGH, INFERENCE, Confidence

if TYPE_CHECKING:
    from pylint.lint import PyLinter


NodesWithNestedBlocks = Union[nodes.Try, nodes.While, nodes.For, nodes.If]

KNOWN_INFINITE_ITERATORS = {"itertools.count", "itertools.cycle"}
BUILTIN_EXIT_FUNCS = frozenset(("quit", "exit"))
CALLS_THAT_COULD_BE_REPLACED_BY_WITH = frozenset(
    (
        "threading.lock.acquire",
        "threading._RLock.acquire",
        "threading.Semaphore.acquire",
        "multiprocessing.managers.BaseManager.start",
        "multiprocessing.managers.SyncManager.start",
    )
)
CALLS_RETURNING_CONTEXT_MANAGERS = frozenset(
    (
        "_io.open",  # regular 'open()' call
        "pathlib.Path.open",
        "pathlib._local.Path.open",  # Python 3.13
        "codecs.open",
        "urllib.request.urlopen",
        "tempfile.NamedTemporaryFile",
        "tempfile.SpooledTemporaryFile",
        "tempfile.TemporaryDirectory",
        "tempfile.TemporaryFile",
        "zipfile.ZipFile",
        "zipfile.PyZipFile",
        "zipfile.ZipFile.open",
        "zipfile.PyZipFile.open",
        "tarfile.TarFile",
        "tarfile.TarFile.open",
        "multiprocessing.context.BaseContext.Pool",
        "subprocess.Popen",
    )
)


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.506">def _if_statement_is_always_returning(
    if_node: nodes.If, returning_node_class: nodes.NodeNG
) -&gt; bool:
    return any(isinstance(node, returning_node_class) for node in if_node.body)


</t>
<t tx="ekr.20250131013600.507">def _except_statement_is_always_returning(
    node: nodes.Try, returning_node_class: nodes.NodeNG
) -&gt; bool:
    """Detect if all except statements return."""
    return all(
        any(isinstance(child, returning_node_class) for child in handler.body)
        for handler in node.handlers
    )


</t>
<t tx="ekr.20250131013600.508">def _is_trailing_comma(tokens: list[tokenize.TokenInfo], index: int) -&gt; bool:
    """Check if the given token is a trailing comma.

    :param tokens: Sequence of modules tokens
    :type tokens: list[tokenize.TokenInfo]
    :param int index: Index of token under check in tokens
    :returns: True if the token is a comma which trails an expression
    :rtype: bool
    """
    token = tokens[index]
    if token.exact_type != tokenize.COMMA:
        return False
    # Must have remaining tokens on the same line such as NEWLINE
    left_tokens = itertools.islice(tokens, index + 1, None)

    more_tokens_on_line = False
    for remaining_token in left_tokens:
        if remaining_token.start[0] == token.start[0]:
            more_tokens_on_line = True
            # If one of the remaining same line tokens is not NEWLINE or COMMENT
            # the comma is not trailing.
            if remaining_token.type not in (tokenize.NEWLINE, tokenize.COMMENT):
                return False

    if not more_tokens_on_line:
        return False

    def get_curline_index_start() -&gt; int:
        """Get the index denoting the start of the current line."""
        for subindex, token in enumerate(reversed(tokens[:index])):
            # See Lib/tokenize.py and Lib/token.py in cpython for more info
            if token.type == tokenize.NEWLINE:
                return index - subindex
        return 0

    curline_start = get_curline_index_start()
    expected_tokens = {"return", "yield"}
    return any(
        "=" in prevtoken.string or prevtoken.string in expected_tokens
        for prevtoken in tokens[curline_start:index]
    )


</t>
<t tx="ekr.20250131013600.509">def _is_inside_context_manager(node: nodes.Call) -&gt; bool:
    frame = node.frame()
    if not isinstance(
        frame, (nodes.FunctionDef, astroid.BoundMethod, astroid.UnboundMethod)
    ):
        return False
    return frame.name == "__enter__" or utils.decorated_with(
        frame, "contextlib.contextmanager"
    )


</t>
<t tx="ekr.20250131013600.51">def node_ignores_exception(
    node: nodes.NodeNG, exception: type[Exception] | str = Exception
) -&gt; bool:
    """Check if the node is in a Try which handles the given exception.

    If the exception is not given, the function is going to look for bare
    excepts.
    """
    managing_handlers = get_exception_handlers(node, exception)
    if managing_handlers:
        return True
    return any(get_contextlib_suppressors(node, exception))


</t>
<t tx="ekr.20250131013600.510">def _is_a_return_statement(node: nodes.Call) -&gt; bool:
    frame = node.frame()
    for parent in node.node_ancestors():
        if parent is frame:
            break
        if isinstance(parent, nodes.Return):
            return True
    return False


</t>
<t tx="ekr.20250131013600.511">def _is_part_of_with_items(node: nodes.Call) -&gt; bool:
    """Checks if one of the node's parents is a ``nodes.With`` node and that the node
    itself is located somewhere under its ``items``.
    """
    frame = node.frame()
    current = node
    while current != frame:
        if isinstance(current, nodes.With):
            items_start = current.items[0][0].lineno
            items_end = current.items[-1][0].tolineno
            return items_start &lt;= node.lineno &lt;= items_end  # type: ignore[no-any-return]
        current = current.parent
    return False


</t>
<t tx="ekr.20250131013600.512">def _will_be_released_automatically(node: nodes.Call) -&gt; bool:
    """Checks if a call that could be used in a ``with`` statement is used in an
    alternative construct which would ensure that its __exit__ method is called.
    """
    callables_taking_care_of_exit = frozenset(
        (
            "contextlib._BaseExitStack.enter_context",
            "contextlib.ExitStack.enter_context",  # necessary for Python 3.6 compatibility
        )
    )
    if not isinstance(node.parent, nodes.Call):
        return False
    func = utils.safe_infer(node.parent.func)
    if not func:
        return False
    return func.qname() in callables_taking_care_of_exit


</t>
<t tx="ekr.20250131013600.513">def _is_part_of_assignment_target(node: nodes.NodeNG) -&gt; bool:
    """Check whether use of a variable is happening as part of the left-hand
    side of an assignment.

    This requires recursive checking, because destructuring assignment can have
    arbitrarily nested tuples and lists to unpack.
    """
    if isinstance(node.parent, nodes.Assign):
        return node in node.parent.targets

    if isinstance(node.parent, nodes.AugAssign):
        return node == node.parent.target  # type: ignore[no-any-return]

    if isinstance(node.parent, (nodes.Tuple, nodes.List)):
        return _is_part_of_assignment_target(node.parent)

    return False


</t>
<t tx="ekr.20250131013600.514">class ConsiderUsingWithStack(NamedTuple):
    """Stack for objects that may potentially trigger a R1732 message
    if they are not used in a ``with`` block later on.
    """

    @others
</t>
<t tx="ekr.20250131013600.515">class RefactoringChecker(checkers.BaseTokenChecker):
    """Looks for code which can be refactored.

    This checker also mixes the astroid and the token approaches
    in order to create knowledge about whether an "else if" node
    is a true "else if" node, or an "elif" node.
    """

    @others
</t>
<t tx="ekr.20250131013600.516">module_scope: dict[str, nodes.NodeNG] = {}
class_scope: dict[str, nodes.NodeNG] = {}
function_scope: dict[str, nodes.NodeNG] = {}

def __iter__(self) -&gt; Iterator[dict[str, nodes.NodeNG]]:
    yield from(self.function_scope, self.class_scope, self.module_scope)

</t>
<t tx="ekr.20250131013600.517">def get_stack_for_frame(
    self, frame: nodes.FunctionDef | nodes.ClassDef | nodes.Module
) -&gt; dict[str, nodes.NodeNG]:
    """Get the stack corresponding to the scope of the given frame."""
    if isinstance(frame, nodes.FunctionDef):
        return self.function_scope
    if isinstance(frame, nodes.ClassDef):
        return self.class_scope
    return self.module_scope

</t>
<t tx="ekr.20250131013600.518">def clear_all(self) -&gt; None:
    """Convenience method to clear all stacks."""
    for stack in self:
        stack.clear()


</t>
<t tx="ekr.20250131013600.519">name = "refactoring"

msgs = {
    "R1701": (
        "Consider merging these isinstance calls to isinstance(%s, (%s))",
        "consider-merging-isinstance",
        "Used when multiple consecutive isinstance calls can be merged into one.",
    ),
    "R1706": (
        "Consider using ternary (%s)",
        "consider-using-ternary",
        "Used when one of known pre-python 2.5 ternary syntax is used.",
    ),
    "R1709": (
        "Boolean expression may be simplified to %s",
        "simplify-boolean-expression",
        "Emitted when redundant pre-python 2.5 ternary syntax is used.",
    ),
    "R1726": (
        'Boolean condition "%s" may be simplified to "%s"',
        "simplifiable-condition",
        "Emitted when a boolean condition is able to be simplified.",
    ),
    "R1727": (
        "Boolean condition '%s' will always evaluate to '%s'",
        "condition-evals-to-constant",
        "Emitted when a boolean condition can be simplified to a constant value.",
    ),
    "R1702": (
        "Too many nested blocks (%s/%s)",
        "too-many-nested-blocks",
        "Used when a function or a method has too many nested "
        "blocks. This makes the code less understandable and "
        "maintainable.",
        {"old_names": [("R0101", "old-too-many-nested-blocks")]},
    ),
    "R1703": (
        "The if statement can be replaced with %s",
        "simplifiable-if-statement",
        "Used when an if statement can be replaced with 'bool(test)'.",
        {"old_names": [("R0102", "old-simplifiable-if-statement")]},
    ),
    "R1704": (
        "Redefining argument with the local name %r",
        "redefined-argument-from-local",
        "Used when a local name is redefining an argument, which might "
        "suggest a potential error. This is taken in account only for "
        "a handful of name binding operations, such as for iteration, "
        "with statement assignment and exception handler assignment.",
    ),
    "R1705": (
        'Unnecessary "%s" after "return", %s',
        "no-else-return",
        "Used in order to highlight an unnecessary block of "
        "code following an if, or a try/except containing a return statement. "
        "As such, it will warn when it encounters an else "
        "following a chain of ifs, all of them containing a "
        "return statement.",
    ),
    "R1707": (
        "Disallow trailing comma tuple",
        "trailing-comma-tuple",
        "In Python, a tuple is actually created by the comma symbol, "
        "not by the parentheses. Unfortunately, one can actually create a "
        "tuple by misplacing a trailing comma, which can lead to potential "
        "weird bugs in your code. You should always use parentheses "
        "explicitly for creating a tuple.",
    ),
    "R1708": (
        "Do not raise StopIteration in generator, use return statement instead",
        "stop-iteration-return",
        "According to PEP479, the raise of StopIteration to end the loop of "
        "a generator may lead to hard to find bugs. This PEP specify that "
        "raise StopIteration has to be replaced by a simple return statement",
    ),
    "R1710": (
        "Either all return statements in a function should return an expression, "
        "or none of them should.",
        "inconsistent-return-statements",
        "According to PEP8, if any return statement returns an expression, "
        "any return statements where no value is returned should explicitly "
        "state this as return None, and an explicit return statement "
        "should be present at the end of the function (if reachable)",
    ),
    "R1711": (
        "Useless return at end of function or method",
        "useless-return",
        'Emitted when a single "return" or "return None" statement is found '
        "at the end of function or method definition. This statement can safely be "
        "removed because Python will implicitly return None",
    ),
    "R1712": (
        "Consider using tuple unpacking for swapping variables",
        "consider-swap-variables",
        "You do not have to use a temporary variable in order to "
        'swap variables. Using "tuple unpacking" to directly swap '
        "variables makes the intention more clear.",
    ),
    "R1713": (
        "Consider using str.join(sequence) for concatenating "
        "strings from an iterable",
        "consider-using-join",
        "Using str.join(sequence) is faster, uses less memory "
        "and increases readability compared to for-loop iteration.",
    ),
    "R1714": (
        "Consider merging these comparisons with 'in' by using '%s %sin (%s)'."
        " Use a set instead if elements are hashable.",
        "consider-using-in",
        "To check if a variable is equal to one of many values, "
        'combine the values into a set or tuple and check if the variable is contained "in" it '
        "instead of checking for equality against each of the values. "
        "This is faster and less verbose.",
    ),
    "R1715": (
        "Consider using dict.get for getting values from a dict "
        "if a key is present or a default if not",
        "consider-using-get",
        "Using the builtin dict.get for getting a value from a dictionary "
        "if a key is present or a default if not, is simpler and considered "
        "more idiomatic, although sometimes a bit slower",
    ),
    "R1716": (
        "Simplify chained comparison between the operands",
        "chained-comparison",
        "This message is emitted when pylint encounters boolean operation like "
        '"a &lt; b and b &lt; c", suggesting instead to refactor it to "a &lt; b &lt; c"',
    ),
    "R1717": (
        "Consider using a dictionary comprehension",
        "consider-using-dict-comprehension",
        "Emitted when we detect the creation of a dictionary "
        "using the dict() callable and a transient list. "
        "Although there is nothing syntactically wrong with this code, "
        "it is hard to read and can be simplified to a dict comprehension. "
        "Also it is faster since you don't need to create another "
        "transient list",
    ),
    "R1718": (
        "Consider using a set comprehension",
        "consider-using-set-comprehension",
        "Although there is nothing syntactically wrong with this code, "
        "it is hard to read and can be simplified to a set comprehension. "
        "Also it is faster since you don't need to create another "
        "transient list",
    ),
    "R1719": (
        "The if expression can be replaced with %s",
        "simplifiable-if-expression",
        "Used when an if expression can be replaced with 'bool(test)' "
        "or simply 'test' if the boolean cast is implicit.",
    ),
    "R1720": (
        'Unnecessary "%s" after "raise", %s',
        "no-else-raise",
        "Used in order to highlight an unnecessary block of "
        "code following an if, or a try/except containing a raise statement. "
        "As such, it will warn when it encounters an else "
        "following a chain of ifs, all of them containing a "
        "raise statement.",
    ),
    "R1721": (
        "Unnecessary use of a comprehension, use %s instead.",
        "unnecessary-comprehension",
        "Instead of using an identity comprehension, "
        "consider using the list, dict or set constructor. "
        "It is faster and simpler.",
    ),
    "R1722": (
        "Consider using 'sys.exit' instead",
        "consider-using-sys-exit",
        "Contrary to 'exit()' or 'quit()', 'sys.exit' does not rely on the "
        "site module being available (as the 'sys' module is always available).",
    ),
    "R1723": (
        'Unnecessary "%s" after "break", %s',
        "no-else-break",
        "Used in order to highlight an unnecessary block of "
        "code following an if containing a break statement. "
        "As such, it will warn when it encounters an else "
        "following a chain of ifs, all of them containing a "
        "break statement.",
    ),
    "R1724": (
        'Unnecessary "%s" after "continue", %s',
        "no-else-continue",
        "Used in order to highlight an unnecessary block of "
        "code following an if containing a continue statement. "
        "As such, it will warn when it encounters an else "
        "following a chain of ifs, all of them containing a "
        "continue statement.",
    ),
    "R1725": (
        "Consider using Python 3 style super() without arguments",
        "super-with-arguments",
        "Emitted when calling the super() builtin with the current class "
        "and instance. On Python 3 these arguments are the default and they can be omitted.",
    ),
    "R1728": (
        "Consider using a generator instead '%s(%s)'",
        "consider-using-generator",
        "If your container can be large using "
        "a generator will bring better performance.",
    ),
    "R1729": (
        "Use a generator instead '%s(%s)'",
        "use-a-generator",
        "Comprehension inside of 'any', 'all', 'max', 'min' or 'sum' is unnecessary. "
        "A generator would be sufficient and faster.",
    ),
    "R1730": (
        "Consider using '%s' instead of unnecessary if block",
        "consider-using-min-builtin",
        "Using the min builtin instead of a conditional improves readability and conciseness.",
    ),
    "R1731": (
        "Consider using '%s' instead of unnecessary if block",
        "consider-using-max-builtin",
        "Using the max builtin instead of a conditional improves readability and conciseness.",
    ),
    "R1732": (
        "Consider using 'with' for resource-allocating operations",
        "consider-using-with",
        "Emitted if a resource-allocating assignment or call may be replaced by a 'with' block. "
        "By using 'with' the release of the allocated resources is ensured even in the case "
        "of an exception.",
    ),
    "R1733": (
        "Unnecessary dictionary index lookup, use '%s' instead",
        "unnecessary-dict-index-lookup",
        "Emitted when iterating over the dictionary items (key-item pairs) and accessing the "
        "value by index lookup. "
        "The value can be accessed directly instead.",
    ),
    "R1734": (
        "Consider using [] instead of list()",
        "use-list-literal",
        "Emitted when using list() to create an empty list instead of the literal []. "
        "The literal is faster as it avoids an additional function call.",
    ),
    "R1735": (
        "Consider using '%s' instead of a call to 'dict'.",
        "use-dict-literal",
        "Emitted when using dict() to create a dictionary instead of a literal '{ ... }'. "
        "The literal is faster as it avoids an additional function call.",
    ),
    "R1736": (
        "Unnecessary list index lookup, use '%s' instead",
        "unnecessary-list-index-lookup",
        "Emitted when iterating over an enumeration and accessing the "
        "value by index lookup. "
        "The value can be accessed directly instead.",
    ),
    "R1737": (
        "Use 'yield from' directly instead of yielding each element one by one",
        "use-yield-from",
        "Yielding directly from the iterator is faster and arguably cleaner code than yielding each element "
        "one by one in the loop.",
    ),
}
options = (
    (
        "max-nested-blocks",
        {
            "default": 5,
            "type": "int",
            "metavar": "&lt;int&gt;",
            "help": "Maximum number of nested blocks for function / method body",
        },
    ),
    (
        "never-returning-functions",
        {
            "default": ("sys.exit", "argparse.parse_error"),
            "type": "csv",
            "metavar": "&lt;members names&gt;",
            "help": "Complete name of functions that never returns. When checking "
            "for inconsistent-return-statements if a never returning function is "
            "called then it will be considered as an explicit return statement "
            "and no message will be printed.",
        },
    ),
    (
        "suggest-join-with-non-empty-separator",
        {
            "default": True,
            "type": "yn",
            "metavar": "&lt;y or n&gt;",
            "help": (
                "Let 'consider-using-join' be raised when the separator to "
                "join on would be non-empty (resulting in expected fixes "
                'of the type: ``"- " + "\n- ".join(items)``)'
            ),
        },
    ),
)

def __init__(self, linter: PyLinter) -&gt; None:
    super().__init__(linter)
    self._return_nodes: dict[str, list[nodes.Return]] = {}
    self._consider_using_with_stack = ConsiderUsingWithStack()
    self._init()
    self._never_returning_functions: set[str] = set()
    self._suggest_join_with_non_empty_separator: bool = False

</t>
<t tx="ekr.20250131013600.52">@lru_cache(maxsize=1024)
def class_is_abstract(node: nodes.ClassDef) -&gt; bool:
    """Return true if the given class node should be considered as an abstract
    class.
    """
    # Protocol classes are considered "abstract"
    if is_protocol_class(node):
        return True

    # Only check for explicit metaclass=ABCMeta on this specific class
    meta = node.declared_metaclass()
    if meta is not None:
        if meta.name == "ABCMeta" and meta.root().name in ABC_MODULES:
            return True

    for ancestor in node.ancestors():
        if ancestor.name == "ABC" and ancestor.root().name in ABC_MODULES:
            # abc.ABC inheritance
            return True

    for method in node.methods():
        if method.parent.frame() is node:
            if method.is_abstract(pass_is_abstract=False):
                return True
    return False


</t>
<t tx="ekr.20250131013600.520">def _init(self) -&gt; None:
    self._nested_blocks: list[NodesWithNestedBlocks] = []
    self._elifs: list[tuple[int, int]] = []
    self._reported_swap_nodes: set[nodes.NodeNG] = set()
    self._can_simplify_bool_op: bool = False
    self._consider_using_with_stack.clear_all()

</t>
<t tx="ekr.20250131013600.521">def open(self) -&gt; None:
    # do this in open since config not fully initialized in __init__
    self._never_returning_functions = set(
        self.linter.config.never_returning_functions
    )
    self._suggest_join_with_non_empty_separator = (
        self.linter.config.suggest_join_with_non_empty_separator
    )

</t>
<t tx="ekr.20250131013600.522">@cached_property
def _dummy_rgx(self) -&gt; Pattern[str]:
    return self.linter.config.dummy_variables_rgx  # type: ignore[no-any-return]

</t>
<t tx="ekr.20250131013600.523">@staticmethod
def _is_bool_const(node: nodes.Return | nodes.Assign) -&gt; bool:
    return isinstance(node.value, nodes.Const) and isinstance(
        node.value.value, bool
    )

</t>
<t tx="ekr.20250131013600.524">def _is_actual_elif(self, node: nodes.If | nodes.Try) -&gt; bool:
    """Check if the given node is an actual elif.

    This is a problem we're having with the builtin ast module,
    which splits `elif` branches into a separate if statement.
    Unfortunately we need to know the exact type in certain
    cases.
    """
    if isinstance(node.parent, nodes.If):
        orelse = node.parent.orelse
        # current if node must directly follow an "else"
        if orelse and orelse == [node]:
            if (node.lineno, node.col_offset) in self._elifs:
                return True
    return False

</t>
<t tx="ekr.20250131013600.525">def _check_simplifiable_if(self, node: nodes.If) -&gt; None:
    """Check if the given if node can be simplified.

    The if statement can be reduced to a boolean expression
    in some cases. For instance, if there are two branches
    and both of them return a boolean value that depends on
    the result of the statement's test, then this can be reduced
    to `bool(test)` without losing any functionality.
    """
    if self._is_actual_elif(node):
        # Not interested in if statements with multiple branches.
        return
    if len(node.orelse) != 1 or len(node.body) != 1:
        return

    # Check if both branches can be reduced.
    first_branch = node.body[0]
    else_branch = node.orelse[0]
    if isinstance(first_branch, nodes.Return):
        if not isinstance(else_branch, nodes.Return):
            return
        first_branch_is_bool = self._is_bool_const(first_branch)
        else_branch_is_bool = self._is_bool_const(else_branch)
        reduced_to = "'return bool(test)'"
    elif isinstance(first_branch, nodes.Assign):
        if not isinstance(else_branch, nodes.Assign):
            return

        # Check if we assign to the same value
        first_branch_targets = [
            target.name
            for target in first_branch.targets
            if isinstance(target, nodes.AssignName)
        ]
        else_branch_targets = [
            target.name
            for target in else_branch.targets
            if isinstance(target, nodes.AssignName)
        ]
        if not first_branch_targets or not else_branch_targets:
            return
        if sorted(first_branch_targets) != sorted(else_branch_targets):
            return

        first_branch_is_bool = self._is_bool_const(first_branch)
        else_branch_is_bool = self._is_bool_const(else_branch)
        reduced_to = "'var = bool(test)'"
    else:
        return

    if not first_branch_is_bool or not else_branch_is_bool:
        return
    if not first_branch.value.value:
        # This is a case that can't be easily simplified and
        # if it can be simplified, it will usually result in a
        # code that's harder to understand and comprehend.
        # Let's take for instance `arg and arg &lt;= 3`. This could theoretically be
        # reduced to `not arg or arg &gt; 3`, but the net result is that now the
        # condition is harder to understand, because it requires understanding of
        # an extra clause:
        #   * first, there is the negation of truthness with `not arg`
        #   * the second clause is `arg &gt; 3`, which occurs when arg has a
        #     a truth value, but it implies that `arg &gt; 3` is equivalent
        #     with `arg and arg &gt; 3`, which means that the user must
        #     think about this assumption when evaluating `arg &gt; 3`.
        #     The original form is easier to grasp.
        return

    self.add_message("simplifiable-if-statement", node=node, args=(reduced_to,))

</t>
<t tx="ekr.20250131013600.526">def process_tokens(self, tokens: list[tokenize.TokenInfo]) -&gt; None:
    # Optimization flag because '_is_trailing_comma' is costly
    trailing_comma_tuple_enabled_for_file = self.linter.is_message_enabled(
        "trailing-comma-tuple"
    )
    trailing_comma_tuple_enabled_once: bool = trailing_comma_tuple_enabled_for_file
    # Process tokens and look for 'if' or 'elif'
    for index, token in enumerate(tokens):
        token_string = token[1]
        if (
            not trailing_comma_tuple_enabled_once
            and token_string.startswith("#")
            # We have at least 1 '#' (one char) at the start of the token
            and "pylint:" in token_string[1:]
            # We have at least '#' 'pylint' ( + ':') (8 chars) at the start of the token
            and "enable" in token_string[8:]
            # We have at least '#', 'pylint', ( + ':'), 'enable' (+ '=') (15 chars) at
            # the start of the token
            and any(
                c in token_string[15:] for c in ("trailing-comma-tuple", "R1707")
            )
        ):
            # Way to not have to check if "trailing-comma-tuple" is enabled or
            # disabled on each line: Any enable for it during tokenization and
            # we'll start using the costly '_is_trailing_comma' to check if we
            # need to raise the message. We still won't raise if it's disabled
            # again due to the usual generic message control handling later.
            trailing_comma_tuple_enabled_once = True
        if token_string == "elif":
            # AST exists by the time process_tokens is called, so
            # it's safe to assume tokens[index+1] exists.
            # tokens[index+1][2] is the elif's position as
            # reported by CPython and PyPy,
            # token[2] is the actual position and also is
            # reported by IronPython.
            self._elifs.extend([token[2], tokens[index + 1][2]])
        elif (
            trailing_comma_tuple_enabled_for_file
            or trailing_comma_tuple_enabled_once
        ) and _is_trailing_comma(tokens, index):
            # If "trailing-comma-tuple" is enabled globally we always check _is_trailing_comma
            # it might be for nothing if there's a local disable, or if the message control is
            # not enabling 'trailing-comma-tuple', but the alternative is having to check if
            # it's enabled for a line each line (just to avoid calling '_is_trailing_comma').
            self.add_message(
                "trailing-comma-tuple", line=token.start[0], confidence=HIGH
            )

</t>
<t tx="ekr.20250131013600.527">@utils.only_required_for_messages("consider-using-with")
def leave_module(self, _: nodes.Module) -&gt; None:
    # check for context managers that have been created but not used
    self._emit_consider_using_with_if_needed(
        self._consider_using_with_stack.module_scope
    )
    self._init()

</t>
<t tx="ekr.20250131013600.528">@utils.only_required_for_messages("too-many-nested-blocks", "no-else-return")
def visit_try(self, node: nodes.Try) -&gt; None:
    self._check_nested_blocks(node)

    self._check_superfluous_else_return(node)
    self._check_superfluous_else_raise(node)

</t>
<t tx="ekr.20250131013600.529">visit_while = visit_try

def _check_redefined_argument_from_local(self, name_node: nodes.AssignName) -&gt; None:
    if self._dummy_rgx and self._dummy_rgx.match(name_node.name):
        return
    if not name_node.lineno:
        # Unknown position, maybe it is a manually built AST?
        return

    scope = name_node.scope()
    if not isinstance(scope, nodes.FunctionDef):
        return

    for defined_argument in scope.args.nodes_of_class(
        nodes.AssignName, skip_klass=(nodes.Lambda,)
    ):
        if defined_argument.name == name_node.name:
            self.add_message(
                "redefined-argument-from-local",
                node=name_node,
                args=(name_node.name,),
            )

</t>
<t tx="ekr.20250131013600.53">def _supports_protocol_method(value: nodes.NodeNG, attr: str) -&gt; bool:
    try:
        attributes = value.getattr(attr)
    except astroid.NotFoundError:
        return False

    first = attributes[0]

    # Return False if a constant is assigned
    if isinstance(first, nodes.AssignName):
        this_assign_parent = get_node_first_ancestor_of_type(
            first, (nodes.Assign, nodes.NamedExpr)
        )
        if this_assign_parent is None:  # pragma: no cover
            # Cannot imagine this being None, but return True to avoid false positives
            return True
        if isinstance(this_assign_parent.value, nodes.BaseContainer):
            if all(isinstance(n, nodes.Const) for n in this_assign_parent.value.elts):
                return False
        if isinstance(this_assign_parent.value, nodes.Const):
            return False
    return True


</t>
<t tx="ekr.20250131013600.530">@utils.only_required_for_messages(
    "redefined-argument-from-local",
    "too-many-nested-blocks",
    "unnecessary-dict-index-lookup",
    "unnecessary-list-index-lookup",
)
def visit_for(self, node: nodes.For) -&gt; None:
    self._check_nested_blocks(node)
    self._check_unnecessary_dict_index_lookup(node)
    self._check_unnecessary_list_index_lookup(node)

    for name in node.target.nodes_of_class(nodes.AssignName):
        self._check_redefined_argument_from_local(name)

</t>
<t tx="ekr.20250131013600.531">@utils.only_required_for_messages("redefined-argument-from-local")
def visit_excepthandler(self, node: nodes.ExceptHandler) -&gt; None:
    if node.name and isinstance(node.name, nodes.AssignName):
        self._check_redefined_argument_from_local(node.name)

</t>
<t tx="ekr.20250131013600.532">@utils.only_required_for_messages(
    "redefined-argument-from-local", "consider-using-with"
)
def visit_with(self, node: nodes.With) -&gt; None:
    for var, names in node.items:
        if isinstance(var, nodes.Name):
            for stack in self._consider_using_with_stack:
                # We don't need to restrict the stacks we search to the current scope and
                # outer scopes, as e.g. the function_scope stack will be empty when we
                # check a ``with`` on the class level.
                if var.name in stack:
                    del stack[var.name]
                    break
        if not names:
            continue
        for name in names.nodes_of_class(nodes.AssignName):
            self._check_redefined_argument_from_local(name)

</t>
<t tx="ekr.20250131013600.533">def _check_superfluous_else(
    self,
    node: nodes.If | nodes.Try,
    msg_id: str,
    returning_node_class: nodes.NodeNG,
) -&gt; None:
    if isinstance(node, nodes.Try) and node.finalbody:
        # Not interested in try/except/else/finally statements.
        return

    if not node.orelse:
        # Not interested in if/try statements without else.
        return

    if self._is_actual_elif(node):
        # Not interested in elif nodes; only if
        return

    if (
        isinstance(node, nodes.If)
        and _if_statement_is_always_returning(node, returning_node_class)
    ) or (
        isinstance(node, nodes.Try)
        and not node.finalbody
        and _except_statement_is_always_returning(node, returning_node_class)
    ):
        orelse = node.orelse[0]
        if (orelse.lineno, orelse.col_offset) in self._elifs:
            args = ("elif", 'remove the leading "el" from "elif"')
        else:
            args = ("else", 'remove the "else" and de-indent the code inside it')
        self.add_message(msg_id, node=node, args=args, confidence=HIGH)

</t>
<t tx="ekr.20250131013600.534">def _check_superfluous_else_return(self, node: nodes.If) -&gt; None:
    return self._check_superfluous_else(
        node, msg_id="no-else-return", returning_node_class=nodes.Return
    )

</t>
<t tx="ekr.20250131013600.535">def _check_superfluous_else_raise(self, node: nodes.If) -&gt; None:
    return self._check_superfluous_else(
        node, msg_id="no-else-raise", returning_node_class=nodes.Raise
    )

</t>
<t tx="ekr.20250131013600.536">def _check_superfluous_else_break(self, node: nodes.If) -&gt; None:
    return self._check_superfluous_else(
        node, msg_id="no-else-break", returning_node_class=nodes.Break
    )

</t>
<t tx="ekr.20250131013600.537">def _check_superfluous_else_continue(self, node: nodes.If) -&gt; None:
    return self._check_superfluous_else(
        node, msg_id="no-else-continue", returning_node_class=nodes.Continue
    )

</t>
<t tx="ekr.20250131013600.538">@staticmethod
def _type_and_name_are_equal(node_a: Any, node_b: Any) -&gt; bool:
    if isinstance(node_a, nodes.Name) and isinstance(node_b, nodes.Name):
        return node_a.name == node_b.name  # type: ignore[no-any-return]
    if isinstance(node_a, nodes.AssignName) and isinstance(
        node_b, nodes.AssignName
    ):
        return node_a.name == node_b.name  # type: ignore[no-any-return]
    if isinstance(node_a, nodes.Const) and isinstance(node_b, nodes.Const):
        return node_a.value == node_b.value  # type: ignore[no-any-return]
    return False

</t>
<t tx="ekr.20250131013600.539">def _is_dict_get_block(self, node: nodes.If) -&gt; bool:
    # "if &lt;compare node&gt;"
    if not isinstance(node.test, nodes.Compare):
        return False

    # Does not have a single statement in the guard's body
    if len(node.body) != 1:
        return False

    # Look for a single variable assignment on the LHS and a subscript on RHS
    stmt = node.body[0]
    if not (
        isinstance(stmt, nodes.Assign)
        and len(node.body[0].targets) == 1
        and isinstance(node.body[0].targets[0], nodes.AssignName)
        and isinstance(stmt.value, nodes.Subscript)
    ):
        return False

    # The subscript's slice needs to be the same as the test variable.
    slice_value = stmt.value.slice
    if not (
        self._type_and_name_are_equal(stmt.value.value, node.test.ops[0][1])
        and self._type_and_name_are_equal(slice_value, node.test.left)
    ):
        return False

    # The object needs to be a dictionary instance
    return isinstance(utils.safe_infer(node.test.ops[0][1]), nodes.Dict)

</t>
<t tx="ekr.20250131013600.54">def is_comprehension(node: nodes.NodeNG) -&gt; bool:
    comprehensions = (
        nodes.ListComp,
        nodes.SetComp,
        nodes.DictComp,
        nodes.GeneratorExp,
    )
    return isinstance(node, comprehensions)


</t>
<t tx="ekr.20250131013600.540">def _check_consider_get(self, node: nodes.If) -&gt; None:
    if_block_ok = self._is_dict_get_block(node)
    if if_block_ok and not node.orelse:
        self.add_message("consider-using-get", node=node)
    elif (
        if_block_ok
        and len(node.orelse) == 1
        and isinstance(node.orelse[0], nodes.Assign)
        and self._type_and_name_are_equal(
            node.orelse[0].targets[0], node.body[0].targets[0]
        )
        and len(node.orelse[0].targets) == 1
    ):
        self.add_message("consider-using-get", node=node)

</t>
<t tx="ekr.20250131013600.541">@utils.only_required_for_messages(
    "too-many-nested-blocks",
    "simplifiable-if-statement",
    "no-else-return",
    "no-else-raise",
    "no-else-break",
    "no-else-continue",
    "consider-using-get",
    "consider-using-min-builtin",
    "consider-using-max-builtin",
)
def visit_if(self, node: nodes.If) -&gt; None:
    self._check_simplifiable_if(node)
    self._check_nested_blocks(node)
    self._check_superfluous_else_return(node)
    self._check_superfluous_else_raise(node)
    self._check_superfluous_else_break(node)
    self._check_superfluous_else_continue(node)
    self._check_consider_get(node)
    self._check_consider_using_min_max_builtin(node)

</t>
<t tx="ekr.20250131013600.542">def _check_consider_using_min_max_builtin(self, node: nodes.If) -&gt; None:
    """Check if the given if node can be refactored as a min/max python builtin."""
    # This function is written expecting a test condition of form:
    #  if a &lt; b: # [consider-using-max-builtin]
    #    a = b
    #  if a &gt; b: # [consider-using-min-builtin]
    #    a = b
    if self._is_actual_elif(node) or node.orelse:
        # Not interested in if statements with multiple branches.
        return

    if len(node.body) != 1:
        return

    def get_node_name(node: nodes.NodeNG) -&gt; str:
        """Obtain simplest representation of a node as a string."""
        if isinstance(node, nodes.Name):
            return node.name  # type: ignore[no-any-return]
        if isinstance(node, nodes.Const):
            return str(node.value)
        # this is a catch-all for nodes that are not of type Name or Const
        # extremely helpful for Call or BinOp
        return node.as_string()  # type: ignore[no-any-return]

    body = node.body[0]
    # Check if condition can be reduced.
    if not hasattr(body, "targets") or len(body.targets) != 1:
        return

    target = body.targets[0]
    if not (
        isinstance(node.test, nodes.Compare)
        and not isinstance(target, nodes.Subscript)
        and not isinstance(node.test.left, nodes.Subscript)
        and isinstance(body, nodes.Assign)
    ):
        return
    # Assign body line has one requirement and that is the assign target
    # is of type name or attribute. Attribute referring to NamedTuple.x perse.
    # So we have to check that target is of these types

    if not (hasattr(target, "name") or hasattr(target, "attrname")):
        return

    target_assignation = get_node_name(target)

    if len(node.test.ops) &gt; 1:
        return
    operator, right_statement = node.test.ops[0]

    body_value = get_node_name(body.value)
    left_operand = get_node_name(node.test.left)
    right_statement_value = get_node_name(right_statement)

    if left_operand == target_assignation:
        # statement is in expected form
        pass
    elif right_statement_value == target_assignation:
        # statement is in reverse form
        operator = utils.get_inverse_comparator(operator)
    else:
        return

    if body_value not in (right_statement_value, left_operand):
        return

    if operator in {"&lt;", "&lt;="}:
        reduced_to = (
            f"{target_assignation} = max({target_assignation}, {body_value})"
        )
        self.add_message(
            "consider-using-max-builtin", node=node, args=(reduced_to,)
        )
    elif operator in {"&gt;", "&gt;="}:
        reduced_to = (
            f"{target_assignation} = min({target_assignation}, {body_value})"
        )
        self.add_message(
            "consider-using-min-builtin", node=node, args=(reduced_to,)
        )

</t>
<t tx="ekr.20250131013600.543">@utils.only_required_for_messages("simplifiable-if-expression")
def visit_ifexp(self, node: nodes.IfExp) -&gt; None:
    self._check_simplifiable_ifexp(node)

</t>
<t tx="ekr.20250131013600.544">def _check_simplifiable_ifexp(self, node: nodes.IfExp) -&gt; None:
    if not isinstance(node.body, nodes.Const) or not isinstance(
        node.orelse, nodes.Const
    ):
        return

    if not isinstance(node.body.value, bool) or not isinstance(
        node.orelse.value, bool
    ):
        return

    if isinstance(node.test, nodes.Compare):
        test_reduced_to = "test"
    else:
        test_reduced_to = "bool(test)"

    if (node.body.value, node.orelse.value) == (True, False):
        reduced_to = f"'{test_reduced_to}'"
    elif (node.body.value, node.orelse.value) == (False, True):
        reduced_to = "'not test'"
    else:
        return

    self.add_message("simplifiable-if-expression", node=node, args=(reduced_to,))

</t>
<t tx="ekr.20250131013600.545">@utils.only_required_for_messages(
    "too-many-nested-blocks",
    "inconsistent-return-statements",
    "useless-return",
    "consider-using-with",
)
def leave_functiondef(self, node: nodes.FunctionDef) -&gt; None:
    # check left-over nested blocks stack
    self._emit_nested_blocks_message_if_needed(self._nested_blocks)
    # new scope = reinitialize the stack of nested blocks
    self._nested_blocks = []
    # check consistent return statements
    self._check_consistent_returns(node)
    # check for single return or return None at the end
    self._check_return_at_the_end(node)
    self._return_nodes[node.name] = []
    # check for context managers that have been created but not used
    self._emit_consider_using_with_if_needed(
        self._consider_using_with_stack.function_scope
    )
    self._consider_using_with_stack.function_scope.clear()

</t>
<t tx="ekr.20250131013600.546">@utils.only_required_for_messages("consider-using-with")
def leave_classdef(self, _: nodes.ClassDef) -&gt; None:
    # check for context managers that have been created but not used
    self._emit_consider_using_with_if_needed(
        self._consider_using_with_stack.class_scope
    )
    self._consider_using_with_stack.class_scope.clear()

</t>
<t tx="ekr.20250131013600.547">@utils.only_required_for_messages("stop-iteration-return")
def visit_raise(self, node: nodes.Raise) -&gt; None:
    self._check_stop_iteration_inside_generator(node)

</t>
<t tx="ekr.20250131013600.548">def _check_stop_iteration_inside_generator(self, node: nodes.Raise) -&gt; None:
    """Check if an exception of type StopIteration is raised inside a generator."""
    frame = node.frame()
    if not isinstance(frame, nodes.FunctionDef) or not frame.is_generator():
        return
    if utils.node_ignores_exception(node, StopIteration):
        return
    if not node.exc:
        return
    exc = utils.safe_infer(node.exc)
    if not exc or not isinstance(exc, (bases.Instance, nodes.ClassDef)):
        return
    if self._check_exception_inherit_from_stopiteration(exc):
        self.add_message("stop-iteration-return", node=node, confidence=INFERENCE)

</t>
<t tx="ekr.20250131013600.549">@staticmethod
def _check_exception_inherit_from_stopiteration(
    exc: nodes.ClassDef | bases.Instance,
) -&gt; bool:
    """Return True if the exception node in argument inherit from StopIteration."""
    stopiteration_qname = f"{utils.EXCEPTIONS_MODULE}.StopIteration"
    return any(_class.qname() == stopiteration_qname for _class in exc.mro())

</t>
<t tx="ekr.20250131013600.55">def _supports_mapping_protocol(value: nodes.NodeNG) -&gt; bool:
    return _supports_protocol_method(
        value, GETITEM_METHOD
    ) and _supports_protocol_method(value, KEYS_METHOD)


</t>
<t tx="ekr.20250131013600.550">def _check_consider_using_comprehension_constructor(self, node: nodes.Call) -&gt; None:
    if (
        isinstance(node.func, nodes.Name)
        and node.args
        and isinstance(node.args[0], nodes.ListComp)
    ):
        if node.func.name == "dict":
            element = node.args[0].elt
            if isinstance(element, nodes.Call):
                return

            # If we have an `IfExp` here where both the key AND value
            # are different, then don't raise the issue. See #5588
            if (
                isinstance(element, nodes.IfExp)
                and isinstance(element.body, (nodes.Tuple, nodes.List))
                and len(element.body.elts) == 2
                and isinstance(element.orelse, (nodes.Tuple, nodes.List))
                and len(element.orelse.elts) == 2
            ):
                key1, value1 = element.body.elts
                key2, value2 = element.orelse.elts
                if (
                    key1.as_string() != key2.as_string()
                    and value1.as_string() != value2.as_string()
                ):
                    return

            message_name = "consider-using-dict-comprehension"
            self.add_message(message_name, node=node)
        elif node.func.name == "set":
            message_name = "consider-using-set-comprehension"
            self.add_message(message_name, node=node)

</t>
<t tx="ekr.20250131013600.551">def _check_consider_using_generator(self, node: nodes.Call) -&gt; None:
    # 'any', 'all', definitely should use generator, while 'list', 'tuple',
    # 'sum', 'max', and 'min' need to be considered first
    # See https://github.com/pylint-dev/pylint/pull/3309#discussion_r576683109
    # https://github.com/pylint-dev/pylint/pull/6595#issuecomment-1125704244
    # and https://peps.python.org/pep-0289/
    checked_call = ["any", "all", "sum", "max", "min", "list", "tuple"]
    if (
        isinstance(node, nodes.Call)
        and node.func
        and isinstance(node.func, nodes.Name)
        and node.func.name in checked_call
    ):
        # functions in checked_calls take exactly one positional argument
        # check whether the argument is list comprehension
        if len(node.args) == 1 and isinstance(node.args[0], nodes.ListComp):
            # remove square brackets '[]'
            inside_comp = node.args[0].as_string()[1:-1]
            if node.keywords:
                inside_comp = f"({inside_comp})"
                inside_comp += ", "
                inside_comp += ", ".join(kw.as_string() for kw in node.keywords)
            call_name = node.func.name
            if call_name in {"any", "all"}:
                self.add_message(
                    "use-a-generator",
                    node=node,
                    args=(call_name, inside_comp),
                )
            else:
                self.add_message(
                    "consider-using-generator",
                    node=node,
                    args=(call_name, inside_comp),
                )

</t>
<t tx="ekr.20250131013600.552">@utils.only_required_for_messages(
    "stop-iteration-return",
    "consider-using-dict-comprehension",
    "consider-using-set-comprehension",
    "consider-using-sys-exit",
    "super-with-arguments",
    "consider-using-generator",
    "consider-using-with",
    "use-list-literal",
    "use-dict-literal",
    "use-a-generator",
)
def visit_call(self, node: nodes.Call) -&gt; None:
    self._check_raising_stopiteration_in_generator_next_call(node)
    self._check_consider_using_comprehension_constructor(node)
    self._check_quit_exit_call(node)
    self._check_super_with_arguments(node)
    self._check_consider_using_generator(node)
    self._check_consider_using_with(node)
    self._check_use_list_literal(node)
    self._check_use_dict_literal(node)

</t>
<t tx="ekr.20250131013600.553">@utils.only_required_for_messages("use-yield-from")
def visit_yield(self, node: nodes.Yield) -&gt; None:
    if not isinstance(node.value, nodes.Name):
        return

    loop_node = node.parent.parent
    if (
        not isinstance(loop_node, nodes.For)
        or isinstance(loop_node, nodes.AsyncFor)
        or len(loop_node.body) != 1
        # Avoid a false positive if the return value from `yield` is used,
        # (such as via Assign, AugAssign, etc).
        or not isinstance(node.parent, nodes.Expr)
    ):
        return

    if loop_node.target.name != node.value.name:
        return

    if isinstance(node.frame(), nodes.AsyncFunctionDef):
        return

    self.add_message("use-yield-from", node=loop_node, confidence=HIGH)

</t>
<t tx="ekr.20250131013600.554">@staticmethod
def _has_exit_in_scope(scope: nodes.LocalsDictNodeNG) -&gt; bool:
    exit_func = scope.locals.get("exit")
    return bool(
        exit_func and isinstance(exit_func[0], (nodes.ImportFrom, nodes.Import))
    )

</t>
<t tx="ekr.20250131013600.555">def _check_quit_exit_call(self, node: nodes.Call) -&gt; None:
    if isinstance(node.func, nodes.Name) and node.func.name in BUILTIN_EXIT_FUNCS:
        # If we have `exit` imported from `sys` in the current or global scope,
        # exempt this instance.
        local_scope = node.scope()
        if self._has_exit_in_scope(local_scope) or self._has_exit_in_scope(
            node.root()
        ):
            return
        self.add_message("consider-using-sys-exit", node=node, confidence=HIGH)

</t>
<t tx="ekr.20250131013600.556">def _check_super_with_arguments(self, node: nodes.Call) -&gt; None:
    if not isinstance(node.func, nodes.Name) or node.func.name != "super":
        return

    if (
        len(node.args) != 2
        or not all(isinstance(arg, nodes.Name) for arg in node.args)
        or node.args[1].name != "self"
        or (frame_class := node_frame_class(node)) is None
        or node.args[0].name != frame_class.name
    ):
        return

    self.add_message("super-with-arguments", node=node)

</t>
<t tx="ekr.20250131013600.557">def _check_raising_stopiteration_in_generator_next_call(
    self, node: nodes.Call
) -&gt; None:
    """Check if a StopIteration exception is raised by the call to next function.

    If the next value has a default value, then do not add message.

    :param node: Check to see if this Call node is a next function
    :type node: :class:`nodes.Call`
    """

    def _looks_like_infinite_iterator(param: nodes.NodeNG) -&gt; bool:
        inferred = utils.safe_infer(param)
        if isinstance(inferred, bases.Instance):
            return inferred.qname() in KNOWN_INFINITE_ITERATORS
        return False

    if isinstance(node.func, nodes.Attribute):
        # A next() method, which is now what we want.
        return

    if len(node.args) == 0:
        # handle case when builtin.next is called without args.
        # see https://github.com/pylint-dev/pylint/issues/7828
        return

    inferred = utils.safe_infer(node.func)

    if (
        isinstance(inferred, nodes.FunctionDef)
        and inferred.qname() == "builtins.next"
    ):
        frame = node.frame()
        # The next builtin can only have up to two
        # positional arguments and no keyword arguments
        has_sentinel_value = len(node.args) &gt; 1
        if (
            isinstance(frame, nodes.FunctionDef)
            and frame.is_generator()
            and not has_sentinel_value
            and not utils.node_ignores_exception(node, StopIteration)
            and not _looks_like_infinite_iterator(node.args[0])
        ):
            self.add_message(
                "stop-iteration-return", node=node, confidence=INFERENCE
            )

</t>
<t tx="ekr.20250131013600.558">def _check_nested_blocks(
    self,
    node: NodesWithNestedBlocks,
) -&gt; None:
    """Update and check the number of nested blocks."""
    # only check block levels inside functions or methods
    if not isinstance(node.scope(), nodes.FunctionDef):
        return
    # messages are triggered on leaving the nested block. Here we save the
    # stack in case the current node isn't nested in the previous one
    nested_blocks = self._nested_blocks[:]
    if node.parent == node.scope():
        self._nested_blocks = [node]
    else:
        # go through ancestors from the most nested to the less
        for ancestor_node in reversed(self._nested_blocks):
            if ancestor_node == node.parent:
                break
            self._nested_blocks.pop()
        # if the node is an elif, this should not be another nesting level
        if isinstance(node, nodes.If) and self._is_actual_elif(node):
            if self._nested_blocks:
                self._nested_blocks.pop()
        self._nested_blocks.append(node)

    # send message only once per group of nested blocks
    if len(nested_blocks) &gt; len(self._nested_blocks):
        self._emit_nested_blocks_message_if_needed(nested_blocks)

</t>
<t tx="ekr.20250131013600.559">def _emit_nested_blocks_message_if_needed(
    self, nested_blocks: list[NodesWithNestedBlocks]
) -&gt; None:
    if len(nested_blocks) &gt; self.linter.config.max_nested_blocks:
        self.add_message(
            "too-many-nested-blocks",
            node=nested_blocks[0],
            args=(len(nested_blocks), self.linter.config.max_nested_blocks),
        )

</t>
<t tx="ekr.20250131013600.56">def _supports_membership_test_protocol(value: nodes.NodeNG) -&gt; bool:
    return _supports_protocol_method(value, CONTAINS_METHOD)


</t>
<t tx="ekr.20250131013600.560">def _emit_consider_using_with_if_needed(
    self, stack: dict[str, nodes.NodeNG]
) -&gt; None:
    for node in stack.values():
        self.add_message("consider-using-with", node=node)

</t>
<t tx="ekr.20250131013600.561">@staticmethod
def _duplicated_isinstance_types(node: nodes.BoolOp) -&gt; dict[str, set[str]]:
    """Get the duplicated types from the underlying isinstance calls.

    :param nodes.BoolOp node: Node which should contain a bunch of isinstance calls.
    :returns: Dictionary of the comparison objects from the isinstance calls,
              to duplicate values from consecutive calls.
    :rtype: dict
    """
    duplicated_objects: set[str] = set()
    all_types: collections.defaultdict[str, set[str]] = collections.defaultdict(set)

    for call in node.values:
        if not isinstance(call, nodes.Call) or len(call.args) != 2:
            continue

        inferred = utils.safe_infer(call.func)
        if not inferred or not utils.is_builtin_object(inferred):
            continue

        if inferred.name != "isinstance":
            continue

        isinstance_object = call.args[0].as_string()
        isinstance_types = call.args[1]

        if isinstance_object in all_types:
            duplicated_objects.add(isinstance_object)

        if isinstance(isinstance_types, nodes.Tuple):
            elems = [
                class_type.as_string() for class_type in isinstance_types.itered()
            ]
        else:
            elems = [isinstance_types.as_string()]
        all_types[isinstance_object].update(elems)

    # Remove all keys which not duplicated
    return {
        key: value for key, value in all_types.items() if key in duplicated_objects
    }

</t>
<t tx="ekr.20250131013600.562">def _check_consider_merging_isinstance(self, node: nodes.BoolOp) -&gt; None:
    """Check isinstance calls which can be merged together."""
    if node.op != "or":
        return

    first_args = self._duplicated_isinstance_types(node)
    for duplicated_name, class_names in first_args.items():
        names = sorted(name for name in class_names)
        self.add_message(
            "consider-merging-isinstance",
            node=node,
            args=(duplicated_name, ", ".join(names)),
        )

</t>
<t tx="ekr.20250131013600.563">def _check_consider_using_in(self, node: nodes.BoolOp) -&gt; None:
    allowed_ops = {"or": "==", "and": "!="}

    if node.op not in allowed_ops or len(node.values) &lt; 2:
        return

    for value in node.values:
        if (
            not isinstance(value, nodes.Compare)
            or len(value.ops) != 1
            or value.ops[0][0] not in allowed_ops[node.op]
        ):
            return
        for comparable in value.left, value.ops[0][1]:
            if isinstance(comparable, nodes.Call):
                return

    # Gather variables and values from comparisons
    variables, values = [], []
    for value in node.values:
        variable_set = set()
        for comparable in value.left, value.ops[0][1]:
            if isinstance(comparable, (nodes.Name, nodes.Attribute)):
                variable_set.add(comparable.as_string())
            values.append(comparable.as_string())
        variables.append(variable_set)

    # Look for (common-)variables that occur in all comparisons
    common_variables = reduce(lambda a, b: a.intersection(b), variables)

    if not common_variables:
        return

    # Gather information for the suggestion
    common_variable = sorted(list(common_variables))[0]
    values = list(collections.OrderedDict.fromkeys(values))
    values.remove(common_variable)
    values_string = ", ".join(values) if len(values) != 1 else values[0] + ","
    maybe_not = "" if node.op == "or" else "not "
    self.add_message(
        "consider-using-in",
        node=node,
        args=(common_variable, maybe_not, values_string),
        confidence=HIGH,
    )

</t>
<t tx="ekr.20250131013600.564">def _check_chained_comparison(self, node: nodes.BoolOp) -&gt; None:
    """Check if there is any chained comparison in the expression.

    Add a refactoring message if a boolOp contains comparison like a &lt; b and b &lt; c,
    which can be chained as a &lt; b &lt; c.

    Care is taken to avoid simplifying a &lt; b &lt; c and b &lt; d.
    """
    if node.op != "and" or len(node.values) &lt; 2:
        return

    def _find_lower_upper_bounds(
        comparison_node: nodes.Compare,
        uses: collections.defaultdict[str, dict[str, set[nodes.Compare]]],
    ) -&gt; None:
        left_operand = comparison_node.left
        for operator, right_operand in comparison_node.ops:
            for operand in (left_operand, right_operand):
                value = None
                if isinstance(operand, nodes.Name):
                    value = operand.name
                elif isinstance(operand, nodes.Const):
                    value = operand.value

                if value is None:
                    continue

                if operator in {"&lt;", "&lt;="}:
                    if operand is left_operand:
                        uses[value]["lower_bound"].add(comparison_node)
                    elif operand is right_operand:
                        uses[value]["upper_bound"].add(comparison_node)
                elif operator in {"&gt;", "&gt;="}:
                    if operand is left_operand:
                        uses[value]["upper_bound"].add(comparison_node)
                    elif operand is right_operand:
                        uses[value]["lower_bound"].add(comparison_node)
            left_operand = right_operand

    uses: collections.defaultdict[str, dict[str, set[nodes.Compare]]] = (
        collections.defaultdict(
            lambda: {"lower_bound": set(), "upper_bound": set()}
        )
    )
    for comparison_node in node.values:
        if isinstance(comparison_node, nodes.Compare):
            _find_lower_upper_bounds(comparison_node, uses)

    for bounds in uses.values():
        num_shared = len(bounds["lower_bound"].intersection(bounds["upper_bound"]))
        num_lower_bounds = len(bounds["lower_bound"])
        num_upper_bounds = len(bounds["upper_bound"])
        if num_shared &lt; num_lower_bounds and num_shared &lt; num_upper_bounds:
            self.add_message("chained-comparison", node=node)
            break

</t>
<t tx="ekr.20250131013600.565">@staticmethod
def _apply_boolean_simplification_rules(
    operator: str, values: list[nodes.NodeNG]
) -&gt; list[nodes.NodeNG]:
    """Removes irrelevant values or returns short-circuiting values.

    This function applies the following two rules:
    1) an OR expression with True in it will always be true, and the
       reverse for AND

    2) False values in OR expressions are only relevant if all values are
       false, and the reverse for AND
    """
    simplified_values: list[nodes.NodeNG] = []

    for subnode in values:
        inferred_bool = None
        if not next(subnode.nodes_of_class(nodes.Name), False):
            inferred = utils.safe_infer(subnode)
            if inferred:
                inferred_bool = inferred.bool_value()

        if not isinstance(inferred_bool, bool):
            simplified_values.append(subnode)
        elif (operator == "or") == inferred_bool:
            return [subnode]

    return simplified_values or [nodes.Const(operator == "and")]

</t>
<t tx="ekr.20250131013600.566">def _simplify_boolean_operation(self, bool_op: nodes.BoolOp) -&gt; nodes.BoolOp:
    """Attempts to simplify a boolean operation.

    Recursively applies simplification on the operator terms,
    and keeps track of whether reductions have been made.
    """
    children = list(bool_op.get_children())
    intermediate = [
        (
            self._simplify_boolean_operation(child)
            if isinstance(child, nodes.BoolOp)
            else child
        )
        for child in children
    ]
    result = self._apply_boolean_simplification_rules(bool_op.op, intermediate)
    if len(result) &lt; len(children):
        self._can_simplify_bool_op = True
    if len(result) == 1:
        return result[0]
    simplified_bool_op = copy.copy(bool_op)
    simplified_bool_op.postinit(result)
    return simplified_bool_op

</t>
<t tx="ekr.20250131013600.567">def _check_simplifiable_condition(self, node: nodes.BoolOp) -&gt; None:
    """Check if a boolean condition can be simplified.

    Variables will not be simplified, even if the value can be inferred,
    and expressions like '3 + 4' will remain expanded.
    """
    if not utils.is_test_condition(node):
        return

    self._can_simplify_bool_op = False
    simplified_expr = self._simplify_boolean_operation(node)

    if not self._can_simplify_bool_op:
        return

    if not next(simplified_expr.nodes_of_class(nodes.Name), False):
        self.add_message(
            "condition-evals-to-constant",
            node=node,
            args=(node.as_string(), simplified_expr.as_string()),
        )
    else:
        self.add_message(
            "simplifiable-condition",
            node=node,
            args=(node.as_string(), simplified_expr.as_string()),
        )

</t>
<t tx="ekr.20250131013600.568">@utils.only_required_for_messages(
    "consider-merging-isinstance",
    "consider-using-in",
    "chained-comparison",
    "simplifiable-condition",
    "condition-evals-to-constant",
)
def visit_boolop(self, node: nodes.BoolOp) -&gt; None:
    self._check_consider_merging_isinstance(node)
    self._check_consider_using_in(node)
    self._check_chained_comparison(node)
    self._check_simplifiable_condition(node)

</t>
<t tx="ekr.20250131013600.569">@staticmethod
def _is_simple_assignment(node: nodes.NodeNG | None) -&gt; bool:
    return (
        isinstance(node, nodes.Assign)
        and len(node.targets) == 1
        and isinstance(node.targets[0], nodes.AssignName)
        and isinstance(node.value, nodes.Name)
    )

</t>
<t tx="ekr.20250131013600.57">def _supports_iteration_protocol(value: nodes.NodeNG) -&gt; bool:
    return _supports_protocol_method(value, ITER_METHOD) or _supports_protocol_method(
        value, GETITEM_METHOD
    )


</t>
<t tx="ekr.20250131013600.570">def _check_swap_variables(self, node: nodes.Return | nodes.Assign) -&gt; None:
    if not node.next_sibling() or not node.next_sibling().next_sibling():
        return
    assignments = [node, node.next_sibling(), node.next_sibling().next_sibling()]
    if not all(self._is_simple_assignment(node) for node in assignments):
        return
    if any(node in self._reported_swap_nodes for node in assignments):
        return
    left = [node.targets[0].name for node in assignments]
    right = [node.value.name for node in assignments]
    if left[0] == right[-1] and left[1:] == right[:-1]:
        self._reported_swap_nodes.update(assignments)
        message = "consider-swap-variables"
        self.add_message(message, node=node)

</t>
<t tx="ekr.20250131013600.571">@utils.only_required_for_messages(
    "simplify-boolean-expression",
    "consider-using-ternary",
    "consider-swap-variables",
    "consider-using-with",
)
def visit_assign(self, node: nodes.Assign) -&gt; None:
    self._append_context_managers_to_stack(node)
    self.visit_return(node)  # remaining checks are identical as for return nodes

</t>
<t tx="ekr.20250131013600.572">@utils.only_required_for_messages(
    "simplify-boolean-expression",
    "consider-using-ternary",
    "consider-swap-variables",
)
def visit_return(self, node: nodes.Return | nodes.Assign) -&gt; None:
    self._check_swap_variables(node)
    if self._is_and_or_ternary(node.value):
        cond, truth_value, false_value = self._and_or_ternary_arguments(node.value)
    else:
        return

    if all(
        isinstance(value, nodes.Compare) for value in (truth_value, false_value)
    ):
        return

    inferred_truth_value = utils.safe_infer(truth_value, compare_constants=True)
    if inferred_truth_value is None or isinstance(
        inferred_truth_value, UninferableBase
    ):
        return
    truth_boolean_value = inferred_truth_value.bool_value()

    if truth_boolean_value is False:
        message = "simplify-boolean-expression"
        suggestion = false_value.as_string()
    else:
        message = "consider-using-ternary"
        suggestion = f"{truth_value.as_string()} if {cond.as_string()} else {false_value.as_string()}"
    self.add_message(message, node=node, args=(suggestion,), confidence=INFERENCE)

</t>
<t tx="ekr.20250131013600.573">def _append_context_managers_to_stack(self, node: nodes.Assign) -&gt; None:
    if _is_inside_context_manager(node):
        # if we are inside a context manager itself, we assume that it will handle
        # the resource management itself.
        return
    if isinstance(node.targets[0], (nodes.Tuple, nodes.List, nodes.Set)):
        assignees = node.targets[0].elts
        value = utils.safe_infer(node.value)
        if value is None or not hasattr(value, "elts"):
            # We cannot deduce what values are assigned, so we have to skip this
            return
        values = value.elts
    else:
        assignees = [node.targets[0]]
        values = [node.value]
    if any(isinstance(n, UninferableBase) for n in (assignees, values)):
        return
    for assignee, value in zip(assignees, values):
        if not isinstance(value, nodes.Call):
            continue
        inferred = utils.safe_infer(value.func)
        if (
            not inferred
            or inferred.qname() not in CALLS_RETURNING_CONTEXT_MANAGERS
            or not isinstance(assignee, (nodes.AssignName, nodes.AssignAttr))
        ):
            continue
        stack = self._consider_using_with_stack.get_stack_for_frame(node.frame())
        varname = (
            assignee.name
            if isinstance(assignee, nodes.AssignName)
            else assignee.attrname
        )
        if varname in stack:
            existing_node = stack[varname]
            if astroid.are_exclusive(node, existing_node):
                # only one of the two assignments can be executed at runtime, thus it is fine
                stack[varname] = value
                continue
            # variable was redefined before it was used in a ``with`` block
            self.add_message(
                "consider-using-with",
                node=existing_node,
            )
        stack[varname] = value

</t>
<t tx="ekr.20250131013600.574">def _check_consider_using_with(self, node: nodes.Call) -&gt; None:
    if _is_inside_context_manager(node) or _is_a_return_statement(node):
        # If we are inside a context manager itself, we assume that it will handle the
        # resource management itself.
        # If the node is a child of a return, we assume that the caller knows he is getting
        # a context manager he should use properly (i.e. in a ``with``).
        return
    if (
        node
        in self._consider_using_with_stack.get_stack_for_frame(
            node.frame()
        ).values()
    ):
        # the result of this call was already assigned to a variable and will be
        # checked when leaving the scope.
        return
    inferred = utils.safe_infer(node.func)
    if not inferred or not isinstance(
        inferred, (nodes.FunctionDef, nodes.ClassDef, bases.BoundMethod)
    ):
        return
    could_be_used_in_with = (
        # things like ``lock.acquire()``
        inferred.qname() in CALLS_THAT_COULD_BE_REPLACED_BY_WITH
        or (
            # things like ``open("foo")`` which are not already inside a ``with`` statement
            inferred.qname() in CALLS_RETURNING_CONTEXT_MANAGERS
            and not _is_part_of_with_items(node)
        )
    )
    if could_be_used_in_with and not _will_be_released_automatically(node):
        self.add_message("consider-using-with", node=node)

</t>
<t tx="ekr.20250131013600.575">def _check_use_list_literal(self, node: nodes.Call) -&gt; None:
    """Check if empty list is created by using the literal []."""
    if node.as_string() == "list()":
        inferred = utils.safe_infer(node.func)
        if isinstance(inferred, nodes.ClassDef) and not node.args:
            if inferred.qname() == "builtins.list":
                self.add_message("use-list-literal", node=node)

</t>
<t tx="ekr.20250131013600.576">def _check_use_dict_literal(self, node: nodes.Call) -&gt; None:
    """Check if dict is created by using the literal {}."""
    if not isinstance(node.func, astroid.Name) or node.func.name != "dict":
        return
    inferred = utils.safe_infer(node.func)
    if (
        isinstance(inferred, nodes.ClassDef)
        and inferred.qname() == "builtins.dict"
        and not node.args
    ):
        self.add_message(
            "use-dict-literal",
            args=(self._dict_literal_suggestion(node),),
            node=node,
            confidence=INFERENCE,
        )

</t>
<t tx="ekr.20250131013600.577">@staticmethod
def _dict_literal_suggestion(node: nodes.Call) -&gt; str:
    """Return a suggestion of reasonable length."""
    elements: list[str] = []
    for keyword in node.keywords:
        if len(", ".join(elements)) &gt;= 64:
            break
        if keyword not in node.kwargs:
            elements.append(f'"{keyword.arg}": {keyword.value.as_string()}')
    for keyword in node.kwargs:
        if len(", ".join(elements)) &gt;= 64:
            break
        elements.append(f"**{keyword.value.as_string()}")
    suggestion = ", ".join(elements)
    return f"{{{suggestion}{', ... '  if len(suggestion) &gt; 64 else ''}}}"

</t>
<t tx="ekr.20250131013600.578">def _name_to_concatenate(self, node: nodes.NodeNG) -&gt; str | None:
    """Try to extract the name used in a concatenation loop."""
    if isinstance(node, nodes.Name):
        return cast("str | None", node.name)
    if not isinstance(node, nodes.JoinedStr):
        return None

    values = [
        value for value in node.values if isinstance(value, nodes.FormattedValue)
    ]
    if len(values) != 1 or not isinstance(values[0].value, nodes.Name):
        return None
    # If there are more values in joined string than formatted values,
    # they are probably separators.
    # Allow them only if the option `suggest-join-with-non-empty-separator` is set
    with_separators = len(node.values) &gt; len(values)
    if with_separators and not self._suggest_join_with_non_empty_separator:
        return None
    return cast("str | None", values[0].value.name)

</t>
<t tx="ekr.20250131013600.579">def _check_consider_using_join(self, aug_assign: nodes.AugAssign) -&gt; None:
    """We start with the augmented assignment and work our way upwards.

    Names of variables for nodes if match successful:
    result = ''  # assign
    for number in ['1', '2', '3']  # for_loop
        result += number  # aug_assign
    """
    for_loop = aug_assign.parent
    if not isinstance(for_loop, nodes.For) or len(for_loop.body) &gt; 1:
        return
    assign = for_loop.previous_sibling()
    if not isinstance(assign, nodes.Assign):
        return
    result_assign_names = {
        target.name
        for target in assign.targets
        if isinstance(target, nodes.AssignName)
    }

    is_concat_loop = (
        aug_assign.op == "+="
        and isinstance(aug_assign.target, nodes.AssignName)
        and len(for_loop.body) == 1
        and aug_assign.target.name in result_assign_names
        and isinstance(assign.value, nodes.Const)
        and isinstance(assign.value.value, str)
        and self._name_to_concatenate(aug_assign.value) == for_loop.target.name
    )
    if is_concat_loop:
        self.add_message("consider-using-join", node=aug_assign)

</t>
<t tx="ekr.20250131013600.58">def _supports_async_iteration_protocol(value: nodes.NodeNG) -&gt; bool:
    return _supports_protocol_method(value, AITER_METHOD)


</t>
<t tx="ekr.20250131013600.580">@utils.only_required_for_messages("consider-using-join")
def visit_augassign(self, node: nodes.AugAssign) -&gt; None:
    self._check_consider_using_join(node)

</t>
<t tx="ekr.20250131013600.581">@utils.only_required_for_messages(
    "unnecessary-comprehension",
    "unnecessary-dict-index-lookup",
    "unnecessary-list-index-lookup",
)
def visit_comprehension(self, node: nodes.Comprehension) -&gt; None:
    self._check_unnecessary_comprehension(node)
    self._check_unnecessary_dict_index_lookup(node)
    self._check_unnecessary_list_index_lookup(node)

</t>
<t tx="ekr.20250131013600.582">def _check_unnecessary_comprehension(self, node: nodes.Comprehension) -&gt; None:
    if (
        isinstance(node.parent, nodes.GeneratorExp)
        or len(node.ifs) != 0
        or len(node.parent.generators) != 1
        or node.is_async
    ):
        return

    if (
        isinstance(node.parent, nodes.DictComp)
        and isinstance(node.parent.key, nodes.Name)
        and isinstance(node.parent.value, nodes.Name)
        and isinstance(node.target, nodes.Tuple)
        and all(isinstance(elt, nodes.AssignName) for elt in node.target.elts)
    ):
        expr_list = [node.parent.key.name, node.parent.value.name]
        target_list = [elt.name for elt in node.target.elts]

    elif isinstance(node.parent, (nodes.ListComp, nodes.SetComp)):
        expr = node.parent.elt
        if isinstance(expr, nodes.Name):
            expr_list = expr.name
        elif isinstance(expr, nodes.Tuple):
            if any(not isinstance(elt, nodes.Name) for elt in expr.elts):
                return
            expr_list = [elt.name for elt in expr.elts]
        else:
            expr_list = []
        target = node.parent.generators[0].target
        target_list = (
            target.name
            if isinstance(target, nodes.AssignName)
            else (
                [
                    elt.name
                    for elt in target.elts
                    if isinstance(elt, nodes.AssignName)
                ]
                if isinstance(target, nodes.Tuple)
                else []
            )
        )
    else:
        return
    if expr_list == target_list and expr_list:
        args: tuple[str] | None = None
        inferred = utils.safe_infer(node.iter)
        if isinstance(node.parent, nodes.DictComp) and isinstance(
            inferred, astroid.objects.DictItems
        ):
            args = (f"dict({node.iter.func.expr.as_string()})",)
        elif isinstance(node.parent, nodes.ListComp) and isinstance(
            inferred, nodes.List
        ):
            args = (f"list({node.iter.as_string()})",)
        elif isinstance(node.parent, nodes.SetComp) and isinstance(
            inferred, nodes.Set
        ):
            args = (f"set({node.iter.as_string()})",)
        if args:
            self.add_message(
                "unnecessary-comprehension", node=node.parent, args=args
            )
            return

        if isinstance(node.parent, nodes.DictComp):
            func = "dict"
        elif isinstance(node.parent, nodes.ListComp):
            func = "list"
        elif isinstance(node.parent, nodes.SetComp):
            func = "set"
        else:
            return

        self.add_message(
            "unnecessary-comprehension",
            node=node.parent,
            args=(f"{func}({node.iter.as_string()})",),
        )

</t>
<t tx="ekr.20250131013600.583">@staticmethod
def _is_and_or_ternary(node: nodes.NodeNG | None) -&gt; bool:
    """Returns true if node is 'condition and true_value or false_value' form.

    All of: condition, true_value and false_value should not be a complex boolean expression
    """
    return (
        isinstance(node, nodes.BoolOp)
        and node.op == "or"
        and len(node.values) == 2
        and isinstance(node.values[0], nodes.BoolOp)
        and not isinstance(node.values[1], nodes.BoolOp)
        and node.values[0].op == "and"
        and not isinstance(node.values[0].values[1], nodes.BoolOp)
        and len(node.values[0].values) == 2
    )

</t>
<t tx="ekr.20250131013600.584">@staticmethod
def _and_or_ternary_arguments(
    node: nodes.BoolOp,
) -&gt; tuple[nodes.NodeNG, nodes.NodeNG, nodes.NodeNG]:
    false_value = node.values[1]
    condition, true_value = node.values[0].values
    return condition, true_value, false_value

</t>
<t tx="ekr.20250131013600.585">def visit_functiondef(self, node: nodes.FunctionDef) -&gt; None:
    self._return_nodes[node.name] = list(
        node.nodes_of_class(nodes.Return, skip_klass=nodes.FunctionDef)
    )

</t>
<t tx="ekr.20250131013600.586">def _check_consistent_returns(self, node: nodes.FunctionDef) -&gt; None:
    """Check that all return statements inside a function are consistent.

    Return statements are consistent if:
        - all returns are explicit and if there is no implicit return;
        - all returns are empty and if there is, possibly, an implicit return.

    Args:
        node (nodes.FunctionDef): the function holding the return statements.
    """
    # explicit return statements are those with a not None value
    explicit_returns = [
        _node for _node in self._return_nodes[node.name] if _node.value is not None
    ]
    if not explicit_returns:
        return
    if len(explicit_returns) == len(
        self._return_nodes[node.name]
    ) and self._is_node_return_ended(node):
        return
    self.add_message("inconsistent-return-statements", node=node)

</t>
<t tx="ekr.20250131013600.587">def _is_if_node_return_ended(self, node: nodes.If) -&gt; bool:
    """Check if the If node ends with an explicit return statement.

    Args:
        node (nodes.If): If node to be checked.

    Returns:
        bool: True if the node ends with an explicit statement, False otherwise.
    """
    # Do not check if inner function definition are return ended.
    is_if_returning = any(
        self._is_node_return_ended(_ifn)
        for _ifn in node.body
        if not isinstance(_ifn, nodes.FunctionDef)
    )
    if not node.orelse:
        # If there is not orelse part then the if statement is returning if :
        # - there is at least one return statement in its siblings;
        # - the if body is itself returning.
        if not self._has_return_in_siblings(node):
            return False
        return is_if_returning
    # If there is an orelse part then both if body and orelse part should return.
    is_orelse_returning = any(
        self._is_node_return_ended(_ore)
        for _ore in node.orelse
        if not isinstance(_ore, nodes.FunctionDef)
    )
    return is_if_returning and is_orelse_returning

</t>
<t tx="ekr.20250131013600.588">def _is_raise_node_return_ended(self, node: nodes.Raise) -&gt; bool:
    """Check if the Raise node ends with an explicit return statement.

    Args:
        node (nodes.Raise): Raise node to be checked.

    Returns:
        bool: True if the node ends with an explicit statement, False otherwise.
    """
    # a Raise statement doesn't need to end with a return statement
    # but if the exception raised is handled, then the handler has to
    # ends with a return statement
    if not node.exc:
        # Ignore bare raises
        return True
    if not utils.is_node_inside_try_except(node):
        # If the raise statement is not inside a try/except statement
        # then the exception is raised and cannot be caught. No need
        # to infer it.
        return True
    exc = utils.safe_infer(node.exc)
    if (
        exc is None
        or isinstance(exc, UninferableBase)
        or not hasattr(exc, "pytype")
    ):
        return False
    exc_name = exc.pytype().split(".")[-1]
    handlers = utils.get_exception_handlers(node, exc_name)
    handlers = list(handlers) if handlers is not None else []
    if handlers:
        # among all the handlers handling the exception at least one
        # must end with a return statement
        return any(self._is_node_return_ended(_handler) for _handler in handlers)
    # if no handlers handle the exception then it's ok
    return True

</t>
<t tx="ekr.20250131013600.589">def _is_node_return_ended(self, node: nodes.NodeNG) -&gt; bool:
    """Check if the node ends with an explicit return statement.

    Args:
        node (nodes.NodeNG): node to be checked.

    Returns:
        bool: True if the node ends with an explicit statement, False otherwise.
    """
    # Recursion base case
    if isinstance(node, nodes.Return):
        return True
    if isinstance(node, nodes.Call):
        return any(
            (
                isinstance(maybe_func, (nodes.FunctionDef, bases.BoundMethod))
                and self._is_function_def_never_returning(maybe_func)
            )
            for maybe_func in utils.infer_all(node.func)
        )
    if isinstance(node, nodes.While):
        # A while-loop is considered return-ended if it has a
        # truthy test and no break statements
        return (node.test.bool_value() and not _loop_exits_early(node)) or any(
            self._is_node_return_ended(child) for child in node.orelse
        )
    if isinstance(node, nodes.Raise):
        return self._is_raise_node_return_ended(node)
    if isinstance(node, nodes.If):
        return self._is_if_node_return_ended(node)
    if isinstance(node, nodes.Try):
        handlers = {
            _child
            for _child in node.get_children()
            if isinstance(_child, nodes.ExceptHandler)
        }
        all_but_handler = set(node.get_children()) - handlers
        return any(
            self._is_node_return_ended(_child) for _child in all_but_handler
        ) and all(self._is_node_return_ended(_child) for _child in handlers)
    if (
        isinstance(node, nodes.Assert)
        and isinstance(node.test, nodes.Const)
        and not node.test.value
    ):
        # consider assert False as a return node
        return True
    # recurses on the children of the node
    return any(self._is_node_return_ended(_child) for _child in node.get_children())

</t>
<t tx="ekr.20250131013600.59">def _supports_getitem_protocol(value: nodes.NodeNG) -&gt; bool:
    return _supports_protocol_method(value, GETITEM_METHOD)


</t>
<t tx="ekr.20250131013600.590">@staticmethod
def _has_return_in_siblings(node: nodes.NodeNG) -&gt; bool:
    """Returns True if there is at least one return in the node's siblings."""
    next_sibling = node.next_sibling()
    while next_sibling:
        if isinstance(next_sibling, nodes.Return):
            return True
        next_sibling = next_sibling.next_sibling()
    return False

</t>
<t tx="ekr.20250131013600.591">def _is_function_def_never_returning(
    self, node: nodes.FunctionDef | astroid.BoundMethod
) -&gt; bool:
    """Return True if the function never returns, False otherwise.

    Args:
        node (nodes.FunctionDef or astroid.BoundMethod): function definition node to be analyzed.

    Returns:
        bool: True if the function never returns, False otherwise.
    """
    try:
        if node.qname() in self._never_returning_functions:
            return True
    except(TypeError, AttributeError):
        pass

    try:
        returns: nodes.NodeNG | None = node.returns
    except AttributeError:
        return False  # the BoundMethod proxy may be a lambda without a returns

    return (
        isinstance(returns, nodes.Attribute)
        and returns.attrname in {"NoReturn", "Never"}
    ) or (isinstance(returns, nodes.Name) and returns.name in {"NoReturn", "Never"})

</t>
<t tx="ekr.20250131013600.592">def _check_return_at_the_end(self, node: nodes.FunctionDef) -&gt; None:
    """Check for presence of a *single* return statement at the end of a
    function.

    "return" or "return None" are useless because None is the
    default return type if they are missing.

    NOTE: produces a message only if there is a single return statement
    in the function body. Otherwise _check_consistent_returns() is called!
    Per its implementation and PEP8 we can have a "return None" at the end
    of the function body if there are other return statements before that!
    """
    if len(self._return_nodes[node.name]) != 1:
        return
    if not node.body:
        return

    last = node.body[-1]
    if isinstance(last, nodes.Return) and len(node.body) == 1:
        return

    while isinstance(last, (nodes.If, nodes.Try, nodes.ExceptHandler)):
        last = last.last_child()

    if isinstance(last, nodes.Return):
        # e.g. "return"
        if last.value is None:
            self.add_message("useless-return", node=node)
        # return None"
        elif isinstance(last.value, nodes.Const) and (last.value.value is None):
            self.add_message("useless-return", node=node)

</t>
<t tx="ekr.20250131013600.593">def _check_unnecessary_dict_index_lookup(
    self, node: nodes.For | nodes.Comprehension
) -&gt; None:
    """Add message when accessing dict values by index lookup."""
    # Verify that we have an .items() call and
    # that the object which is iterated is used as a subscript in the
    # body of the for.
    # Is it a proper items call?
    if (
        isinstance(node.iter, nodes.Call)
        and isinstance(node.iter.func, nodes.Attribute)
        and node.iter.func.attrname == "items"
    ):
        inferred = utils.safe_infer(node.iter.func)
        if not isinstance(inferred, astroid.BoundMethod):
            return
        iterating_object_name = node.iter.func.expr.as_string()

        # Store potential violations. These will only be reported if we don't
        # discover any writes to the collection during the loop.
        messages = []

        # Verify that the body of the for loop uses a subscript
        # with the object that was iterated. This uses some heuristics
        # in order to make sure that the same object is used in the
        # for body.

        children = (
            node.body
            if isinstance(node, nodes.For)
            else list(node.parent.get_children())
        )

        # Check if there are any for / while loops within the loop in question;
        # If so, we will be more conservative about reporting errors as we
        # can't yet do proper control flow analysis to be sure when
        # reassignment will affect us
        nested_loops = itertools.chain.from_iterable(
            child.nodes_of_class((nodes.For, nodes.While)) for child in children
        )
        has_nested_loops = next(nested_loops, None) is not None

        for child in children:
            for subscript in child.nodes_of_class(nodes.Subscript):
                if not isinstance(subscript.value, (nodes.Name, nodes.Attribute)):
                    continue

                value = subscript.slice

                if isinstance(node, nodes.For) and _is_part_of_assignment_target(
                    subscript
                ):
                    # Ignore this subscript if it is the target of an assignment
                    # Early termination; after reassignment dict index lookup will be necessary
                    return

                if isinstance(subscript.parent, nodes.Delete):
                    # Ignore this subscript if it's used with the delete keyword
                    return

                # Case where .items is assigned to k,v (i.e., for k, v in d.items())
                if isinstance(value, nodes.Name):
                    if (
                        not isinstance(node.target, nodes.Tuple)
                        # Ignore 1-tuples: for k, in d.items()
                        or len(node.target.elts) &lt; 2
                        or value.name != node.target.elts[0].name
                        or iterating_object_name != subscript.value.as_string()
                    ):
                        continue

                    if (
                        isinstance(node, nodes.For)
                        and value.lookup(value.name)[1][-1].lineno &gt; node.lineno
                    ):
                        # Ignore this subscript if it has been redefined after
                        # the for loop. This checks for the line number using .lookup()
                        # to get the line number where the iterating object was last
                        # defined and compare that to the for loop's line number
                        continue

                    if has_nested_loops:
                        messages.append(
                            {
                                "node": subscript,
                                "variable": node.target.elts[1].as_string(),
                            }
                        )
                    else:
                        self.add_message(
                            "unnecessary-dict-index-lookup",
                            node=subscript,
                            args=(node.target.elts[1].as_string(),),
                        )

                # Case where .items is assigned to single var (i.e., for item in d.items())
                elif isinstance(value, nodes.Subscript):
                    if (
                        not isinstance(node.target, nodes.AssignName)
                        or not isinstance(value.value, nodes.Name)
                        or node.target.name != value.value.name
                        or iterating_object_name != subscript.value.as_string()
                    ):
                        continue

                    if (
                        isinstance(node, nodes.For)
                        and value.value.lookup(value.value.name)[1][-1].lineno
                        &gt; node.lineno
                    ):
                        # Ignore this subscript if it has been redefined after
                        # the for loop. This checks for the line number using .lookup()
                        # to get the line number where the iterating object was last
                        # defined and compare that to the for loop's line number
                        continue

                    # check if subscripted by 0 (key)
                    inferred = utils.safe_infer(value.slice)
                    if not isinstance(inferred, nodes.Const) or inferred.value != 0:
                        continue

                    if has_nested_loops:
                        messages.append(
                            {
                                "node": subscript,
                                "variable": "1".join(
                                    value.as_string().rsplit("0", maxsplit=1)
                                ),
                            }
                        )
                    else:
                        self.add_message(
                            "unnecessary-dict-index-lookup",
                            node=subscript,
                            args=(
                                "1".join(value.as_string().rsplit("0", maxsplit=1)),
                            ),
                        )

        for message in messages:
            self.add_message(
                "unnecessary-dict-index-lookup",
                node=message["node"],
                args=(message["variable"],),
            )

</t>
<t tx="ekr.20250131013600.594">def _check_unnecessary_list_index_lookup(
    self, node: nodes.For | nodes.Comprehension
) -&gt; None:
    if (
        not isinstance(node.iter, nodes.Call)
        or not isinstance(node.iter.func, nodes.Name)
        or not node.iter.func.name == "enumerate"
    ):
        return

    preliminary_confidence = HIGH
    try:
        iterable_arg = utils.get_argument_from_call(
            node.iter, position=0, keyword="iterable"
        )
    except utils.NoSuchArgumentError:
        iterable_arg = utils.infer_kwarg_from_call(node.iter, keyword="iterable")
        preliminary_confidence = INFERENCE

    if not isinstance(iterable_arg, nodes.Name):
        return

    if not isinstance(node.target, nodes.Tuple) or len(node.target.elts) &lt; 2:
        # enumerate() result is being assigned without destructuring
        return

    if not isinstance(node.target.elts[1], nodes.AssignName):
        # The value is not being assigned to a single variable, e.g. being
        # destructured, so we can't necessarily use it.
        return

    has_start_arg, confidence = self._enumerate_with_start(node)
    if has_start_arg:
        # enumerate is being called with start arg/kwarg so resulting index lookup
        # is not redundant, hence we should not report an error.
        return

    # Preserve preliminary_confidence if it was INFERENCE
    confidence = (
        preliminary_confidence
        if preliminary_confidence == INFERENCE
        else confidence
    )

    iterating_object_name = iterable_arg.name
    value_variable = node.target.elts[1]

    # Store potential violations. These will only be reported if we don't
    # discover any writes to the collection during the loop.
    bad_nodes = []

    children = (
        node.body
        if isinstance(node, nodes.For)
        else list(node.parent.get_children())
    )

    # Check if there are any for / while loops within the loop in question;
    # If so, we will be more conservative about reporting errors as we
    # can't yet do proper control flow analysis to be sure when
    # reassignment will affect us
    nested_loops = itertools.chain.from_iterable(
        child.nodes_of_class((nodes.For, nodes.While)) for child in children
    )
    has_nested_loops = next(nested_loops, None) is not None

    # Check if there are any if statements within the loop in question;
    # If so, we will be more conservative about reporting errors as we
    # can't yet do proper control flow analysis to be sure when
    # reassignment will affect us
    if_statements = itertools.chain.from_iterable(
        child.nodes_of_class(nodes.If) for child in children
    )
    has_if_statements = next(if_statements, None) is not None

    for child in children:
        for subscript in child.nodes_of_class(nodes.Subscript):
            if isinstance(node, nodes.For) and _is_part_of_assignment_target(
                subscript
            ):
                # Ignore this subscript if it is the target of an assignment
                # Early termination; after reassignment index lookup will be necessary
                return

            if isinstance(subscript.parent, nodes.Delete):
                # Ignore this subscript if it's used with the delete keyword
                return

            index = subscript.slice
            if isinstance(index, nodes.Name):
                if (
                    index.name != node.target.elts[0].name
                    or iterating_object_name != subscript.value.as_string()
                ):
                    continue

                if (
                    isinstance(node, nodes.For)
                    and index.lookup(index.name)[1][-1].lineno &gt; node.lineno
                ):
                    # Ignore this subscript if it has been redefined after
                    # the for loop.
                    continue

                if (
                    isinstance(node, nodes.For)
                    and index.lookup(value_variable.name)[1][-1].lineno
                    &gt; node.lineno
                ):
                    # The variable holding the value from iteration has been
                    # reassigned on a later line, so it can't be used.
                    continue

                if has_nested_loops:
                    # Have found a likely issue, but since there are nested
                    # loops we don't want to report this unless we get to the
                    # end of the loop without updating the collection
                    bad_nodes.append(subscript)
                elif has_if_statements:
                    continue
                else:
                    self.add_message(
                        "unnecessary-list-index-lookup",
                        node=subscript,
                        args=(node.target.elts[1].name,),
                        confidence=confidence,
                    )

    for subscript in bad_nodes:
        self.add_message(
            "unnecessary-list-index-lookup",
            node=subscript,
            args=(node.target.elts[1].name,),
            confidence=confidence,
        )

</t>
<t tx="ekr.20250131013600.595">def _enumerate_with_start(
    self, node: nodes.For | nodes.Comprehension
) -&gt; tuple[bool, Confidence]:
    """Check presence of `start` kwarg or second argument to enumerate.

    For example:

    `enumerate([1,2,3], start=1)`
    `enumerate([1,2,3], 1)`

    If `start` is assigned to `0`, the default value, this is equivalent to
    not calling `enumerate` with start.
    """
    confidence = HIGH

    if len(node.iter.args) &gt; 1:
        # We assume the second argument to `enumerate` is the `start` int arg.
        # It's a reasonable assumption for now as it's the only possible argument:
        # https://docs.python.org/3/library/functions.html#enumerate
        start_arg = node.iter.args[1]
        start_val, confidence = self._get_start_value(start_arg)
        if start_val is None:
            return False, confidence
        return not start_val == 0, confidence

    for keyword in node.iter.keywords:
        if keyword.arg == "start":
            start_val, confidence = self._get_start_value(keyword.value)
            if start_val is None:
                return False, confidence
            return not start_val == 0, confidence

    return False, confidence

</t>
<t tx="ekr.20250131013600.596">def _get_start_value(self, node: nodes.NodeNG) -&gt; tuple[int | None, Confidence]:
    if isinstance(node, (nodes.Name, nodes.Call, nodes.Attribute)) or (
        isinstance(node, nodes.UnaryOp)
        and isinstance(node.operand, (nodes.Attribute, nodes.Name))
    ):
        inferred = utils.safe_infer(node)
        # inferred can be an astroid.base.Instance as in 'enumerate(x, int(y))' or
        # not correctly inferred (None)
        start_val = inferred.value if isinstance(inferred, nodes.Const) else None
        return start_val, INFERENCE
    if isinstance(node, nodes.UnaryOp):
        return node.operand.value, HIGH
    if isinstance(node, nodes.Const):
        return node.value, HIGH
    return None, HIGH
</t>
<t tx="ekr.20250131013600.597"></t>
<t tx="ekr.20250131013600.598">@path pylint/config
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

__all__ = ["find_default_config_files"]

from pylint.config.find_default_config_files import find_default_config_files
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.599">@path pylint/config
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""List the breaking changes in configuration files and their solutions."""

from __future__ import annotations

import enum
from typing import NamedTuple


@others
ConditionsToBeAffected = list[Condition]
# A solution to a breaking change might imply multiple actions
MultipleActionSolution = list[Solution]
# Sometimes there's multiple solutions and the user needs to choose
Solutions = list[MultipleActionSolution]
BreakingChangeWithSolution = tuple[
    BreakingChange, Information, ConditionsToBeAffected, Solutions
]

NO_SELF_USE = Information(
    msgid_or_symbol="no-self-use", extension="pylint.extensions.no_self_use"
)
COMPARE_TO_ZERO = Information(
    msgid_or_symbol="compare-to-zero", extension="pylint.extensions.comparetozero"
)
COMPARE_TO_EMPTY_STRING = Information(
    msgid_or_symbol="compare-to-empty-string",
    extension="pylint.extensions.emptystring",
)

CONFIGURATION_BREAKING_CHANGES: dict[str, list[BreakingChangeWithSolution]] = {
    "2.14.0": [
        (
            BreakingChange.MESSAGE_MOVED_TO_EXTENSION,
            NO_SELF_USE,
            [Condition.MESSAGE_IS_ENABLED, Condition.EXTENSION_IS_NOT_LOADED],
            [[Solution.ADD_EXTENSION], [Solution.DISABLE_MESSAGE_IMPLICITLY]],
        ),
    ],
    "3.0.0": [
        (
            BreakingChange.EXTENSION_REMOVED,
            COMPARE_TO_ZERO,
            [Condition.MESSAGE_IS_NOT_DISABLED, Condition.EXTENSION_IS_LOADED],
            [[Solution.REMOVE_EXTENSION, Solution.ENABLE_MESSAGE_EXPLICITLY]],
        ),
        (
            BreakingChange.EXTENSION_REMOVED,
            COMPARE_TO_EMPTY_STRING,
            [Condition.MESSAGE_IS_NOT_DISABLED, Condition.EXTENSION_IS_LOADED],
            [[Solution.REMOVE_EXTENSION, Solution.ENABLE_MESSAGE_EXPLICITLY]],
        ),
    ],
}
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.6">builtins = builtins.__dict__.copy()  # type: ignore[assignment]
SPECIAL_BUILTINS = ("__builtins__",)  # '__path__', '__file__')


def is_builtin_object(node: nodes.NodeNG) -&gt; bool:
    """Returns True if the given node is an object from the __builtin__ module."""
    return node and node.root().name == "builtins"  # type: ignore[no-any-return]


</t>
<t tx="ekr.20250131013600.60">def _supports_setitem_protocol(value: nodes.NodeNG) -&gt; bool:
    return _supports_protocol_method(value, SETITEM_METHOD)


</t>
<t tx="ekr.20250131013600.600">class BreakingChange(enum.Enum):
    MESSAGE_MADE_DISABLED_BY_DEFAULT = "{symbol} ({msgid}) was disabled by default"
    MESSAGE_MADE_ENABLED_BY_DEFAULT = "{symbol} ({msgid}) was enabled by default"
    MESSAGE_MOVED_TO_EXTENSION = "{symbol} ({msgid}) was moved to {extension}"
    EXTENSION_REMOVED = "{extension} was removed"
</t>
<t tx="ekr.20250131013600.601">    # This kind of upgrade is non-breaking but if we want to automatically upgrade it,
    # then we should use the message store and old_names values instead of duplicating
    # MESSAGE_RENAMED= "{symbol} ({msgid}) was renamed"


class Condition(enum.Enum):
    MESSAGE_IS_ENABLED = "{symbol} ({msgid}) is enabled"
    MESSAGE_IS_NOT_ENABLED = "{symbol} ({msgid}) is not enabled"
    MESSAGE_IS_DISABLED = "{symbol} ({msgid}) is disabled"
    MESSAGE_IS_NOT_DISABLED = "{symbol} ({msgid}) is not disabled"
    EXTENSION_IS_LOADED = "{extension} is loaded"
    EXTENSION_IS_NOT_LOADED = "{extension} is not loaded"


</t>
<t tx="ekr.20250131013600.602">class Information(NamedTuple):
    msgid_or_symbol: str
    extension: str | None


</t>
<t tx="ekr.20250131013600.603">class Solution(enum.Enum):
    ADD_EXTENSION = "Add {extension} in 'load-plugins' option"
    REMOVE_EXTENSION = "Remove {extension} from the 'load-plugins' option"
    ENABLE_MESSAGE_EXPLICITLY = (
        "{symbol} ({msgid}) should be added in the 'enable' option"
    )
    ENABLE_MESSAGE_IMPLICITLY = (
        "{symbol} ({msgid}) should be removed from the 'disable' option"
    )
    DISABLE_MESSAGE_EXPLICITLY = (
        "{symbol} ({msgid}) should be added in the 'disable' option"
    )
    DISABLE_MESSAGE_IMPLICITLY = (
        "{symbol} ({msgid}) should be removed from the 'enable' option"
    )


</t>
<t tx="ekr.20250131013600.604">@path pylint/config
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Definition of an Argument class and transformers for various argument types.

An Argument instance represents a pylint option to be handled by an argparse.ArgumentParser
"""

from __future__ import annotations

import argparse
import os
import pathlib
import re
from collections.abc import Callable, Sequence
from glob import glob
from re import Pattern
from typing import Any, Literal, Union

from pylint import interfaces
from pylint import utils as pylint_utils
from pylint.config.callback_actions import _CallbackAction
from pylint.config.deprecation_actions import _NewNamesAction, _OldNamesAction

_ArgumentTypes = Union[
    str,
    int,
    float,
    bool,
    Pattern[str],
    Sequence[str],
    Sequence[Pattern[str]],
    tuple[int, ...],
]
"""List of possible argument types."""


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.605">def _confidence_transformer(value: str) -&gt; Sequence[str]:
    """Transforms a comma separated string of confidence values."""
    if not value:
        return interfaces.CONFIDENCE_LEVEL_NAMES
    values = pylint_utils._check_csv(value)
    for confidence in values:
        if confidence not in interfaces.CONFIDENCE_LEVEL_NAMES:
            raise argparse.ArgumentTypeError(
                f"{value} should be in {*interfaces.CONFIDENCE_LEVEL_NAMES,}"
            )
    return values


</t>
<t tx="ekr.20250131013600.606">def _csv_transformer(value: str) -&gt; Sequence[str]:
    """Transforms a comma separated string."""
    return pylint_utils._check_csv(value)


</t>
<t tx="ekr.20250131013600.607">YES_VALUES = {"y", "yes", "true"}
NO_VALUES = {"n", "no", "false"}


def _yn_transformer(value: str) -&gt; bool:
    """Transforms a yes/no or stringified bool into a bool."""
    value = value.lower()
    if value in YES_VALUES:
        return True
    if value in NO_VALUES:
        return False
    raise argparse.ArgumentTypeError(
        None, f"Invalid yn value '{value}', should be in {*YES_VALUES, *NO_VALUES}"
    )


</t>
<t tx="ekr.20250131013600.608">def _non_empty_string_transformer(value: str) -&gt; str:
    """Check that a string is not empty and remove quotes."""
    if not value:
        raise argparse.ArgumentTypeError("Option cannot be an empty string.")
    return pylint_utils._unquote(value)


</t>
<t tx="ekr.20250131013600.609">def _path_transformer(value: str) -&gt; str:
    """Expand user and variables in a path."""
    return os.path.expandvars(os.path.expanduser(value))


</t>
<t tx="ekr.20250131013600.61">def _supports_delitem_protocol(value: nodes.NodeNG) -&gt; bool:
    return _supports_protocol_method(value, DELITEM_METHOD)


</t>
<t tx="ekr.20250131013600.610">def _glob_paths_csv_transformer(value: str) -&gt; Sequence[str]:
    """Transforms a comma separated list of paths while expanding user and
    variables and glob patterns.
    """
    paths: list[str] = []
    for path in _csv_transformer(value):
        paths.extend(glob(_path_transformer(path), recursive=True))
    return paths


</t>
<t tx="ekr.20250131013600.611">def _py_version_transformer(value: str) -&gt; tuple[int, ...]:
    """Transforms a version string into a version tuple."""
    try:
        version = tuple(int(val) for val in value.replace(",", ".").split("."))
    except ValueError:
        raise argparse.ArgumentTypeError(
            f"{value} has an invalid format, should be a version string. E.g., '3.8'"
        ) from None
    return version


</t>
<t tx="ekr.20250131013600.612">def _regex_transformer(value: str) -&gt; Pattern[str]:
    """Prevents 're.error' from propagating and crash pylint."""
    try:
        return re.compile(value)
    except re.error as e:
        msg = f"Error in provided regular expression: {value} beginning at index {e.pos}: {e.msg}"
        raise argparse.ArgumentTypeError(msg) from e


</t>
<t tx="ekr.20250131013600.613">def _regexp_csv_transfomer(value: str) -&gt; Sequence[Pattern[str]]:
    """Transforms a comma separated list of regular expressions."""
    patterns: list[Pattern[str]] = []
    for pattern in pylint_utils._check_regexp_csv(value):
        patterns.append(_regex_transformer(pattern))
    return patterns


</t>
<t tx="ekr.20250131013600.614">def _regexp_paths_csv_transfomer(value: str) -&gt; Sequence[Pattern[str]]:
    """Transforms a comma separated list of regular expressions paths."""
    patterns: list[Pattern[str]] = []
    for pattern in _csv_transformer(value):
        patterns.append(
            _regex_transformer(
                str(pathlib.PureWindowsPath(pattern)).replace("\\", "\\\\")
                + "|"
                + pathlib.PureWindowsPath(pattern).as_posix()
            )
        )
    return patterns


</t>
<t tx="ekr.20250131013600.615">_TYPE_TRANSFORMERS: dict[str, Callable[[str], _ArgumentTypes]] = {
    "choice": str,
    "csv": _csv_transformer,
    "float": float,
    "int": int,
    "confidence": _confidence_transformer,
    "non_empty_string": _non_empty_string_transformer,
    "path": _path_transformer,
    "glob_paths_csv": _glob_paths_csv_transformer,
    "py_version": _py_version_transformer,
    "regexp": _regex_transformer,
    "regexp_csv": _regexp_csv_transfomer,
    "regexp_paths_csv": _regexp_paths_csv_transfomer,
    "string": pylint_utils._unquote,
    "yn": _yn_transformer,
}
"""Type transformers for all argument types.

A transformer should accept a string and return one of the supported
Argument types. It will only be called when parsing 1) command-line,
2) configuration files and 3) a string default value.
Non-string default values are assumed to be of the correct type.
"""


class _Argument:
    """Class representing an argument to be parsed by an argparse.ArgumentsParser.

    This is based on the parameters passed to argparse.ArgumentsParser.add_message.
    See:
    https://docs.python.org/3/library/argparse.html#argparse.ArgumentParser.add_argument
    """

    @others
</t>
<t tx="ekr.20250131013600.616">class _BaseStoreArgument(_Argument):
    """Base class for store arguments to be parsed by an argparse.ArgumentsParser.

    This is based on the parameters passed to argparse.ArgumentsParser.add_message.
    See:
    https://docs.python.org/3/library/argparse.html#argparse.ArgumentParser.add_argument
    """

    @others
</t>
<t tx="ekr.20250131013600.617">class _StoreArgument(_BaseStoreArgument):
    """Class representing a store argument to be parsed by an argparse.ArgumentsParser.

    This is based on the parameters passed to argparse.ArgumentsParser.add_message.
    See:
    https://docs.python.org/3/library/argparse.html#argparse.ArgumentParser.add_argument
    """

    @others
</t>
<t tx="ekr.20250131013600.618">class _StoreTrueArgument(_BaseStoreArgument):
    """Class representing a 'store_true' argument to be parsed by an
    argparse.ArgumentsParser.

    This is based on the parameters passed to argparse.ArgumentsParser.add_message.
    See:
    https://docs.python.org/3/library/argparse.html#argparse.ArgumentParser.add_argument
    """

    @others
</t>
<t tx="ekr.20250131013600.619">class _DeprecationArgument(_Argument):
    """Store arguments while also handling deprecation warnings for old and new names.

    This is based on the parameters passed to argparse.ArgumentsParser.add_message.
    See:
    https://docs.python.org/3/library/argparse.html#argparse.ArgumentParser.add_argument
    """

    @others
</t>
<t tx="ekr.20250131013600.62">def _is_abstract_class_name(name: str) -&gt; bool:
    lname = name.lower()
    is_mixin = lname.endswith("mixin")
    is_abstract = lname.startswith("abstract")
    is_base = lname.startswith("base") or lname.endswith("base")
    return is_mixin or is_abstract or is_base


</t>
<t tx="ekr.20250131013600.620">class _ExtendArgument(_DeprecationArgument):
    """Class for extend arguments to be parsed by an argparse.ArgumentsParser.

    This is based on the parameters passed to argparse.ArgumentsParser.add_message.
    See:
    https://docs.python.org/3/library/argparse.html#argparse.ArgumentParser.add_argument
    """

    @others
</t>
<t tx="ekr.20250131013600.621">class _StoreOldNamesArgument(_DeprecationArgument):
    """Store arguments while also handling old names.

    This is based on the parameters passed to argparse.ArgumentsParser.add_message.
    See:
    https://docs.python.org/3/library/argparse.html#argparse.ArgumentParser.add_argument
    """

    @others
</t>
<t tx="ekr.20250131013600.622">class _StoreNewNamesArgument(_DeprecationArgument):
    """Store arguments while also emitting deprecation warnings.

    This is based on the parameters passed to argparse.ArgumentsParser.add_message.
    See:
    https://docs.python.org/3/library/argparse.html#argparse.ArgumentParser.add_argument
    """

    @others
</t>
<t tx="ekr.20250131013600.623">class _CallableArgument(_Argument):
    """Class representing an callable argument to be parsed by an
    argparse.ArgumentsParser.

    This is based on the parameters passed to argparse.ArgumentsParser.add_message.
    See:
    https://docs.python.org/3/library/argparse.html#argparse.ArgumentParser.add_argument
    """

    @others
</t>
<t tx="ekr.20250131013600.624">def __init__(
    self,
    *,
    flags: list[str],
    arg_help: str,
    hide_help: bool,
    section: str | None,
) -&gt; None:
    self.flags = flags
    """The name of the argument."""

    self.hide_help = hide_help
    """Whether to hide this argument in the help message."""

    # argparse uses % formatting on help strings, so a % needs to be escaped
    self.help = arg_help.replace("%", "%%")
    """The description of the argument."""

    if hide_help:
        self.help = argparse.SUPPRESS

    self.section = section
    """The section to add this argument to."""


</t>
<t tx="ekr.20250131013600.625">def __init__(
    self,
    *,
    flags: list[str],
    action: str,
    default: _ArgumentTypes,
    arg_help: str,
    hide_help: bool,
    section: str | None,
) -&gt; None:
    super().__init__(
        flags=flags, arg_help=arg_help, hide_help=hide_help, section=section
    )

    self.action = action
    """The action to perform with the argument."""

    self.default = default
    """The default value of the argument."""


</t>
<t tx="ekr.20250131013600.626"># pylint: disable-next=too-many-arguments
def __init__(
    self,
    *,
    flags: list[str],
    action: str,
    default: _ArgumentTypes,
    arg_type: str,
    choices: list[str] | None,
    arg_help: str,
    metavar: str,
    hide_help: bool,
    section: str | None,
) -&gt; None:
    super().__init__(
        flags=flags,
        action=action,
        default=default,
        arg_help=arg_help,
        hide_help=hide_help,
        section=section,
    )

    self.type = _TYPE_TRANSFORMERS[arg_type]
    """A transformer function that returns a transformed type of the argument."""

    self.choices = choices
    """A list of possible choices for the argument.

    None if there are no restrictions.
    """

    self.metavar = metavar
    """The metavar of the argument.

    See:
    https://docs.python.org/3/library/argparse.html#metavar
    """


</t>
<t tx="ekr.20250131013600.627"># pylint: disable-next=useless-parent-delegation # We narrow down the type of action
def __init__(
    self,
    *,
    flags: list[str],
    action: Literal["store_true"],
    default: _ArgumentTypes,
    arg_help: str,
    hide_help: bool,
    section: str | None,
) -&gt; None:
    super().__init__(
        flags=flags,
        action=action,
        default=default,
        arg_help=arg_help,
        hide_help=hide_help,
        section=section,
    )


</t>
<t tx="ekr.20250131013600.628"># pylint: disable-next=too-many-arguments
def __init__(
    self,
    *,
    flags: list[str],
    action: type[argparse.Action],
    default: _ArgumentTypes,
    arg_type: str,
    choices: list[str] | None,
    arg_help: str,
    metavar: str,
    hide_help: bool,
    section: str | None,
) -&gt; None:
    super().__init__(
        flags=flags, arg_help=arg_help, hide_help=hide_help, section=section
    )

    self.action = action
    """The action to perform with the argument."""

    self.default = default
    """The default value of the argument."""

    self.type = _TYPE_TRANSFORMERS[arg_type]
    """A transformer function that returns a transformed type of the argument."""

    self.choices = choices
    """A list of possible choices for the argument.

    None if there are no restrictions.
    """

    self.metavar = metavar
    """The metavar of the argument.

    See:
    https://docs.python.org/3/library/argparse.html#metavar
    """


</t>
<t tx="ekr.20250131013600.629"># pylint: disable-next=too-many-arguments
def __init__(
    self,
    *,
    flags: list[str],
    action: Literal["extend"],
    default: _ArgumentTypes,
    arg_type: str,
    metavar: str,
    arg_help: str,
    hide_help: bool,
    section: str | None,
    choices: list[str] | None,
    dest: str | None,
) -&gt; None:
    action_class = argparse._ExtendAction

    self.dest = dest
    """The destination of the argument."""

    super().__init__(
        flags=flags,
        action=action_class,
        default=default,
        arg_type=arg_type,
        choices=choices,
        arg_help=arg_help,
        metavar=metavar,
        hide_help=hide_help,
        section=section,
    )


</t>
<t tx="ekr.20250131013600.63">def is_inside_abstract_class(node: nodes.NodeNG) -&gt; bool:
    while node is not None:
        if isinstance(node, nodes.ClassDef):
            if class_is_abstract(node):
                return True
            name = getattr(node, "name", None)
            if name is not None and _is_abstract_class_name(name):
                return True
        node = node.parent
    return False


</t>
<t tx="ekr.20250131013600.630"># pylint: disable-next=too-many-arguments
def __init__(
    self,
    *,
    flags: list[str],
    default: _ArgumentTypes,
    arg_type: str,
    choices: list[str] | None,
    arg_help: str,
    metavar: str,
    hide_help: bool,
    kwargs: dict[str, Any],
    section: str | None,
) -&gt; None:
    super().__init__(
        flags=flags,
        action=_OldNamesAction,
        default=default,
        arg_type=arg_type,
        choices=choices,
        arg_help=arg_help,
        metavar=metavar,
        hide_help=hide_help,
        section=section,
    )

    self.kwargs = kwargs
    """Any additional arguments passed to the action."""


</t>
<t tx="ekr.20250131013600.631"># pylint: disable-next=too-many-arguments
def __init__(
    self,
    *,
    flags: list[str],
    default: _ArgumentTypes,
    arg_type: str,
    choices: list[str] | None,
    arg_help: str,
    metavar: str,
    hide_help: bool,
    kwargs: dict[str, Any],
    section: str | None,
) -&gt; None:
    super().__init__(
        flags=flags,
        action=_NewNamesAction,
        default=default,
        arg_type=arg_type,
        choices=choices,
        arg_help=arg_help,
        metavar=metavar,
        hide_help=hide_help,
        section=section,
    )

    self.kwargs = kwargs
    """Any additional arguments passed to the action."""


</t>
<t tx="ekr.20250131013600.632">def __init__(
    self,
    *,
    flags: list[str],
    action: type[_CallbackAction],
    arg_help: str,
    kwargs: dict[str, Any],
    hide_help: bool,
    section: str | None,
    metavar: str,
) -&gt; None:
    super().__init__(
        flags=flags, arg_help=arg_help, hide_help=hide_help, section=section
    )

    self.action = action
    """The action to perform with the argument."""

    self.kwargs = kwargs
    """Any additional arguments passed to the action."""

    self.metavar = metavar
    """The metavar of the argument.

    See:
    https://docs.python.org/3/library/argparse.html#metavar
    """
</t>
<t tx="ekr.20250131013600.633">@path pylint/config
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Arguments manager class used to handle command-line arguments and options."""

from __future__ import annotations

import argparse
import re
import sys
import textwrap
import warnings
from collections.abc import Sequence
from typing import TYPE_CHECKING, Any, TextIO

import tomlkit

from pylint import utils
from pylint.config.argument import (
    _Argument,
    _CallableArgument,
    _ExtendArgument,
    _StoreArgument,
    _StoreNewNamesArgument,
    _StoreOldNamesArgument,
    _StoreTrueArgument,
)
from pylint.config.exceptions import (
    UnrecognizedArgumentAction,
    _UnrecognizedOptionError,
)
from pylint.config.help_formatter import _HelpFormatter
from pylint.config.utils import _convert_option_to_argument, _parse_rich_type_value
from pylint.constants import MAIN_CHECKER_NAME
from pylint.typing import DirectoryNamespaceDict, OptionDict

if sys.version_info &gt;= (3, 11):
    import tomllib
else:
    import tomli as tomllib


if TYPE_CHECKING:
    from pylint.config.arguments_provider import _ArgumentsProvider


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.634">class _ArgumentsManager:
    """Arguments manager class used to handle command-line arguments and options."""

    @others
</t>
<t tx="ekr.20250131013600.635">def __init__(
    self, prog: str, usage: str | None = None, description: str | None = None
) -&gt; None:
    self._config = argparse.Namespace()
    """Namespace for all options."""

    self._base_config = self._config
    """Fall back Namespace object created during initialization.

    This is necessary for the per-directory configuration support. Whenever we
    fail to match a file with a directory we fall back to the Namespace object
    created during initialization.
    """

    self._arg_parser = argparse.ArgumentParser(
        prog=prog,
        usage=usage or "%(prog)s [options]",
        description=description,
        formatter_class=_HelpFormatter,
        # Needed to let 'pylint-config' overwrite the -h command
        conflict_handler="resolve",
    )
    """The command line argument parser."""

    self._argument_groups_dict: dict[str, argparse._ArgumentGroup] = {}
    """Dictionary of all the argument groups."""

    self._option_dicts: dict[str, OptionDict] = {}
    """All option dictionaries that have been registered."""

    self._directory_namespaces: DirectoryNamespaceDict = {}
    """Mapping of directories and their respective namespace objects."""

</t>
<t tx="ekr.20250131013600.636">@property
def config(self) -&gt; argparse.Namespace:
    """Namespace for all options."""
    return self._config

</t>
<t tx="ekr.20250131013600.637">@config.setter
def config(self, value: argparse.Namespace) -&gt; None:
    self._config = value

</t>
<t tx="ekr.20250131013600.638">def _register_options_provider(self, provider: _ArgumentsProvider) -&gt; None:
    """Register an options provider and load its defaults."""
    for opt, optdict in provider.options:
        self._option_dicts[opt] = optdict
        argument = _convert_option_to_argument(opt, optdict)
        section = argument.section or provider.name.capitalize()

        section_desc = provider.option_groups_descs.get(section, None)

        # We exclude main since its docstring comes from PyLinter
        if provider.name != MAIN_CHECKER_NAME and provider.__doc__:
            section_desc = provider.__doc__.split("\n\n")[0]

        self._add_arguments_to_parser(section, section_desc, argument)

    self._load_default_argument_values()

</t>
<t tx="ekr.20250131013600.639">def _add_arguments_to_parser(
    self, section: str, section_desc: str | None, argument: _Argument
) -&gt; None:
    """Add an argument to the correct argument section/group."""
    try:
        section_group = self._argument_groups_dict[section]
    except KeyError:
        if section_desc:
            section_group = self._arg_parser.add_argument_group(
                section, section_desc
            )
        else:
            section_group = self._arg_parser.add_argument_group(title=section)
        self._argument_groups_dict[section] = section_group
    self._add_parser_option(section_group, argument)

</t>
<t tx="ekr.20250131013600.64">def _supports_protocol(
    value: nodes.NodeNG, protocol_callback: Callable[[nodes.NodeNG], bool]
) -&gt; bool:
    if isinstance(value, nodes.ClassDef):
        if not has_known_bases(value):
            return True
        # classobj can only be iterable if it has an iterable metaclass
        meta = value.metaclass()
        if meta is not None:
            if protocol_callback(meta):
                return True
    if isinstance(value, astroid.BaseInstance):
        if not has_known_bases(value):
            return True
        if value.has_dynamic_getattr():
            return True
        if protocol_callback(value):
            return True

    if isinstance(value, nodes.ComprehensionScope):
        return True

    if (
        isinstance(value, astroid.bases.Proxy)
        and isinstance(value._proxied, astroid.BaseInstance)
        and has_known_bases(value._proxied)
    ):
        value = value._proxied
        return protocol_callback(value)

    return False


</t>
<t tx="ekr.20250131013600.640">@staticmethod
def _add_parser_option(
    section_group: argparse._ArgumentGroup, argument: _Argument
) -&gt; None:
    """Add an argument."""
    if isinstance(argument, _StoreArgument):
        section_group.add_argument(
            *argument.flags,
            action=argument.action,
            default=argument.default,
            type=argument.type,
            help=argument.help,
            metavar=argument.metavar,
            choices=argument.choices,
        )
    elif isinstance(argument, _StoreOldNamesArgument):
        section_group.add_argument(
            *argument.flags,
            **argument.kwargs,
            action=argument.action,
            default=argument.default,
            type=argument.type,
            help=argument.help,
            metavar=argument.metavar,
            choices=argument.choices,
        )
        # We add the old name as hidden option to make its default value get loaded when
        # argparse initializes all options from the checker
        assert argument.kwargs["old_names"]
        for old_name in argument.kwargs["old_names"]:
            section_group.add_argument(
                f"--{old_name}",
                action="store",
                default=argument.default,
                type=argument.type,
                help=argparse.SUPPRESS,
                metavar=argument.metavar,
                choices=argument.choices,
            )
    elif isinstance(argument, _StoreNewNamesArgument):
        section_group.add_argument(
            *argument.flags,
            **argument.kwargs,
            action=argument.action,
            default=argument.default,
            type=argument.type,
            help=argument.help,
            metavar=argument.metavar,
            choices=argument.choices,
        )
    elif isinstance(argument, _StoreTrueArgument):
        section_group.add_argument(
            *argument.flags,
            action=argument.action,
            default=argument.default,
            help=argument.help,
        )
    elif isinstance(argument, _CallableArgument):
        section_group.add_argument(
            *argument.flags,
            **argument.kwargs,
            action=argument.action,
            help=argument.help,
            metavar=argument.metavar,
        )
    elif isinstance(argument, _ExtendArgument):
        section_group.add_argument(
            *argument.flags,
            action=argument.action,
            default=argument.default,
            type=argument.type,
            help=argument.help,
            metavar=argument.metavar,
            choices=argument.choices,
            dest=argument.dest,
        )
    else:
        raise UnrecognizedArgumentAction

</t>
<t tx="ekr.20250131013600.641">def _load_default_argument_values(self) -&gt; None:
    """Loads the default values of all registered options."""
    self.config = self._arg_parser.parse_args([], self.config)

</t>
<t tx="ekr.20250131013600.642">def _parse_configuration_file(self, arguments: list[str]) -&gt; None:
    """Parse the arguments found in a configuration file into the namespace."""
    try:
        self.config, parsed_args = self._arg_parser.parse_known_args(
            arguments, self.config
        )
    except SystemExit:
        sys.exit(32)
    unrecognized_options: list[str] = []
    for opt in parsed_args:
        if opt.startswith("--"):
            unrecognized_options.append(opt[2:])
    if unrecognized_options:
        raise _UnrecognizedOptionError(options=unrecognized_options)

</t>
<t tx="ekr.20250131013600.643">def _parse_command_line_configuration(
    self, arguments: Sequence[str] | None = None
) -&gt; list[str]:
    """Parse the arguments found on the command line into the namespace."""
    arguments = sys.argv[1:] if arguments is None else arguments

    self.config, parsed_args = self._arg_parser.parse_known_args(
        arguments, self.config
    )

    return parsed_args

</t>
<t tx="ekr.20250131013600.644">def _generate_config(
    self, stream: TextIO | None = None, skipsections: tuple[str, ...] = ()
</t>
<t tx="ekr.20250131013600.645">) -&gt; None:
    """Write a configuration file according to the current configuration
    into the given stream or stdout.
    """
    options_by_section = {}
    sections = []
    for group in sorted(
        self._arg_parser._action_groups,
        key=lambda x: (x.title != "Main", x.title),
    ):
        group_name = group.title
        assert group_name
        if group_name in skipsections:
            continue

        options = []
        option_actions = [
            i
            for i in group._group_actions
            if not isinstance(i, argparse._SubParsersAction)
        ]
        for opt in sorted(option_actions, key=lambda x: x.option_strings[0][2:]):
            if "--help" in opt.option_strings:
                continue

            optname = opt.option_strings[0][2:]

            try:
                optdict = self._option_dicts[optname]
            except KeyError:
                continue

            options.append(
                (
                    optname,
                    optdict,
                    getattr(self.config, optname.replace("-", "_")),
                )
            )

            options = [
                (n, d, v) for (n, d, v) in options if not d.get("deprecated")
            ]

        if options:
            sections.append(group_name)
            options_by_section[group_name] = options
    stream = stream or sys.stdout
    printed = False
    for section in sections:
        if printed:
            print("\n", file=stream)
        with warnings.catch_warnings():
            warnings.filterwarnings("ignore", category=DeprecationWarning)
            utils.format_section(
                stream, section.upper(), sorted(options_by_section[section])
            )
        printed = True

def help(self) -&gt; str:
    """Return the usage string based on the available options."""
    return self._arg_parser.format_help()

</t>
<t tx="ekr.20250131013600.646">def _generate_config_file(self, *, minimal: bool = False) -&gt; str:
    """Write a configuration file according to the current configuration into
    stdout.
    """
    toml_doc = tomlkit.document()
    tool_table = tomlkit.table(is_super_table=True)
    toml_doc.add(tomlkit.key("tool"), tool_table)

    pylint_tool_table = tomlkit.table(is_super_table=True)
    tool_table.add(tomlkit.key("pylint"), pylint_tool_table)

    for group in sorted(
        self._arg_parser._action_groups,
        key=lambda x: (x.title != "Main", x.title),
    ):
        # Skip the options section with the --help option
        if group.title in {"options", "optional arguments", "Commands"}:
            continue

        # Skip sections without options such as "positional arguments"
        if not group._group_actions:
            continue

        group_table = tomlkit.table()
        option_actions = [
            i
            for i in group._group_actions
            if not isinstance(i, argparse._SubParsersAction)
        ]
        for action in sorted(option_actions, key=lambda x: x.option_strings[0][2:]):
            optname = action.option_strings[0][2:]

            # We skip old name options that don't have their own optdict
            try:
                optdict = self._option_dicts[optname]
            except KeyError:
                continue

            if optdict.get("hide_from_config_file"):
                continue

            # Add help comment
            if not minimal:
                help_msg = optdict.get("help", "")
                assert isinstance(help_msg, str)
                help_text = textwrap.wrap(help_msg, width=79)
                for line in help_text:
                    group_table.add(tomlkit.comment(line))

            # Get current value of option
            value = getattr(self.config, optname.replace("-", "_"))

            # Create a comment if the option has no value
            if not value:
                if not minimal:
                    group_table.add(tomlkit.comment(f"{optname} ="))
                    group_table.add(tomlkit.nl())
                continue

            # Skip deprecated options
            if "kwargs" in optdict:
                assert isinstance(optdict["kwargs"], dict)
                if "new_names" in optdict["kwargs"]:
                    continue

            # Tomlkit doesn't support regular expressions
            if isinstance(value, re.Pattern):
                value = value.pattern
            elif isinstance(value, (list, tuple)) and isinstance(
                value[0], re.Pattern
            ):
                value = [i.pattern for i in value]

            # Handle tuples that should be strings
            if optdict.get("type") == "py_version":
                value = ".".join(str(i) for i in value)

            # Check if it is default value if we are in minimal mode
            if minimal and value == optdict.get("default"):
                continue

            # Add to table
            group_table.add(optname, value)
            group_table.add(tomlkit.nl())

        assert group.title
        if group_table:
            pylint_tool_table.add(group.title.lower(), group_table)

    toml_string = tomlkit.dumps(toml_doc)

    # Make sure the string we produce is valid toml and can be parsed
    tomllib.loads(toml_string)

    return str(toml_string)

</t>
<t tx="ekr.20250131013600.647">def set_option(self, optname: str, value: Any) -&gt; None:
    """Set an option on the namespace object."""
    self.config = self._arg_parser.parse_known_args(
        [f"--{optname.replace('_', '-')}", _parse_rich_type_value(value)],
        self.config,
    )[0]
</t>
<t tx="ekr.20250131013600.648">@path pylint/config
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Arguments provider class used to expose options."""

from __future__ import annotations

from collections.abc import Iterator
from typing import Any

from pylint.config.arguments_manager import _ArgumentsManager
from pylint.typing import OptionDict, Options


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.649">class _ArgumentsProvider:
    """Base class for classes that provide arguments."""

    @others
</t>
<t tx="ekr.20250131013600.65">def is_iterable(value: nodes.NodeNG, check_async: bool = False) -&gt; bool:
    if check_async:
        protocol_check = _supports_async_iteration_protocol
    else:
        protocol_check = _supports_iteration_protocol
    return _supports_protocol(value, protocol_check)


</t>
<t tx="ekr.20250131013600.650">name: str
"""Name of the provider."""

options: Options = ()
"""Options provided by this provider."""

option_groups_descs: dict[str, str] = {}
"""Option groups of this provider and their descriptions."""

def __init__(self, arguments_manager: _ArgumentsManager) -&gt; None:
    self._arguments_manager = arguments_manager
    """The manager that will parse and register any options provided."""

    self._arguments_manager._register_options_provider(self)

</t>
<t tx="ekr.20250131013600.651">def _option_value(self, opt: str) -&gt; Any:
    """Get the current value for the given option."""
    return getattr(self._arguments_manager.config, opt.replace("-", "_"), None)

</t>
<t tx="ekr.20250131013600.652">def _options_by_section(
    self,
) -&gt; Iterator[
    tuple[str, list[tuple[str, OptionDict, Any]]]
    | tuple[None, dict[str, list[tuple[str, OptionDict, Any]]]]
</t>
<t tx="ekr.20250131013600.653">]:
    """Return an iterator on options grouped by section.

    (section, [list of (optname, optdict, optvalue)])
    """
    sections: dict[str, list[tuple[str, OptionDict, Any]]] = {}
    for optname, optdict in self.options:
        sections.setdefault(optdict.get("group"), []).append(  # type: ignore[arg-type]
            (optname, optdict, self._option_value(optname))
        )
    if None in sections:
        yield None, sections.pop(None)  # type: ignore[call-overload]
    for section, options in sorted(sections.items()):
        yield section.upper(), options

def _options_and_values(
    self, options: Options | None = None
) -&gt; Iterator[tuple[str, OptionDict, Any]]:
    """DEPRECATED."""
    if options is None:
        options = self.options
    for optname, optdict in options:
        yield optname, optdict, self._option_value(optname)
</t>
<t tx="ekr.20250131013600.654">@path pylint/config
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

# pylint: disable=too-many-arguments, redefined-builtin, duplicate-code

"""Callback actions for various options."""

from __future__ import annotations

import abc
import argparse
import sys
from collections.abc import Callable, Sequence
from pathlib import Path
from typing import TYPE_CHECKING, Any

from pylint import exceptions, extensions, interfaces, utils

if TYPE_CHECKING:
    from pylint.config.help_formatter import _HelpFormatter
    from pylint.lint import PyLinter
    from pylint.lint.run import Run


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.655">class _CallbackAction(argparse.Action):
    """Custom callback action."""

    @others
</t>
<t tx="ekr.20250131013600.656">class _DoNothingAction(_CallbackAction):
    """Action that just passes.

    This action is used to allow pre-processing of certain options
    without erroring when they are then processed again by argparse.
    """

    @others
</t>
<t tx="ekr.20250131013600.657">class _AccessRunObjectAction(_CallbackAction):
    """Action that has access to the Run object."""

    @others
</t>
<t tx="ekr.20250131013600.658">class _MessageHelpAction(_CallbackAction):
    """Display the help message of a message."""

    @others
</t>
<t tx="ekr.20250131013600.659">class _ListMessagesAction(_AccessRunObjectAction):
    """Display all available messages."""

    @others
</t>
<t tx="ekr.20250131013600.66">def is_mapping(value: nodes.NodeNG) -&gt; bool:
    return _supports_protocol(value, _supports_mapping_protocol)


</t>
<t tx="ekr.20250131013600.660">class _ListMessagesEnabledAction(_AccessRunObjectAction):
    """Display all enabled messages."""

    @others
</t>
<t tx="ekr.20250131013600.661">class _ListCheckGroupsAction(_AccessRunObjectAction):
    """Display all the check groups that pylint knows about."""

    @others
</t>
<t tx="ekr.20250131013600.662">class _ListConfidenceLevelsAction(_AccessRunObjectAction):
    """Display all the confidence levels that pylint knows about."""

    @others
</t>
<t tx="ekr.20250131013600.663">class _ListExtensionsAction(_AccessRunObjectAction):
    """Display all extensions under pylint.extensions."""

    @others
</t>
<t tx="ekr.20250131013600.664">class _FullDocumentationAction(_AccessRunObjectAction):
    """Display the full documentation."""

    @others
</t>
<t tx="ekr.20250131013600.665">class _GenerateRCFileAction(_AccessRunObjectAction):
    """Generate a pylintrc file."""

    @others
</t>
<t tx="ekr.20250131013600.666">class _GenerateConfigFileAction(_AccessRunObjectAction):
    """Generate a .toml format configuration file."""

    @others
</t>
<t tx="ekr.20250131013600.667">class _ErrorsOnlyModeAction(_AccessRunObjectAction):
    """Turn on errors-only mode.

    Error mode:
        * disable all but error messages
        * disable the 'miscellaneous' checker which can be safely deactivated in
          debug
        * disable reports
        * do not save execution information
    """

    @others
</t>
<t tx="ekr.20250131013600.668">class _LongHelpAction(_AccessRunObjectAction):
    """Display the long help message."""

    @others
</t>
<t tx="ekr.20250131013600.669">class _AccessLinterObjectAction(_CallbackAction):
    """Action that has access to the Linter object."""

    @others
</t>
<t tx="ekr.20250131013600.67">def supports_membership_test(value: nodes.NodeNG) -&gt; bool:
    supported = _supports_protocol(value, _supports_membership_test_protocol)
    return supported or is_iterable(value)


</t>
<t tx="ekr.20250131013600.670">class _XableAction(_AccessLinterObjectAction):
    """Callback action for enabling or disabling a message."""

    @others
</t>
<t tx="ekr.20250131013600.671">class _DisableAction(_XableAction):
    """Callback action for disabling a message."""

    @others
</t>
<t tx="ekr.20250131013600.672">class _EnableAction(_XableAction):
    """Callback action for enabling a message."""

    @others
</t>
<t tx="ekr.20250131013600.673">class _OutputFormatAction(_AccessLinterObjectAction):
    """Callback action for setting the output format."""

    @others
</t>
<t tx="ekr.20250131013600.674">class _AccessParserAction(_CallbackAction):
    """Action that has access to the ArgumentParser object."""

    @others
</t>
<t tx="ekr.20250131013600.675">@abc.abstractmethod
def __call__(
    self,
    parser: argparse.ArgumentParser,
    namespace: argparse.Namespace,
    values: str | Sequence[Any] | None,
    option_string: str | None = None,
) -&gt; None:
    raise NotImplementedError  # pragma: no cover


</t>
<t tx="ekr.20250131013600.676">def __call__(
    self,
    parser: argparse.ArgumentParser,
    namespace: argparse.Namespace,
    values: str | Sequence[Any] | None,
    option_string: str | None = None,
) -&gt; None:
    return None


</t>
<t tx="ekr.20250131013600.677">def __init__(
    self,
    option_strings: Sequence[str],
    dest: str,
    nargs: None = None,
    const: None = None,
    default: None = None,
    type: None = None,
    choices: None = None,
    required: bool = False,
    help: str = "",
    metavar: str = "",
    **kwargs: Run,
) -&gt; None:
    self.run = kwargs["Run"]

    super().__init__(
        option_strings,
        dest,
        0,
        const,
        default,
        type,
        choices,
        required,
        help,
        metavar,
    )

</t>
<t tx="ekr.20250131013600.678">@abc.abstractmethod
def __call__(
    self,
    parser: argparse.ArgumentParser,
    namespace: argparse.Namespace,
    values: str | Sequence[Any] | None,
    option_string: str | None = None,
) -&gt; None:
    raise NotImplementedError  # pragma: no cover


</t>
<t tx="ekr.20250131013600.679">def __init__(
    self,
    option_strings: Sequence[str],
    dest: str,
    nargs: None = None,
    const: None = None,
    default: None = None,
    type: None = None,
    choices: None = None,
    required: bool = False,
    help: str = "",
    metavar: str = "",
    **kwargs: Run,
) -&gt; None:
    self.run = kwargs["Run"]
    super().__init__(
        option_strings,
        dest,
        "+",
        const,
        default,
        type,
        choices,
        required,
        help,
        metavar,
    )

</t>
<t tx="ekr.20250131013600.68">def supports_getitem(value: nodes.NodeNG, node: nodes.NodeNG) -&gt; bool:
    if isinstance(value, nodes.ClassDef):
        if _supports_protocol_method(value, CLASS_GETITEM_METHOD):
            return True
        if is_postponed_evaluation_enabled(node) and is_node_in_type_annotation_context(
            node
        ):
            return True
    return _supports_protocol(value, _supports_getitem_protocol)


</t>
<t tx="ekr.20250131013600.680">def __call__(
    self,
    parser: argparse.ArgumentParser,
    namespace: argparse.Namespace,
    values: str | Sequence[str] | None,
    option_string: str | None = "--help-msg",
) -&gt; None:
    assert isinstance(values, (list, tuple))
    values_to_print: list[str] = []
    for msg in values:
        assert isinstance(msg, str)
        values_to_print += utils._check_csv(msg)
    self.run.linter.msgs_store.help_message(values_to_print)
    sys.exit(0)


</t>
<t tx="ekr.20250131013600.681">def __call__(
    self,
    parser: argparse.ArgumentParser,
    namespace: argparse.Namespace,
    values: str | Sequence[Any] | None,
    option_string: str | None = "--list-enabled",
) -&gt; None:
    self.run.linter.msgs_store.list_messages()
    sys.exit(0)


</t>
<t tx="ekr.20250131013600.682">def __call__(
    self,
    parser: argparse.ArgumentParser,
    namespace: argparse.Namespace,
    values: str | Sequence[Any] | None,
    option_string: str | None = "--list-msgs-enabled",
) -&gt; None:
    self.run.linter.list_messages_enabled()
    sys.exit(0)


</t>
<t tx="ekr.20250131013600.683">def __call__(
    self,
    parser: argparse.ArgumentParser,
    namespace: argparse.Namespace,
    values: str | Sequence[Any] | None,
    option_string: str | None = "--list-groups",
) -&gt; None:
    for check in self.run.linter.get_checker_names():
        print(check)
    sys.exit(0)


</t>
<t tx="ekr.20250131013600.684">def __call__(
    self,
    parser: argparse.ArgumentParser,
    namespace: argparse.Namespace,
    values: str | Sequence[Any] | None,
    option_string: str | None = "--list-conf-levels",
) -&gt; None:
    for level in interfaces.CONFIDENCE_LEVELS:
        print(f"%-18s: {level}")
    sys.exit(0)


</t>
<t tx="ekr.20250131013600.685">def __call__(
    self,
    parser: argparse.ArgumentParser,
    namespace: argparse.Namespace,
    values: str | Sequence[Any] | None,
    option_string: str | None = "--list-extensions",
) -&gt; None:
    for filename in Path(extensions.__file__).parent.iterdir():
        if filename.suffix == ".py" and not filename.stem.startswith("_"):
            extension_name, _, _ = filename.stem.partition(".")
            print(f"pylint.extensions.{extension_name}")
    sys.exit(0)


</t>
<t tx="ekr.20250131013600.686">def __call__(
    self,
    parser: argparse.ArgumentParser,
    namespace: argparse.Namespace,
    values: str | Sequence[Any] | None,
    option_string: str | None = "--full-documentation",
) -&gt; None:
    utils.print_full_documentation(self.run.linter)
    sys.exit(0)


</t>
<t tx="ekr.20250131013600.687">def __call__(
    self,
    parser: argparse.ArgumentParser,
    namespace: argparse.Namespace,
    values: str | Sequence[Any] | None,
    option_string: str | None = "--generate-rcfile",
) -&gt; None:
    # TODO: 4.x: Deprecate this after the auto-upgrade functionality of
    # pylint-config is sufficient.
    self.run.linter._generate_config(skipsections=("Commands",))
    sys.exit(0)


</t>
<t tx="ekr.20250131013600.688">def __call__(
    self,
    parser: argparse.ArgumentParser,
    namespace: argparse.Namespace,
    values: str | Sequence[Any] | None,
    option_string: str | None = "--generate-toml-config",
) -&gt; None:
    print(self.run.linter._generate_config_file())
    sys.exit(0)


</t>
<t tx="ekr.20250131013600.689">def __call__(
    self,
    parser: argparse.ArgumentParser,
    namespace: argparse.Namespace,
    values: str | Sequence[Any] | None,
    option_string: str | None = "--errors-only",
) -&gt; None:
    self.run.linter._error_mode = True


</t>
<t tx="ekr.20250131013600.69">def supports_setitem(value: nodes.NodeNG, _: nodes.NodeNG) -&gt; bool:
    return _supports_protocol(value, _supports_setitem_protocol)


</t>
<t tx="ekr.20250131013600.690">def __call__(
    self,
    parser: argparse.ArgumentParser,
    namespace: argparse.Namespace,
    values: str | Sequence[Any] | None,
    option_string: str | None = "--long-help",
) -&gt; None:
    formatter: _HelpFormatter = self.run.linter._arg_parser._get_formatter()  # type: ignore[assignment]

    # Add extra info as epilog to the help message
    self.run.linter._arg_parser.epilog = formatter.get_long_description()
    print(self.run.linter.help())

    sys.exit(0)


</t>
<t tx="ekr.20250131013600.691">def __init__(
    self,
    option_strings: Sequence[str],
    dest: str,
    nargs: None = None,
    const: None = None,
    default: None = None,
    type: None = None,
    choices: None = None,
    required: bool = False,
    help: str = "",
    metavar: str = "",
    **kwargs: PyLinter,
) -&gt; None:
    self.linter = kwargs["linter"]

    super().__init__(
        option_strings,
        dest,
        1,
        const,
        default,
        type,
        choices,
        required,
        help,
        metavar,
    )

</t>
<t tx="ekr.20250131013600.692">@abc.abstractmethod
def __call__(
    self,
    parser: argparse.ArgumentParser,
    namespace: argparse.Namespace,
    values: str | Sequence[Any] | None,
    option_string: str | None = None,
) -&gt; None:
    raise NotImplementedError  # pragma: no cover


</t>
<t tx="ekr.20250131013600.693">def _call(
    self,
    xabling_function: Callable[[str], None],
    values: str | Sequence[Any] | None,
    option_string: str | None,
) -&gt; None:
    assert isinstance(values, (tuple, list))
    for msgid in utils._check_csv(values[0]):
        try:
            xabling_function(msgid)
        except(
            exceptions.DeletedMessageError,
            exceptions.MessageBecameExtensionError,
        ) as e:
            self.linter._stashed_messages[
                (self.linter.current_name, "useless-option-value")
            ].append((option_string, str(e)))
        except exceptions.UnknownMessageError:
            self.linter._stashed_messages[
                (self.linter.current_name, "unknown-option-value")
            ].append((option_string, msgid))

</t>
<t tx="ekr.20250131013600.694">@abc.abstractmethod
def __call__(
    self,
    parser: argparse.ArgumentParser,
    namespace: argparse.Namespace,
    values: str | Sequence[Any] | None,
    option_string: str | None = "--disable",
) -&gt; None:
    raise NotImplementedError  # pragma: no cover


</t>
<t tx="ekr.20250131013600.695">def __call__(
    self,
    parser: argparse.ArgumentParser,
    namespace: argparse.Namespace,
    values: str | Sequence[Any] | None,
    option_string: str | None = "--disable",
) -&gt; None:
    self._call(self.linter.disable, values, option_string)


</t>
<t tx="ekr.20250131013600.696">def __call__(
    self,
    parser: argparse.ArgumentParser,
    namespace: argparse.Namespace,
    values: str | Sequence[Any] | None,
    option_string: str | None = "--enable",
) -&gt; None:
    self._call(self.linter.enable, values, option_string)


</t>
<t tx="ekr.20250131013600.697">def __call__(
    self,
    parser: argparse.ArgumentParser,
    namespace: argparse.Namespace,
    values: str | Sequence[Any] | None,
    option_string: str | None = "--enable",
) -&gt; None:
    assert isinstance(values, (tuple, list))
    assert isinstance(
        values[0], str
    ), "'output-format' should be a comma separated string of reporters"
    self.linter._load_reporters(values[0])


</t>
<t tx="ekr.20250131013600.698">def __init__(
    self,
    option_strings: Sequence[str],
    dest: str,
    nargs: None = None,
    const: None = None,
    default: None = None,
    type: None = None,
    choices: None = None,
    required: bool = False,
    help: str = "",
    metavar: str = "",
    **kwargs: argparse.ArgumentParser,
) -&gt; None:
    self.parser = kwargs["parser"]

    super().__init__(
        option_strings,
        dest,
        0,
        const,
        default,
        type,
        choices,
        required,
        help,
        metavar,
    )

</t>
<t tx="ekr.20250131013600.699">@abc.abstractmethod
def __call__(
    self,
    parser: argparse.ArgumentParser,
    namespace: argparse.Namespace,
    values: str | Sequence[Any] | None,
    option_string: str | None = None,
) -&gt; None:
    raise NotImplementedError  # pragma: no cover
</t>
<t tx="ekr.20250131013600.7">def is_builtin(name: str) -&gt; bool:
    """Return true if &lt;name&gt; could be considered as a builtin defined by python."""
    return name in builtins or name in SPECIAL_BUILTINS  # type: ignore[operator]


</t>
<t tx="ekr.20250131013600.70">def supports_delitem(value: nodes.NodeNG, _: nodes.NodeNG) -&gt; bool:
    return _supports_protocol(value, _supports_delitem_protocol)


</t>
<t tx="ekr.20250131013600.700">@path pylint/config
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Configuration file parser class."""

from __future__ import annotations

import configparser
import os
import sys
from pathlib import Path
from typing import TYPE_CHECKING

from pylint.config.utils import _parse_rich_type_value

if sys.version_info &gt;= (3, 11):
    import tomllib
else:
    import tomli as tomllib

if TYPE_CHECKING:
    from pylint.lint import PyLinter

PylintConfigFileData = tuple[dict[str, str], list[str]]


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.701">class _RawConfParser:
    """Class to parse various formats of configuration files."""

    @others
</t>
<t tx="ekr.20250131013600.702">class _ConfigurationFileParser:
    """Class to parse various formats of configuration files."""

    @others
</t>
<t tx="ekr.20250131013600.703">@staticmethod
def parse_ini_file(file_path: Path) -&gt; PylintConfigFileData:
    """Parse and handle errors of an ini configuration file.

    Raises ``configparser.Error``.
    """
    parser = configparser.ConfigParser(inline_comment_prefixes=("#", ";"))
    # Use this encoding in order to strip the BOM marker, if any.
    with open(file_path, encoding="utf_8_sig") as fp:
        parser.read_file(fp)

    config_content: dict[str, str] = {}
    options: list[str] = []
    ini_file_with_sections = _RawConfParser._ini_file_with_sections(file_path)
    for section in parser.sections():
        if ini_file_with_sections and not section.startswith("pylint"):
            continue
        for option, value in parser[section].items():
            config_content[option] = value
            options += [f"--{option}", value]
    return config_content, options

</t>
<t tx="ekr.20250131013600.704">@staticmethod
def _ini_file_with_sections(file_path: Path) -&gt; bool:
    """Return whether the file uses sections."""
    if "setup.cfg" in file_path.parts:
        return True
    if "tox.ini" in file_path.parts:
        return True
    return False

</t>
<t tx="ekr.20250131013600.705">@staticmethod
def parse_toml_file(file_path: Path) -&gt; PylintConfigFileData:
    """Parse and handle errors of a toml configuration file.

    Raises ``tomllib.TOMLDecodeError``.
    """
    with open(file_path, mode="rb") as fp:
        content = tomllib.load(fp)
    try:
        sections_values = content["tool"]["pylint"]
    except KeyError:
        return {}, []

    config_content: dict[str, str] = {}
    options: list[str] = []
    for opt, values in sections_values.items():
        if isinstance(values, dict):
            for config, value in values.items():
                value = _parse_rich_type_value(value)
                config_content[config] = value
                options += [f"--{config}", value]
        else:
            values = _parse_rich_type_value(values)
            config_content[opt] = values
            options += [f"--{opt}", values]
    return config_content, options

</t>
<t tx="ekr.20250131013600.706">@staticmethod
def parse_config_file(
    file_path: Path | None, verbose: bool
) -&gt; PylintConfigFileData:
    """Parse a config file and return str-str pairs.

    Raises ``tomllib.TOMLDecodeError``, ``configparser.Error``.
    """
    if file_path is None:
        if verbose:
            print(
                "No config file found, using default configuration", file=sys.stderr
            )
        return {}, []

    file_path = Path(os.path.expandvars(file_path)).expanduser()
    if not file_path.exists():
        raise OSError(f"The config file {file_path} doesn't exist!")

    if verbose:
        print(f"Using config file {file_path}", file=sys.stderr)

    if file_path.suffix == ".toml":
        return _RawConfParser.parse_toml_file(file_path)
    return _RawConfParser.parse_ini_file(file_path)


</t>
<t tx="ekr.20250131013600.707">def __init__(self, verbose: bool, linter: PyLinter) -&gt; None:
    self.verbose_mode = verbose
    self.linter = linter

</t>
<t tx="ekr.20250131013600.708">def parse_config_file(self, file_path: Path | None) -&gt; PylintConfigFileData:
    """Parse a config file and return str-str pairs."""
    try:
        return _RawConfParser.parse_config_file(file_path, self.verbose_mode)
    except(configparser.Error, tomllib.TOMLDecodeError) as e:
        self.linter.add_message("config-parse-error", line=0, args=str(e))
        return {}, []
</t>
<t tx="ekr.20250131013600.709">@path pylint/config
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import sys
import warnings
from glob import glob
from itertools import chain
from pathlib import Path
from typing import TYPE_CHECKING

from pylint import reporters
from pylint.config.config_file_parser import _ConfigurationFileParser
from pylint.config.exceptions import (
    ArgumentPreprocessingError,
    _UnrecognizedOptionError,
)
from pylint.utils import utils

if TYPE_CHECKING:
    from pylint.lint import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.71">def _get_python_type_of_node(node: nodes.NodeNG) -&gt; str | None:
    pytype: Callable[[], str] | None = getattr(node, "pytype", None)
    if callable(pytype):
        return pytype()
    return None


</t>
<t tx="ekr.20250131013600.710">def _config_initialization(  # pylint: disable=too-many-statements
    linter: PyLinter,
    args_list: list[str],
    reporter: reporters.BaseReporter | reporters.MultiReporter | None = None,
    config_file: None | str | Path = None,
    verbose_mode: bool = False,
) -&gt; list[str]:
    """Parse all available options, read config files and command line arguments and
    set options accordingly.
    """
    linter.verbose = verbose_mode
    config_file = Path(config_file) if config_file else None

    # Set the current module to the configuration file
    # to allow raising messages on the configuration file.
    linter.set_current_module(str(config_file) if config_file else "")

    # Read the configuration file
    config_file_parser = _ConfigurationFileParser(verbose_mode, linter)
    try:
        config_data, config_args = config_file_parser.parse_config_file(
            file_path=config_file
        )
    except OSError as ex:
        print(ex, file=sys.stderr)
        sys.exit(32)

    # Order --enable=all or --disable=all to come first.
    config_args = _order_all_first(config_args, joined=False)

    # Run init hook, if present, before loading plugins
    if "init-hook" in config_data:
        exec(utils._unquote(config_data["init-hook"]))  # pylint: disable=exec-used

    # Load plugins if specified in the config file
    if "load-plugins" in config_data:
        linter.load_plugin_modules(utils._splitstrip(config_data["load-plugins"]))

    unrecognized_options_message = None
    # First we parse any options from a configuration file
    try:
        linter._parse_configuration_file(config_args)
    except _UnrecognizedOptionError as exc:
        unrecognized_options_message = ", ".join(exc.options)

    # Then, if a custom reporter is provided as argument, it may be overridden
    # by file parameters, so we re-set it here. We do this before command line
    # parsing, so it's still overridable by command line options
    if reporter:
        linter.set_reporter(reporter)

    # Set the current module to the command line
    # to allow raising messages on it
    linter.set_current_module("Command line")

    # Now we parse any options from the command line, so they can override
    # the configuration file
    args_list = _order_all_first(args_list, joined=True)
    parsed_args_list = linter._parse_command_line_configuration(args_list)

    # Remove the positional arguments separator from the list of arguments if it exists
    try:
        parsed_args_list.remove("--")
    except ValueError:
        pass

    # Check if there are any options that we do not recognize
    unrecognized_options: list[str] = []
    for opt in parsed_args_list:
        if opt.startswith("--"):
            unrecognized_options.append(opt[2:])
        elif opt.startswith("-"):
            unrecognized_options.append(opt[1:])
    if unrecognized_options:
        msg = ", ".join(unrecognized_options)
        try:
            linter._arg_parser.error(f"Unrecognized option found: {msg}")
        except SystemExit:
            sys.exit(32)

    # Now that config file and command line options have been loaded
    # with all disables, it is safe to emit messages
    if unrecognized_options_message is not None:
        linter.set_current_module(str(config_file) if config_file else "")
        linter.add_message(
            "unrecognized-option", args=unrecognized_options_message, line=0
        )

    # TODO: Change this to be checked only when upgrading the configuration
    for exc_name in linter.config.overgeneral_exceptions:
        if "." not in exc_name:
            warnings.warn_explicit(
                f"'{exc_name}' is not a proper value for the 'overgeneral-exceptions' option. "
                f"Use fully qualified name (maybe 'builtins.{exc_name}' ?) instead. "
                "This will cease to be checked at runtime when the configuration "
                "upgrader is released.",
                category=UserWarning,
                filename="pylint: Command line or configuration file",
                lineno=1,
                module="pylint",
            )

    linter._emit_stashed_messages()

    # Set the current module to configuration as we don't know where
    # the --load-plugins key is coming from
    linter.set_current_module("Command line or configuration file")

    # We have loaded configuration from config file and command line. Now, we can
    # load plugin specific configuration.
    linter.load_plugin_configuration()

    # Now that plugins are loaded, get list of all fail_on messages, and
    # enable them
    linter.enable_fail_on_messages()

    linter._parse_error_mode()

    # Link the base Namespace object on the current directory
    linter._directory_namespaces[Path().resolve()] = (linter.config, {})

    # parsed_args_list should now only be a list of inputs to lint.
    # All other options have been removed from the list.
    return list(
        chain.from_iterable(
            # NOTE: 'or [arg]' is needed in the case the input file or directory does
            # not exist and 'glob(arg)' cannot find anything. Without this we would
            # not be able to output the fatal import error for this module later on,
            # as it would get silently ignored.
            glob(arg, recursive=True) or [arg]
            for arg in parsed_args_list
        )
    )


</t>
<t tx="ekr.20250131013600.711">def _order_all_first(config_args: list[str], *, joined: bool) -&gt; list[str]:
    """Reorder config_args such that --enable=all or --disable=all comes first.

    Raise if both are given.

    If joined is True, expect args in the form '--enable=all,for-any-all'.
    If joined is False, expect args in the form '--enable', 'all,for-any-all'.
    """
    indexes_to_prepend = []
    all_action = ""

    for i, arg in enumerate(config_args):
        if joined and arg.startswith(("--enable=", "--disable=")):
            value = arg.split("=")[1]
        elif arg in {"--enable", "--disable"}:
            value = config_args[i + 1]
        else:
            continue

        if "all" not in (msg.strip() for msg in value.split(",")):
            continue

        arg = arg.split("=")[0]
        if all_action and (arg != all_action):
            raise ArgumentPreprocessingError(
                "--enable=all and --disable=all are incompatible."
            )
        all_action = arg

        indexes_to_prepend.append(i)
        if not joined:
            indexes_to_prepend.append(i + 1)

    returned_args = []
    for i in indexes_to_prepend:
        returned_args.append(config_args[i])

    for i, arg in enumerate(config_args):
        if i in indexes_to_prepend:
            continue
        returned_args.append(arg)

    return returned_args
</t>
<t tx="ekr.20250131013600.712">@path pylint/config
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

# pylint: disable=too-many-arguments, redefined-builtin

"""Deprecated option actions."""

from __future__ import annotations

import argparse
import warnings
from collections.abc import Sequence
from typing import Any


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.713">class _OldNamesAction(argparse._StoreAction):
    """Store action that also sets the value to old names."""

    @others
</t>
<t tx="ekr.20250131013600.714">class _NewNamesAction(argparse._StoreAction):
    """Store action that also emits a deprecation warning about a new name."""

    @others
</t>
<t tx="ekr.20250131013600.715">def __init__(
    self,
    option_strings: Sequence[str],
    dest: str,
    nargs: None = None,
    const: None = None,
    default: None = None,
    type: None = None,
    choices: None = None,
    required: bool = False,
    help: str = "",
    metavar: str = "",
    old_names: list[str] | None = None,
) -&gt; None:
    assert old_names
    self.old_names = old_names
    super().__init__(
        option_strings,
        dest,
        1,
        const,
        default,
        type,
        choices,
        required,
        help,
        metavar,
    )

</t>
<t tx="ekr.20250131013600.716">def __call__(
    self,
    parser: argparse.ArgumentParser,
    namespace: argparse.Namespace,
    values: str | Sequence[Any] | None,
    option_string: str | None = None,
) -&gt; None:
    assert isinstance(values, list)
    setattr(namespace, self.dest, values[0])
    for old_name in self.old_names:
        setattr(namespace, old_name, values[0])


</t>
<t tx="ekr.20250131013600.717">def __init__(
    self,
    option_strings: Sequence[str],
    dest: str,
    nargs: None = None,
    const: None = None,
    default: None = None,
    type: None = None,
    choices: None = None,
    required: bool = False,
    help: str = "",
    metavar: str = "",
    new_names: list[str] | None = None,
) -&gt; None:
    assert new_names
    self.new_names = new_names
    super().__init__(
        option_strings,
        dest,
        1,
        const,
        default,
        type,
        choices,
        required,
        help,
        metavar,
    )

</t>
<t tx="ekr.20250131013600.718">def __call__(
    self,
    parser: argparse.ArgumentParser,
    namespace: argparse.Namespace,
    values: str | Sequence[Any] | None,
    option_string: str | None = None,
) -&gt; None:
    assert isinstance(values, list)
    setattr(namespace, self.dest, values[0])
    warnings.warn(
        f"{self.option_strings[0]} has been deprecated. Please look into "
        f"using any of the following options: {', '.join(self.new_names)}.",
        DeprecationWarning,
        stacklevel=2,
    )
</t>
<t tx="ekr.20250131013600.719">@path pylint/config
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.72">@lru_cache(maxsize=1024)
def safe_infer(
    node: nodes.NodeNG,
    context: InferenceContext | None = None,
    *,
    compare_constants: bool = False,
    compare_constructors: bool = False,
) -&gt; InferenceResult | None:
    """Return the inferred value for the given node.

    Return None if inference failed or if there is some ambiguity (more than
    one node has been inferred of different types).

    If compare_constants is True and if multiple constants are inferred,
    unequal inferred values are also considered ambiguous and return None.

    If compare_constructors is True and if multiple classes are inferred,
    constructors with different signatures are held ambiguous and return None.
    """
    inferred_types: set[str | None] = set()
    try:
        infer_gen = node.infer(context=context)
        value = next(infer_gen)
    except astroid.InferenceError:
        return None
    except Exception as e:  # pragma: no cover
        raise AstroidError from e

    if not isinstance(value, util.UninferableBase):
        inferred_types.add(_get_python_type_of_node(value))

    # pylint: disable = too-many-try-statements
    try:
        for inferred in infer_gen:
            inferred_type = _get_python_type_of_node(inferred)
            if inferred_type not in inferred_types:
                return None  # If there is ambiguity on the inferred node.
            if (
                compare_constants
                and isinstance(inferred, nodes.Const)
                and isinstance(value, nodes.Const)
                and inferred.value != value.value
            ):
                return None
            if (
                isinstance(inferred, nodes.FunctionDef)
                and isinstance(value, nodes.FunctionDef)
                and function_arguments_are_ambiguous(inferred, value)
            ):
                return None
            if (
                compare_constructors
                and isinstance(inferred, nodes.ClassDef)
                and isinstance(value, nodes.ClassDef)
                and class_constructors_are_ambiguous(inferred, value)
            ):
                return None
    except astroid.InferenceError:
        return None  # There is some kind of ambiguity
    except StopIteration:
        return value
    except Exception as e:  # pragma: no cover
        raise AstroidError from e
    return value if len(inferred_types) &lt;= 1 else None


</t>
<t tx="ekr.20250131013600.720">class UnrecognizedArgumentAction(Exception):
    """Raised if an ArgumentManager instance tries to add an argument for which the
    action is not recognized.
    """


</t>
<t tx="ekr.20250131013600.721">class _UnrecognizedOptionError(Exception):
    """Raised if an ArgumentManager instance tries to parse an option that is
    unknown.
    """

    @others
</t>
<t tx="ekr.20250131013600.722">class ArgumentPreprocessingError(Exception):
    """Raised if an error occurs during argument pre-processing."""
</t>
<t tx="ekr.20250131013600.723">def __init__(self, options: list[str], *args: object) -&gt; None:
    self.options = options
    super().__init__(*args)


</t>
<t tx="ekr.20250131013600.724">@path pylint/config
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import configparser
import os
import sys
from collections.abc import Iterator
from pathlib import Path

if sys.version_info &gt;= (3, 11):
    import tomllib
else:
    import tomli as tomllib

RC_NAMES = (
    Path("pylintrc"),
    Path("pylintrc.toml"),
    Path(".pylintrc"),
    Path(".pylintrc.toml"),
)
PYPROJECT_NAME = Path("pyproject.toml")
CONFIG_NAMES = (* RC_NAMES, PYPROJECT_NAME, Path("setup.cfg"), Path("tox.ini"))


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.725">def _find_pyproject() -&gt; Path:
    """Search for file pyproject.toml in the parent directories recursively.

    It resolves symlinks, so if there is any symlink up in the tree, it does not respect them
    """
    current_dir = Path.cwd().resolve()
    is_root = False
    while not is_root:
        if (current_dir / PYPROJECT_NAME).is_file():
            return current_dir / PYPROJECT_NAME
        is_root = (
            current_dir == current_dir.parent
            or (current_dir / ".git").is_dir()
            or (current_dir / ".hg").is_dir()
        )
        current_dir = current_dir.parent

    return current_dir


</t>
<t tx="ekr.20250131013600.726">def _toml_has_config(path: Path | str) -&gt; bool:
    with open(path, mode="rb") as toml_handle:
        try:
            content = tomllib.load(toml_handle)
        except tomllib.TOMLDecodeError as error:
            print(f"Failed to load '{path}': {error}")
            return False
    return "pylint" in content.get("tool", [])


</t>
<t tx="ekr.20250131013600.727">def _cfg_or_ini_has_config(path: Path | str) -&gt; bool:
    parser = configparser.ConfigParser()
    try:
        parser.read(path, encoding="utf-8")
    except configparser.Error:
        return False
    return any(
        section == "pylint" or section.startswith("pylint.")
        for section in parser.sections()
    )


</t>
<t tx="ekr.20250131013600.728">def _yield_default_files() -&gt; Iterator[Path]:
    """Iterate over the default config file names and see if they exist."""
    for config_name in CONFIG_NAMES:
        try:
            if config_name.is_file():
                if config_name.suffix == ".toml" and not _toml_has_config(config_name):
                    continue
                if config_name.suffix in {
                    ".cfg",
                    ".ini",
                } and not _cfg_or_ini_has_config(config_name):
                    continue

                yield config_name.resolve()
        except OSError:
            pass


</t>
<t tx="ekr.20250131013600.729">def _find_project_config() -&gt; Iterator[Path]:
    """Traverse up the directory tree to find a config file.

    Stop if no '__init__' is found and thus we are no longer in a package.
    """
    if Path("__init__.py").is_file():
        curdir = Path(os.getcwd()).resolve()
        while (curdir / "__init__.py").is_file():
            curdir = curdir.parent
            for rc_name in RC_NAMES:
                rc_path = curdir / rc_name
                if rc_path.is_file():
                    yield rc_path.resolve()


</t>
<t tx="ekr.20250131013600.73">@lru_cache(maxsize=512)
def infer_all(
    node: nodes.NodeNG, context: InferenceContext | None = None
) -&gt; list[InferenceResult]:
    try:
        return list(node.infer(context=context))
    except astroid.InferenceError:
        return []
    except Exception as e:  # pragma: no cover
        raise AstroidError from e


</t>
<t tx="ekr.20250131013600.730">def _find_config_in_home_or_environment() -&gt; Iterator[Path]:
    """Find a config file in the specified environment var or the home directory."""
    if "PYLINTRC" in os.environ and Path(os.environ["PYLINTRC"]).exists():
        if Path(os.environ["PYLINTRC"]).is_file():
            yield Path(os.environ["PYLINTRC"]).resolve()
    else:
        try:
            user_home = Path.home()
        except RuntimeError:
            # If the home directory does not exist a RuntimeError will be raised
            user_home = None

        if user_home is not None and str(user_home) not in ("~", "/root"):
            home_rc = user_home / ".pylintrc"
            if home_rc.is_file():
                yield home_rc.resolve()

            home_rc = user_home / ".config" / "pylintrc"
            if home_rc.is_file():
                yield home_rc.resolve()


</t>
<t tx="ekr.20250131013600.731">def find_default_config_files() -&gt; Iterator[Path]:
    """Find all possible config files."""
    yield from _yield_default_files()

    try:
        yield from _find_project_config()
    except OSError:
        pass

    try:
        parent_pyproject = _find_pyproject()
        if parent_pyproject.is_file() and _toml_has_config(parent_pyproject):
            yield parent_pyproject.resolve()
    except OSError:
        pass

    try:
        yield from _find_config_in_home_or_environment()
    except OSError:
        pass

    try:
        if os.path.isfile("/etc/pylintrc"):
            yield Path("/etc/pylintrc").resolve()
    except OSError:
        pass
</t>
<t tx="ekr.20250131013600.732">@path pylint/config
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import argparse

from pylint.config.callback_actions import _CallbackAction
from pylint.constants import DEFAULT_PYLINT_HOME


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.733">class _HelpFormatter(argparse.RawDescriptionHelpFormatter):
    """Formatter for the help message emitted by argparse."""

@others
</t>
<t tx="ekr.20250131013600.734">    def _get_help_string(self, action: argparse.Action) -&gt; str | None:
        """Copied from argparse.ArgumentDefaultsHelpFormatter."""
        assert action.help
        help_string = action.help

        # CallbackActions don't have a default
        if isinstance(action, _CallbackAction):
            return help_string

        if "%(default)" not in help_string:
            if action.default is not argparse.SUPPRESS:
                defaulting_nargs = [argparse.OPTIONAL, argparse.ZERO_OR_MORE]
                if action.option_strings or action.nargs in defaulting_nargs:
                    help_string += " (default: %(default)s)"
        return help_string

</t>
<t tx="ekr.20250131013600.735">    @staticmethod
    def get_long_description() -&gt; str:
        return f"""
Environment variables:
    The following environment variables are used:
        * PYLINTHOME    Path to the directory where persistent data for the run will
                        be stored. If not found, it defaults to '{DEFAULT_PYLINT_HOME}'.
        * PYLINTRC      Path to the configuration file. See the documentation for the method used
                        to search for configuration file.

Output:
    Using the default text output, the message format is :

        MESSAGE_TYPE: LINE_NUM:[OBJECT:] MESSAGE

    There are 5 kind of message types :
        * (I) info,         for informational messages
        * (C) convention,   for programming standard violation
        * (R) refactor,     for bad code smell
        * (W) warning,      for python specific problems
        * (E) error,        for probable bugs in the code
        * (F) fatal,        if an error occurred which prevented pylint from doing further processing.

Output status code:
    Pylint should leave with following bitwise status codes:
        * 0 if everything went fine
        * 1 if a fatal message was issued
        * 2 if an error message was issued
        * 4 if a warning message was issued
        * 8 if a refactor message was issued
        * 16 if a convention message was issued
        * 32 on usage error
"""
</t>
<t tx="ekr.20250131013600.736">@path pylint/config
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Utils for arguments/options parsing and handling."""

from __future__ import annotations

import re
from collections.abc import Callable, Sequence
from pathlib import Path
from typing import TYPE_CHECKING, Any

from pylint import extensions, utils
from pylint.config.argument import (
    _CallableArgument,
    _ExtendArgument,
    _StoreArgument,
    _StoreNewNamesArgument,
    _StoreOldNamesArgument,
    _StoreTrueArgument,
)
from pylint.config.callback_actions import _CallbackAction
from pylint.config.exceptions import ArgumentPreprocessingError

if TYPE_CHECKING:
    from pylint.lint.run import Run


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.737">def _convert_option_to_argument(
    opt: str, optdict: dict[str, Any]
) -&gt; (
    _StoreArgument
    | _StoreTrueArgument
    | _CallableArgument
    | _StoreOldNamesArgument
    | _StoreNewNamesArgument
    | _ExtendArgument
</t>
<t tx="ekr.20250131013600.738">):
    """Convert an optdict to an Argument class instance."""
    # Get the long and short flags
    flags = [f"--{opt}"]
    if "short" in optdict:
        flags += [f"-{optdict['short']}"]

    # Get the action type
    action = optdict.get("action", "store")

    if action == "store_true":
        return _StoreTrueArgument(
            flags=flags,
            action=action,
            default=optdict.get("default", True),
            arg_help=optdict.get("help", ""),
            hide_help=optdict.get("hide", False),
            section=optdict.get("group", None),
        )
    if not isinstance(action, str) and issubclass(action, _CallbackAction):
        return _CallableArgument(
            flags=flags,
            action=action,
            arg_help=optdict.get("help", ""),
            kwargs=optdict.get("kwargs", {}),
            hide_help=optdict.get("hide", False),
            section=optdict.get("group", None),
            metavar=optdict.get("metavar", None),
        )

    default = optdict["default"]

    if action == "extend":
        return _ExtendArgument(
            flags=flags,
            action=action,
            default=[] if default is None else default,
            arg_type=optdict["type"],
            choices=optdict.get("choices", None),
            arg_help=optdict.get("help", ""),
            metavar=optdict.get("metavar", ""),
            hide_help=optdict.get("hide", False),
            section=optdict.get("group", None),
            dest=optdict.get("dest", None),
        )
    if "kwargs" in optdict:
        if "old_names" in optdict["kwargs"]:
            return _StoreOldNamesArgument(
                flags=flags,
                default=default,
                arg_type=optdict["type"],
                choices=optdict.get("choices", None),
                arg_help=optdict.get("help", ""),
                metavar=optdict.get("metavar", ""),
                hide_help=optdict.get("hide", False),
                kwargs=optdict.get("kwargs", {}),
                section=optdict.get("group", None),
            )
        if "new_names" in optdict["kwargs"]:
            return _StoreNewNamesArgument(
                flags=flags,
                default=default,
                arg_type=optdict["type"],
                choices=optdict.get("choices", None),
                arg_help=optdict.get("help", ""),
                metavar=optdict.get("metavar", ""),
                hide_help=optdict.get("hide", False),
                kwargs=optdict.get("kwargs", {}),
                section=optdict.get("group", None),
            )
    if "dest" in optdict:
        return _StoreOldNamesArgument(
            flags=flags,
            default=default,
            arg_type=optdict["type"],
            choices=optdict.get("choices", None),
            arg_help=optdict.get("help", ""),
            metavar=optdict.get("metavar", ""),
            hide_help=optdict.get("hide", False),
            kwargs={"old_names": [optdict["dest"]]},
            section=optdict.get("group", None),
        )
    return _StoreArgument(
        flags=flags,
        action=action,
        default=default,
        arg_type=optdict["type"],
        choices=optdict.get("choices", None),
        arg_help=optdict.get("help", ""),
        metavar=optdict.get("metavar", ""),
        hide_help=optdict.get("hide", False),
        section=optdict.get("group", None),
    )


def _parse_rich_type_value(value: Any) -&gt; str:
    """Parse rich (toml) types into strings."""
    if isinstance(value, (list, tuple)):
        return ",".join(_parse_rich_type_value(i) for i in value)
    if isinstance(value, re.Pattern):
        return str(value.pattern)
    if isinstance(value, dict):
        return ",".join(f"{k}:{v}" for k, v in value.items())
    return str(value)


</t>
<t tx="ekr.20250131013600.739"># pylint: disable-next=unused-argument
def _init_hook(run: Run, value: str | None) -&gt; None:
    """Execute arbitrary code from the init_hook.

    This can be used to set the 'sys.path' for example.
    """
    assert value is not None
    exec(value)  # pylint: disable=exec-used


</t>
<t tx="ekr.20250131013600.74">def function_arguments_are_ambiguous(
    func1: nodes.FunctionDef, func2: nodes.FunctionDef
) -&gt; bool:
    if func1.argnames() != func2.argnames():
        return True
    # Check ambiguity among function default values
    pairs_of_defaults = [
        (func1.args.defaults, func2.args.defaults),
        (func1.args.kw_defaults, func2.args.kw_defaults),
    ]
    for zippable_default in pairs_of_defaults:
        if None in zippable_default:
            continue
        if len(zippable_default[0]) != len(zippable_default[1]):
            return True
        for default1, default2 in zip(*zippable_default):
            if isinstance(default1, nodes.Const) and isinstance(default2, nodes.Const):
                if default1.value != default2.value:
                    return True
            elif isinstance(default1, nodes.Name) and isinstance(default2, nodes.Name):
                if default1.name != default2.name:
                    return True
            else:
                return True
    return False


</t>
<t tx="ekr.20250131013600.740">def _set_rcfile(run: Run, value: str | None) -&gt; None:
    """Set the rcfile."""
    assert value is not None
    run._rcfile = value


</t>
<t tx="ekr.20250131013600.741">def _set_output(run: Run, value: str | None) -&gt; None:
    """Set the output."""
    assert value is not None
    run._output = value


</t>
<t tx="ekr.20250131013600.742">def _add_plugins(run: Run, value: str | None) -&gt; None:
    """Add plugins to the list of loadable plugins."""
    assert value is not None
    run._plugins.extend(utils._splitstrip(value))


</t>
<t tx="ekr.20250131013600.743">def _set_verbose_mode(run: Run, value: str | None) -&gt; None:
    assert value is None
    run.verbose = True


</t>
<t tx="ekr.20250131013600.744">def _enable_all_extensions(run: Run, value: str | None) -&gt; None:
    """Enable all extensions."""
    assert value is None
    for filename in Path(extensions.__file__).parent.iterdir():
        if filename.suffix == ".py" and not filename.stem.startswith("_"):
            extension_name = f"pylint.extensions.{filename.stem}"
            if extension_name not in run._plugins:
                run._plugins.append(extension_name)


</t>
<t tx="ekr.20250131013600.745">PREPROCESSABLE_OPTIONS: dict[
    str, tuple[bool, Callable[[Run, str | None], None], int]
] = {  # pylint: disable=consider-using-namedtuple-or-dataclass
    # pylint: disable=useless-suppression, wrong-spelling-in-comment
    # Argparse by default allows abbreviations. It behaves differently
    # if you turn this off, so we also turn it on. We mimic this
    # by allowing some abbreviations or incorrect spelling here.
    # The integer at the end of the tuple indicates how many letters
    # should match, include the '-'. 0 indicates a full match.
    #
    # Clashes with --init-(import)
    "--init-hook": (True, _init_hook, 8),
    # Clashes with --r(ecursive)
    "--rcfile": (True, _set_rcfile, 4),
    # Clashes with --output(-format)
    "--output": (True, _set_output, 0),
    # Clashes with --lo(ng-help)
    "--load-plugins": (True, _add_plugins, 5),
    # Clashes with --v(ariable-rgx)
    "--verbose": (False, _set_verbose_mode, 4),
    "-v": (False, _set_verbose_mode, 2),
    # Clashes with --enable
    "--enable-all-extensions": (False, _enable_all_extensions, 9),
}
# pylint: enable=wrong-spelling-in-comment


def _preprocess_options(run: Run, args: Sequence[str]) -&gt; list[str]:
    """Pre-process options before full config parsing has started."""
    processed_args: list[str] = []

    i = 0
    while i &lt; len(args):
        argument = args[i]
        if not argument.startswith("-"):
            processed_args.append(argument)
            i += 1
            continue

        try:
            option, value = argument.split("=", 1)
        except ValueError:
            option, value = argument, None

        matched_option = None
        for option_name, data in PREPROCESSABLE_OPTIONS.items():
            to_match = data[2]
            if to_match == 0:
                if option == option_name:
                    matched_option = option_name
            elif option.startswith(option_name[:to_match]):
                matched_option = option_name

        if matched_option is None:
            processed_args.append(argument)
            i += 1
            continue

        takearg, cb, _ = PREPROCESSABLE_OPTIONS[matched_option]

        if takearg and value is None:
            i += 1
            if i &gt;= len(args) or args[i].startswith("-"):
                raise ArgumentPreprocessingError(f"Option {option} expects a value")
            value = args[i]
        elif not takearg and value is not None:
            raise ArgumentPreprocessingError(f"Option {option} doesn't expect a value")

        cb(run, value)
        i += 1

    return processed_args
</t>
<t tx="ekr.20250131013600.746"></t>
<t tx="ekr.20250131013600.747">@path pylint/config/_pylint_config
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Everything related to the 'pylint-config' command.

Everything in this module is private.
"""

from pylint.config._pylint_config.main import _handle_pylint_config_commands
from pylint.config._pylint_config.setup import _register_generate_config_options

__all__ = ("_handle_pylint_config_commands", "_register_generate_config_options")
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.748">@path pylint/config/_pylint_config
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Everything related to the 'pylint-config generate' command."""


from __future__ import annotations

from io import StringIO
from typing import TYPE_CHECKING

from pylint.config._pylint_config import utils
from pylint.config._pylint_config.help_message import get_subparser_help

if TYPE_CHECKING:
    from pylint.lint.pylinter import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.749">def generate_interactive_config(linter: PyLinter) -&gt; None:
    print("Starting interactive pylint configuration generation")

    format_type = utils.get_and_validate_format()
    minimal = format_type == "toml" and utils.get_minimal_setting()
    to_file, output_file_name = utils.get_and_validate_output_file()

    if format_type == "toml":
        config_string = linter._generate_config_file(minimal=minimal)
    else:
        output_stream = StringIO()
        linter._generate_config(stream=output_stream, skipsections=("Commands",))
        config_string = output_stream.getvalue()

    if to_file:
        with open(output_file_name, "w", encoding="utf-8") as f:
            print(config_string, file=f)
        print(f"Wrote configuration file to {output_file_name.resolve()}")
    else:
        print(config_string)


</t>
<t tx="ekr.20250131013600.75">def class_constructors_are_ambiguous(
    class1: nodes.ClassDef, class2: nodes.ClassDef
) -&gt; bool:
    try:
        constructor1 = class1.local_attr("__init__")[0]
        constructor2 = class2.local_attr("__init__")[0]
    except astroid.NotFoundError:
        return False
    if not isinstance(constructor1, nodes.FunctionDef):
        return False
    if not isinstance(constructor2, nodes.FunctionDef):
        return False
    return function_arguments_are_ambiguous(constructor1, constructor2)


</t>
<t tx="ekr.20250131013600.750">def handle_generate_command(linter: PyLinter) -&gt; int:
    """Handle 'pylint-config generate'."""
    # Interactively generate a pylint configuration
    if linter.config.interactive:
        generate_interactive_config(linter)
        return 0
    print(get_subparser_help(linter, "generate"))
    return 32
</t>
<t tx="ekr.20250131013600.751">@path pylint/config/_pylint_config
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Everything related to the 'pylint-config -h' command and subcommands."""


from __future__ import annotations

import argparse
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from pylint.lint.pylinter import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.752">def get_subparser_help(linter: PyLinter, command: str) -&gt; str:
    """Get the help message for one of the subcommands."""
    # Make sure subparsers are initialized properly
    assert linter._arg_parser._subparsers
    subparser_action = linter._arg_parser._subparsers._group_actions[0]
    assert isinstance(subparser_action, argparse._SubParsersAction)

    for name, subparser in subparser_action.choices.items():
        assert isinstance(subparser, argparse.ArgumentParser)
        if name == command:
            # Remove last character which is an extra new line
            return subparser.format_help()[:-1]
    return ""  # pragma: no cover


</t>
<t tx="ekr.20250131013600.753">def get_help(parser: argparse.ArgumentParser) -&gt; str:
    """Get the help message for the main 'pylint-config' command.

    Taken from argparse.ArgumentParser.format_help.
    """
    formatter = parser._get_formatter()

    # usage
    formatter.add_usage(
        parser.usage, parser._actions, parser._mutually_exclusive_groups
    )

    # description
    formatter.add_text(parser.description)

    # positionals, optionals and user-defined groups
    for action_group in parser._action_groups:
        if action_group.title == "Subcommands":
            formatter.start_section(action_group.title)
            formatter.add_text(action_group.description)
            formatter.add_arguments(action_group._group_actions)
            formatter.end_section()

    # epilog
    formatter.add_text(parser.epilog)

    # determine help from format above
    return formatter.format_help()
</t>
<t tx="ekr.20250131013600.754">@path pylint/config/_pylint_config
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Everything related to the 'pylint-config' command."""


from __future__ import annotations

from typing import TYPE_CHECKING

from pylint.config._pylint_config.generate_command import handle_generate_command
from pylint.config._pylint_config.help_message import get_help

if TYPE_CHECKING:
    from pylint.lint.pylinter import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.755">def _handle_pylint_config_commands(linter: PyLinter) -&gt; int:
    """Handle whichever command is passed to 'pylint-config'."""
    if linter.config.config_subcommand == "generate":
        return handle_generate_command(linter)

    print(get_help(linter._arg_parser))
    return 32
</t>
<t tx="ekr.20250131013600.756">@path pylint/config/_pylint_config
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Everything related to the setup of the 'pylint-config' command."""


from __future__ import annotations

import argparse
from collections.abc import Sequence
from typing import Any

from pylint.config._pylint_config.help_message import get_help
from pylint.config.callback_actions import _AccessParserAction


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.757">class _HelpAction(_AccessParserAction):
    @others
</t>
<t tx="ekr.20250131013600.758">def _register_generate_config_options(parser: argparse.ArgumentParser) -&gt; None:
    """Registers the necessary arguments on the parser."""
    parser.prog = "pylint-config"
    # Overwrite the help command
    parser.add_argument(
        "-h",
        "--help",
        action=_HelpAction,
        default=argparse.SUPPRESS,
        help="show this help message and exit",
        parser=parser,
    )

    # We use subparsers to create various subcommands under 'pylint-config'
    subparsers = parser.add_subparsers(dest="config_subcommand", title="Subcommands")

    # Add the generate command
    generate_parser = subparsers.add_parser(
        "generate", help="Generate a pylint configuration"
    )
    generate_parser.add_argument("--interactive", action="store_true")
</t>
<t tx="ekr.20250131013600.759">def __call__(
    self,
    parser: argparse.ArgumentParser,
    namespace: argparse.Namespace,
    values: str | Sequence[Any] | None,
    option_string: str | None = "--help",
) -&gt; None:
    get_help(self.parser)


</t>
<t tx="ekr.20250131013600.76">def has_known_bases(
    klass: nodes.ClassDef, context: InferenceContext | None = None
) -&gt; bool:
    """Return true if all base classes of a class could be inferred."""
    try:
        return klass._all_bases_known  # type: ignore[no-any-return]
    except AttributeError:
        pass
    for base in klass.bases:
        result = safe_infer(base, context=context)
        if (
            not isinstance(result, nodes.ClassDef)
            or result is klass
            or not has_known_bases(result, context=context)
        ):
            klass._all_bases_known = False
            return False
    klass._all_bases_known = True
    return True


</t>
<t tx="ekr.20250131013600.760">@path pylint/config/_pylint_config
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Utils for the 'pylint-config' command."""

from __future__ import annotations

import sys
from collections.abc import Callable
from pathlib import Path
from typing import Literal, TypeVar

if sys.version_info &gt;= (3, 10):
    from typing import ParamSpec
else:
    from typing_extensions import ParamSpec

_P = ParamSpec("_P")
_ReturnValueT = TypeVar("_ReturnValueT", bool, str)

SUPPORTED_FORMATS = {"t", "toml", "i", "ini"}
YES_NO_ANSWERS = {"y", "yes", "n", "no"}


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.761">class InvalidUserInput(Exception):
    """Raised whenever a user input is invalid."""

    @others
</t>
<t tx="ekr.20250131013600.762">def should_retry_after_invalid_input(
    func: Callable[_P, _ReturnValueT]
) -&gt; Callable[_P, _ReturnValueT]:
    """Decorator that handles InvalidUserInput exceptions and retries."""

    def inner_function(*args: _P.args, **kwargs: _P.kwargs) -&gt; _ReturnValueT:
        called_once = False
        while True:
            try:
                return func(*args, **kwargs)
            except InvalidUserInput as exc:
                if called_once and exc.input == "exit()":
                    print("Stopping 'pylint-config'.")
                    sys.exit()
                print(f"Answer should be one of {exc.valid}.")
                print("Type 'exit()' if you want to exit the program.")
                called_once = True

    return inner_function


</t>
<t tx="ekr.20250131013600.763">@should_retry_after_invalid_input
def get_and_validate_format() -&gt; Literal["toml", "ini"]:
    """Make sure that the output format is either .toml or .ini."""
    # pylint: disable-next=bad-builtin
    format_type = input(
        "Please choose the format of configuration, (T)oml or (I)ni (.cfg): "
    ).lower()

    if format_type not in SUPPORTED_FORMATS:
        raise InvalidUserInput(", ".join(sorted(SUPPORTED_FORMATS)), format_type)

    if format_type.startswith("t"):
        return "toml"
    return "ini"


</t>
<t tx="ekr.20250131013600.764">@should_retry_after_invalid_input
def validate_yes_no(question: str, default: Literal["yes", "no"] | None) -&gt; bool:
    """Validate that a yes or no answer is correct."""
    question = f"{question} (y)es or (n)o "
    if default:
        question += f" (default={default}) "
    # pylint: disable-next=bad-builtin
    answer = input(question).lower()

    if not answer and default:
        answer = default

    if answer not in YES_NO_ANSWERS:
        raise InvalidUserInput(", ".join(sorted(YES_NO_ANSWERS)), answer)

    return answer.startswith("y")


</t>
<t tx="ekr.20250131013600.765">def get_minimal_setting() -&gt; bool:
    """Ask the user if they want to use the minimal setting."""
    return validate_yes_no(
        "Do you want a minimal configuration without comments or default values?", "no"
    )


</t>
<t tx="ekr.20250131013600.766">def get_and_validate_output_file() -&gt; tuple[bool, Path]:
    """Make sure that the output file is correct."""
    to_file = validate_yes_no("Do you want to write the output to a file?", "no")

    if not to_file:
        return False, Path()

    # pylint: disable-next=bad-builtin
    file_name = Path(input("What should the file be called: "))
    if file_name.exists():
        overwrite = validate_yes_no(
            f"{file_name} already exists. Are you sure you want to overwrite?", "no"
        )

        if not overwrite:
            return False, file_name
        return True, file_name

    return True, file_name
</t>
<t tx="ekr.20250131013600.767">def __init__(self, valid_input: str, input_value: str, *args: object) -&gt; None:
    self.valid = valid_input
    self.input = input_value
    super().__init__(*args)


</t>
<t tx="ekr.20250131013600.768"></t>
<t tx="ekr.20250131013600.769">@path pylint/extensions
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

from typing import TYPE_CHECKING

from pylint.utils import register_plugins

if TYPE_CHECKING:
    from pylint.lint import PyLinter


@others
__all__ = ["initialize"]
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.77">def is_none(node: nodes.NodeNG) -&gt; bool:
    return (
        node is None
        or (isinstance(node, nodes.Const) and node.value is None)
        or (isinstance(node, nodes.Name) and node.name == "None")
    )


</t>
<t tx="ekr.20250131013600.770">def initialize(linter: PyLinter) -&gt; None:
    """Initialize linter with checkers in the extensions' directory."""
    register_plugins(linter, __path__[0])


</t>
<t tx="ekr.20250131013600.771">@path pylint/extensions
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Utility methods for docstring checking."""

from __future__ import annotations

import itertools
import re
from collections.abc import Iterable

import astroid
from astroid import nodes
from astroid.util import UninferableBase

from pylint.checkers import utils


@others
DOCSTRING_TYPES = {
    "sphinx": SphinxDocstring,
    "epytext": EpytextDocstring,
    "google": GoogleDocstring,
    "numpy": NumpyDocstring,
    "default": Docstring,
}
"""A map of the name of the docstring type to its class.

:type: dict(str, type)
"""
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.772">def space_indentation(s: str) -&gt; int:
    """The number of leading spaces in a string.

    :param str s: input string

    :rtype: int
    :return: number of leading spaces
    """
    return len(s) - len(s.lstrip(" "))


</t>
<t tx="ekr.20250131013600.773">def get_setters_property_name(node: nodes.FunctionDef) -&gt; str | None:
    """Get the name of the property that the given node is a setter for.

    :param node: The node to get the property name for.
    :type node: str

    :rtype: str or None
    :returns: The name of the property that the node is a setter for,
        or None if one could not be found.
    """
    decorators = node.decorators.nodes if node.decorators else []
    for decorator in decorators:
        if (
            isinstance(decorator, nodes.Attribute)
            and decorator.attrname == "setter"
            and isinstance(decorator.expr, nodes.Name)
        ):
            return decorator.expr.name  # type: ignore[no-any-return]
    return None


</t>
<t tx="ekr.20250131013600.774">def get_setters_property(node: nodes.FunctionDef) -&gt; nodes.FunctionDef | None:
    """Get the property node for the given setter node.

    :param node: The node to get the property for.
    :type node: nodes.FunctionDef

    :rtype: nodes.FunctionDef or None
    :returns: The node relating to the property of the given setter node,
        or None if one could not be found.
    """
    property_ = None

    property_name = get_setters_property_name(node)
    class_node = utils.node_frame_class(node)
    if property_name and class_node:
        class_attrs: list[nodes.FunctionDef] = class_node.getattr(node.name)
        for attr in class_attrs:
            if utils.decorated_with_property(attr):
                property_ = attr
                break

    return property_


</t>
<t tx="ekr.20250131013600.775">def returns_something(return_node: nodes.Return) -&gt; bool:
    """Check if a return node returns a value other than None.

    :param return_node: The return node to check.
    :type return_node: astroid.Return

    :rtype: bool
    :return: True if the return node returns a value other than None,
        False otherwise.
    """
    returns = return_node.value

    if returns is None:
        return False

    return not (isinstance(returns, nodes.Const) and returns.value is None)


</t>
<t tx="ekr.20250131013600.776">def _get_raise_target(node: nodes.NodeNG) -&gt; nodes.NodeNG | UninferableBase | None:
    if isinstance(node.exc, nodes.Call):
        func = node.exc.func
        if isinstance(func, (nodes.Name, nodes.Attribute)):
            return utils.safe_infer(func)
    return None


</t>
<t tx="ekr.20250131013600.777">def _split_multiple_exc_types(target: str) -&gt; list[str]:
    delimiters = r"(\s*,(?:\s*or\s)?\s*|\s+or\s+)"
    return re.split(delimiters, target)


</t>
<t tx="ekr.20250131013600.778">def possible_exc_types(node: nodes.NodeNG) -&gt; set[nodes.ClassDef]:
    """Gets all the possible raised exception types for the given raise node.

    .. note::

        Caught exception types are ignored.

    :param node: The raise node to find exception types for.

    :returns: A list of exception types possibly raised by :param:`node`.
    """
    exceptions = []
    if isinstance(node.exc, nodes.Name):
        inferred = utils.safe_infer(node.exc)
        if inferred:
            exceptions = [inferred]
    elif node.exc is None:
        handler = node.parent
        while handler and not isinstance(handler, nodes.ExceptHandler):
            handler = handler.parent

        if handler and handler.type:
            try:
                for exception in astroid.unpack_infer(handler.type):
                    if not isinstance(exception, UninferableBase):
                        exceptions.append(exception)
            except astroid.InferenceError:
                pass
    else:
        target = _get_raise_target(node)
        if isinstance(target, nodes.ClassDef):
            exceptions = [target]
        elif isinstance(target, nodes.FunctionDef):
            for ret in target.nodes_of_class(nodes.Return):
                if ret.value is None:
                    continue
                if ret.frame() != target:
                    # return from inner function - ignore it
                    continue

                val = utils.safe_infer(ret.value)
                if val and utils.inherit_from_std_ex(val):
                    if isinstance(val, nodes.ClassDef):
                        exceptions.append(val)
                    elif isinstance(val, astroid.Instance):
                        exceptions.append(val.getattr("__class__")[0])

    try:
        return {
            exc
            for exc in exceptions
            if not utils.node_ignores_exception(node, exc.name)
        }
    except astroid.InferenceError:
        return set()


</t>
<t tx="ekr.20250131013600.779">def _is_ellipsis(node: nodes.NodeNG) -&gt; bool:
    return isinstance(node, nodes.Const) and node.value == Ellipsis


</t>
<t tx="ekr.20250131013600.78">def node_type(node: nodes.NodeNG) -&gt; SuccessfulInferenceResult | None:
    """Return the inferred type for `node`.

    If there is more than one possible type, or if inferred type is Uninferable or None,
    return None
    """
    # check there is only one possible type for the assign node. Else we
    # don't handle it for now
    types: set[SuccessfulInferenceResult] = set()
    try:
        for var_type in node.infer():
            if isinstance(var_type, util.UninferableBase) or is_none(var_type):
                continue
            types.add(var_type)
            if len(types) &gt; 1:
                return None
    except astroid.InferenceError:
        return None
    return types.pop() if types else None


</t>
<t tx="ekr.20250131013600.780">def _merge_annotations(
    annotations: Iterable[nodes.NodeNG], comment_annotations: Iterable[nodes.NodeNG]
) -&gt; Iterable[nodes.NodeNG | None]:
    for ann, comment_ann in itertools.zip_longest(annotations, comment_annotations):
        if ann and not _is_ellipsis(ann):
            yield ann
        elif comment_ann and not _is_ellipsis(comment_ann):
            yield comment_ann
        else:
            yield None


</t>
<t tx="ekr.20250131013600.781">def _annotations_list(args_node: nodes.Arguments) -&gt; list[nodes.NodeNG]:
    """Get a merged list of annotations.

    The annotations can come from:

    * Real type annotations.
    * A type comment on the function.
    * A type common on the individual argument.

    :param args_node: The node to get the annotations for.
    :returns: The annotations.
    """
    plain_annotations = args_node.annotations or ()
    func_comment_annotations = args_node.parent.type_comment_args or ()
    comment_annotations = args_node.type_comment_posonlyargs
    comment_annotations += args_node.type_comment_args or []
    comment_annotations += args_node.type_comment_kwonlyargs
    return list(
        _merge_annotations(
            plain_annotations,
            _merge_annotations(func_comment_annotations, comment_annotations),
        )
    )


</t>
<t tx="ekr.20250131013600.782">def args_with_annotation(args_node: nodes.Arguments) -&gt; set[str]:
    result = set()
    annotations = _annotations_list(args_node)
    annotation_offset = 0

    if args_node.posonlyargs:
        posonlyargs_annotations = args_node.posonlyargs_annotations
        if not any(args_node.posonlyargs_annotations):
            num_args = len(args_node.posonlyargs)
            posonlyargs_annotations = annotations[
                annotation_offset : annotation_offset + num_args
            ]
            annotation_offset += num_args

        for arg, annotation in zip(args_node.posonlyargs, posonlyargs_annotations):
            if annotation:
                result.add(arg.name)

    if args_node.args:
        num_args = len(args_node.args)
        for arg, annotation in zip(
            args_node.args,
            annotations[annotation_offset : annotation_offset + num_args],
        ):
            if annotation:
                result.add(arg.name)

        annotation_offset += num_args

    if args_node.vararg:
        if args_node.varargannotation:
            result.add(args_node.vararg)
        elif len(annotations) &gt; annotation_offset and annotations[annotation_offset]:
            result.add(args_node.vararg)
            annotation_offset += 1

    if args_node.kwonlyargs:
        kwonlyargs_annotations = args_node.kwonlyargs_annotations
        if not any(args_node.kwonlyargs_annotations):
            num_args = len(args_node.kwonlyargs)
            kwonlyargs_annotations = annotations[
                annotation_offset : annotation_offset + num_args
            ]
            annotation_offset += num_args

        for arg, annotation in zip(args_node.kwonlyargs, kwonlyargs_annotations):
            if annotation:
                result.add(arg.name)

    if args_node.kwarg:
        if args_node.kwargannotation:
            result.add(args_node.kwarg)
        elif len(annotations) &gt; annotation_offset and annotations[annotation_offset]:
            result.add(args_node.kwarg)
            annotation_offset += 1

    return result


</t>
<t tx="ekr.20250131013600.783">def docstringify(
    docstring: nodes.Const | None, default_type: str = "default"
) -&gt; Docstring:
    best_match = (0, DOCSTRING_TYPES.get(default_type, Docstring)(docstring))
    for docstring_type in (
        SphinxDocstring,
        EpytextDocstring,
        GoogleDocstring,
        NumpyDocstring,
    ):
        instance = docstring_type(docstring)
        matching_sections = instance.matching_sections()
        if matching_sections &gt; best_match[0]:
            best_match = (matching_sections, instance)

    return best_match[1]


</t>
<t tx="ekr.20250131013600.784">class Docstring:
    @others
</t>
<t tx="ekr.20250131013600.785">class SphinxDocstring(Docstring):
    @others
</t>
<t tx="ekr.20250131013600.786">class EpytextDocstring(SphinxDocstring):
    """Epytext is similar to Sphinx.

    See the docs:
        http://epydoc.sourceforge.net/epytext.html
        http://epydoc.sourceforge.net/fields.html#fields

    It's used in PyCharm:
        https://www.jetbrains.com/help/pycharm/2016.1/creating-documentation-comments.html#d848203e314
        https://www.jetbrains.com/help/pycharm/2016.1/using-docstrings-to-specify-types.html
    """

    @others
</t>
<t tx="ekr.20250131013600.787">class GoogleDocstring(Docstring):
    @others
</t>
<t tx="ekr.20250131013600.788">class NumpyDocstring(GoogleDocstring):
    @others
</t>
<t tx="ekr.20250131013600.789">re_for_parameters_see = re.compile(
    r"""
    For\s+the\s+(other)?\s*parameters\s*,\s+see
    """,
    re.X | re.S,
)

supports_yields: bool = False
"""True if the docstring supports a "yield" section.

False if the docstring uses the returns section to document generators.
"""

# These methods are designed to be overridden
def __init__(self, doc: nodes.Const | None) -&gt; None:
    docstring: str = doc.value if doc else ""
    self.doc = docstring.expandtabs()

</t>
<t tx="ekr.20250131013600.79">def is_registered_in_singledispatch_function(node: nodes.FunctionDef) -&gt; bool:
    """Check if the given function node is a singledispatch function."""
    singledispatch_qnames = (
        "functools.singledispatch",
        "singledispatch.singledispatch",
    )

    if not isinstance(node, nodes.FunctionDef):
        return False

    decorators = node.decorators.nodes if node.decorators else []
    for decorator in decorators:
        # func.register are function calls or register attributes
        # when the function is annotated with types
        if isinstance(decorator, nodes.Call):
            func = decorator.func
        elif isinstance(decorator, nodes.Attribute):
            func = decorator
        else:
            continue

        if not isinstance(func, nodes.Attribute) or func.attrname != "register":
            continue

        try:
            func_def = next(func.expr.infer())
        except astroid.InferenceError:
            continue

        if isinstance(func_def, nodes.FunctionDef):
            return decorated_with(func_def, singledispatch_qnames)

    return False


</t>
<t tx="ekr.20250131013600.790">def __repr__(self) -&gt; str:
    return f"&lt;{self.__class__.__name__}:'''{self.doc}'''&gt;"

</t>
<t tx="ekr.20250131013600.791">def matching_sections(self) -&gt; int:
    """Returns the number of matching docstring sections."""
    return 0

</t>
<t tx="ekr.20250131013600.792">def exceptions(self) -&gt; set[str]:
    return set()

</t>
<t tx="ekr.20250131013600.793">def has_params(self) -&gt; bool:
    return False

</t>
<t tx="ekr.20250131013600.794">def has_returns(self) -&gt; bool:
    return False

</t>
<t tx="ekr.20250131013600.795">def has_rtype(self) -&gt; bool:
    return False

</t>
<t tx="ekr.20250131013600.796">def has_property_returns(self) -&gt; bool:
    return False

</t>
<t tx="ekr.20250131013600.797">def has_property_type(self) -&gt; bool:
    return False

</t>
<t tx="ekr.20250131013600.798">def has_yields(self) -&gt; bool:
    return False

</t>
<t tx="ekr.20250131013600.799">def has_yields_type(self) -&gt; bool:
    return False

</t>
<t tx="ekr.20250131013600.8">def is_defined_in_scope(
    var_node: nodes.NodeNG,
    varname: str,
    scope: nodes.NodeNG,
) -&gt; bool:
    return defnode_in_scope(var_node, varname, scope) is not None


</t>
<t tx="ekr.20250131013600.80">def find_inferred_fn_from_register(node: nodes.NodeNG) -&gt; nodes.FunctionDef | None:
    # func.register are function calls or register attributes
    # when the function is annotated with types
    if isinstance(node, nodes.Call):
        func = node.func
    elif isinstance(node, nodes.Attribute):
        func = node
    else:
        return None

    if not isinstance(func, nodes.Attribute) or func.attrname != "register":
        return None

    func_def = safe_infer(func.expr)
    if not isinstance(func_def, nodes.FunctionDef):
        return None

    return func_def


</t>
<t tx="ekr.20250131013600.800">def match_param_docs(self) -&gt; tuple[set[str], set[str]]:
    return set(), set()

</t>
<t tx="ekr.20250131013600.801">def params_documented_elsewhere(self) -&gt; bool:
    return self.re_for_parameters_see.search(self.doc) is not None


</t>
<t tx="ekr.20250131013600.802">re_type = r"""
    [~!.]?               # Optional link style prefix
    \w(?:\w|\.[^\.])*    # Valid python name
    """

re_simple_container_type = rf"""
    {re_type}                     # a container type
    [\(\[] [^\n\s]+ [\)\]]        # with the contents of the container
"""

re_multiple_simple_type = rf"""
    (?:{re_simple_container_type}|{re_type})
    (?:(?:\s+(?:of|or)\s+|\s*,\s*|\s+\|\s+)(?:{re_simple_container_type}|{re_type}))*
"""

re_xref = rf"""
    (?::\w+:)?                    # optional tag
    `{re_type}`                   # what to reference
    """

re_param_raw = rf"""
    :                       # initial colon
    (?:                     # Sphinx keywords
    param|parameter|
    arg|argument|
    key|keyword
    )
    \s+                     # whitespace

    (?:                     # optional type declaration
    ({re_type}|{re_simple_container_type})
    \s+
    )?

    ((\\\*{{0,2}}\w+)|(\w+))  # Parameter name with potential asterisks
    \s*                       # whitespace
    :                         # final colon
    """
re_param_in_docstring = re.compile(re_param_raw, re.X | re.S)

re_type_raw = rf"""
    :type                           # Sphinx keyword
    \s+                             # whitespace
    ({re_multiple_simple_type})     # Parameter name
    \s*                             # whitespace
    :                               # final colon
    """
re_type_in_docstring = re.compile(re_type_raw, re.X | re.S)

re_property_type_raw = rf"""
    :type:                      # Sphinx keyword
    \s+                         # whitespace
    {re_multiple_simple_type}   # type declaration
    """
re_property_type_in_docstring = re.compile(re_property_type_raw, re.X | re.S)

re_raise_raw = rf"""
    :                               # initial colon
    (?:                             # Sphinx keyword
    raises?|
    except|exception
    )
    \s+                             # whitespace
    ({re_multiple_simple_type})     # exception type
    \s*                             # whitespace
    :                               # final colon
    """
re_raise_in_docstring = re.compile(re_raise_raw, re.X | re.S)

re_rtype_in_docstring = re.compile(r":rtype:")

re_returns_in_docstring = re.compile(r":returns?:")

supports_yields = False

def matching_sections(self) -&gt; int:
    """Returns the number of matching docstring sections."""
    return sum(
        bool(i)
        for i in (
            self.re_param_in_docstring.search(self.doc),
            self.re_raise_in_docstring.search(self.doc),
            self.re_rtype_in_docstring.search(self.doc),
            self.re_returns_in_docstring.search(self.doc),
            self.re_property_type_in_docstring.search(self.doc),
        )
    )

</t>
<t tx="ekr.20250131013600.803">def exceptions(self) -&gt; set[str]:
    types: set[str] = set()

    for match in re.finditer(self.re_raise_in_docstring, self.doc):
        raise_type = match.group(1)
        types.update(_split_multiple_exc_types(raise_type))

    return types

</t>
<t tx="ekr.20250131013600.804">def has_params(self) -&gt; bool:
    if not self.doc:
        return False

    return self.re_param_in_docstring.search(self.doc) is not None

</t>
<t tx="ekr.20250131013600.805">def has_returns(self) -&gt; bool:
    if not self.doc:
        return False

    return bool(self.re_returns_in_docstring.search(self.doc))

</t>
<t tx="ekr.20250131013600.806">def has_rtype(self) -&gt; bool:
    if not self.doc:
        return False

    return bool(self.re_rtype_in_docstring.search(self.doc))

</t>
<t tx="ekr.20250131013600.807">def has_property_returns(self) -&gt; bool:
    if not self.doc:
        return False

    # The summary line is the return doc,
    # so the first line must not be a known directive.
    return not self.doc.lstrip().startswith(":")

</t>
<t tx="ekr.20250131013600.808">def has_property_type(self) -&gt; bool:
    if not self.doc:
        return False

    return bool(self.re_property_type_in_docstring.search(self.doc))

</t>
<t tx="ekr.20250131013600.809">def match_param_docs(self) -&gt; tuple[set[str], set[str]]:
    params_with_doc = set()
    params_with_type = set()

    for match in re.finditer(self.re_param_in_docstring, self.doc):
        name = match.group(2)
        # Remove escape characters necessary for asterisks
        name = name.replace("\\", "")
        params_with_doc.add(name)
        param_type = match.group(1)
        if param_type is not None:
            params_with_type.add(name)

    params_with_type.update(re.findall(self.re_type_in_docstring, self.doc))
    return params_with_doc, params_with_type


</t>
<t tx="ekr.20250131013600.81">def is_registered_in_singledispatchmethod_function(node: nodes.FunctionDef) -&gt; bool:
    """Check if the given function node is a singledispatchmethod function."""
    singledispatchmethod_qnames = (
        "functools.singledispatchmethod",
        "singledispatch.singledispatchmethod",
    )

    decorators = node.decorators.nodes if node.decorators else []
    for decorator in decorators:
        func_def = find_inferred_fn_from_register(decorator)
        if func_def:
            return decorated_with(func_def, singledispatchmethod_qnames)

    return False


</t>
<t tx="ekr.20250131013600.810">re_param_in_docstring = re.compile(
    SphinxDocstring.re_param_raw.replace(":", "@", 1), re.X | re.S
)

re_type_in_docstring = re.compile(
    SphinxDocstring.re_type_raw.replace(":", "@", 1), re.X | re.S
)

re_property_type_in_docstring = re.compile(
    SphinxDocstring.re_property_type_raw.replace(":", "@", 1), re.X | re.S
)

re_raise_in_docstring = re.compile(
    SphinxDocstring.re_raise_raw.replace(":", "@", 1), re.X | re.S
)

re_rtype_in_docstring = re.compile(
    r"""
    @                       # initial "at" symbol
    (?:                     # Epytext keyword
    rtype|returntype
    )
    :                       # final colon
    """,
    re.X | re.S,
)

re_returns_in_docstring = re.compile(r"@returns?:")

def has_property_returns(self) -&gt; bool:
    if not self.doc:
        return False

    # If this is a property docstring, the summary is the return doc.
    if self.has_property_type():
        # The summary line is the return doc,
        # so the first line must not be a known directive.
        return not self.doc.lstrip().startswith("@")

    return False


</t>
<t tx="ekr.20250131013600.811">re_type = SphinxDocstring.re_type

re_xref = SphinxDocstring.re_xref

re_container_type = rf"""
    (?:{re_type}|{re_xref})       # a container type
    [\(\[] [^\n]+ [\)\]]          # with the contents of the container
"""

re_multiple_type = rf"""
    (?:{re_container_type}|{re_type}|{re_xref})
    (?:(?:\s+(?:of|or)\s+|\s*,\s*|\s+\|\s+)(?:{re_container_type}|{re_type}|{re_xref}))*
"""

_re_section_template = r"""
    ^([ ]*)   {0} \s*:   \s*$     # Google parameter header
    (  .* )                       # section
    """

re_param_section = re.compile(
    _re_section_template.format(r"(?:Args|Arguments|Parameters)"),
    re.X | re.S | re.M,
)

re_keyword_param_section = re.compile(
    _re_section_template.format(r"Keyword\s(?:Args|Arguments|Parameters)"),
    re.X | re.S | re.M,
)

re_param_line = re.compile(
    rf"""
    \s*  ((?:\\?\*{{0,2}})?[\w\\]+) # identifier potentially with asterisks or escaped `\`
    \s*  ( [(]
        {re_multiple_type}
        (?:,\s+optional)?
        [)] )? \s* :                # optional type declaration
    \s*  (.*)                       # beginning of optional description
""",
    re.X | re.S | re.M,
)

re_raise_section = re.compile(
    _re_section_template.format(r"Raises"), re.X | re.S | re.M
)

re_raise_line = re.compile(
    rf"""
    \s*  ({re_multiple_type}) \s* :  # identifier
    \s*  (.*)                        # beginning of optional description
""",
    re.X | re.S | re.M,
)

re_returns_section = re.compile(
    _re_section_template.format(r"Returns?"), re.X | re.S | re.M
)

re_returns_line = re.compile(
    rf"""
    \s* ({re_multiple_type}:)?        # identifier
    \s* (.*)                          # beginning of description
""",
    re.X | re.S | re.M,
)

re_property_returns_line = re.compile(
    rf"""
    ^{re_multiple_type}:           # identifier
    \s* (.*)                       # Summary line / description
""",
    re.X | re.S | re.M,
)

re_yields_section = re.compile(
    _re_section_template.format(r"Yields?"), re.X | re.S | re.M
)

re_yields_line = re_returns_line

supports_yields = True

def matching_sections(self) -&gt; int:
    """Returns the number of matching docstring sections."""
    return sum(
        bool(i)
        for i in (
            self.re_param_section.search(self.doc),
            self.re_raise_section.search(self.doc),
            self.re_returns_section.search(self.doc),
            self.re_yields_section.search(self.doc),
            self.re_property_returns_line.search(self._first_line()),
        )
    )

</t>
<t tx="ekr.20250131013600.812">def has_params(self) -&gt; bool:
    if not self.doc:
        return False

    return self.re_param_section.search(self.doc) is not None

</t>
<t tx="ekr.20250131013600.813">def has_returns(self) -&gt; bool:
    if not self.doc:
        return False

    entries = self._parse_section(self.re_returns_section)
    for entry in entries:
        match = self.re_returns_line.match(entry)
        if not match:
            continue

        return_desc = match.group(2)
        if return_desc:
            return True

    return False

</t>
<t tx="ekr.20250131013600.814">def has_rtype(self) -&gt; bool:
    if not self.doc:
        return False

    entries = self._parse_section(self.re_returns_section)
    for entry in entries:
        match = self.re_returns_line.match(entry)
        if not match:
            continue

        return_type = match.group(1)
        if return_type:
            return True

    return False

</t>
<t tx="ekr.20250131013600.815">def has_property_returns(self) -&gt; bool:
    # The summary line is the return doc,
    # so the first line must not be a known directive.
    first_line = self._first_line()
    return not bool(
        self.re_param_section.search(first_line)
        or self.re_raise_section.search(first_line)
        or self.re_returns_section.search(first_line)
        or self.re_yields_section.search(first_line)
    )

</t>
<t tx="ekr.20250131013600.816">def has_property_type(self) -&gt; bool:
    if not self.doc:
        return False

    return bool(self.re_property_returns_line.match(self._first_line()))

</t>
<t tx="ekr.20250131013600.817">def has_yields(self) -&gt; bool:
    if not self.doc:
        return False

    entries = self._parse_section(self.re_yields_section)
    for entry in entries:
        match = self.re_yields_line.match(entry)
        if not match:
            continue

        yield_desc = match.group(2)
        if yield_desc:
            return True

    return False

</t>
<t tx="ekr.20250131013600.818">def has_yields_type(self) -&gt; bool:
    if not self.doc:
        return False

    entries = self._parse_section(self.re_yields_section)
    for entry in entries:
        match = self.re_yields_line.match(entry)
        if not match:
            continue

        yield_type = match.group(1)
        if yield_type:
            return True

    return False

</t>
<t tx="ekr.20250131013600.819">def exceptions(self) -&gt; set[str]:
    types: set[str] = set()

    entries = self._parse_section(self.re_raise_section)
    for entry in entries:
        match = self.re_raise_line.match(entry)
        if not match:
            continue

        exc_type = match.group(1)
        exc_desc = match.group(2)
        if exc_desc:
            types.update(_split_multiple_exc_types(exc_type))

    return types

</t>
<t tx="ekr.20250131013600.82">def get_node_last_lineno(node: nodes.NodeNG) -&gt; int:
    """Get the last lineno of the given node.

    For a simple statement this will just be node.lineno,
    but for a node that has child statements (e.g. a method) this will be the lineno of the last
    child statement recursively.
    """
    # 'finalbody' is always the last clause in a try statement, if present
    if getattr(node, "finalbody", False):
        return get_node_last_lineno(node.finalbody[-1])
    # For if, while, and for statements 'orelse' is always the last clause.
    # For try statements 'orelse' is the last in the absence of a 'finalbody'
    if getattr(node, "orelse", False):
        return get_node_last_lineno(node.orelse[-1])
    # try statements have the 'handlers' last if there is no 'orelse' or 'finalbody'
    if getattr(node, "handlers", False):
        return get_node_last_lineno(node.handlers[-1])
    # All compound statements have a 'body'
    if getattr(node, "body", False):
        return get_node_last_lineno(node.body[-1])
    # Not a compound statement
    return node.lineno  # type: ignore[no-any-return]


</t>
<t tx="ekr.20250131013600.820">def match_param_docs(self) -&gt; tuple[set[str], set[str]]:
    params_with_doc: set[str] = set()
    params_with_type: set[str] = set()

    entries = self._parse_section(self.re_param_section)
    entries.extend(self._parse_section(self.re_keyword_param_section))
    for entry in entries:
        match = self.re_param_line.match(entry)
        if not match:
            continue

        param_name = match.group(1)
        # Remove escape characters necessary for asterisks
        param_name = param_name.replace("\\", "")

        param_type = match.group(2)
        param_desc = match.group(3)

        if param_type:
            params_with_type.add(param_name)

        if param_desc:
            params_with_doc.add(param_name)

    return params_with_doc, params_with_type

</t>
<t tx="ekr.20250131013600.821">def _first_line(self) -&gt; str:
    return self.doc.lstrip().split("\n", 1)[0]

</t>
<t tx="ekr.20250131013600.822">@staticmethod
def min_section_indent(section_match: re.Match[str]) -&gt; int:
    return len(section_match.group(1)) + 1

</t>
<t tx="ekr.20250131013600.823">@staticmethod
def _is_section_header(_: str) -&gt; bool:
    # Google parsing does not need to detect section headers,
    # because it works off of indentation level only
    return False

</t>
<t tx="ekr.20250131013600.824">def _parse_section(self, section_re: re.Pattern[str]) -&gt; list[str]:
    section_match = section_re.search(self.doc)
    if section_match is None:
        return []

    min_indentation = self.min_section_indent(section_match)

    entries: list[str] = []
    entry: list[str] = []
    is_first = True
    for line in section_match.group(2).splitlines():
        if not line.strip():
            continue
        indentation = space_indentation(line)
        if indentation &lt; min_indentation:
            break

        # The first line after the header defines the minimum
        # indentation.
        if is_first:
            min_indentation = indentation
            is_first = False

        if indentation == min_indentation:
            if self._is_section_header(line):
                break
            # Lines with minimum indentation must contain the beginning
            # of a new parameter documentation.
            if entry:
                entries.append("\n".join(entry))
                entry = []

        entry.append(line)

    if entry:
        entries.append("\n".join(entry))

    return entries


</t>
<t tx="ekr.20250131013600.825">_re_section_template = r"""
    ^([ ]*)   {0}   \s*?$          # Numpy parameters header
    \s*     [-=]+   \s*?$          # underline
    (  .* )                        # section
"""

re_param_section = re.compile(
    _re_section_template.format(r"(?:Args|Arguments|Parameters)"),
    re.X | re.S | re.M,
)

re_default_value = r"""((['"]\w+\s*['"])|(\d+)|(True)|(False)|(None))"""

re_param_line = re.compile(
    rf"""
    \s*  (?P&lt;param_name&gt;\*{{0,2}}\w+)(\s?(:|\n)) # identifier with potential asterisks
    \s*
    (?P&lt;param_type&gt;
     (
      ({GoogleDocstring.re_multiple_type})      # default type declaration
      (,\s+optional)?                           # optional 'optional' indication
     )?
     (
      {{({re_default_value},?\s*)+}}            # set of default values
     )?
     (?:$|\n)
    )?
    (
     \s* (?P&lt;param_desc&gt;.*)                     # optional description
    )?
""",
    re.X | re.S,
)

re_raise_section = re.compile(
    _re_section_template.format(r"Raises"), re.X | re.S | re.M
)

re_raise_line = re.compile(
    rf"""
    \s* ({GoogleDocstring.re_type})$   # type declaration
    \s* (.*)                           # optional description
""",
    re.X | re.S | re.M,
)

re_returns_section = re.compile(
    _re_section_template.format(r"Returns?"), re.X | re.S | re.M
)

re_returns_line = re.compile(
    rf"""
    \s* (?:\w+\s+:\s+)? # optional name
    ({GoogleDocstring.re_multiple_type})$   # type declaration
    \s* (.*)                                # optional description
""",
    re.X | re.S | re.M,
)

re_yields_section = re.compile(
    _re_section_template.format(r"Yields?"), re.X | re.S | re.M
)

re_yields_line = re_returns_line

supports_yields = True

def match_param_docs(self) -&gt; tuple[set[str], set[str]]:
    """Matches parameter documentation section to parameter documentation rules."""
    params_with_doc = set()
    params_with_type = set()

    entries = self._parse_section(self.re_param_section)
    entries.extend(self._parse_section(self.re_keyword_param_section))
    for entry in entries:
        match = self.re_param_line.match(entry)
        if not match:
            continue

        # check if parameter has description only
        re_only_desc = re.match(r"\s*(\*{0,2}\w+)\s*:?\n\s*\w*$", entry)
        if re_only_desc:
            param_name = match.group("param_name")
            param_desc = match.group("param_type")
            param_type = None
        else:
            param_name = match.group("param_name")
            param_type = match.group("param_type")
            param_desc = match.group("param_desc")
            # The re_param_line pattern needs to match multi-line which removes the ability
            # to match a single line description like 'arg : a number type.'
            # We are not trying to determine whether 'a number type' is correct typing
            # but we do accept it as typing as it is in the place where typing
            # should be
            if param_type is None and re.match(r"\s*(\*{0,2}\w+)\s*:.+$", entry):
                param_type = param_desc
            # If the description is "" but we have a type description
            # we consider the description to be the type
            if not param_desc and param_type:
                param_desc = param_type

        if param_type:
            params_with_type.add(param_name)

        if param_desc:
            params_with_doc.add(param_name)

    return params_with_doc, params_with_type

</t>
<t tx="ekr.20250131013600.826">@staticmethod
def min_section_indent(section_match: re.Match[str]) -&gt; int:
    return len(section_match.group(1))

</t>
<t tx="ekr.20250131013600.827">@staticmethod
def _is_section_header(line: str) -&gt; bool:
    return bool(re.match(r"\s*-+$", line))


</t>
<t tx="ekr.20250131013600.828">@path pylint/extensions
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Checker for deprecated builtins."""

from __future__ import annotations

from typing import TYPE_CHECKING

from astroid import nodes

from pylint.checkers import BaseChecker
from pylint.checkers.utils import only_required_for_messages

if TYPE_CHECKING:
    from pylint.lint import PyLinter

BAD_FUNCTIONS = ["map", "filter"]
# Some hints regarding the use of bad builtins.
LIST_COMP_MSG = "Using a list comprehension can be clearer."
BUILTIN_HINTS = {"map": LIST_COMP_MSG, "filter": LIST_COMP_MSG}


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.829">class BadBuiltinChecker(BaseChecker):
    @others
</t>
<t tx="ekr.20250131013600.83">def is_postponed_evaluation_enabled(node: nodes.NodeNG) -&gt; bool:
    """Check if the postponed evaluation of annotations is enabled."""
    module = node.root()
    return "annotations" in module.future_imports


</t>
<t tx="ekr.20250131013600.830">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(BadBuiltinChecker(linter))
</t>
<t tx="ekr.20250131013600.831">name = "deprecated_builtins"
msgs = {
    "W0141": (
        "Used builtin function %s",
        "bad-builtin",
        "Used when a disallowed builtin function is used (see the "
        "bad-function option). Usual disallowed functions are the ones "
        "like map, or filter , where Python offers now some cleaner "
        "alternative like list comprehension.",
    )
}

options = (
    (
        "bad-functions",
        {
            "default": BAD_FUNCTIONS,
            "type": "csv",
            "metavar": "&lt;builtin function names&gt;",
            "help": "List of builtins function names that should not be "
            "used, separated by a comma",
        },
    ),
)

@only_required_for_messages("bad-builtin")
def visit_call(self, node: nodes.Call) -&gt; None:
    if isinstance(node.func, nodes.Name):
        name = node.func.name
        # ignore the name if it's not a builtin (i.e. not defined in the
        # locals nor globals scope)
        if not (name in node.frame() or name in node.root()):
            if name in self.linter.config.bad_functions:
                hint = BUILTIN_HINTS.get(name)
                args = f"{name!r}. {hint}" if hint else repr(name)
                self.add_message("bad-builtin", node=node, args=args)


</t>
<t tx="ekr.20250131013600.832">@path pylint/extensions
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Looks for try/except statements with too much code in the try clause."""

from __future__ import annotations

from typing import TYPE_CHECKING

from astroid import nodes

from pylint import checkers

if TYPE_CHECKING:
    from pylint.lint import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.833">class BroadTryClauseChecker(checkers.BaseChecker):
    """Checks for try clauses with too many lines.

    According to PEP 8, ``try`` clauses shall contain the absolute minimum
    amount of code. This checker enforces a maximum number of statements within
    ``try`` clauses.
    """

    @others
</t>
<t tx="ekr.20250131013600.834">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(BroadTryClauseChecker(linter))
</t>
<t tx="ekr.20250131013600.835"># configuration section name
name = "broad_try_clause"
msgs = {
    "W0717": (
        "%s",
        "too-many-try-statements",
        "Try clause contains too many statements.",
    )
}

options = (
    (
        "max-try-statements",
        {
            "default": 1,
            "type": "int",
            "metavar": "&lt;int&gt;",
            "help": "Maximum number of statements allowed in a try clause",
        },
    ),
)

def _count_statements(
    self, node: nodes.For | nodes.If | nodes.Try | nodes.While | nodes.With
) -&gt; int:
    statement_count = len(node.body)

    for body_node in node.body:
        if isinstance(body_node, (nodes.For, nodes.If, nodes.While, nodes.With)):
            statement_count += self._count_statements(body_node)

    return statement_count

</t>
<t tx="ekr.20250131013600.836">def visit_try(self, node: nodes.Try) -&gt; None:
    try_clause_statements = self._count_statements(node)
    if try_clause_statements &gt; self.linter.config.max_try_statements:
        msg = (
            f"try clause contains {try_clause_statements} statements, expected at"
            f" most {self.linter.config.max_try_statements}"
        )
        self.add_message(
            "too-many-try-statements", node.lineno, node=node, args=msg
        )


</t>
<t tx="ekr.20250131013600.837">@path pylint/extensions
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import tokenize
from tokenize import TokenInfo
from typing import TYPE_CHECKING

from astroid import nodes

from pylint.checkers import BaseTokenChecker
from pylint.checkers.utils import only_required_for_messages
from pylint.interfaces import HIGH

if TYPE_CHECKING:
    from pylint.lint import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.838">class ElseifUsedChecker(BaseTokenChecker):
    """Checks for use of "else if" when an "elif" could be used."""

    @others
</t>
<t tx="ekr.20250131013600.839">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(ElseifUsedChecker(linter))
</t>
<t tx="ekr.20250131013600.84">def is_node_in_type_annotation_context(node: nodes.NodeNG) -&gt; bool:
    """Check if node is in type annotation context.

    Check for 'AnnAssign', function 'Arguments',
    or part of function return type annotation.
    """
    # pylint: disable=too-many-boolean-expressions
    current_node, parent_node = node, node.parent
    while True:
        if (
            (
                isinstance(parent_node, nodes.AnnAssign)
                and parent_node.annotation == current_node
            )
            or (
                isinstance(parent_node, nodes.Arguments)
                and current_node
                in (
                    * parent_node.annotations,
                    * parent_node.posonlyargs_annotations,
                    * parent_node.kwonlyargs_annotations,
                    parent_node.varargannotation,
                    parent_node.kwargannotation,
                )
            )
            or (
                isinstance(parent_node, nodes.FunctionDef)
                and parent_node.returns == current_node
            )
        ):
            return True
        current_node, parent_node = parent_node, parent_node.parent
        if isinstance(parent_node, nodes.Module):
            return False


</t>
<t tx="ekr.20250131013600.840">name = "else_if_used"
msgs = {
    "R5501": (
        'Consider using "elif" instead of "else" then "if" to remove one indentation level',
        "else-if-used",
        "Used when an else statement is immediately followed by "
        "an if statement and does not contain statements that "
        "would be unrelated to it.",
    )
}

def __init__(self, linter: PyLinter) -&gt; None:
    super().__init__(linter)
    self._init()

</t>
<t tx="ekr.20250131013600.841">def _init(self) -&gt; None:
    self._elifs: dict[tokenize._Position, str] = {}

</t>
<t tx="ekr.20250131013600.842">def process_tokens(self, tokens: list[TokenInfo]) -&gt; None:
    """Process tokens and look for 'if' or 'elif'."""
    self._elifs = {
        begin: token for _, token, begin, _, _ in tokens if token in {"elif", "if"}
    }

</t>
<t tx="ekr.20250131013600.843">def leave_module(self, _: nodes.Module) -&gt; None:
    self._init()

</t>
<t tx="ekr.20250131013600.844">@only_required_for_messages("else-if-used")
def visit_if(self, node: nodes.If) -&gt; None:
    """Current if node must directly follow an 'else'."""
    if (
        isinstance(node.parent, nodes.If)
        and node.parent.orelse == [node]
        and (node.lineno, node.col_offset) in self._elifs
        and self._elifs[(node.lineno, node.col_offset)] == "if"
    ):
        self.add_message("else-if-used", node=node, confidence=HIGH)


</t>
<t tx="ekr.20250131013600.845">@path pylint/extensions
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import sys
from typing import TYPE_CHECKING, cast

from astroid import nodes

from pylint.checkers import BaseChecker, utils
from pylint.checkers.utils import only_required_for_messages, safe_infer
from pylint.interfaces import INFERENCE

if TYPE_CHECKING:
    from pylint.lint import PyLinter

if sys.version_info &gt;= (3, 10):
    from typing import TypeGuard
else:
    from typing_extensions import TypeGuard


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.846">class CodeStyleChecker(BaseChecker):
    """Checkers that can improve code consistency.

    As such they don't necessarily provide a performance benefit and
    are often times opinionated.

    Before adding another checker here, consider this:
    1. Does the checker provide a clear benefit,
       i.e. detect a common issue or improve performance
       =&gt; it should probably be part of the core checker classes
    2. Is it something that would improve code consistency,
       maybe because it's slightly better with regard to performance
       and therefore preferred =&gt; this is the right place
    3. Everything else should go into another extension
    """

    @others
</t>
<t tx="ekr.20250131013600.847">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(CodeStyleChecker(linter))
</t>
<t tx="ekr.20250131013600.848">name = "code_style"
msgs = {
    "R6101": (
        "Consider using namedtuple or dataclass for dictionary values",
        "consider-using-namedtuple-or-dataclass",
        "Emitted when dictionary values can be replaced by namedtuples or dataclass instances.",
    ),
    "R6102": (
        "Consider using an in-place tuple instead of list",
        "consider-using-tuple",
        "Only for style consistency! "
        "Emitted where an in-place defined ``list`` can be replaced by a ``tuple``. "
        "Due to optimizations by CPython, there is no performance benefit from it.",
    ),
    "R6103": (
        "Use '%s' instead",
        "consider-using-assignment-expr",
        "Emitted when an if assignment is directly followed by an if statement and "
        "both can be combined by using an assignment expression ``:=``. "
        "Requires Python 3.8 and ``py-version &gt;= 3.8``.",
    ),
    "R6104": (
        "Use '%s' to do an augmented assign directly",
        "consider-using-augmented-assign",
        "Emitted when an assignment is referring to the object that it is assigning "
        "to. This can be changed to be an augmented assign.\n"
        "Disabled by default!",
        {
            "default_enabled": False,
        },
    ),
    "R6105": (
        "Prefer 'typing.NamedTuple' over 'collections.namedtuple'",
        "prefer-typing-namedtuple",
        "'typing.NamedTuple' uses the well-known 'class' keyword "
        "with type-hints for readability (it's also faster as it avoids "
        "an internal exec call).\n"
        "Disabled by default!",
        {
            "default_enabled": False,
        },
    ),
}
options = (
    (
        "max-line-length-suggestions",
        {
            "type": "int",
            "default": 0,
            "metavar": "&lt;int&gt;",
            "help": (
                "Max line length for which to sill emit suggestions. "
                "Used to prevent optional suggestions which would get split "
                "by a code formatter (e.g., black). "
                "Will default to the setting for ``max-line-length``."
            ),
        },
    ),
)

def open(self) -&gt; None:
    py_version = self.linter.config.py_version
    self._py36_plus = py_version &gt;= (3, 6)
    self._py38_plus = py_version &gt;= (3, 8)
    self._max_length: int = (
        self.linter.config.max_line_length_suggestions
        or self.linter.config.max_line_length
    )

</t>
<t tx="ekr.20250131013600.849">@only_required_for_messages("prefer-typing-namedtuple")
def visit_call(self, node: nodes.Call) -&gt; None:
    if self._py36_plus:
        called = safe_infer(node.func)
        if called and called.qname() == "collections.namedtuple":
            self.add_message(
                "prefer-typing-namedtuple", node=node, confidence=INFERENCE
            )

</t>
<t tx="ekr.20250131013600.85">def is_subclass_of(child: nodes.ClassDef, parent: nodes.ClassDef) -&gt; bool:
    """Check if first node is a subclass of second node.

    :param child: Node to check for subclass.
    :param parent: Node to check for superclass.
    :returns: True if child is derived from parent. False otherwise.
    """
    if not all(isinstance(node, nodes.ClassDef) for node in (child, parent)):
        return False

    for ancestor in child.ancestors():
        try:
            if astroid.helpers.is_subtype(ancestor, parent):
                return True
        except astroid.exceptions._NonDeducibleTypeHierarchy:
            continue
    return False


</t>
<t tx="ekr.20250131013600.850">@only_required_for_messages("consider-using-namedtuple-or-dataclass")
def visit_dict(self, node: nodes.Dict) -&gt; None:
    self._check_dict_consider_namedtuple_dataclass(node)

</t>
<t tx="ekr.20250131013600.851">@only_required_for_messages("consider-using-tuple")
def visit_for(self, node: nodes.For) -&gt; None:
    if isinstance(node.iter, nodes.List):
        self.add_message("consider-using-tuple", node=node.iter)

</t>
<t tx="ekr.20250131013600.852">@only_required_for_messages("consider-using-tuple")
def visit_comprehension(self, node: nodes.Comprehension) -&gt; None:
    if isinstance(node.iter, nodes.List):
        self.add_message("consider-using-tuple", node=node.iter)

</t>
<t tx="ekr.20250131013600.853">@only_required_for_messages("consider-using-assignment-expr")
def visit_if(self, node: nodes.If) -&gt; None:
    if self._py38_plus:
        self._check_consider_using_assignment_expr(node)

</t>
<t tx="ekr.20250131013600.854">def _check_dict_consider_namedtuple_dataclass(self, node: nodes.Dict) -&gt; None:
    """Check if dictionary values can be replaced by Namedtuple or Dataclass."""
    if not (
        (
            isinstance(node.parent, (nodes.Assign, nodes.AnnAssign))
            and isinstance(node.parent.parent, nodes.Module)
        )
        or (
            isinstance(node.parent, nodes.AnnAssign)
            and isinstance(node.parent.target, nodes.AssignName)
            and utils.is_assign_name_annotated_with(node.parent.target, "Final")
        )
    ):
        # If dict is not part of an 'Assign' or 'AnnAssign' node in
        # a module context OR 'AnnAssign' with 'Final' annotation, skip check.
        return

    # All dict_values are itself dict nodes
    if len(node.items) &gt; 1 and all(
        isinstance(dict_value, nodes.Dict) for _, dict_value in node.items
    ):
        KeyTupleT = tuple[type[nodes.NodeNG], str]

        # Makes sure all keys are 'Const' string nodes
        keys_checked: set[KeyTupleT] = set()
        for _, dict_value in node.items:
            dict_value = cast(nodes.Dict, dict_value)
            for key, _ in dict_value.items:
                key_tuple = (type(key), key.as_string())
                if key_tuple in keys_checked:
                    continue
                inferred = safe_infer(key)
                if not (
                    isinstance(inferred, nodes.Const)
                    and inferred.pytype() == "builtins.str"
                ):
                    return
                keys_checked.add(key_tuple)

        # Makes sure all subdicts have at least 1 common key
        key_tuples: list[tuple[KeyTupleT, ...]] = []
        for _, dict_value in node.items:
            dict_value = cast(nodes.Dict, dict_value)
            key_tuples.append(
                tuple((type(key), key.as_string()) for key, _ in dict_value.items)
            )
        keys_intersection: set[KeyTupleT] = set(key_tuples[0])
        for sub_key_tuples in key_tuples[1:]:
            keys_intersection.intersection_update(sub_key_tuples)
        if not keys_intersection:
            return

        self.add_message("consider-using-namedtuple-or-dataclass", node=node)
        return

    # All dict_values are itself either list or tuple nodes
    if len(node.items) &gt; 1 and all(
        isinstance(dict_value, (nodes.List, nodes.Tuple))
        for _, dict_value in node.items
    ):
        # Make sure all sublists have the same length &gt; 0
        list_length = len(node.items[0][1].elts)
        if list_length == 0:
            return
        for _, dict_value in node.items[1:]:
            if len(dict_value.elts) != list_length:
                return

        # Make sure at least one list entry isn't a dict
        for _, dict_value in node.items:
            if all(isinstance(entry, nodes.Dict) for entry in dict_value.elts):
                return

        self.add_message("consider-using-namedtuple-or-dataclass", node=node)
        return

</t>
<t tx="ekr.20250131013600.855">def _check_consider_using_assignment_expr(self, node: nodes.If) -&gt; None:
    """Check if an assignment expression (walrus operator) can be used.

    For example if an assignment is directly followed by an if statement:
    &gt;&gt;&gt; x = 2
    &gt;&gt;&gt; if x:
    &gt;&gt;&gt;     ...

    Can be replaced by:
    &gt;&gt;&gt; if (x := 2):
    &gt;&gt;&gt;     ...

    Note: Assignment expressions were added in Python 3.8
    """
    # Check if `node.test` contains a `Name` node
    node_name: nodes.Name | None = None
    if isinstance(node.test, nodes.Name):
        node_name = node.test
    elif (
        isinstance(node.test, nodes.UnaryOp)
        and node.test.op == "not"
        and isinstance(node.test.operand, nodes.Name)
    ):
        node_name = node.test.operand
    elif (
        isinstance(node.test, nodes.Compare)
        and isinstance(node.test.left, nodes.Name)
        and len(node.test.ops) == 1
    ):
        node_name = node.test.left
    else:
        return

    # Make sure the previous node is an assignment to the same name
    # used in `node.test`. Furthermore, ignore if assignment spans multiple lines.
    prev_sibling = node.previous_sibling()
    if CodeStyleChecker._check_prev_sibling_to_if_stmt(
        prev_sibling, node_name.name
    ):
        # Check if match statement would be a better fit.
        # I.e. multiple ifs that test the same name.
        if CodeStyleChecker._check_ignore_assignment_expr_suggestion(
            node, node_name.name
        ):
            return

        # Build suggestion string. Check length of suggestion
        # does not exceed max-line-length-suggestions
        test_str = node.test.as_string().replace(
            node_name.name,
            f"({node_name.name} := {prev_sibling.value.as_string()})",
            1,
        )
        suggestion = f"if {test_str}:"
        if (
            node.col_offset is not None
            and len(suggestion) + node.col_offset &gt; self._max_length
        ) or len(suggestion) &gt; self._max_length:
            return

        self.add_message(
            "consider-using-assignment-expr",
            node=node_name,
            args=(suggestion,),
        )

</t>
<t tx="ekr.20250131013600.856">@staticmethod
def _check_prev_sibling_to_if_stmt(
    prev_sibling: nodes.NodeNG | None, name: str | None
) -&gt; TypeGuard[nodes.Assign | nodes.AnnAssign]:
    """Check if previous sibling is an assignment with the same name.

    Ignore statements which span multiple lines.
    """
    if prev_sibling is None or prev_sibling.tolineno - prev_sibling.fromlineno != 0:
        return False

    if (
        isinstance(prev_sibling, nodes.Assign)
        and len(prev_sibling.targets) == 1
        and isinstance(prev_sibling.targets[0], nodes.AssignName)
        and prev_sibling.targets[0].name == name
    ):
        return True
    if (
        isinstance(prev_sibling, nodes.AnnAssign)
        and isinstance(prev_sibling.target, nodes.AssignName)
        and prev_sibling.target.name == name
    ):
        return True
    return False

</t>
<t tx="ekr.20250131013600.857">@staticmethod
def _check_ignore_assignment_expr_suggestion(
    node: nodes.If, name: str | None
) -&gt; bool:
    """Return True if suggestion for assignment expr should be ignored.

    E.g., in cases where a match statement would be a better fit
    (multiple conditions).
    """
    if isinstance(node.test, nodes.Compare):
        next_if_node: nodes.If | None = None
        next_sibling = node.next_sibling()
        if len(node.orelse) == 1 and isinstance(node.orelse[0], nodes.If):
            # elif block
            next_if_node = node.orelse[0]
        elif isinstance(next_sibling, nodes.If):
            # separate if block
            next_if_node = next_sibling

        if (  # pylint: disable=too-many-boolean-expressions
            next_if_node is not None
            and (
                (
                    isinstance(next_if_node.test, nodes.Compare)
                    and isinstance(next_if_node.test.left, nodes.Name)
                    and next_if_node.test.left.name == name
                )
                or (
                    isinstance(next_if_node.test, nodes.Name)
                    and next_if_node.test.name == name
                )
            )
        ):
            return True
    return False

</t>
<t tx="ekr.20250131013600.858">@only_required_for_messages("consider-using-augmented-assign")
def visit_assign(self, node: nodes.Assign) -&gt; None:
    is_aug, op = utils.is_augmented_assign(node)
    if is_aug:
        self.add_message(
            "consider-using-augmented-assign",
            args=f"{op}=",
            node=node,
            line=node.lineno,
            col_offset=node.col_offset,
            confidence=INFERENCE,
        )


</t>
<t tx="ekr.20250131013600.859">@path pylint/extensions
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Checks for yoda comparisons (variable before constant)
See https://en.wikipedia.org/wiki/Yoda_conditions.
"""

from __future__ import annotations

from typing import TYPE_CHECKING

from astroid import nodes

from pylint.checkers import BaseChecker, utils

if TYPE_CHECKING:
    from pylint.lint import PyLinter

REVERSED_COMPS = {"&lt;": "&gt;", "&lt;=": "&gt;=", "&gt;": "&lt;", "&gt;=": "&lt;="}
COMPARISON_OPERATORS = frozenset(("==", "!=", "&lt;", "&gt;", "&lt;=", "&gt;="))


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.86">@lru_cache(maxsize=1024)
def is_overload_stub(node: nodes.NodeNG) -&gt; bool:
    """Check if a node is a function stub decorated with typing.overload.

    :param node: Node to check.
    :returns: True if node is an overload function stub. False otherwise.
    """
    decorators = getattr(node, "decorators", None)
    return bool(decorators and decorated_with(node, ["typing.overload", "overload"]))


</t>
<t tx="ekr.20250131013600.860">class MisplacedComparisonConstantChecker(BaseChecker):
    """Checks the placement of constants in comparisons."""

    @others
</t>
<t tx="ekr.20250131013600.861">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(MisplacedComparisonConstantChecker(linter))
</t>
<t tx="ekr.20250131013600.862"># configuration section name
name = "comparison-placement"
msgs = {
    "C2201": (
        "Comparison should be %s",
        "misplaced-comparison-constant",
        "Used when the constant is placed on the left side "
        "of a comparison. It is usually clearer in intent to "
        "place it in the right hand side of the comparison.",
        {"old_names": [("C0122", "old-misplaced-comparison-constant")]},
    )
}

options = ()

def _check_misplaced_constant(
    self,
    node: nodes.Compare,
    left: nodes.NodeNG,
    right: nodes.NodeNG,
    operator: str,
) -&gt; None:
    if isinstance(right, nodes.Const):
        return
    operator = REVERSED_COMPS.get(operator, operator)
    suggestion = f"{right.as_string()} {operator} {left.value!r}"
    self.add_message("misplaced-comparison-constant", node=node, args=(suggestion,))

</t>
<t tx="ekr.20250131013600.863">@utils.only_required_for_messages("misplaced-comparison-constant")
def visit_compare(self, node: nodes.Compare) -&gt; None:
    # NOTE: this checker only works with binary comparisons like 'x == 42'
    # but not 'x == y == 42'
    if len(node.ops) != 1:
        return

    left = node.left
    operator, right = node.ops[0]
    if operator in COMPARISON_OPERATORS and isinstance(left, nodes.Const):
        self._check_misplaced_constant(node, left, right, operator)


</t>
<t tx="ekr.20250131013600.864">@path pylint/extensions
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

from typing import TYPE_CHECKING

from astroid import nodes

from pylint.checkers import BaseChecker
from pylint.checkers.utils import only_required_for_messages

if TYPE_CHECKING:
    from pylint.lint import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.865">class ConfusingConsecutiveElifChecker(BaseChecker):
    """Checks if "elif" is used right after an indented block that finishes with "if" or
    "elif" itself.
    """

    @others
</t>
<t tx="ekr.20250131013600.866">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(ConfusingConsecutiveElifChecker(linter))
</t>
<t tx="ekr.20250131013600.867">name = "confusing_elif"
msgs = {
    "R5601": (
        "Consecutive elif with differing indentation level, consider creating a function to separate the inner"
        " elif",
        "confusing-consecutive-elif",
        "Used when an elif statement follows right after an indented block which itself ends with if or elif. "
        "It may not be obvious if the elif statement was willingly or mistakenly unindented. "
        "Extracting the indented if statement into a separate function might avoid confusion and prevent "
        "errors.",
    )
}

@only_required_for_messages("confusing-consecutive-elif")
def visit_if(self, node: nodes.If) -&gt; None:
    body_ends_with_if = isinstance(
        node.body[-1], nodes.If
    ) and self._has_no_else_clause(node.body[-1])
    if node.has_elif_block() and body_ends_with_if:
        self.add_message("confusing-consecutive-elif", node=node.orelse[0])

</t>
<t tx="ekr.20250131013600.868">@staticmethod
def _has_no_else_clause(node: nodes.If) -&gt; bool:
    orelse = node.orelse
    while orelse and isinstance(orelse[0], nodes.If):
        orelse = orelse[0].orelse
    if not orelse or isinstance(orelse[0], nodes.If):
        return True
    return False


</t>
<t tx="ekr.20250131013600.869">@path pylint/extensions
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Looks for try/except statements with too much code in the try clause."""

from __future__ import annotations

from typing import TYPE_CHECKING

from astroid import nodes

from pylint import checkers
from pylint.checkers import utils
from pylint.interfaces import HIGH

if TYPE_CHECKING:
    from pylint.lint import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.87">def is_protocol_class(cls: nodes.NodeNG) -&gt; bool:
    """Check if the given node represents a protocol class.

    :param cls: The node to check
    :returns: True if the node is or inherits from typing.Protocol directly, false otherwise.
    """
    if not isinstance(cls, nodes.ClassDef):
        return False

    # Return if klass is protocol
    if cls.qname() in TYPING_PROTOCOLS:
        return True

    for base in cls.bases:
        try:
            for inf_base in base.infer():
                if inf_base.qname() in TYPING_PROTOCOLS:
                    return True
        except astroid.InferenceError:
            continue
    return False


</t>
<t tx="ekr.20250131013600.870">class ConsiderRefactorIntoWhileConditionChecker(checkers.BaseChecker):
    """Checks for instances where while loops are implemented with a constant condition
    which.

    always evaluates to truthy and the first statement(s) is/are if statements which, when
    evaluated.

    to True, breaks out of the loop.

    The if statement(s) can be refactored into the while loop.
    """

    @others
</t>
<t tx="ekr.20250131013600.871">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(ConsiderRefactorIntoWhileConditionChecker(linter))
</t>
<t tx="ekr.20250131013600.872">name = "consider_refactoring_into_while"
msgs = {
    "R3501": (
        "Consider using 'while %s' instead of 'while %s:' an 'if', and a 'break'",
        "consider-refactoring-into-while-condition",
        "Emitted when `while True:` loop is used and the first statement is a break condition. "
        "The ``if / break`` construct can be removed if the check is inverted and moved to "
        "the ``while`` statement.",
    ),
}

@utils.only_required_for_messages("consider-refactoring-into-while-condition")
def visit_while(self, node: nodes.While) -&gt; None:
    self._check_breaking_after_while_true(node)

</t>
<t tx="ekr.20250131013600.873">def _check_breaking_after_while_true(self, node: nodes.While) -&gt; None:
    """Check that any loop with an ``if`` clause has a break statement."""
    if not isinstance(node.test, nodes.Const) or not node.test.bool_value():
        return
    pri_candidates: list[nodes.If] = []
    for n in node.body:
        if not isinstance(n, nodes.If):
            break
        pri_candidates.append(n)
    candidates = []
    tainted = False
    for c in pri_candidates:
        if tainted or not isinstance(c.body[0], nodes.Break):
            break
        candidates.append(c)
        orelse = c.orelse
        while orelse:
            orelse_node = orelse[0]
            if not isinstance(orelse_node, nodes.If):
                tainted = True
            else:
                candidates.append(orelse_node)
            if not isinstance(orelse_node, nodes.If):
                break
            orelse = orelse_node.orelse

    candidates = [n for n in candidates if isinstance(n.body[0], nodes.Break)]
    msg = " and ".join(
        [f"({utils.not_condition_as_string(c.test)})" for c in candidates]
    )
    if len(candidates) == 1:
        msg = utils.not_condition_as_string(candidates[0].test)
    if not msg:
        return

    self.add_message(
        "consider-refactoring-into-while-condition",
        node=node,
        line=node.lineno,
        args=(msg, node.test.as_string()),
        confidence=HIGH,
    )


</t>
<t tx="ekr.20250131013600.874">@path pylint/extensions
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Check for if / assign blocks that can be rewritten with if-expressions."""

from __future__ import annotations

from typing import TYPE_CHECKING

from astroid import nodes

from pylint.checkers import BaseChecker

if TYPE_CHECKING:
    from pylint.lint import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.875">class ConsiderTernaryExpressionChecker(BaseChecker):
    @others
</t>
<t tx="ekr.20250131013600.876">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(ConsiderTernaryExpressionChecker(linter))
</t>
<t tx="ekr.20250131013600.877">name = "consider_ternary_expression"
msgs = {
    "W0160": (
        "Consider rewriting as a ternary expression",
        "consider-ternary-expression",
        "Multiple assign statements spread across if/else blocks can be "
        "rewritten with a single assignment and ternary expression",
    )
}

def visit_if(self, node: nodes.If) -&gt; None:
    if isinstance(node.parent, nodes.If):
        return

    if len(node.body) != 1 or len(node.orelse) != 1:
        return

    bst = node.body[0]
    ost = node.orelse[0]

    if not isinstance(bst, nodes.Assign) or not isinstance(ost, nodes.Assign):
        return

    for bname, oname in zip(bst.targets, ost.targets):
        if not isinstance(bname, nodes.AssignName) or not isinstance(
            oname, nodes.AssignName
        ):
            return

        if bname.name != oname.name:
            return

    self.add_message("consider-ternary-expression", node=node)


</t>
<t tx="ekr.20250131013600.878">@path pylint/extensions
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Check for use of dictionary mutation after initialization."""
from __future__ import annotations

from typing import TYPE_CHECKING

from astroid import nodes

from pylint.checkers import BaseChecker
from pylint.checkers.utils import only_required_for_messages
from pylint.interfaces import HIGH

if TYPE_CHECKING:
    from pylint.lint.pylinter import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.879">class DictInitMutateChecker(BaseChecker):
    @others
</t>
<t tx="ekr.20250131013600.88">def is_call_of_name(node: nodes.NodeNG, name: str) -&gt; bool:
    """Checks if node is a function call with the given name."""
    return (
        isinstance(node, nodes.Call)
        and isinstance(node.func, nodes.Name)
        and node.func.name == name
    )


</t>
<t tx="ekr.20250131013600.880">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(DictInitMutateChecker(linter))
</t>
<t tx="ekr.20250131013600.881">name = "dict-init-mutate"
msgs = {
    "C3401": (
        "Declare all known key/values when initializing the dictionary.",
        "dict-init-mutate",
        "Dictionaries can be initialized with a single statement "
        "using dictionary literal syntax.",
    )
}

@only_required_for_messages("dict-init-mutate")
def visit_assign(self, node: nodes.Assign) -&gt; None:
    """
    Detect dictionary mutation immediately after initialization.

    At this time, detecting nested mutation is not supported.
    """
    if not isinstance(node.value, nodes.Dict):
        return

    dict_name = node.targets[0]
    if len(node.targets) != 1 or not isinstance(dict_name, nodes.AssignName):
        return

    first_sibling = node.next_sibling()
    if (
        not first_sibling
        or not isinstance(first_sibling, nodes.Assign)
        or len(first_sibling.targets) != 1
    ):
        return

    sibling_target = first_sibling.targets[0]
    if not isinstance(sibling_target, nodes.Subscript):
        return

    sibling_name = sibling_target.value
    if not isinstance(sibling_name, nodes.Name):
        return

    if sibling_name.name == dict_name.name:
        self.add_message("dict-init-mutate", node=node, confidence=HIGH)


</t>
<t tx="ekr.20250131013600.882">@path pylint/extensions
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Pylint plugin for checking in Sphinx, Google, or Numpy style docstrings."""

from __future__ import annotations

import re
from typing import TYPE_CHECKING

import astroid
from astroid import nodes

from pylint.checkers import BaseChecker
from pylint.checkers import utils as checker_utils
from pylint.extensions import _check_docs_utils as utils
from pylint.extensions._check_docs_utils import Docstring
from pylint.interfaces import HIGH

if TYPE_CHECKING:
    from pylint.lint import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.883">class DocstringParameterChecker(BaseChecker):
    """Checker for Sphinx, Google, or Numpy style docstrings.

    * Check that all function, method and constructor parameters are mentioned
      in the params and types part of the docstring.  Constructor parameters
      can be documented in either the class docstring or ``__init__`` docstring,
      but not both.
    * Check that there are no naming inconsistencies between the signature and
      the documentation, i.e. also report documented parameters that are missing
      in the signature. This is important to find cases where parameters are
      renamed only in the code, not in the documentation.
    * Check that all explicitly raised exceptions in a function are documented
      in the function docstring. Caught exceptions are ignored.

    Activate this checker by adding the line::

        load-plugins=pylint.extensions.docparams

    to the ``MAIN`` section of your ``.pylintrc``.
    """

    @others
</t>
<t tx="ekr.20250131013600.884">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(DocstringParameterChecker(linter))
</t>
<t tx="ekr.20250131013600.885">name = "parameter_documentation"
msgs = {
    "W9005": (
        '"%s" has constructor parameters documented in class and __init__',
        "multiple-constructor-doc",
        "Please remove parameter declarations in the class or constructor.",
    ),
    "W9006": (
        '"%s" not documented as being raised',
        "missing-raises-doc",
        "Please document exceptions for all raised exception types.",
    ),
    "W9008": (
        "Redundant returns documentation",
        "redundant-returns-doc",
        "Please remove the return/rtype documentation from this method.",
    ),
    "W9010": (
        "Redundant yields documentation",
        "redundant-yields-doc",
        "Please remove the yields documentation from this method.",
    ),
    "W9011": (
        "Missing return documentation",
        "missing-return-doc",
        "Please add documentation about what this method returns.",
        {"old_names": [("W9007", "old-missing-returns-doc")]},
    ),
    "W9012": (
        "Missing return type documentation",
        "missing-return-type-doc",
        "Please document the type returned by this method.",
        # we can't use the same old_name for two different warnings
        # {'old_names': [('W9007', 'missing-returns-doc')]},
    ),
    "W9013": (
        "Missing yield documentation",
        "missing-yield-doc",
        "Please add documentation about what this generator yields.",
        {"old_names": [("W9009", "old-missing-yields-doc")]},
    ),
    "W9014": (
        "Missing yield type documentation",
        "missing-yield-type-doc",
        "Please document the type yielded by this method.",
        # we can't use the same old_name for two different warnings
        # {'old_names': [('W9009', 'missing-yields-doc')]},
    ),
    "W9015": (
        '"%s" missing in parameter documentation',
        "missing-param-doc",
        "Please add parameter declarations for all parameters.",
        {"old_names": [("W9003", "old-missing-param-doc")]},
    ),
    "W9016": (
        '"%s" missing in parameter type documentation',
        "missing-type-doc",
        "Please add parameter type declarations for all parameters.",
        {"old_names": [("W9004", "old-missing-type-doc")]},
    ),
    "W9017": (
        '"%s" differing in parameter documentation',
        "differing-param-doc",
        "Please check parameter names in declarations.",
    ),
    "W9018": (
        '"%s" differing in parameter type documentation',
        "differing-type-doc",
        "Please check parameter names in type declarations.",
    ),
    "W9019": (
        '"%s" useless ignored parameter documentation',
        "useless-param-doc",
        "Please remove the ignored parameter documentation.",
    ),
    "W9020": (
        '"%s" useless ignored parameter type documentation',
        "useless-type-doc",
        "Please remove the ignored parameter type documentation.",
    ),
    "W9021": (
        'Missing any documentation in "%s"',
        "missing-any-param-doc",
        "Please add parameter and/or type documentation.",
    ),
}

options = (
    (
        "accept-no-param-doc",
        {
            "default": True,
            "type": "yn",
            "metavar": "&lt;y or n&gt;",
            "help": "Whether to accept totally missing parameter "
            "documentation in the docstring of a function that has "
            "parameters.",
        },
    ),
    (
        "accept-no-raise-doc",
        {
            "default": True,
            "type": "yn",
            "metavar": "&lt;y or n&gt;",
            "help": "Whether to accept totally missing raises "
            "documentation in the docstring of a function that "
            "raises an exception.",
        },
    ),
    (
        "accept-no-return-doc",
        {
            "default": True,
            "type": "yn",
            "metavar": "&lt;y or n&gt;",
            "help": "Whether to accept totally missing return "
            "documentation in the docstring of a function that "
            "returns a statement.",
        },
    ),
    (
        "accept-no-yields-doc",
        {
            "default": True,
            "type": "yn",
            "metavar": "&lt;y or n&gt;",
            "help": "Whether to accept totally missing yields "
            "documentation in the docstring of a generator.",
        },
    ),
    (
        "default-docstring-type",
        {
            "type": "choice",
            "default": "default",
            "metavar": "&lt;docstring type&gt;",
            "choices": list(utils.DOCSTRING_TYPES),
            "help": "If the docstring type cannot be guessed "
            "the specified docstring type will be used.",
        },
    ),
)

constructor_names = {"__init__", "__new__"}
not_needed_param_in_docstring = {"self", "cls"}

def visit_functiondef(self, node: nodes.FunctionDef) -&gt; None:
    """Called for function and method definitions (def).

    :param node: Node for a function or method definition in the AST
    :type node: :class:`astroid.scoped_nodes.Function`
    """
    if checker_utils.is_overload_stub(node):
        return

    node_doc = utils.docstringify(
        node.doc_node, self.linter.config.default_docstring_type
    )

    # skip functions that match the 'no-docstring-rgx' config option
    no_docstring_rgx = self.linter.config.no_docstring_rgx
    if no_docstring_rgx and re.match(no_docstring_rgx, node.name):
        return

    # skip functions smaller than 'docstring-min-length'
    lines = checker_utils.get_node_last_lineno(node) - node.lineno
    max_lines = self.linter.config.docstring_min_length
    if max_lines &gt; -1 and lines &lt; max_lines:
        return

    self.check_functiondef_params(node, node_doc)
    self.check_functiondef_returns(node, node_doc)
    self.check_functiondef_yields(node, node_doc)

</t>
<t tx="ekr.20250131013600.886">visit_asyncfunctiondef = visit_functiondef

def check_functiondef_params(
    self, node: nodes.FunctionDef, node_doc: Docstring
) -&gt; None:
    node_allow_no_param = None
    if node.name in self.constructor_names:
        class_node = checker_utils.node_frame_class(node)
        if class_node is not None:
            class_doc = utils.docstringify(
                class_node.doc_node, self.linter.config.default_docstring_type
            )
            self.check_single_constructor_params(class_doc, node_doc, class_node)

            # __init__ or class docstrings can have no parameters documented
            # as long as the other documents them.
            node_allow_no_param = (
                class_doc.has_params()
                or class_doc.params_documented_elsewhere()
                or None
            )
            class_allow_no_param = (
                node_doc.has_params()
                or node_doc.params_documented_elsewhere()
                or None
            )

            self.check_arguments_in_docstring(
                class_doc, node.args, class_node, class_allow_no_param
            )

    self.check_arguments_in_docstring(
        node_doc, node.args, node, node_allow_no_param
    )

</t>
<t tx="ekr.20250131013600.887">def check_functiondef_returns(
    self, node: nodes.FunctionDef, node_doc: Docstring
) -&gt; None:
    if (not node_doc.supports_yields and node.is_generator()) or node.is_abstract():
        return

    return_nodes = node.nodes_of_class(astroid.Return)
    if (node_doc.has_returns() or node_doc.has_rtype()) and not any(
        utils.returns_something(ret_node) for ret_node in return_nodes
    ):
        self.add_message("redundant-returns-doc", node=node, confidence=HIGH)

</t>
<t tx="ekr.20250131013600.888">def check_functiondef_yields(
    self, node: nodes.FunctionDef, node_doc: Docstring
) -&gt; None:
    if not node_doc.supports_yields or node.is_abstract():
        return

    if (
        node_doc.has_yields() or node_doc.has_yields_type()
    ) and not node.is_generator():
        self.add_message("redundant-yields-doc", node=node)

</t>
<t tx="ekr.20250131013600.889">def visit_raise(self, node: nodes.Raise) -&gt; None:
    func_node = node.frame()
    if not isinstance(func_node, astroid.FunctionDef):
        return

    # skip functions that match the 'no-docstring-rgx' config option
    no_docstring_rgx = self.linter.config.no_docstring_rgx
    if no_docstring_rgx and re.match(no_docstring_rgx, func_node.name):
        return

    expected_excs = utils.possible_exc_types(node)

    if not expected_excs:
        return

    if not func_node.doc_node:
        # If this is a property setter,
        # the property should have the docstring instead.
        property_ = utils.get_setters_property(func_node)
        if property_:
            func_node = property_

    doc = utils.docstringify(
        func_node.doc_node, self.linter.config.default_docstring_type
    )

    if self.linter.config.accept_no_raise_doc and not doc.exceptions():
        return

    if not doc.matching_sections():
        if doc.doc:
            missing = {exc.name for exc in expected_excs}
            self._add_raise_message(missing, func_node)
        return

    found_excs_full_names = doc.exceptions()

    # Extract just the class name, e.g. "error" from "re.error"
    found_excs_class_names = {exc.split(".")[-1] for exc in found_excs_full_names}

    missing_excs = set()
    for expected in expected_excs:
        for found_exc in found_excs_class_names:
            if found_exc == expected.name:
                break
            if found_exc == "error" and expected.name == "PatternError":
                # Python 3.13: re.error aliases re.PatternError
                break
            if any(found_exc == ancestor.name for ancestor in expected.ancestors()):
                break
        else:
            missing_excs.add(expected.name)

    self._add_raise_message(missing_excs, func_node)

</t>
<t tx="ekr.20250131013600.89">def is_test_condition(
    node: nodes.NodeNG,
    parent: nodes.NodeNG | None = None,
) -&gt; bool:
    """Returns true if the given node is being tested for truthiness."""
    parent = parent or node.parent
    if isinstance(parent, (nodes.While, nodes.If, nodes.IfExp, nodes.Assert)):
        return node is parent.test or parent.test.parent_of(node)
    if isinstance(parent, nodes.Comprehension):
        return node in parent.ifs
    return is_call_of_name(parent, "bool") and parent.parent_of(node)


</t>
<t tx="ekr.20250131013600.890">def visit_return(self, node: nodes.Return) -&gt; None:
    if not utils.returns_something(node):
        return

    if self.linter.config.accept_no_return_doc:
        return

    func_node: astroid.FunctionDef = node.frame()

    # skip functions that match the 'no-docstring-rgx' config option
    no_docstring_rgx = self.linter.config.no_docstring_rgx
    if no_docstring_rgx and re.match(no_docstring_rgx, func_node.name):
        return

    doc = utils.docstringify(
        func_node.doc_node, self.linter.config.default_docstring_type
    )

    is_property = checker_utils.decorated_with_property(func_node)

    if not (doc.has_returns() or (doc.has_property_returns() and is_property)):
        self.add_message("missing-return-doc", node=func_node, confidence=HIGH)

    if func_node.returns or func_node.type_comment_returns:
        return

    if not (doc.has_rtype() or (doc.has_property_type() and is_property)):
        self.add_message("missing-return-type-doc", node=func_node, confidence=HIGH)

</t>
<t tx="ekr.20250131013600.891">def visit_yield(self, node: nodes.Yield | nodes.YieldFrom) -&gt; None:
    if self.linter.config.accept_no_yields_doc:
        return

    func_node: astroid.FunctionDef = node.frame()

    # skip functions that match the 'no-docstring-rgx' config option
    no_docstring_rgx = self.linter.config.no_docstring_rgx
    if no_docstring_rgx and re.match(no_docstring_rgx, func_node.name):
        return

    doc = utils.docstringify(
        func_node.doc_node, self.linter.config.default_docstring_type
    )

    if doc.supports_yields:
        doc_has_yields = doc.has_yields()
        doc_has_yields_type = doc.has_yields_type()
    else:
        doc_has_yields = doc.has_returns()
        doc_has_yields_type = doc.has_rtype()

    if not doc_has_yields:
        self.add_message("missing-yield-doc", node=func_node, confidence=HIGH)

    if not (
        doc_has_yields_type or func_node.returns or func_node.type_comment_returns
    ):
        self.add_message("missing-yield-type-doc", node=func_node, confidence=HIGH)

</t>
<t tx="ekr.20250131013600.892">visit_yieldfrom = visit_yield

def _compare_missing_args(
    self,
    found_argument_names: set[str],
    message_id: str,
    not_needed_names: set[str],
    expected_argument_names: set[str],
    warning_node: nodes.NodeNG,
) -&gt; None:
    """Compare the found argument names with the expected ones and
    generate a message if there are arguments missing.

    :param found_argument_names: argument names found in the docstring

    :param message_id: pylint message id

    :param not_needed_names: names that may be omitted

    :param expected_argument_names: Expected argument names

    :param warning_node: The node to be analyzed
    """
    potential_missing_argument_names = (
        expected_argument_names - found_argument_names
    ) - not_needed_names

    # Handle variadic and keyword args without asterisks
    missing_argument_names = set()
    for name in potential_missing_argument_names:
        if name.replace("*", "") in found_argument_names:
            continue
        missing_argument_names.add(name)

    if missing_argument_names:
        self.add_message(
            message_id,
            args=(", ".join(sorted(missing_argument_names)),),
            node=warning_node,
            confidence=HIGH,
        )

</t>
<t tx="ekr.20250131013600.893">def _compare_different_args(
    self,
    found_argument_names: set[str],
    message_id: str,
    not_needed_names: set[str],
    expected_argument_names: set[str],
    warning_node: nodes.NodeNG,
) -&gt; None:
    """Compare the found argument names with the expected ones and
    generate a message if there are extra arguments found.

    :param found_argument_names: argument names found in the docstring

    :param message_id: pylint message id

    :param not_needed_names: names that may be omitted

    :param expected_argument_names: Expected argument names

    :param warning_node: The node to be analyzed
    """
    # Handle variadic and keyword args without asterisks
    modified_expected_argument_names: set[str] = set()
    for name in expected_argument_names:
        if name.replace("*", "") in found_argument_names:
            modified_expected_argument_names.add(name.replace("*", ""))
        else:
            modified_expected_argument_names.add(name)

    differing_argument_names = (
        (modified_expected_argument_names ^ found_argument_names)
        - not_needed_names
        - expected_argument_names
    )

    if differing_argument_names:
        self.add_message(
            message_id,
            args=(", ".join(sorted(differing_argument_names)),),
            node=warning_node,
            confidence=HIGH,
        )

</t>
<t tx="ekr.20250131013600.894">def _compare_ignored_args(  # pylint: disable=useless-param-doc
    self,
    found_argument_names: set[str],
    message_id: str,
    ignored_argument_names: set[str],
    warning_node: nodes.NodeNG,
) -&gt; None:
    """Compare the found argument names with the ignored ones and
    generate a message if there are ignored arguments found.

    :param found_argument_names: argument names found in the docstring
    :param message_id: pylint message id
    :param ignored_argument_names: Expected argument names
    :param warning_node: The node to be analyzed
    """
    existing_ignored_argument_names = ignored_argument_names &amp; found_argument_names

    if existing_ignored_argument_names:
        self.add_message(
            message_id,
            args=(", ".join(sorted(existing_ignored_argument_names)),),
            node=warning_node,
            confidence=HIGH,
        )

</t>
<t tx="ekr.20250131013600.895">def check_arguments_in_docstring(
    self,
    doc: Docstring,
    arguments_node: astroid.Arguments,
    warning_node: astroid.NodeNG,
    accept_no_param_doc: bool | None = None,
) -&gt; None:
    """Check that all parameters are consistent with the parameters mentioned
    in the parameter documentation (e.g. the Sphinx tags 'param' and 'type').

    * Undocumented parameters except 'self' are noticed.
    * Undocumented parameter types except for 'self' and the ``*&lt;args&gt;``
      and ``**&lt;kwargs&gt;`` parameters are noticed.
    * Parameters mentioned in the parameter documentation that don't or no
      longer exist in the function parameter list are noticed.
    * If the text "For the parameters, see" or "For the other parameters,
      see" (ignoring additional white-space) is mentioned in the docstring,
      missing parameter documentation is tolerated.
    * If there's no Sphinx style, Google style or NumPy style parameter
      documentation at all, i.e. ``:param`` is never mentioned etc., the
      checker assumes that the parameters are documented in another format
      and the absence is tolerated.

    :param doc: Docstring for the function, method or class.
    :type doc: :class:`Docstring`

    :param arguments_node: Arguments node for the function, method or
        class constructor.
    :type arguments_node: :class:`astroid.scoped_nodes.Arguments`

    :param warning_node: The node to assign the warnings to
    :type warning_node: :class:`astroid.scoped_nodes.Node`

    :param accept_no_param_doc: Whether to allow no parameters to be
        documented. If None then this value is read from the configuration.
    :type accept_no_param_doc: bool or None
    """
    # Tolerate missing param or type declarations if there is a link to
    # another method carrying the same name.
    if not doc.doc:
        return

    if accept_no_param_doc is None:
        accept_no_param_doc = self.linter.config.accept_no_param_doc
    tolerate_missing_params = doc.params_documented_elsewhere()

    # Collect the function arguments.
    expected_argument_names = {arg.name for arg in arguments_node.args}
    expected_argument_names.update(
        a.name for a in arguments_node.posonlyargs + arguments_node.kwonlyargs
    )
    not_needed_type_in_docstring = self.not_needed_param_in_docstring.copy()

    expected_but_ignored_argument_names = set()
    ignored_argument_names = self.linter.config.ignored_argument_names
    if ignored_argument_names:
        expected_but_ignored_argument_names = {
            arg
            for arg in expected_argument_names
            if ignored_argument_names.match(arg)
        }

    if arguments_node.vararg is not None:
        expected_argument_names.add(f"*{arguments_node.vararg}")
        not_needed_type_in_docstring.add(f"*{arguments_node.vararg}")
    if arguments_node.kwarg is not None:
        expected_argument_names.add(f"**{arguments_node.kwarg}")
        not_needed_type_in_docstring.add(f"**{arguments_node.kwarg}")
    params_with_doc, params_with_type = doc.match_param_docs()
    # Tolerate no parameter documentation at all.
    if not params_with_doc and not params_with_type and accept_no_param_doc:
        tolerate_missing_params = True

    # This is before the update of params_with_type because this must check only
    # the type documented in a docstring, not the one using pep484
    # See #4117 and #4593
    self._compare_ignored_args(
        params_with_type,
        "useless-type-doc",
        expected_but_ignored_argument_names,
        warning_node,
    )
    params_with_type |= utils.args_with_annotation(arguments_node)

    if not tolerate_missing_params:
        missing_param_doc = (expected_argument_names - params_with_doc) - (
            self.not_needed_param_in_docstring | expected_but_ignored_argument_names
        )
        missing_type_doc = (expected_argument_names - params_with_type) - (
            not_needed_type_in_docstring | expected_but_ignored_argument_names
        )
        if (
            missing_param_doc == expected_argument_names == missing_type_doc
            and len(expected_argument_names) != 0
        ):
            self.add_message(
                "missing-any-param-doc",
                args=(warning_node.name,),
                node=warning_node,
                confidence=HIGH,
            )
        else:
            self._compare_missing_args(
                params_with_doc,
                "missing-param-doc",
                self.not_needed_param_in_docstring
                | expected_but_ignored_argument_names,
                expected_argument_names,
                warning_node,
            )
            self._compare_missing_args(
                params_with_type,
                "missing-type-doc",
                not_needed_type_in_docstring | expected_but_ignored_argument_names,
                expected_argument_names,
                warning_node,
            )

    self._compare_different_args(
        params_with_doc,
        "differing-param-doc",
        self.not_needed_param_in_docstring,
        expected_argument_names,
        warning_node,
    )
    self._compare_different_args(
        params_with_type,
        "differing-type-doc",
        not_needed_type_in_docstring,
        expected_argument_names,
        warning_node,
    )
    self._compare_ignored_args(
        params_with_doc,
        "useless-param-doc",
        expected_but_ignored_argument_names,
        warning_node,
    )

</t>
<t tx="ekr.20250131013600.896">def check_single_constructor_params(
    self, class_doc: Docstring, init_doc: Docstring, class_node: nodes.ClassDef
) -&gt; None:
    if class_doc.has_params() and init_doc.has_params():
        self.add_message(
            "multiple-constructor-doc",
            args=(class_node.name,),
            node=class_node,
            confidence=HIGH,
        )

</t>
<t tx="ekr.20250131013600.897">def _add_raise_message(
    self, missing_exceptions: set[str], node: nodes.FunctionDef
) -&gt; None:
    """Adds a message on :param:`node` for the missing exception type.

    :param missing_exceptions: A list of missing exception types.
    :param node: The node to show the message on.
    """
    if node.is_abstract():
        try:
            missing_exceptions.remove("NotImplementedError")
        except KeyError:
            pass
    if missing_exceptions:
        self.add_message(
            "missing-raises-doc",
            args=(", ".join(sorted(missing_exceptions)),),
            node=node,
            confidence=HIGH,
        )


</t>
<t tx="ekr.20250131013600.898">@path pylint/extensions
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import linecache
from typing import TYPE_CHECKING

from astroid import nodes

from pylint import checkers
from pylint.checkers.utils import only_required_for_messages
from pylint.interfaces import HIGH

if TYPE_CHECKING:
    from pylint.lint import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.899">class DocStringStyleChecker(checkers.BaseChecker):
    """Checks format of docstrings based on PEP 0257."""

    @others
</t>
<t tx="ekr.20250131013600.9"># pylint: disable = too-many-branches
def defnode_in_scope(
    var_node: nodes.NodeNG,
    varname: str,
    scope: nodes.NodeNG,
) -&gt; nodes.NodeNG | None:
    if isinstance(scope, nodes.If):
        for node in scope.body:
            if isinstance(node, nodes.Nonlocal) and varname in node.names:
                return node
            if isinstance(node, nodes.Assign):
                for target in node.targets:
                    if isinstance(target, nodes.AssignName) and target.name == varname:
                        return target
    elif isinstance(scope, (COMP_NODE_TYPES, nodes.For)):
        for ass_node in scope.nodes_of_class(nodes.AssignName):
            if ass_node.name == varname:
                return ass_node
    elif isinstance(scope, nodes.With):
        for expr, ids in scope.items:
            if expr.parent_of(var_node):
                break
            if ids and isinstance(ids, nodes.AssignName) and ids.name == varname:
                return ids
    elif isinstance(scope, (nodes.Lambda, nodes.FunctionDef)):
        if scope.args.is_argument(varname):
            # If the name is found inside a default value
            # of a function, then let the search continue
            # in the parent's tree.
            if scope.args.parent_of(var_node):
                try:
                    scope.args.default_value(varname)
                    scope = scope.parent
                    defnode = defnode_in_scope(var_node, varname, scope)
                except astroid.NoDefault:
                    pass
                else:
                    return defnode
            return scope
        if getattr(scope, "name", None) == varname:
            return scope
    elif isinstance(scope, nodes.ExceptHandler):
        if isinstance(scope.name, nodes.AssignName):
            ass_node = scope.name
            if ass_node.name == varname:
                return ass_node
    return None


</t>
<t tx="ekr.20250131013600.90">def is_classdef_type(node: nodes.ClassDef) -&gt; bool:
    """Test if ClassDef node is Type."""
    if node.name == "type":
        return True
    return any(isinstance(b, nodes.Name) and b.name == "type" for b in node.bases)


</t>
<t tx="ekr.20250131013600.900">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(DocStringStyleChecker(linter))
</t>
<t tx="ekr.20250131013600.901">name = "docstyle"

msgs = {
    "C0198": (
        'Bad docstring quotes in %s, expected """, given %s',
        "bad-docstring-quotes",
        "Used when a docstring does not have triple double quotes.",
    ),
    "C0199": (
        "First line empty in %s docstring",
        "docstring-first-line-empty",
        "Used when a blank line is found at the beginning of a docstring.",
    ),
}

@only_required_for_messages("docstring-first-line-empty", "bad-docstring-quotes")
def visit_module(self, node: nodes.Module) -&gt; None:
    self._check_docstring("module", node)

</t>
<t tx="ekr.20250131013600.902">def visit_classdef(self, node: nodes.ClassDef) -&gt; None:
    self._check_docstring("class", node)

</t>
<t tx="ekr.20250131013600.903">def visit_functiondef(self, node: nodes.FunctionDef) -&gt; None:
    ftype = "method" if node.is_method() else "function"
    self._check_docstring(ftype, node)

</t>
<t tx="ekr.20250131013600.904">visit_asyncfunctiondef = visit_functiondef

def _check_docstring(
    self, node_type: str, node: nodes.Module | nodes.ClassDef | nodes.FunctionDef
) -&gt; None:
    docstring = node.doc_node.value if node.doc_node else None
    if docstring and docstring[0] == "\n":
        self.add_message(
            "docstring-first-line-empty",
            node=node,
            args=(node_type,),
            confidence=HIGH,
        )

    # Use "linecache", instead of node.as_string(), because the latter
    # looses the original form of the docstrings.

    if docstring:
        lineno = node.fromlineno + 1
        line = linecache.getline(node.root().file, lineno).lstrip()
        if line and line.find('"""') == 0:
            return
        if line and "'''" in line:
            quotes = "'''"
        elif line and line[0] == '"':
            quotes = '"'
        elif line and line[0] == "'":
            quotes = "'"
        else:
            quotes = ""
        if quotes:
            self.add_message(
                "bad-docstring-quotes",
                node=node,
                args=(node_type, quotes),
                confidence=HIGH,
            )


</t>
<t tx="ekr.20250131013600.905">@path pylint/extensions
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

from typing import TYPE_CHECKING

from astroid import nodes

from pylint.checkers import BaseChecker
from pylint.constants import DUNDER_METHODS, DUNDER_PROPERTIES, EXTRA_DUNDER_METHODS
from pylint.interfaces import HIGH

if TYPE_CHECKING:
    from pylint.lint import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.906">class DunderChecker(BaseChecker):
    """Checks related to dunder methods."""

    @others
</t>
<t tx="ekr.20250131013600.907">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(DunderChecker(linter))
</t>
<t tx="ekr.20250131013600.908">name = "dunder"
msgs = {
    "W3201": (
        "Bad or misspelled dunder method name %s.",
        "bad-dunder-name",
        "Used when a dunder method is misspelled or defined with a name "
        "not within the predefined list of dunder names.",
    ),
}
options = (
    (
        "good-dunder-names",
        {
            "default": [],
            "type": "csv",
            "metavar": "&lt;comma-separated names&gt;",
            "help": "Good dunder names which should always be accepted.",
        },
    ),
)

def open(self) -&gt; None:
    self._dunder_methods = (
        EXTRA_DUNDER_METHODS
        + DUNDER_PROPERTIES
        + self.linter.config.good_dunder_names
    )
    for since_vers, dunder_methods in DUNDER_METHODS.items():
        if since_vers &lt;= self.linter.config.py_version:
            self._dunder_methods.extend(list(dunder_methods.keys()))

</t>
<t tx="ekr.20250131013600.909">def visit_functiondef(self, node: nodes.FunctionDef) -&gt; None:
    """Check if known dunder method is misspelled or dunder name is not one
    of the pre-defined names.
    """
    # ignore module-level functions
    if not node.is_method():
        return

    # Detect something that could be a bad dunder method
    if (
        node.name.startswith("_")
        and node.name.endswith("_")
        and node.name not in self._dunder_methods
    ):
        self.add_message(
            "bad-dunder-name",
            node=node,
            args=(node.name),
            confidence=HIGH,
        )


</t>
<t tx="ekr.20250131013600.91">def is_attribute_typed_annotation(
    node: nodes.ClassDef | astroid.Instance, attr_name: str
) -&gt; bool:
    """Test if attribute is typed annotation in current node
    or any base nodes.
    """
    attribute = node.locals.get(attr_name, [None])[0]
    if (
        attribute
        and isinstance(attribute, nodes.AssignName)
        and isinstance(attribute.parent, nodes.AnnAssign)
    ):
        return True
    for base in node.bases:
        inferred = safe_infer(base)
        if (
            inferred
            and isinstance(inferred, nodes.ClassDef)
            and is_attribute_typed_annotation(inferred, attr_name)
        ):
            return True
    return False


</t>
<t tx="ekr.20250131013600.910">@path pylint/extensions
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

from typing import TYPE_CHECKING

from astroid import nodes

from pylint.checkers import BaseRawFileChecker

if TYPE_CHECKING:
    from pylint.lint import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.911">def is_line_commented(line: bytes) -&gt; bool:
    """Checks if a `# symbol that is not part of a string was found in line."""
    comment_idx = line.find(b"#")
    if comment_idx == -1:
        return False
    if comment_part_of_string(line, comment_idx):
        return is_line_commented(line[:comment_idx] + line[comment_idx + 1 :])
    return True


</t>
<t tx="ekr.20250131013600.912">def comment_part_of_string(line: bytes, comment_idx: int) -&gt; bool:
    """Checks if the symbol at comment_idx is part of a string."""
    if (
        line[:comment_idx].count(b"'") % 2 == 1
        and line[comment_idx:].count(b"'") % 2 == 1
    ) or (
        line[:comment_idx].count(b'"') % 2 == 1
        and line[comment_idx:].count(b'"') % 2 == 1
    ):
        return True
    return False


</t>
<t tx="ekr.20250131013600.913">class CommentChecker(BaseRawFileChecker):
    @others
</t>
<t tx="ekr.20250131013600.914">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(CommentChecker(linter))
</t>
<t tx="ekr.20250131013600.915">name = "empty-comment"
msgs = {
    "R2044": (
        "Line with empty comment",
        "empty-comment",
        (
            "Used when a # symbol appears on a line not followed by an actual comment"
        ),
    )
}
options = ()

def process_module(self, node: nodes.Module) -&gt; None:
    with node.stream() as stream:
        for line_num, line in enumerate(stream):
            line = line.rstrip()
            if line.endswith(b"#"):
                if not is_line_commented(line[:-1]):
                    self.add_message("empty-comment", line=line_num + 1)


</t>
<t tx="ekr.20250131013600.916">@path pylint/extensions
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""This is the remnant of the python3 checker.

It was removed because the transition from python 2 to python3 is
behind us, but some checks are still useful in python3 after all.
See https://github.com/pylint-dev/pylint/issues/5025
"""

from astroid import nodes

from pylint import checkers, interfaces
from pylint.checkers import utils
from pylint.lint import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.917">class EqWithoutHash(checkers.BaseChecker):
    @others
</t>
<t tx="ekr.20250131013600.918">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(EqWithoutHash(linter))
</t>
<t tx="ekr.20250131013600.919">name = "eq-without-hash"

msgs = {
    "W1641": (
        "Implementing __eq__ without also implementing __hash__",
        "eq-without-hash",
        "Used when a class implements __eq__ but not __hash__. Objects get "
        "None as their default __hash__ implementation if they also implement __eq__.",
    ),
}

@utils.only_required_for_messages("eq-without-hash")
def visit_classdef(self, node: nodes.ClassDef) -&gt; None:
    locals_and_methods = set(node.locals).union(x.name for x in node.mymethods())
    if "__eq__" in locals_and_methods and "__hash__" not in locals_and_methods:
        self.add_message("eq-without-hash", node=node, confidence=interfaces.HIGH)


</t>
<t tx="ekr.20250131013600.92">def is_enum(node: nodes.ClassDef) -&gt; bool:
    return node.name == "Enum" and node.root().name == "enum"  # type: ignore[no-any-return]


</t>
<t tx="ekr.20250131013600.920">@path pylint/extensions
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Check for use of for loops that only check for a condition."""

from __future__ import annotations

from typing import TYPE_CHECKING

from astroid import nodes

from pylint.checkers import BaseChecker
from pylint.checkers.utils import (
    assigned_bool,
    only_required_for_messages,
    returns_bool,
)
from pylint.interfaces import HIGH

if TYPE_CHECKING:
    from pylint.lint.pylinter import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.921">class ConsiderUsingAnyOrAllChecker(BaseChecker):
    @others
</t>
<t tx="ekr.20250131013600.922">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(ConsiderUsingAnyOrAllChecker(linter))
</t>
<t tx="ekr.20250131013600.923">name = "consider-using-any-or-all"
msgs = {
    "C0501": (
        "`for` loop could be `%s`",
        "consider-using-any-or-all",
        "A for loop that checks for a condition and return a bool can be replaced with any or all.",
    )
}

@only_required_for_messages("consider-using-any-or-all")
def visit_for(self, node: nodes.For) -&gt; None:
    if len(node.body) != 1:  # Only If node with no Else
        return
    if not isinstance(node.body[0], nodes.If):
        return

    if_children = list(node.body[0].get_children())
    if any(isinstance(child, nodes.If) for child in if_children):
        # an if node within the if-children indicates an elif clause,
        # suggesting complex logic.
        return

    node_after_loop = node.next_sibling()

    if self._assigned_reassigned_returned(node, if_children, node_after_loop):
        final_return_bool = node_after_loop.value.name
        suggested_string = self._build_suggested_string(node, final_return_bool)
        self.add_message(
            "consider-using-any-or-all",
            node=node,
            args=suggested_string,
            confidence=HIGH,
        )
        return

    if self._if_statement_returns_bool(if_children, node_after_loop):
        final_return_bool = node_after_loop.value.value
        suggested_string = self._build_suggested_string(node, final_return_bool)
        self.add_message(
            "consider-using-any-or-all",
            node=node,
            args=suggested_string,
            confidence=HIGH,
        )
        return

</t>
<t tx="ekr.20250131013600.924">@staticmethod
def _if_statement_returns_bool(
    if_children: list[nodes.NodeNG], node_after_loop: nodes.NodeNG
) -&gt; bool:
    """Detect for-loop, if-statement, return pattern:

    Ex:
        def any_uneven(items):
            for item in items:
                if not item % 2 == 0:
                    return True
            return False
    """
    if not len(if_children) == 2:
        # The If node has only a comparison and return
        return False
    if not returns_bool(if_children[1]):
        return False

    # Check for terminating boolean return right after the loop
    return returns_bool(node_after_loop)

</t>
<t tx="ekr.20250131013600.925">@staticmethod
def _assigned_reassigned_returned(
    node: nodes.For, if_children: list[nodes.NodeNG], node_after_loop: nodes.NodeNG
) -&gt; bool:
    """Detect boolean-assign, for-loop, re-assign, return pattern:

    Ex:
        def check_lines(lines, max_chars):
            long_line = False
            for line in lines:
                if len(line) &gt; max_chars:
                    long_line = True
                # no elif / else statement
            return long_line
    """
    node_before_loop = node.previous_sibling()

    if not assigned_bool(node_before_loop):
        # node before loop isn't assigning to boolean
        return False

    assign_children = [x for x in if_children if isinstance(x, nodes.Assign)]
    if not assign_children:
        # if-nodes inside loop aren't assignments
        return False

    # We only care for the first assign node of the if-children. Otherwise it breaks the pattern.
    first_target = assign_children[0].targets[0]
    target_before_loop = node_before_loop.targets[0]

    if not (
        isinstance(first_target, nodes.AssignName)
        and isinstance(target_before_loop, nodes.AssignName)
    ):
        return False

    node_before_loop_name = node_before_loop.targets[0].name
    return (
        first_target.name == node_before_loop_name
        and isinstance(node_after_loop, nodes.Return)
        and isinstance(node_after_loop.value, nodes.Name)
        and node_after_loop.value.name == node_before_loop_name
    )

</t>
<t tx="ekr.20250131013600.926">@staticmethod
def _build_suggested_string(node: nodes.For, final_return_bool: bool) -&gt; str:
    """When a nodes.For node can be rewritten as an any/all statement, return a
    suggestion for that statement.

    'final_return_bool' is the boolean literal returned after the for loop if all
    conditions fail.
    """
    loop_var = node.target.as_string()
    loop_iter = node.iter.as_string()
    test_node = next(node.body[0].get_children())

    if isinstance(test_node, nodes.UnaryOp) and test_node.op == "not":
        # The condition is negated. Advance the node to the operand and modify the suggestion
        test_node = test_node.operand
        suggested_function = "all" if final_return_bool else "not all"
    else:
        suggested_function = "not any" if final_return_bool else "any"

    test = test_node.as_string()
    return f"{suggested_function}({test} for {loop_var} in {loop_iter})"


</t>
<t tx="ekr.20250131013600.927">@path pylint/extensions
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Checks for magic values instead of literals."""

from __future__ import annotations

from re import match as regex_match
from typing import TYPE_CHECKING

from astroid import nodes

from pylint.checkers import BaseChecker, utils
from pylint.interfaces import HIGH

if TYPE_CHECKING:
    from pylint.lint import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.928">class MagicValueChecker(BaseChecker):
    """Checks for constants in comparisons."""

    @others
</t>
<t tx="ekr.20250131013600.929">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(MagicValueChecker(linter))
</t>
<t tx="ekr.20250131013600.93">def is_assign_name_annotated_with(node: nodes.AssignName, typing_name: str) -&gt; bool:
    """Test if AssignName node has `typing_name` annotation.

    Especially useful to check for `typing._SpecialForm` instances
    like: `Union`, `Optional`, `Literal`, `ClassVar`, `Final`.
    """
    if not isinstance(node.parent, nodes.AnnAssign):
        return False
    annotation = node.parent.annotation
    if isinstance(annotation, nodes.Subscript):
        annotation = annotation.value
    if (isinstance(annotation, nodes.Name) and annotation.name == typing_name) or (
        isinstance(annotation, nodes.Attribute) and annotation.attrname == typing_name
    ):
        return True
    return False


</t>
<t tx="ekr.20250131013600.930">name = "magic-value"
msgs = {
    "R2004": (
        "Consider using a named constant or an enum instead of '%s'.",
        "magic-value-comparison",
        "Using named constants instead of magic values helps improve readability and maintainability of your"
        " code, try to avoid them in comparisons.",
    )
}

options = (
    (
        "valid-magic-values",
        {
            "default": (0, -1, 1, "", "__main__"),
            "type": "csv",
            "metavar": "&lt;argument names&gt;",
            "help": "List of valid magic values that `magic-value-compare` will not detect. "
            "Supports integers, floats, negative numbers, for empty string enter ``''``,"
            " for backslash values just use one backslash e.g \\n.",
        },
    ),
)

def __init__(self, linter: PyLinter) -&gt; None:
    """Initialize checker instance."""
    super().__init__(linter=linter)
    self.valid_magic_vals: tuple[float | str, ...] = ()

</t>
<t tx="ekr.20250131013600.931">def open(self) -&gt; None:
    # Extra manipulation is needed in case of using external configuration like an rcfile
    if self._magic_vals_ext_configured():
        self.valid_magic_vals = tuple(
            self._parse_rcfile_magic_numbers(value)
            for value in self.linter.config.valid_magic_values
        )
    else:
        self.valid_magic_vals = self.linter.config.valid_magic_values

</t>
<t tx="ekr.20250131013600.932">def _magic_vals_ext_configured(self) -&gt; bool:
    return not isinstance(self.linter.config.valid_magic_values, tuple)

</t>
<t tx="ekr.20250131013600.933">def _check_constants_comparison(self, node: nodes.Compare) -&gt; None:
    """
    Magic values in any side of the comparison should be avoided,
    Detects comparisons that `comparison-of-constants` core checker cannot detect.
    """
    const_operands = []
    LEFT_OPERAND = 0
    RIGHT_OPERAND = 1

    left_operand = node.left
    const_operands.append(isinstance(left_operand, nodes.Const))

    right_operand = node.ops[0][1]
    const_operands.append(isinstance(right_operand, nodes.Const))

    if all(const_operands):
        # `comparison-of-constants` avoided
        return

    operand_value = None
    if const_operands[LEFT_OPERAND] and self._is_magic_value(left_operand):
        operand_value = left_operand.as_string()
    elif const_operands[RIGHT_OPERAND] and self._is_magic_value(right_operand):
        operand_value = right_operand.as_string()
    if operand_value is not None:
        self.add_message(
            "magic-value-comparison",
            node=node,
            args=(operand_value),
            confidence=HIGH,
        )

</t>
<t tx="ekr.20250131013600.934">def _is_magic_value(self, node: nodes.Const) -&gt; bool:
    return (not utils.is_singleton_const(node)) and (
        node.value not in (self.valid_magic_vals)
    )

</t>
<t tx="ekr.20250131013600.935">@staticmethod
def _parse_rcfile_magic_numbers(parsed_val: str) -&gt; float | str:
    parsed_val = parsed_val.encode().decode("unicode_escape")

    if parsed_val.startswith("'") and parsed_val.endswith("'"):
        return parsed_val[1:-1]

    is_number = regex_match(r"[-+]?\d+(\.0*)?$", parsed_val)
    return float(parsed_val) if is_number else parsed_val

</t>
<t tx="ekr.20250131013600.936">@utils.only_required_for_messages("magic-comparison")
def visit_compare(self, node: nodes.Compare) -&gt; None:
    self._check_constants_comparison(node)


</t>
<t tx="ekr.20250131013600.937">@path pylint/extensions
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Module to add McCabe checker class for pylint."""

from __future__ import annotations

from collections.abc import Sequence
from typing import TYPE_CHECKING, Any, TypeVar, Union

from astroid import nodes
from mccabe import PathGraph as Mccabe_PathGraph
from mccabe import PathGraphingAstVisitor as Mccabe_PathGraphingAstVisitor

from pylint import checkers
from pylint.checkers.utils import only_required_for_messages
from pylint.interfaces import HIGH

if TYPE_CHECKING:
    from pylint.lint import PyLinter

_StatementNodes = Union[
    nodes.Assert,
    nodes.Assign,
    nodes.AugAssign,
    nodes.Delete,
    nodes.Raise,
    nodes.Yield,
    nodes.Import,
    nodes.Call,
    nodes.Subscript,
    nodes.Pass,
    nodes.Continue,
    nodes.Break,
    nodes.Global,
    nodes.Return,
    nodes.Expr,
    nodes.Await,
]

_SubGraphNodes = Union[nodes.If, nodes.Try, nodes.For, nodes.While]
_AppendableNodeT = TypeVar(
    "_AppendableNodeT", bound=Union[_StatementNodes, nodes.While, nodes.FunctionDef]
)


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.938">class PathGraph(Mccabe_PathGraph):  # type: ignore[misc]
    @others
</t>
<t tx="ekr.20250131013600.939">class PathGraphingAstVisitor(Mccabe_PathGraphingAstVisitor):  # type: ignore[misc]
    @others
</t>
<t tx="ekr.20250131013600.94">def get_iterating_dictionary_name(node: nodes.For | nodes.Comprehension) -&gt; str | None:
    """Get the name of the dictionary which keys are being iterated over on
    a ``nodes.For`` or ``nodes.Comprehension`` node.

    If the iterating object is not either the keys method of a dictionary
    or a dictionary itself, this returns None.
    """
    # Is it a proper keys call?
    if (
        isinstance(node.iter, nodes.Call)
        and isinstance(node.iter.func, nodes.Attribute)
        and node.iter.func.attrname == "keys"
    ):
        inferred = safe_infer(node.iter.func)
        if not isinstance(inferred, astroid.BoundMethod):
            return None
        return node.iter.as_string().rpartition(".keys")[0]  # type: ignore[no-any-return]

    # Is it a dictionary?
    if isinstance(node.iter, (nodes.Name, nodes.Attribute)):
        inferred = safe_infer(node.iter)
        if not isinstance(inferred, nodes.Dict):
            return None
        return node.iter.as_string()  # type: ignore[no-any-return]

    return None


</t>
<t tx="ekr.20250131013600.940">class McCabeMethodChecker(checkers.BaseChecker):
    """Checks McCabe complexity cyclomatic threshold in methods and functions
    to validate a too complex code.
    """

    @others
</t>
<t tx="ekr.20250131013600.941">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(McCabeMethodChecker(linter))
</t>
<t tx="ekr.20250131013600.942">def __init__(self, node: _SubGraphNodes | nodes.FunctionDef):
    super().__init__(name="", entity="", lineno=1)
    self.root = node


</t>
<t tx="ekr.20250131013600.943">def __init__(self) -&gt; None:
    super().__init__()
    self._bottom_counter = 0
    self.graph: PathGraph | None = None

</t>
<t tx="ekr.20250131013600.944">def default(self, node: nodes.NodeNG, *args: Any) -&gt; None:
    for child in node.get_children():
        self.dispatch(child, *args)

</t>
<t tx="ekr.20250131013600.945">def dispatch(self, node: nodes.NodeNG, *args: Any) -&gt; Any:
    self.node = node
    klass = node.__class__
    meth = self._cache.get(klass)
    if meth is None:
        class_name = klass.__name__
        meth = getattr(self.visitor, "visit" + class_name, self.default)
        self._cache[klass] = meth
    return meth(node, *args)

</t>
<t tx="ekr.20250131013600.946">def visitFunctionDef(self, node: nodes.FunctionDef) -&gt; None:
    if self.graph is not None:
        # closure
        pathnode = self._append_node(node)
        self.tail = pathnode
        self.dispatch_list(node.body)
        bottom = f"{self._bottom_counter}"
        self._bottom_counter += 1
        self.graph.connect(self.tail, bottom)
        self.graph.connect(node, bottom)
        self.tail = bottom
    else:
        self.graph = PathGraph(node)
        self.tail = node
        self.dispatch_list(node.body)
        self.graphs[f"{self.classname}{node.name}"] = self.graph
        self.reset()

</t>
<t tx="ekr.20250131013600.947">visitAsyncFunctionDef = visitFunctionDef

def visitSimpleStatement(self, node: _StatementNodes) -&gt; None:
    self._append_node(node)

</t>
<t tx="ekr.20250131013600.948">visitAssert = visitAssign = visitAugAssign = visitDelete = visitRaise = (
    visitYield
) = visitImport = visitCall = visitSubscript = visitPass = visitContinue = (
    visitBreak
) = visitGlobal = visitReturn = visitExpr = visitAwait = visitSimpleStatement

def visitWith(self, node: nodes.With) -&gt; None:
    self._append_node(node)
    self.dispatch_list(node.body)

</t>
<t tx="ekr.20250131013600.949">visitAsyncWith = visitWith

def _append_node(self, node: _AppendableNodeT) -&gt; _AppendableNodeT | None:
    if not self.tail or not self.graph:
        return None
    self.graph.connect(self.tail, node)
    self.tail = node
    return node

</t>
<t tx="ekr.20250131013600.95">def get_subscript_const_value(node: nodes.Subscript) -&gt; nodes.Const:
    """Returns the value 'subscript.slice' of a Subscript node.

    :param node: Subscript Node to extract value from
    :returns: Const Node containing subscript value
    :raises InferredTypeError: if the subscript node cannot be inferred as a Const
    """
    inferred = safe_infer(node.slice)
    if not isinstance(inferred, nodes.Const):
        raise InferredTypeError("Subscript.slice cannot be inferred as a nodes.Const")

    return inferred


</t>
<t tx="ekr.20250131013600.950">def _subgraph(
    self,
    node: _SubGraphNodes,
    name: str,
    extra_blocks: Sequence[nodes.ExceptHandler] = (),
</t>
<t tx="ekr.20250131013600.951">) -&gt; None:
    """Create the subgraphs representing any `if` and `for` statements."""
    if self.graph is None:
        # global loop
        self.graph = PathGraph(node)
        self._subgraph_parse(node, node, extra_blocks)
        self.graphs[f"{self.classname}{name}"] = self.graph
        self.reset()
    else:
        self._append_node(node)
        self._subgraph_parse(node, node, extra_blocks)

def _subgraph_parse(
    self,
    node: _SubGraphNodes,
    pathnode: _SubGraphNodes,
    extra_blocks: Sequence[nodes.ExceptHandler],
) -&gt; None:
    """Parse the body and any `else` block of `if` and `for` statements."""
    loose_ends = []
    self.tail = node
    self.dispatch_list(node.body)
    loose_ends.append(self.tail)
    for extra in extra_blocks:
        self.tail = node
        self.dispatch_list(extra.body)
        loose_ends.append(self.tail)
    if node.orelse:
        self.tail = node
        self.dispatch_list(node.orelse)
        loose_ends.append(self.tail)
    else:
        loose_ends.append(node)
    if node and self.graph:
        bottom = f"{self._bottom_counter}"
        self._bottom_counter += 1
        for end in loose_ends:
            self.graph.connect(end, bottom)
        self.tail = bottom


</t>
<t tx="ekr.20250131013600.952">name = "design"

msgs = {
    "R1260": (
        "%s is too complex. The McCabe rating is %d",
        "too-complex",
        "Used when a method or function is too complex based on "
        "McCabe Complexity Cyclomatic",
    )
}
options = (
    (
        "max-complexity",
        {
            "default": 10,
            "type": "int",
            "metavar": "&lt;int&gt;",
            "help": "McCabe complexity cyclomatic threshold",
        },
    ),
)

@only_required_for_messages("too-complex")
def visit_module(self, node: nodes.Module) -&gt; None:
    """Visit an astroid.Module node to check too complex rating and
    add message if is greater than max_complexity stored from options.
    """
    visitor = PathGraphingAstVisitor()
    for child in node.body:
        visitor.preorder(child, visitor)
    for graph in visitor.graphs.values():
        complexity = graph.complexity()
        node = graph.root
        if hasattr(node, "name"):
            node_name = f"'{node.name}'"
        else:
            node_name = f"This '{node.__class__.__name__.lower()}'"
        if complexity &lt;= self.linter.config.max_complexity:
            continue
        self.add_message(
            "too-complex", node=node, confidence=HIGH, args=(node_name, complexity)
        )


</t>
<t tx="ekr.20250131013600.953">@path pylint/extensions
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

from typing import TYPE_CHECKING

from astroid import nodes

from pylint.checkers import BaseChecker
from pylint.checkers.utils import (
    PYMETHODS,
    decorated_with_property,
    is_overload_stub,
    is_protocol_class,
    overrides_a_method,
)
from pylint.interfaces import INFERENCE

if TYPE_CHECKING:
    from pylint.lint.pylinter import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.954">class NoSelfUseChecker(BaseChecker):
    @others
    leave_asyncfunctiondef = leave_functiondef


</t>
<t tx="ekr.20250131013600.955">def _has_bare_super_call(fundef_node: nodes.FunctionDef) -&gt; bool:
    for call in fundef_node.nodes_of_class(nodes.Call):
        func = call.func
        if isinstance(func, nodes.Name) and func.name == "super" and not call.args:
            return True
    return False


</t>
<t tx="ekr.20250131013600.956">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(NoSelfUseChecker(linter))
</t>
<t tx="ekr.20250131013600.957">name = "no_self_use"
msgs = {
    "R6301": (
        "Method could be a function",
        "no-self-use",
        "Used when a method doesn't use its bound instance, and so could "
        "be written as a function.",
        {"old_names": [("R0201", "old-no-self-use")]},
    ),
}

def __init__(self, linter: PyLinter) -&gt; None:
    super().__init__(linter)
    self._first_attrs: list[str | None] = []
    self._meth_could_be_func: bool | None = None

</t>
<t tx="ekr.20250131013600.958">def visit_name(self, node: nodes.Name) -&gt; None:
    """Check if the name handle an access to a class member
    if so, register it.
    """
    if self._first_attrs and (
        node.name == self._first_attrs[-1] or not self._first_attrs[-1]
    ):
        self._meth_could_be_func = False

</t>
<t tx="ekr.20250131013600.959">def visit_functiondef(self, node: nodes.FunctionDef) -&gt; None:
    if not node.is_method():
        return
    self._meth_could_be_func = True
    self._check_first_arg_for_type(node)

</t>
<t tx="ekr.20250131013600.96">def get_import_name(importnode: ImportNode, modname: str | None) -&gt; str | None:
    """Get a prepared module name from the given import node.

    In the case of relative imports, this will return the
    absolute qualified module name, which might be useful
    for debugging. Otherwise, the initial module name
    is returned unchanged.

    :param importnode: node representing import statement.
    :param modname: module name from import statement.
    :returns: absolute qualified module name of the module
        used in import.
    """
    if isinstance(importnode, nodes.ImportFrom) and importnode.level:
        root = importnode.root()
        if isinstance(root, nodes.Module):
            try:
                return root.relative_to_absolute_name(  # type: ignore[no-any-return]
                    modname, level=importnode.level
                )
            except TooManyLevelsError:
                return modname
    return modname


</t>
<t tx="ekr.20250131013600.960">visit_asyncfunctiondef = visit_functiondef

def _check_first_arg_for_type(self, node: nodes.FunctionDef) -&gt; None:
    """Check the name of first argument."""
    # pylint: disable=duplicate-code
    if node.args.posonlyargs:
        first_arg = node.args.posonlyargs[0].name
    elif node.args.args:
        first_arg = node.argnames()[0]
    else:
        first_arg = None
    self._first_attrs.append(first_arg)
    # static method
    if node.type == "staticmethod":
        self._first_attrs[-1] = None

</t>
<t tx="ekr.20250131013600.961">def leave_functiondef(self, node: nodes.FunctionDef) -&gt; None:
    """On method node, check if this method couldn't be a function.

    ignore class, static and abstract methods, initializer,
    methods overridden from a parent class.
    """
    if node.is_method():
        first = self._first_attrs.pop()
        if first is None:
            return
        class_node = node.parent.frame()
        if (
            self._meth_could_be_func
            and node.type == "method"
            and node.name not in PYMETHODS
            and not (
                node.is_abstract()
                or overrides_a_method(class_node, node.name)
                or decorated_with_property(node)
                or _has_bare_super_call(node)
                or is_protocol_class(class_node)
                or is_overload_stub(node)
            )
        ):
            self.add_message("no-self-use", node=node, confidence=INFERENCE)

</t>
<t tx="ekr.20250131013600.962">@path pylint/extensions
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Looks for overlapping exceptions."""

from __future__ import annotations

from typing import TYPE_CHECKING, Any

import astroid
from astroid import nodes, util

from pylint import checkers
from pylint.checkers import utils
from pylint.checkers.exceptions import _annotated_unpack_infer

if TYPE_CHECKING:
    from pylint.lint import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.963">class OverlappingExceptionsChecker(checkers.BaseChecker):
    """Checks for two or more exceptions in the same exception handler
    clause that are identical or parts of the same inheritance hierarchy.

    (i.e. overlapping).
    """

    @others
</t>
<t tx="ekr.20250131013600.964">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(OverlappingExceptionsChecker(linter))
</t>
<t tx="ekr.20250131013600.965">name = "overlap-except"
msgs = {
    "W0714": (
        "Overlapping exceptions (%s)",
        "overlapping-except",
        "Used when exceptions in handler overlap or are identical",
    )
}
options = ()

@utils.only_required_for_messages("overlapping-except")
def visit_try(self, node: nodes.Try) -&gt; None:
    """Check for empty except."""
    for handler in node.handlers:
        if handler.type is None:
            continue
        if isinstance(handler.type, astroid.BoolOp):
            continue
        try:
            excs = list(_annotated_unpack_infer(handler.type))
        except astroid.InferenceError:
            continue

        handled_in_clause: list[tuple[Any, Any]] = []
        for part, exc in excs:
            if isinstance(exc, util.UninferableBase):
                continue
            if isinstance(exc, astroid.Instance) and utils.inherit_from_std_ex(exc):
                exc = exc._proxied

            if not isinstance(exc, astroid.ClassDef):
                continue

            exc_ancestors = [
                a for a in exc.ancestors() if isinstance(a, astroid.ClassDef)
            ]

            for prev_part, prev_exc in handled_in_clause:
                prev_exc_ancestors = [
                    a
                    for a in prev_exc.ancestors()
                    if isinstance(a, astroid.ClassDef)
                ]
                if exc == prev_exc:
                    self.add_message(
                        "overlapping-except",
                        node=handler.type,
                        args=f"{prev_part.as_string()} and {part.as_string()} are the same",
                    )
                elif prev_exc in exc_ancestors or exc in prev_exc_ancestors:
                    ancestor = part if exc in prev_exc_ancestors else prev_part
                    descendant = part if prev_exc in exc_ancestors else prev_part
                    self.add_message(
                        "overlapping-except",
                        node=handler.type,
                        args=f"{ancestor.as_string()} is an ancestor class of {descendant.as_string()}",
                    )
            handled_in_clause += [(part, exc)]


</t>
<t tx="ekr.20250131013600.966">@path pylint/extensions
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Check for imports on private external modules and names."""

from __future__ import annotations

from pathlib import Path
from typing import TYPE_CHECKING

from astroid import nodes

from pylint.checkers import BaseChecker, utils
from pylint.interfaces import HIGH

if TYPE_CHECKING:
    from pylint.lint.pylinter import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.967">class PrivateImportChecker(BaseChecker):
    @others
</t>
<t tx="ekr.20250131013600.968">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(PrivateImportChecker(linter))
</t>
<t tx="ekr.20250131013600.969">name = "import-private-name"
msgs = {
    "C2701": (
        "Imported private %s (%s)",
        "import-private-name",
        "Used when a private module or object prefixed with _ is imported. "
        "PEP8 guidance on Naming Conventions states that public attributes with "
        "leading underscores should be considered private.",
    ),
}

def __init__(self, linter: PyLinter) -&gt; None:
    BaseChecker.__init__(self, linter)

    # A mapping of private names used as a type annotation to whether it is an acceptable import
    self.all_used_type_annotations: dict[str, bool] = {}
    self.populated_annotations = False

</t>
<t tx="ekr.20250131013600.97">def is_sys_guard(node: nodes.If) -&gt; bool:
    """Return True if IF stmt is a sys.version_info guard.

    &gt;&gt;&gt; import sys
    &gt;&gt;&gt; from typing import Literal
    """
    if isinstance(node.test, nodes.Compare):
        value = node.test.left
        if isinstance(value, nodes.Subscript):
            value = value.value
        if (
            isinstance(value, nodes.Attribute)
            and value.as_string() == "sys.version_info"
        ):
            return True
    elif isinstance(node.test, nodes.Attribute) and node.test.as_string() in {
        "six.PY2",
        "six.PY3",
    }:
        return True
    return False


</t>
<t tx="ekr.20250131013600.970">@utils.only_required_for_messages("import-private-name")
def visit_import(self, node: nodes.Import) -&gt; None:
    if utils.in_type_checking_block(node):
        return
    names = [name[0] for name in node.names]
    private_names = self._get_private_imports(names)
    private_names = self._get_type_annotation_names(node, private_names)
    if private_names:
        imported_identifier = "modules" if len(private_names) &gt; 1 else "module"
        private_name_string = ", ".join(private_names)
        self.add_message(
            "import-private-name",
            node=node,
            args=(imported_identifier, private_name_string),
            confidence=HIGH,
        )

</t>
<t tx="ekr.20250131013600.971">@utils.only_required_for_messages("import-private-name")
def visit_importfrom(self, node: nodes.ImportFrom) -&gt; None:
    if utils.in_type_checking_block(node):
        return
    # Only check imported names if the module is external
    if self.same_root_dir(node, node.modname):
        return

    names = [n[0] for n in node.names]

    # Check the imported objects first. If they are all valid type annotations,
    # the package can be private
    private_names = self._get_type_annotation_names(node, names)
    if not private_names:
        return

    # There are invalid imported objects, so check the name of the package
    private_module_imports = self._get_private_imports([node.modname])
    private_module_imports = self._get_type_annotation_names(
        node, private_module_imports
    )
    if private_module_imports:
        self.add_message(
            "import-private-name",
            node=node,
            args=("module", private_module_imports[0]),
            confidence=HIGH,
        )
        return  # Do not emit messages on the objects if the package is private

    private_names = self._get_private_imports(private_names)

    if private_names:
        imported_identifier = "objects" if len(private_names) &gt; 1 else "object"
        private_name_string = ", ".join(private_names)
        self.add_message(
            "import-private-name",
            node=node,
            args=(imported_identifier, private_name_string),
            confidence=HIGH,
        )

</t>
<t tx="ekr.20250131013600.972">def _get_private_imports(self, names: list[str]) -&gt; list[str]:
    """Returns the private names from input names by a simple string check."""
    return [name for name in names if self._name_is_private(name)]

</t>
<t tx="ekr.20250131013600.973">@staticmethod
def _name_is_private(name: str) -&gt; bool:
    """Returns true if the name exists, starts with `_`, and if len(name) &gt; 4
    it is not a dunder, i.e. it does not begin and end with two underscores.
    """
    return (
        bool(name)
        and name[0] == "_"
        and (len(name) &lt;= 4 or name[1] != "_" or name[-2:] != "__")
    )

</t>
<t tx="ekr.20250131013600.974">def _get_type_annotation_names(
    self, node: nodes.Import | nodes.ImportFrom, names: list[str]
) -&gt; list[str]:
    """Removes from names any names that are used as type annotations with no other
    illegal usages.
    """
    if names and not self.populated_annotations:
        self._populate_type_annotations(node.root(), self.all_used_type_annotations)
        self.populated_annotations = True

    return [
        n
        for n in names
        if n not in self.all_used_type_annotations
        or (
            n in self.all_used_type_annotations
            and not self.all_used_type_annotations[n]
        )
    ]

</t>
<t tx="ekr.20250131013600.975">def _populate_type_annotations(
    self, node: nodes.LocalsDictNodeNG, all_used_type_annotations: dict[str, bool]
) -&gt; None:
    """Adds to `all_used_type_annotations` all names ever used as a type annotation
    in the node's (nested) scopes and whether they are only used as annotation.
    """
    for name in node.locals:
        # If we find a private type annotation, make sure we do not mask illegal usages
        private_name = None
        # All the assignments using this variable that we might have to check for
        # illegal usages later
        name_assignments = []
        for usage_node in node.locals[name]:
            if isinstance(usage_node, nodes.AssignName) and isinstance(
                usage_node.parent, (nodes.AnnAssign, nodes.Assign)
            ):
                assign_parent = usage_node.parent
                if isinstance(assign_parent, nodes.AnnAssign):
                    name_assignments.append(assign_parent)
                    private_name = self._populate_type_annotations_annotation(
                        usage_node.parent.annotation, all_used_type_annotations
                    )
                elif isinstance(assign_parent, nodes.Assign):
                    name_assignments.append(assign_parent)

            if isinstance(usage_node, nodes.FunctionDef):
                self._populate_type_annotations_function(
                    usage_node, all_used_type_annotations
                )
            if isinstance(usage_node, nodes.LocalsDictNodeNG):
                self._populate_type_annotations(
                    usage_node, all_used_type_annotations
                )
        if private_name is not None:
            # Found a new private annotation, make sure we are not accessing it elsewhere
            all_used_type_annotations[private_name] = (
                self._assignments_call_private_name(name_assignments, private_name)
            )

</t>
<t tx="ekr.20250131013600.976">def _populate_type_annotations_function(
    self, node: nodes.FunctionDef, all_used_type_annotations: dict[str, bool]
) -&gt; None:
    """Adds all names used as type annotation in the arguments and return type of
    the function node into the dict `all_used_type_annotations`.
    """
    if node.args and node.args.annotations:
        for annotation in node.args.annotations:
            self._populate_type_annotations_annotation(
                annotation, all_used_type_annotations
            )
    if node.returns:
        self._populate_type_annotations_annotation(
            node.returns, all_used_type_annotations
        )

</t>
<t tx="ekr.20250131013600.977">def _populate_type_annotations_annotation(
    self,
    node: nodes.Attribute | nodes.Subscript | nodes.Name | None,
    all_used_type_annotations: dict[str, bool],
) -&gt; str | None:
    """Handles the possibility of an annotation either being a Name, i.e. just type,
    or a Subscript e.g. `Optional[type]` or an Attribute, e.g. `pylint.lint.linter`.
    """
    if isinstance(node, nodes.Name) and node.name not in all_used_type_annotations:
        all_used_type_annotations[node.name] = True
        return node.name  # type: ignore[no-any-return]
    if isinstance(node, nodes.Subscript):  # e.g. Optional[List[str]]
        # slice is the next nested type
        self._populate_type_annotations_annotation(
            node.slice, all_used_type_annotations
        )
        # value is the current type name: could be a Name or Attribute
        return self._populate_type_annotations_annotation(
            node.value, all_used_type_annotations
        )
    if isinstance(node, nodes.Attribute):
        # An attribute is a type like `pylint.lint.pylinter`. node.expr is the next level
        # up, could be another attribute
        return self._populate_type_annotations_annotation(
            node.expr, all_used_type_annotations
        )
    return None

</t>
<t tx="ekr.20250131013600.978">@staticmethod
def _assignments_call_private_name(
    assignments: list[nodes.AnnAssign | nodes.Assign], private_name: str
) -&gt; bool:
    """Returns True if no assignments involve accessing `private_name`."""
    if all(not assignment.value for assignment in assignments):
        # Variable annotated but unassigned is not allowed because there may be
        # possible illegal access elsewhere
        return False
    for assignment in assignments:
        current_attribute = None
        if isinstance(assignment.value, nodes.Call):
            current_attribute = assignment.value.func
        elif isinstance(assignment.value, nodes.Attribute):
            current_attribute = assignment.value
        elif isinstance(assignment.value, nodes.Name):
            current_attribute = assignment.value.name
        if not current_attribute:
            continue
        while isinstance(current_attribute, (nodes.Attribute, nodes.Call)):
            if isinstance(current_attribute, nodes.Call):
                current_attribute = current_attribute.func
            if not isinstance(current_attribute, nodes.Name):
                current_attribute = current_attribute.expr
        if (
            isinstance(current_attribute, nodes.Name)
            and current_attribute.name == private_name
        ):
            return False
    return True

</t>
<t tx="ekr.20250131013600.979">@staticmethod
def same_root_dir(
    node: nodes.Import | nodes.ImportFrom, import_mod_name: str
) -&gt; bool:
    """Does the node's file's path contain the base name of `import_mod_name`?"""
    if not import_mod_name:  # from . import ...
        return True
    if node.level:  # from .foo import ..., from ..bar import ...
        return True

    base_import_package = import_mod_name.split(".")[0]

    return base_import_package in Path(node.root().file).parent.parts


</t>
<t tx="ekr.20250131013600.98">def is_reassigned_after_current(node: nodes.NodeNG, varname: str) -&gt; bool:
    """Check if the given variable name is reassigned in the same scope after the
    current node.
    """
    return any(
        a.name == varname and a.lineno &gt; node.lineno
        for a in node.scope().nodes_of_class(
            (nodes.AssignName, nodes.ClassDef, nodes.FunctionDef)
        )
    )


</t>
<t tx="ekr.20250131013600.980">@path pylint/extensions
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Optional checker to warn when loop variables are overwritten in the loop's body."""

from __future__ import annotations

from astroid import nodes

from pylint import checkers
from pylint.checkers import utils
from pylint.interfaces import HIGH
from pylint.lint import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.981">class RedefinedLoopNameChecker(checkers.BaseChecker):
    @others
</t>
<t tx="ekr.20250131013600.982">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(RedefinedLoopNameChecker(linter))
</t>
<t tx="ekr.20250131013600.983">name = "redefined-loop-name"

msgs = {
    "W2901": (
        "Redefining %r from loop (line %s)",
        "redefined-loop-name",
        "Used when a loop variable is overwritten in the loop body.",
    ),
}

def __init__(self, linter: PyLinter) -&gt; None:
    super().__init__(linter)
    self._loop_variables: list[
        tuple[nodes.For, list[str], nodes.LocalsDictNodeNG]
    ] = []

</t>
<t tx="ekr.20250131013600.984">@utils.only_required_for_messages("redefined-loop-name")
def visit_assignname(self, node: nodes.AssignName) -&gt; None:
    assign_type = node.assign_type()
    if not isinstance(assign_type, (nodes.Assign, nodes.AugAssign)):
        return
    node_scope = node.scope()
    for outer_for, outer_variables, outer_for_scope in self._loop_variables:
        if node_scope is not outer_for_scope:
            continue
        if node.name in outer_variables and not utils.in_for_else_branch(
            outer_for, node
        ):
            self.add_message(
                "redefined-loop-name",
                args=(node.name, outer_for.fromlineno),
                node=node,
                confidence=HIGH,
            )
            break

</t>
<t tx="ekr.20250131013600.985">@utils.only_required_for_messages("redefined-loop-name")
def visit_for(self, node: nodes.For) -&gt; None:
    assigned_to = [a.name for a in node.target.nodes_of_class(nodes.AssignName)]
    # Only check variables that are used
    assigned_to = [
        var
        for var in assigned_to
        if not self.linter.config.dummy_variables_rgx.match(var)
    ]

    node_scope = node.scope()
    for variable in assigned_to:
        for outer_for, outer_variables, outer_for_scope in self._loop_variables:
            if node_scope is not outer_for_scope:
                continue
            if variable in outer_variables and not utils.in_for_else_branch(
                outer_for, node
            ):
                self.add_message(
                    "redefined-loop-name",
                    args=(variable, outer_for.fromlineno),
                    node=node,
                    confidence=HIGH,
                )
                break

    self._loop_variables.append((node, assigned_to, node.scope()))

</t>
<t tx="ekr.20250131013600.986">@utils.only_required_for_messages("redefined-loop-name")
def leave_for(self, node: nodes.For) -&gt; None:  # pylint: disable=unused-argument
    self._loop_variables.pop()


</t>
<t tx="ekr.20250131013600.987">@path pylint/extensions
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

from typing import TYPE_CHECKING

from astroid import nodes

from pylint.checkers import BaseChecker
from pylint.checkers.utils import is_none, node_type, only_required_for_messages

if TYPE_CHECKING:
    from pylint.lint import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.988">class MultipleTypesChecker(BaseChecker):
    """Checks for variable type redefinition (NoneType excepted).

    At a function, method, class or module scope

    This rule could be improved:

    - Currently, if an attribute is set to different types in 2 methods of a
      same class, it won't be detected (see functional test)
    - One could improve the support for inference on assignment with tuples,
      ifexpr, etc. Also, it would be great to have support for inference on
      str.split()
    """

    @others
</t>
<t tx="ekr.20250131013600.989">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(MultipleTypesChecker(linter))
</t>
<t tx="ekr.20250131013600.99">def is_deleted_after_current(node: nodes.NodeNG, varname: str) -&gt; bool:
    """Check if the given variable name is deleted in the same scope after the current
    node.
    """
    return any(
        getattr(target, "name", None) == varname and target.lineno &gt; node.lineno
        for del_node in node.scope().nodes_of_class(nodes.Delete)
        for target in del_node.targets
    )


</t>
<t tx="ekr.20250131013600.990">name = "multiple_types"
msgs = {
    "R0204": (
        "Redefinition of %s type from %s to %s",
        "redefined-variable-type",
        "Used when the type of a variable changes inside a "
        "method or a function.",
    )
}

def visit_classdef(self, _: nodes.ClassDef) -&gt; None:
    self._assigns.append({})

</t>
<t tx="ekr.20250131013600.991">@only_required_for_messages("redefined-variable-type")
def leave_classdef(self, _: nodes.ClassDef) -&gt; None:
    self._check_and_add_messages()

</t>
<t tx="ekr.20250131013600.992">visit_functiondef = visit_asyncfunctiondef = visit_classdef
leave_functiondef = leave_asyncfunctiondef = leave_module = leave_classdef

def visit_module(self, _: nodes.Module) -&gt; None:
    self._assigns: list[dict[str, list[tuple[nodes.Assign, str]]]] = [{}]

</t>
<t tx="ekr.20250131013600.993">def _check_and_add_messages(self) -&gt; None:
    assigns = self._assigns.pop()
    for name, args in assigns.items():
        if len(args) &lt;= 1:
            continue
        orig_node, orig_type = args[0]
        # Check if there is a type in the following nodes that would be
        # different from orig_type.
        for redef_node, redef_type in args[1:]:
            if redef_type == orig_type:
                continue
            # if a variable is defined to several types in an if node,
            # this is not actually redefining.
            orig_parent = orig_node.parent
            redef_parent = redef_node.parent
            if isinstance(orig_parent, nodes.If):
                if orig_parent == redef_parent:
                    if (
                        redef_node in orig_parent.orelse
                        and orig_node not in orig_parent.orelse
                    ):
                        orig_node, orig_type = redef_node, redef_type
                        continue
                elif isinstance(
                    redef_parent, nodes.If
                ) and redef_parent in orig_parent.nodes_of_class(nodes.If):
                    orig_node, orig_type = redef_node, redef_type
                    continue
            orig_type = orig_type.replace("builtins.", "")
            redef_type = redef_type.replace("builtins.", "")
            self.add_message(
                "redefined-variable-type",
                node=redef_node,
                args=(name, orig_type, redef_type),
            )
            break

</t>
<t tx="ekr.20250131013600.994">def visit_assign(self, node: nodes.Assign) -&gt; None:
    # we don't handle multiple assignment nor slice assignment
    target = node.targets[0]
    if isinstance(target, (nodes.Tuple, nodes.Subscript)):
        return
    # ignore NoneType
    if is_none(node):
        return
    _type = node_type(node.value)
    if _type:
        self._assigns[-1].setdefault(target.as_string(), []).append(
            (node, _type.pytype())
        )


</t>
<t tx="ekr.20250131013600.995">@path pylint/extensions
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

from typing import TYPE_CHECKING

from astroid import nodes

from pylint.checkers import BaseChecker
from pylint.checkers.utils import only_required_for_messages

if TYPE_CHECKING:
    from pylint.lint import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013600.996">class SetMembershipChecker(BaseChecker):
    @others
</t>
<t tx="ekr.20250131013600.997">def register(linter: PyLinter) -&gt; None:
    linter.register_checker(SetMembershipChecker(linter))
</t>
<t tx="ekr.20250131013600.998">name = "set_membership"
msgs = {
    "R6201": (
        "Consider using set for membership test",
        "use-set-for-membership",
        "Membership tests are more efficient when performed on "
        "a lookup optimized datatype like ``sets``.",
    ),
}

def __init__(self, linter: PyLinter) -&gt; None:
    """Initialize checker instance."""
    super().__init__(linter=linter)

</t>
<t tx="ekr.20250131013600.999">@only_required_for_messages("use-set-for-membership")
def visit_compare(self, node: nodes.Compare) -&gt; None:
    for op, comparator in node.ops:
        if op == "in":
            self._check_in_comparison(comparator)

</t>
<t tx="ekr.20250131013601.1">class GetAstProtocol(Protocol):
    @others
</t>
<t tx="ekr.20250131013601.10">    def _load_reporter_by_name(self, reporter_name: str) -&gt; reporters.BaseReporter:
        name = reporter_name.lower()
        if name in self._reporters:
            return self._reporters[name]()

        try:
            reporter_class = _load_reporter_by_class(reporter_name)
        except(ImportError, AttributeError, AssertionError) as e:
            raise exceptions.InvalidReporterError(name) from e

        return reporter_class()

</t>
<t tx="ekr.20250131013601.100">@path pylint/message
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

from typing import NoReturn

from pylint.exceptions import (
    DeletedMessageError,
    InvalidMessageError,
    MessageBecameExtensionError,
    UnknownMessageError,
)
from pylint.message._deleted_message_ids import (
    is_deleted_msgid,
    is_deleted_symbol,
    is_moved_msgid,
    is_moved_symbol,
)


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.101">class MessageIdStore:
    """The MessageIdStore store MessageId and make sure that there is a 1-1 relation
    between msgid and symbol.
    """

    @others
</t>
<t tx="ekr.20250131013601.102">def __init__(self) -&gt; None:
    self.__msgid_to_symbol: dict[str, str] = {}
    self.__symbol_to_msgid: dict[str, str] = {}
    self.__old_names: dict[str, list[str]] = {}
    self.__active_msgids: dict[str, list[str]] = {}

</t>
<t tx="ekr.20250131013601.103">def __len__(self) -&gt; int:
    return len(self.__msgid_to_symbol)

</t>
<t tx="ekr.20250131013601.104">def __repr__(self) -&gt; str:
    result = "MessageIdStore: [\n"
    for msgid, symbol in self.__msgid_to_symbol.items():
        result += f"  - {msgid} ({symbol})\n"
    result += "]"
    return result

</t>
<t tx="ekr.20250131013601.105">def get_symbol(self, msgid: str) -&gt; str:
    try:
        return self.__msgid_to_symbol[msgid.upper()]
    except KeyError as e:
        msg = f"'{msgid}' is not stored in the message store."
        raise UnknownMessageError(msg) from e

</t>
<t tx="ekr.20250131013601.106">def get_msgid(self, symbol: str) -&gt; str:
    try:
        return self.__symbol_to_msgid[symbol]
    except KeyError as e:
        msg = f"'{symbol}' is not stored in the message store."
        raise UnknownMessageError(msg) from e

</t>
<t tx="ekr.20250131013601.107">def register_message_definition(
    self, msgid: str, symbol: str, old_names: list[tuple[str, str]]
) -&gt; None:
    self.check_msgid_and_symbol(msgid, symbol)
    self.add_msgid_and_symbol(msgid, symbol)
    for old_msgid, old_symbol in old_names:
        self.check_msgid_and_symbol(old_msgid, old_symbol)
        self.add_legacy_msgid_and_symbol(old_msgid, old_symbol, msgid)

</t>
<t tx="ekr.20250131013601.108">def add_msgid_and_symbol(self, msgid: str, symbol: str) -&gt; None:
    """Add valid message id.

    There is a little duplication with add_legacy_msgid_and_symbol to avoid a function call,
    this is called a lot at initialization.
    """
    self.__msgid_to_symbol[msgid] = symbol
    self.__symbol_to_msgid[symbol] = msgid

</t>
<t tx="ekr.20250131013601.109">def add_legacy_msgid_and_symbol(
    self, msgid: str, symbol: str, new_msgid: str
) -&gt; None:
    """Add valid legacy message id.

    There is a little duplication with add_msgid_and_symbol to avoid a function call,
    this is called a lot at initialization.
    """
    self.__msgid_to_symbol[msgid] = symbol
    self.__symbol_to_msgid[symbol] = msgid
    existing_old_names = self.__old_names.get(msgid, [])
    existing_old_names.append(new_msgid)
    self.__old_names[msgid] = existing_old_names

</t>
<t tx="ekr.20250131013601.11">    def set_reporter(
        self, reporter: reporters.BaseReporter | reporters.MultiReporter
    ) -&gt; None:
        """Set the reporter used to display messages and reports."""
        self.reporter = reporter
        reporter.linter = self

</t>
<t tx="ekr.20250131013601.110">def check_msgid_and_symbol(self, msgid: str, symbol: str) -&gt; None:
    existing_msgid: str | None = self.__symbol_to_msgid.get(symbol)
    existing_symbol: str | None = self.__msgid_to_symbol.get(msgid)
    if existing_symbol is None and existing_msgid is None:
        return  # both symbol and msgid are usable
    if existing_msgid is not None:
        if existing_msgid != msgid:
            self._raise_duplicate_msgid(symbol, msgid, existing_msgid)
    if existing_symbol and existing_symbol != symbol:
        # See https://github.com/python/mypy/issues/10559
        self._raise_duplicate_symbol(msgid, symbol, existing_symbol)

</t>
<t tx="ekr.20250131013601.111">@staticmethod
def _raise_duplicate_symbol(msgid: str, symbol: str, other_symbol: str) -&gt; NoReturn:
    """Raise an error when a symbol is duplicated."""
    symbols = [symbol, other_symbol]
    symbols.sort()
    error_message = f"Message id '{msgid}' cannot have both "
    error_message += f"'{symbols[0]}' and '{symbols[1]}' as symbolic name."
    raise InvalidMessageError(error_message)

</t>
<t tx="ekr.20250131013601.112">@staticmethod
def _raise_duplicate_msgid(symbol: str, msgid: str, other_msgid: str) -&gt; NoReturn:
    """Raise an error when a msgid is duplicated."""
    msgids = [msgid, other_msgid]
    msgids.sort()
    error_message = (
        f"Message symbol '{symbol}' cannot be used for "
        f"'{msgids[0]}' and '{msgids[1]}' at the same time."
        f" If you're creating an 'old_names' use 'old-{symbol}' as the old symbol."
    )
    raise InvalidMessageError(error_message)

</t>
<t tx="ekr.20250131013601.113">def get_active_msgids(self, msgid_or_symbol: str) -&gt; list[str]:
    """Return msgids but the input can be a symbol.

    self.__active_msgids is used to implement a primitive cache for this function.
    """
    try:
        return self.__active_msgids[msgid_or_symbol]
    except KeyError:
        pass

    # If we don't have a cached value yet we compute it
    msgid: str | None
    deletion_reason = None
    moved_reason = None
    if msgid_or_symbol[1:].isdigit():
        # Only msgid can have a digit as second letter
        msgid = msgid_or_symbol.upper()
        symbol = self.__msgid_to_symbol.get(msgid)
        if not symbol:
            deletion_reason = is_deleted_msgid(msgid)
            if deletion_reason is None:
                moved_reason = is_moved_msgid(msgid)
    else:
        symbol = msgid_or_symbol
        msgid = self.__symbol_to_msgid.get(msgid_or_symbol)
        if not msgid:
            deletion_reason = is_deleted_symbol(symbol)
            if deletion_reason is None:
                moved_reason = is_moved_symbol(symbol)
    if not msgid or not symbol:
        if deletion_reason is not None:
            raise DeletedMessageError(msgid_or_symbol, deletion_reason)
        if moved_reason is not None:
            raise MessageBecameExtensionError(msgid_or_symbol, moved_reason)
        error_msg = f"No such message id or symbol '{msgid_or_symbol}'."
        raise UnknownMessageError(error_msg)
    ids = self.__old_names.get(msgid, [msgid])
    # Add to cache
    self.__active_msgids[msgid_or_symbol] = ids
    return ids
</t>
<t tx="ekr.20250131013601.114"></t>
<t tx="ekr.20250131013601.115">@path pylint/pyreverse
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Pyreverse.extensions."""

__revision__ = "$Id $"
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.116">@path pylint/pyreverse
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Handle diagram generation options for class diagram or default diagrams."""

from __future__ import annotations

import argparse
from collections.abc import Generator
from typing import Any

import astroid
from astroid import nodes
from astroid.modutils import is_stdlib_module

from pylint.pyreverse.diagrams import ClassDiagram, PackageDiagram
from pylint.pyreverse.inspector import Linker, Project
from pylint.pyreverse.utils import LocalsVisitor

# diagram generators ##########################################################


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.117">class DiaDefGenerator:
    """Handle diagram generation options."""

    @others
</t>
<t tx="ekr.20250131013601.118">class DefaultDiadefGenerator(LocalsVisitor, DiaDefGenerator):
    """Generate minimum diagram definition for the project :

    * a package diagram including project's modules
    * a class diagram including project's classes
    """

    @others
</t>
<t tx="ekr.20250131013601.119">class ClassDiadefGenerator(DiaDefGenerator):
    """Generate a class diagram definition including all classes related to a
    given class.
    """

    @others
</t>
<t tx="ekr.20250131013601.12">    def register_reporter(self, reporter_class: type[reporters.BaseReporter]) -&gt; None:
        """Registers a reporter class on the _reporters attribute."""
        self._reporters[reporter_class.name] = reporter_class

</t>
<t tx="ekr.20250131013601.120"># diagram handler #############################################################


class DiadefsHandler:
    """Get diagram definitions from user (i.e. xml files) or generate them."""

    @others
</t>
<t tx="ekr.20250131013601.121">def __init__(self, linker: Linker, handler: DiadefsHandler) -&gt; None:
    """Common Diagram Handler initialization."""
    self.config = handler.config
    self.module_names: bool = False
    self._set_default_options()
    self.linker = linker
    self.classdiagram: ClassDiagram  # defined by subclasses

</t>
<t tx="ekr.20250131013601.122">def get_title(self, node: nodes.ClassDef) -&gt; str:
    """Get title for objects."""
    title = node.name
    if self.module_names:
        title = f"{node.root().name}.{title}"
    return title  # type: ignore[no-any-return]

</t>
<t tx="ekr.20250131013601.123">def _set_option(self, option: bool | None) -&gt; bool:
    """Activate some options if not explicitly deactivated."""
    # if we have a class diagram, we want more information by default;
    # so if the option is None, we return True
    if option is None:
        return bool(self.config.classes)
    return option

</t>
<t tx="ekr.20250131013601.124">def _set_default_options(self) -&gt; None:
    """Set different default options with _default dictionary."""
    self.module_names = self._set_option(self.config.module_names)
    all_ancestors = self._set_option(self.config.all_ancestors)
    all_associated = self._set_option(self.config.all_associated)
    anc_level, association_level = (0, 0)
    if all_ancestors:
        anc_level = -1
    if all_associated:
        association_level = -1
    if self.config.show_ancestors is not None:
        anc_level = self.config.show_ancestors
    if self.config.show_associated is not None:
        association_level = self.config.show_associated
    self.anc_level, self.association_level = anc_level, association_level

</t>
<t tx="ekr.20250131013601.125">def _get_levels(self) -&gt; tuple[int, int]:
    """Help function for search levels."""
    return self.anc_level, self.association_level

</t>
<t tx="ekr.20250131013601.126">def show_node(self, node: nodes.ClassDef) -&gt; bool:
    """Determine if node should be shown based on config."""
    if node.root().name == "builtins":
        return self.config.show_builtin  # type: ignore[no-any-return]

    if is_stdlib_module(node.root().name):
        return self.config.show_stdlib  # type: ignore[no-any-return]

    return True

</t>
<t tx="ekr.20250131013601.127">def add_class(self, node: nodes.ClassDef) -&gt; None:
    """Visit one class and add it to diagram."""
    self.linker.visit(node)
    self.classdiagram.add_object(self.get_title(node), node)

</t>
<t tx="ekr.20250131013601.128">def get_ancestors(
    self, node: nodes.ClassDef, level: int
) -&gt; Generator[nodes.ClassDef]:
    """Return ancestor nodes of a class node."""
    if level == 0:
        return
    for ancestor in node.ancestors(recurs=False):
        if not self.show_node(ancestor):
            continue
        yield ancestor

</t>
<t tx="ekr.20250131013601.129">def get_associated(
    self, klass_node: nodes.ClassDef, level: int
) -&gt; Generator[nodes.ClassDef]:
    """Return associated nodes of a class node."""
    if level == 0:
        return
    for association_nodes in list(klass_node.instance_attrs_type.values()) + list(
        klass_node.locals_type.values()
    ):
        for node in association_nodes:
            if isinstance(node, astroid.Instance):
                node = node._proxied
            if not (isinstance(node, nodes.ClassDef) and self.show_node(node)):
                continue
            yield node

</t>
<t tx="ekr.20250131013601.13">    def report_order(self) -&gt; list[BaseChecker]:
        reports = sorted(self._reports, key=lambda x: getattr(x, "name", ""))
        try:
            # Remove the current reporter and add it
            # at the end of the list.
            reports.pop(reports.index(self))
        except ValueError:
            pass
        else:
            reports.append(self)
        return reports

</t>
<t tx="ekr.20250131013601.130">def extract_classes(
    self, klass_node: nodes.ClassDef, anc_level: int, association_level: int
) -&gt; None:
    """Extract recursively classes related to klass_node."""
    if self.classdiagram.has_node(klass_node) or not self.show_node(klass_node):
        return
    self.add_class(klass_node)

    for ancestor in self.get_ancestors(klass_node, anc_level):
        self.extract_classes(ancestor, anc_level - 1, association_level)

    for node in self.get_associated(klass_node, association_level):
        self.extract_classes(node, anc_level, association_level - 1)


</t>
<t tx="ekr.20250131013601.131">def __init__(self, linker: Linker, handler: DiadefsHandler) -&gt; None:
    DiaDefGenerator.__init__(self, linker, handler)
    LocalsVisitor.__init__(self)

</t>
<t tx="ekr.20250131013601.132">def visit_project(self, node: Project) -&gt; None:
    """Visit a pyreverse.utils.Project node.

    create a diagram definition for packages
    """
    mode = self.config.mode
    if len(node.modules) &gt; 1:
        self.pkgdiagram: PackageDiagram | None = PackageDiagram(
            f"packages {node.name}", mode
        )
    else:
        self.pkgdiagram = None
    self.classdiagram = ClassDiagram(f"classes {node.name}", mode)

</t>
<t tx="ekr.20250131013601.133">def leave_project(self, _: Project) -&gt; Any:
    """Leave the pyreverse.utils.Project node.

    return the generated diagram definition
    """
    if self.pkgdiagram:
        return self.pkgdiagram, self.classdiagram
    return (self.classdiagram,)

</t>
<t tx="ekr.20250131013601.134">def visit_module(self, node: nodes.Module) -&gt; None:
    """Visit an astroid.Module node.

    add this class to the package diagram definition
    """
    if self.pkgdiagram:
        self.linker.visit(node)
        self.pkgdiagram.add_object(node.name, node)

</t>
<t tx="ekr.20250131013601.135">def visit_classdef(self, node: nodes.ClassDef) -&gt; None:
    """Visit an astroid.Class node.

    add this class to the class diagram definition
    """
    anc_level, association_level = self._get_levels()
    self.extract_classes(node, anc_level, association_level)

</t>
<t tx="ekr.20250131013601.136">def visit_importfrom(self, node: nodes.ImportFrom) -&gt; None:
    """Visit astroid.ImportFrom  and catch modules for package diagram."""
    if self.pkgdiagram:
        self.pkgdiagram.add_from_depend(node, node.modname)


</t>
<t tx="ekr.20250131013601.137">def class_diagram(self, project: Project, klass: nodes.ClassDef) -&gt; ClassDiagram:
    """Return a class diagram definition for the class and related classes."""
    self.classdiagram = ClassDiagram(klass, self.config.mode)
    if len(project.modules) &gt; 1:
        module, klass = klass.rsplit(".", 1)
        module = project.get_module(module)
    else:
        module = project.modules[0]
        klass = klass.split(".")[-1]
    klass = next(module.ilookup(klass))

    anc_level, association_level = self._get_levels()
    self.extract_classes(klass, anc_level, association_level)
    return self.classdiagram


</t>
<t tx="ekr.20250131013601.138">def __init__(self, config: argparse.Namespace) -&gt; None:
    self.config = config

</t>
<t tx="ekr.20250131013601.139">def get_diadefs(self, project: Project, linker: Linker) -&gt; list[ClassDiagram]:
    """Get the diagram's configuration data.

    :param project:The pyreverse project
    :type project: pyreverse.utils.Project
    :param linker: The linker
    :type linker: pyreverse.inspector.Linker(IdGeneratorMixIn, LocalsVisitor)

    :returns: The list of diagram definitions
    :rtype: list(:class:`pylint.pyreverse.diagrams.ClassDiagram`)
    """
    #  read and interpret diagram definitions (Diadefs)
    diagrams = []
    generator = ClassDiadefGenerator(linker, self)
    for klass in self.config.classes:
        diagrams.append(generator.class_diagram(project, klass))
    if not diagrams:
        diagrams = DefaultDiadefGenerator(linker, self).visit(project)
    for diagram in diagrams:
        diagram.extract_relationships()
    return diagrams
</t>
<t tx="ekr.20250131013601.14">    # checkers manipulation methods ############################################

    def register_checker(self, checker: checkers.BaseChecker) -&gt; None:
        """This method auto registers the checker."""
        self._checkers[checker.name].append(checker)
        for r_id, r_title, r_cb in checker.reports:
            self.register_report(r_id, r_title, r_cb, checker)
        if hasattr(checker, "msgs"):
            self.msgs_store.register_messages_from_checker(checker)
            for message in checker.messages:
                if not message.default_enabled:
                    self.disable(message.msgid)
        # Register the checker, but disable all of its messages.
        if not getattr(checker, "enabled", True):
            self.disable(checker.name)

</t>
<t tx="ekr.20250131013601.140">@path pylint/pyreverse
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Diagram objects."""

from __future__ import annotations

from collections.abc import Iterable
from typing import Any

import astroid
from astroid import nodes, util

from pylint.checkers.utils import decorated_with_property, in_type_checking_block
from pylint.pyreverse.utils import FilterMixIn


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.141">class Figure:
    """Base class for counter handling."""

    @others
</t>
<t tx="ekr.20250131013601.142">class Relationship(Figure):
    """A relationship from an object in the diagram to another."""

    @others
</t>
<t tx="ekr.20250131013601.143">class DiagramEntity(Figure):
    """A diagram object, i.e. a label associated to an astroid node."""

    @others
</t>
<t tx="ekr.20250131013601.144">class PackageEntity(DiagramEntity):
    """A diagram object representing a package."""

    default_shape = "package"


</t>
<t tx="ekr.20250131013601.145">class ClassEntity(DiagramEntity):
    """A diagram object representing a class."""

    @others
</t>
<t tx="ekr.20250131013601.146">class ClassDiagram(Figure, FilterMixIn):
    """Main class diagram handling."""

    @others
</t>
<t tx="ekr.20250131013601.147">class PackageDiagram(ClassDiagram):
    """Package diagram handling."""

    @others
</t>
<t tx="ekr.20250131013601.148">def __init__(self) -&gt; None:
    self.fig_id: str = ""


</t>
<t tx="ekr.20250131013601.149">def __init__(
    self,
    from_object: DiagramEntity,
    to_object: DiagramEntity,
    relation_type: str,
    name: str | None = None,
):
    super().__init__()
    self.from_object = from_object
    self.to_object = to_object
    self.type = relation_type
    self.name = name


</t>
<t tx="ekr.20250131013601.15">    def enable_fail_on_messages(self) -&gt; None:
        """Enable 'fail on' msgs.

        Convert values in config.fail_on (which might be msg category, msg id,
        or symbol) to specific msgs, then enable and flag them for later.
        """
        fail_on_vals = self.config.fail_on
        if not fail_on_vals:
            return

        fail_on_cats = set()
        fail_on_msgs = set()
        for val in fail_on_vals:
            # If value is a category, add category, else add message
            if val in MSG_TYPES:
                fail_on_cats.add(val)
            else:
                fail_on_msgs.add(val)

        # For every message in every checker, if cat or msg flagged, enable check
        for all_checkers in self._checkers.values():
            for checker in all_checkers:
                for msg in checker.messages:
                    if msg.msgid in fail_on_msgs or msg.symbol in fail_on_msgs:
                        # message id/symbol matched, enable and flag it
                        self.enable(msg.msgid)
                        self.fail_on_symbols.append(msg.symbol)
                    elif msg.msgid[0] in fail_on_cats:
                        # message starts with a category value, flag (but do not enable) it
                        self.fail_on_symbols.append(msg.symbol)

</t>
<t tx="ekr.20250131013601.150">default_shape = ""

def __init__(
    self, title: str = "No name", node: nodes.NodeNG | None = None
) -&gt; None:
    super().__init__()
    self.title = title
    self.node: nodes.NodeNG = node or nodes.NodeNG(
        lineno=None,
        col_offset=None,
        end_lineno=None,
        end_col_offset=None,
        parent=None,
    )
    self.shape = self.default_shape


</t>
<t tx="ekr.20250131013601.151">default_shape = "class"

def __init__(self, title: str, node: nodes.ClassDef) -&gt; None:
    super().__init__(title=title, node=node)
    self.attrs: list[str] = []
    self.methods: list[nodes.FunctionDef] = []


</t>
<t tx="ekr.20250131013601.152">TYPE = "class"

def __init__(self, title: str, mode: str) -&gt; None:
    FilterMixIn.__init__(self, mode)
    Figure.__init__(self)
    self.title = title
    # TODO: Specify 'Any' after refactor of `DiagramEntity`
    self.objects: list[Any] = []
    self.relationships: dict[str, list[Relationship]] = {}
    self._nodes: dict[nodes.NodeNG, DiagramEntity] = {}

</t>
<t tx="ekr.20250131013601.153">def get_relationships(self, role: str) -&gt; Iterable[Relationship]:
    # sorted to get predictable (hence testable) results
    return sorted(
        self.relationships.get(role, ()),
        key=lambda x: (x.from_object.fig_id, x.to_object.fig_id),
    )

</t>
<t tx="ekr.20250131013601.154">def add_relationship(
    self,
    from_object: DiagramEntity,
    to_object: DiagramEntity,
    relation_type: str,
    name: str | None = None,
) -&gt; None:
    """Create a relationship."""
    rel = Relationship(from_object, to_object, relation_type, name)
    self.relationships.setdefault(relation_type, []).append(rel)

</t>
<t tx="ekr.20250131013601.155">def get_relationship(
    self, from_object: DiagramEntity, relation_type: str
) -&gt; Relationship:
    """Return a relationship or None."""
    for rel in self.relationships.get(relation_type, ()):
        if rel.from_object is from_object:
            return rel
    raise KeyError(relation_type)

</t>
<t tx="ekr.20250131013601.156">def get_attrs(self, node: nodes.ClassDef) -&gt; list[str]:
    """Return visible attributes, possibly with class name."""
    attrs = []
    properties = {
        local_name: local_node
        for local_name, local_node in node.items()
        if isinstance(local_node, nodes.FunctionDef)
        and decorated_with_property(local_node)
    }
    for attr_name, attr_type in list(node.locals_type.items()) + list(
        node.instance_attrs_type.items()
    ):
        if attr_name not in properties:
            properties[attr_name] = attr_type

    for node_name, associated_nodes in properties.items():
        if not self.show_attr(node_name):
            continue
        names = self.class_names(associated_nodes)
        if names:
            node_name = f"{node_name} : {', '.join(names)}"
        attrs.append(node_name)
    return sorted(attrs)

</t>
<t tx="ekr.20250131013601.157">def get_methods(self, node: nodes.ClassDef) -&gt; list[nodes.FunctionDef]:
    """Return visible methods."""
    methods = [
        m
        for m in node.values()
        if isinstance(m, nodes.FunctionDef)
        and not isinstance(m, astroid.objects.Property)
        and not decorated_with_property(m)
        and self.show_attr(m.name)
    ]
    return sorted(methods, key=lambda n: n.name)

</t>
<t tx="ekr.20250131013601.158">def add_object(self, title: str, node: nodes.ClassDef) -&gt; None:
    """Create a diagram object."""
    assert node not in self._nodes
    ent = ClassEntity(title, node)
    self._nodes[node] = ent
    self.objects.append(ent)

</t>
<t tx="ekr.20250131013601.159">def class_names(self, nodes_lst: Iterable[nodes.NodeNG]) -&gt; list[str]:
    """Return class names if needed in diagram."""
    names = []
    for node in nodes_lst:
        if isinstance(node, astroid.Instance):
            node = node._proxied
        if (
            isinstance(
                node, (nodes.ClassDef, nodes.Name, nodes.Subscript, nodes.BinOp)
            )
            and hasattr(node, "name")
            and not self.has_node(node)
        ):
            if node.name not in names:
                node_name = node.name
                names.append(node_name)
    # sorted to get predictable (hence testable) results
    return sorted(
        name
        for name in names
        if all(name not in other or name == other for other in names)
    )

</t>
<t tx="ekr.20250131013601.16">    def any_fail_on_issues(self) -&gt; bool:
        return any(x in self.fail_on_symbols for x in self.stats.by_msg.keys())

</t>
<t tx="ekr.20250131013601.160">def has_node(self, node: nodes.NodeNG) -&gt; bool:
    """Return true if the given node is included in the diagram."""
    return node in self._nodes

</t>
<t tx="ekr.20250131013601.161">def object_from_node(self, node: nodes.NodeNG) -&gt; DiagramEntity:
    """Return the diagram object mapped to node."""
    return self._nodes[node]

</t>
<t tx="ekr.20250131013601.162">def classes(self) -&gt; list[ClassEntity]:
    """Return all class nodes in the diagram."""
    return [o for o in self.objects if isinstance(o, ClassEntity)]

</t>
<t tx="ekr.20250131013601.163">def classe(self, name: str) -&gt; ClassEntity:
    """Return a class by its name, raise KeyError if not found."""
    for klass in self.classes():
        if klass.node.name == name:
            return klass
    raise KeyError(name)

</t>
<t tx="ekr.20250131013601.164">def extract_relationships(self) -&gt; None:
    """Extract relationships between nodes in the diagram."""
    for obj in self.classes():
        node = obj.node
        obj.attrs = self.get_attrs(node)
        obj.methods = self.get_methods(node)
        obj.shape = "class"
        # inheritance link
        for par_node in node.ancestors(recurs=False):
            try:
                par_obj = self.object_from_node(par_node)
                self.add_relationship(obj, par_obj, "specialization")
            except KeyError:
                continue

        # associations &amp; aggregations links
        for name, values in list(node.aggregations_type.items()):
            for value in values:
                self.assign_association_relationship(
                    value, obj, name, "aggregation"
                )

        associations = node.associations_type.copy()

        for name, values in node.locals_type.items():
            if name not in associations:
                associations[name] = values

        for name, values in associations.items():
            for value in values:
                self.assign_association_relationship(
                    value, obj, name, "association"
                )

</t>
<t tx="ekr.20250131013601.165">def assign_association_relationship(
    self, value: astroid.NodeNG, obj: ClassEntity, name: str, type_relationship: str
) -&gt; None:
    if isinstance(value, util.UninferableBase):
        return
    if isinstance(value, astroid.Instance):
        value = value._proxied
    try:
        associated_obj = self.object_from_node(value)
        self.add_relationship(associated_obj, obj, type_relationship, name)
    except KeyError:
        return


</t>
<t tx="ekr.20250131013601.166">TYPE = "package"

def modules(self) -&gt; list[PackageEntity]:
    """Return all module nodes in the diagram."""
    return [o for o in self.objects if isinstance(o, PackageEntity)]

</t>
<t tx="ekr.20250131013601.167">def module(self, name: str) -&gt; PackageEntity:
    """Return a module by its name, raise KeyError if not found."""
    for mod in self.modules():
        if mod.node.name == name:
            return mod
    raise KeyError(name)

</t>
<t tx="ekr.20250131013601.168">def add_object(self, title: str, node: nodes.Module) -&gt; None:
    """Create a diagram object."""
    assert node not in self._nodes
    ent = PackageEntity(title, node)
    self._nodes[node] = ent
    self.objects.append(ent)

</t>
<t tx="ekr.20250131013601.169">def get_module(self, name: str, node: nodes.Module) -&gt; PackageEntity:
    """Return a module by its name, looking also for relative imports;
    raise KeyError if not found.
    """
    for mod in self.modules():
        mod_name = mod.node.name
        if mod_name == name:
            return mod
        # search for fullname of relative import modules
        package = node.root().name
        if mod_name == f"{package}.{name}":
            return mod
        if mod_name == f"{package.rsplit('.', 1)[0]}.{name}":
            return mod
    raise KeyError(name)

</t>
<t tx="ekr.20250131013601.17">    def disable_reporters(self) -&gt; None:
        """Disable all reporters."""
        for _reporters in self._reports.values():
            for report_id, _, _ in _reporters:
                self.disable_report(report_id)

</t>
<t tx="ekr.20250131013601.170">def add_from_depend(self, node: nodes.ImportFrom, from_module: str) -&gt; None:
    """Add dependencies created by from-imports."""
    mod_name = node.root().name
    package = self.module(mod_name).node

    if from_module in package.depends:
        return

    if not in_type_checking_block(node):
        package.depends.append(from_module)
    elif from_module not in package.type_depends:
        package.type_depends.append(from_module)

</t>
<t tx="ekr.20250131013601.171">def extract_relationships(self) -&gt; None:
    """Extract relationships between nodes in the diagram."""
    super().extract_relationships()
    for class_obj in self.classes():
        # ownership
        try:
            mod = self.object_from_node(class_obj.node.root())
            self.add_relationship(class_obj, mod, "ownership")
        except KeyError:
            continue
    for package_obj in self.modules():
        package_obj.shape = "package"
        # dependencies
        for dep_name in package_obj.node.depends:
            try:
                dep = self.get_module(dep_name, package_obj.node)
            except KeyError:
                continue
            self.add_relationship(package_obj, dep, "depends")

        for dep_name in package_obj.node.type_depends:
            try:
                dep = self.get_module(dep_name, package_obj.node)
            except KeyError:  # pragma: no cover
                continue
            self.add_relationship(package_obj, dep, "type_depends")
</t>
<t tx="ekr.20250131013601.172">@path pylint/pyreverse
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Class to generate files in dot format and image formats supported by Graphviz."""

from __future__ import annotations

import os
import subprocess
import tempfile
from enum import Enum
from pathlib import Path

from astroid import nodes

from pylint.pyreverse.printer import EdgeType, Layout, NodeProperties, NodeType, Printer
from pylint.pyreverse.utils import get_annotation_label


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.173">class HTMLLabels(Enum):
    LINEBREAK_LEFT = '&lt;br ALIGN="LEFT"/&gt;'


</t>
<t tx="ekr.20250131013601.174">ALLOWED_CHARSETS: frozenset[str] = frozenset(("utf-8", "iso-8859-1", "latin1"))
SHAPES: dict[NodeType, str] = {
    NodeType.PACKAGE: "box",
    NodeType.CLASS: "record",
}
# pylint: disable-next=consider-using-namedtuple-or-dataclass
ARROWS: dict[EdgeType, dict[str, str]] = {
    EdgeType.INHERITS: {"arrowtail": "none", "arrowhead": "empty"},
    EdgeType.ASSOCIATION: {
        "fontcolor": "green",
        "arrowtail": "none",
        "arrowhead": "diamond",
        "style": "solid",
    },
    EdgeType.AGGREGATION: {
        "fontcolor": "green",
        "arrowtail": "none",
        "arrowhead": "odiamond",
        "style": "solid",
    },
    EdgeType.USES: {"arrowtail": "none", "arrowhead": "open"},
    EdgeType.TYPE_DEPENDENCY: {
        "arrowtail": "none",
        "arrowhead": "open",
        "style": "dashed",
    },
}


class DotPrinter(Printer):
    @others
</t>
<t tx="ekr.20250131013601.175">DEFAULT_COLOR = "black"

def __init__(
    self,
    title: str,
    layout: Layout | None = None,
    use_automatic_namespace: bool | None = None,
):
    layout = layout or Layout.BOTTOM_TO_TOP
    self.charset = "utf-8"
    super().__init__(title, layout, use_automatic_namespace)

</t>
<t tx="ekr.20250131013601.176">def _open_graph(self) -&gt; None:
    """Emit the header lines."""
    self.emit(f'digraph "{self.title}" {{')
    if self.layout:
        self.emit(f"rankdir={self.layout.value}")
    if self.charset:
        assert(
            self.charset.lower() in ALLOWED_CHARSETS
        ), f"unsupported charset {self.charset}"
        self.emit(f'charset="{self.charset}"')

</t>
<t tx="ekr.20250131013601.177">def emit_node(
    self,
    name: str,
    type_: NodeType,
    properties: NodeProperties | None = None,
) -&gt; None:
    """Create a new node.

    Nodes can be classes, packages, participants etc.
    """
    if properties is None:
        properties = NodeProperties(label=name)
    shape = SHAPES[type_]
    color = properties.color if properties.color is not None else self.DEFAULT_COLOR
    style = "filled" if color != self.DEFAULT_COLOR else "solid"
    label = self._build_label_for_node(properties)
    label_part = f", label=&lt;{label}&gt;" if label else ""
    fontcolor_part = (
        f', fontcolor="{properties.fontcolor}"' if properties.fontcolor else ""
    )
    self.emit(
        f'"{name}" [color="{color}"{fontcolor_part}{label_part}, shape="{shape}", style="{style}"];'
    )

</t>
<t tx="ekr.20250131013601.178">def _build_label_for_node(self, properties: NodeProperties) -&gt; str:
    if not properties.label:
        return ""

    label: str = properties.label
    if properties.attrs is None and properties.methods is None:
        # return a "compact" form which only displays the class name in a box
        return label

    # Add class attributes
    attrs: list[str] = properties.attrs or []
    attrs_string = rf"{HTMLLabels.LINEBREAK_LEFT.value}".join(
        attr.replace("|", r"\|") for attr in attrs
    )
    label = rf"{{{label}|{attrs_string}{HTMLLabels.LINEBREAK_LEFT.value}|"

    # Add class methods
    methods: list[nodes.FunctionDef] = properties.methods or []
    for func in methods:
        args = ", ".join(self._get_method_arguments(func)).replace("|", r"\|")
        method_name = (
            f"&lt;I&gt;{func.name}&lt;/I&gt;" if func.is_abstract() else f"{func.name}"
        )
        label += rf"{method_name}({args})"
        if func.returns:
            annotation_label = get_annotation_label(func.returns)
            label += ": " + self._escape_annotation_label(annotation_label)
        label += rf"{HTMLLabels.LINEBREAK_LEFT.value}"
    label += "}"
    return label

</t>
<t tx="ekr.20250131013601.179">def _escape_annotation_label(self, annotation_label: str) -&gt; str:
    # Escape vertical bar characters to make them appear as a literal characters
    # otherwise it gets treated as field separator of record-based nodes
    annotation_label = annotation_label.replace("|", r"\|")

    return annotation_label

</t>
<t tx="ekr.20250131013601.18">    def _parse_error_mode(self) -&gt; None:
        """Parse the current state of the error mode.

        Error mode: enable only errors; no reports, no persistent.
        """
        if not self._error_mode:
            return

        self.disable_noerror_messages()
        self.disable("miscellaneous")
        self.set_option("reports", False)
        self.set_option("persistent", False)
        self.set_option("score", False)

</t>
<t tx="ekr.20250131013601.180">def emit_edge(
    self,
    from_node: str,
    to_node: str,
    type_: EdgeType,
    label: str | None = None,
) -&gt; None:
    """Create an edge from one node to another to display relationships."""
    arrowstyle = ARROWS[type_]
    attrs = [f'{prop}="{value}"' for prop, value in arrowstyle.items()]
    if label:
        attrs.append(f'label="{label}"')
    self.emit(f'"{from_node}" -&gt; "{to_node}" [{", ".join(sorted(attrs))}];')

</t>
<t tx="ekr.20250131013601.181">def generate(self, outputfile: str) -&gt; None:
    self._close_graph()
    graphviz_extensions = ("dot", "gv")
    name = self.title
    if outputfile is None:
        target = "png"
        pdot, dot_sourcepath = tempfile.mkstemp(".gv", name)
        ppng, outputfile = tempfile.mkstemp(".png", name)
        os.close(pdot)
        os.close(ppng)
    else:
        target = Path(outputfile).suffix.lstrip(".")
        if not target:
            target = "png"
            outputfile = outputfile + "." + target
        if target not in graphviz_extensions:
            pdot, dot_sourcepath = tempfile.mkstemp(".gv", name)
            os.close(pdot)
        else:
            dot_sourcepath = outputfile
    with open(dot_sourcepath, "w", encoding="utf8") as outfile:
        outfile.writelines(self.lines)
    if target not in graphviz_extensions:
        subprocess.run(
            ["dot", "-T", target, dot_sourcepath, "-o", outputfile], check=True
        )
        os.unlink(dot_sourcepath)

</t>
<t tx="ekr.20250131013601.182">def _close_graph(self) -&gt; None:
    """Emit the lines needed to properly close the graph."""
    self.emit("}\n")
</t>
<t tx="ekr.20250131013601.183">@path pylint/pyreverse
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Visitor doing some post-processing on the astroid tree.

Try to resolve definitions (namespace) dictionary, relationship...
"""

from __future__ import annotations

import collections
import os
import traceback
from abc import ABC, abstractmethod
from collections.abc import Callable, Sequence
from typing import Optional

import astroid
from astroid import nodes

from pylint import constants
from pylint.pyreverse import utils

_WrapperFuncT = Callable[
    [Callable[[str], nodes.Module], str, bool], Optional[nodes.Module]
]


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.184">def _astroid_wrapper(
    func: Callable[[str], nodes.Module],
    modname: str,
    verbose: bool = False,
) -&gt; nodes.Module | None:
    if verbose:
        print(f"parsing {modname}...")
    try:
        return func(modname)
    except astroid.exceptions.AstroidBuildingError as exc:
        print(exc)
    except Exception:  # pylint: disable=broad-except
        traceback.print_exc()
    return None


</t>
<t tx="ekr.20250131013601.185">class IdGeneratorMixIn:
    """Mixin adding the ability to generate integer uid."""

    @others
</t>
<t tx="ekr.20250131013601.186">class Project:
    """A project handle a set of modules / packages."""

    @others
</t>
<t tx="ekr.20250131013601.187">class Linker(IdGeneratorMixIn, utils.LocalsVisitor):
    """Walk on the project tree and resolve relationships.

    According to options the following attributes may be
    added to visited nodes:

    * uid,
      a unique identifier for the node (on astroid.Project, astroid.Module,
      astroid.Class and astroid.locals_type). Only if the linker
      has been instantiated with tag=True parameter (False by default).

    * Function
      a mapping from locals names to their bounded value, which may be a
      constant like a string or an integer, or an astroid node
      (on astroid.Module, astroid.Class and astroid.Function).

    * instance_attrs_type
      as locals_type but for klass member attributes (only on astroid.Class)

    * associations_type
      as instance_attrs_type but for association relationships

    * aggregations_type
      as instance_attrs_type but for aggregations relationships
    """

    @others
</t>
<t tx="ekr.20250131013601.188">class AssociationHandlerInterface(ABC):
    @others
</t>
<t tx="ekr.20250131013601.189">class AbstractAssociationHandler(AssociationHandlerInterface):
    """
    Chain of Responsibility for handling types of association, useful
    to expand in the future if we want to add more distinct associations.

    Every link of the chain checks if it's a certain type of association.
    If no association is found it's set as a generic association in `associations_type`.

    The default chaining behavior is implemented inside the base handler
    class.
    """

    @others
</t>
<t tx="ekr.20250131013601.19">    # code checking methods ###################################################

    def get_checkers(self) -&gt; list[BaseChecker]:
        """Return all available checkers as an ordered list."""
        return sorted(c for _checkers in self._checkers.values() for c in _checkers)

</t>
<t tx="ekr.20250131013601.190">class AggregationsHandler(AbstractAssociationHandler):
    @others
</t>
<t tx="ekr.20250131013601.191">class OtherAssociationsHandler(AbstractAssociationHandler):
    @others
</t>
<t tx="ekr.20250131013601.192">def project_from_files(
    files: Sequence[str],
    func_wrapper: _WrapperFuncT = _astroid_wrapper,
    project_name: str = "no name",
    black_list: tuple[str, ...] = constants.DEFAULT_IGNORE_LIST,
    verbose: bool = False,
) -&gt; Project:
    """Return a Project from a list of files or modules."""
    # build the project representation
    astroid_manager = astroid.MANAGER
    project = Project(project_name)
    for something in files:
        if not os.path.exists(something):
            fpath = astroid.modutils.file_from_modpath(something.split("."))
        elif os.path.isdir(something):
            fpath = os.path.join(something, "__init__.py")
        else:
            fpath = something
        ast = func_wrapper(astroid_manager.ast_from_file, fpath, verbose)
        if ast is None:
            continue
        project.path = project.path or ast.file
        project.add_module(ast)
        base_name = ast.name
        # recurse in package except if __init__ was explicitly given
        if ast.package and something.find("__init__") == -1:
            # recurse on others packages / modules if this is a package
            for fpath in astroid.modutils.get_module_files(
                os.path.dirname(ast.file), black_list
            ):
                ast = func_wrapper(astroid_manager.ast_from_file, fpath, verbose)
                if ast is None or ast.name == base_name:
                    continue
                project.add_module(ast)
    return project
</t>
<t tx="ekr.20250131013601.193">def __init__(self, start_value: int = 0) -&gt; None:
    self.id_count = start_value

</t>
<t tx="ekr.20250131013601.194">def init_counter(self, start_value: int = 0) -&gt; None:
    """Init the id counter."""
    self.id_count = start_value

</t>
<t tx="ekr.20250131013601.195">def generate_id(self) -&gt; int:
    """Generate a new identifier."""
    self.id_count += 1
    return self.id_count


</t>
<t tx="ekr.20250131013601.196">def __init__(self, name: str = ""):
    self.name = name
    self.uid: int | None = None
    self.path: str = ""
    self.modules: list[nodes.Module] = []
    self.locals: dict[str, nodes.Module] = {}
    self.__getitem__ = self.locals.__getitem__
    self.__iter__ = self.locals.__iter__
    self.values = self.locals.values
    self.keys = self.locals.keys
    self.items = self.locals.items

</t>
<t tx="ekr.20250131013601.197">def add_module(self, node: nodes.Module) -&gt; None:
    self.locals[node.name] = node
    self.modules.append(node)

</t>
<t tx="ekr.20250131013601.198">def get_module(self, name: str) -&gt; nodes.Module:
    return self.locals[name]

</t>
<t tx="ekr.20250131013601.199">def get_children(self) -&gt; list[nodes.Module]:
    return self.modules

</t>
<t tx="ekr.20250131013601.2">def _read_stdin() -&gt; str:
    # See https://github.com/python/typeshed/pull/5623 for rationale behind assertion
    assert isinstance(sys.stdin, TextIOWrapper)
    sys.stdin = TextIOWrapper(sys.stdin.detach(), encoding="utf-8")
    return sys.stdin.read()


</t>
<t tx="ekr.20250131013601.20">    def get_checker_names(self) -&gt; list[str]:
        """Get all the checker names that this linter knows about."""
        return sorted(
            {
                checker.name
                for checker in self.get_checkers()
                if checker.name != MAIN_CHECKER_NAME
            }
        )

</t>
<t tx="ekr.20250131013601.200">def __repr__(self) -&gt; str:
    return f"&lt;Project {self.name!r} at {id(self)} ({len(self.modules)} modules)&gt;"


</t>
<t tx="ekr.20250131013601.201">def __init__(self, project: Project, tag: bool = False) -&gt; None:
    IdGeneratorMixIn.__init__(self)
    utils.LocalsVisitor.__init__(self)
    # tag nodes or not
    self.tag = tag
    # visited project
    self.project = project
    self.associations_handler = AggregationsHandler()
    self.associations_handler.set_next(OtherAssociationsHandler())

</t>
<t tx="ekr.20250131013601.202">def visit_project(self, node: Project) -&gt; None:
    """Visit a pyreverse.utils.Project node.

    * optionally tag the node with a unique id
    """
    if self.tag:
        node.uid = self.generate_id()
    for module in node.modules:
        self.visit(module)

</t>
<t tx="ekr.20250131013601.203">def visit_module(self, node: nodes.Module) -&gt; None:
    """Visit an astroid.Module node.

    * set the locals_type mapping
    * set the depends mapping
    * optionally tag the node with a unique id
    """
    if hasattr(node, "locals_type"):
        return
    node.locals_type = collections.defaultdict(list)
    node.depends = []
    node.type_depends = []
    if self.tag:
        node.uid = self.generate_id()

</t>
<t tx="ekr.20250131013601.204">def visit_classdef(self, node: nodes.ClassDef) -&gt; None:
    """Visit an astroid.Class node.

    * set the locals_type and instance_attrs_type mappings
    * optionally tag the node with a unique id
    """
    if hasattr(node, "locals_type"):
        return
    node.locals_type = collections.defaultdict(list)
    if self.tag:
        node.uid = self.generate_id()
    # resolve ancestors
    for baseobj in node.ancestors(recurs=False):
        specializations = getattr(baseobj, "specializations", [])
        specializations.append(node)
        baseobj.specializations = specializations
    # resolve instance attributes
    node.instance_attrs_type = collections.defaultdict(list)
    node.aggregations_type = collections.defaultdict(list)
    node.associations_type = collections.defaultdict(list)
    for assignattrs in tuple(node.instance_attrs.values()):
        for assignattr in assignattrs:
            if not isinstance(assignattr, nodes.Unknown):
                self.associations_handler.handle(assignattr, node)
                self.handle_assignattr_type(assignattr, node)

</t>
<t tx="ekr.20250131013601.205">def visit_functiondef(self, node: nodes.FunctionDef) -&gt; None:
    """Visit an astroid.Function node.

    * set the locals_type mapping
    * optionally tag the node with a unique id
    """
    if hasattr(node, "locals_type"):
        return
    node.locals_type = collections.defaultdict(list)
    if self.tag:
        node.uid = self.generate_id()

</t>
<t tx="ekr.20250131013601.206">def visit_assignname(self, node: nodes.AssignName) -&gt; None:
    """Visit an astroid.AssignName node.

    handle locals_type
    """
    # avoid double parsing done by different Linkers.visit
    # running over the same project:
    if hasattr(node, "_handled"):
        return
    node._handled = True
    if node.name in node.frame():
        frame = node.frame()
    else:
        # the name has been defined as 'global' in the frame and belongs
        # there.
        frame = node.root()
    if not hasattr(frame, "locals_type"):
        # If the frame doesn't have a locals_type yet,
        # it means it wasn't yet visited. Visit it now
        # to add what's missing from it.
        if isinstance(frame, nodes.ClassDef):
            self.visit_classdef(frame)
        elif isinstance(frame, nodes.FunctionDef):
            self.visit_functiondef(frame)
        else:
            self.visit_module(frame)

    current = frame.locals_type[node.name]
    frame.locals_type[node.name] = list(set(current) | utils.infer_node(node))

</t>
<t tx="ekr.20250131013601.207">@staticmethod
def handle_assignattr_type(node: nodes.AssignAttr, parent: nodes.ClassDef) -&gt; None:
    """Handle an astroid.assignattr node.

    handle instance_attrs_type
    """
    current = set(parent.instance_attrs_type[node.attrname])
    parent.instance_attrs_type[node.attrname] = list(
        current | utils.infer_node(node)
    )

</t>
<t tx="ekr.20250131013601.208">def visit_import(self, node: nodes.Import) -&gt; None:
    """Visit an astroid.Import node.

    resolve module dependencies
    """
    context_file = node.root().file
    for name in node.names:
        relative = astroid.modutils.is_relative(name[0], context_file)
        self._imported_module(node, name[0], relative)

</t>
<t tx="ekr.20250131013601.209">def visit_importfrom(self, node: nodes.ImportFrom) -&gt; None:
    """Visit an astroid.ImportFrom node.

    resolve module dependencies
    """
    basename = node.modname
    context_file = node.root().file
    if context_file is not None:
        relative = astroid.modutils.is_relative(basename, context_file)
    else:
        relative = False
    for name in node.names:
        if name[0] == "*":
            continue
        # analyze dependencies
        fullname = f"{basename}.{name[0]}"
        if fullname.find(".") &gt; -1:
            try:
                fullname = astroid.modutils.get_module_part(fullname, context_file)
            except ImportError:
                continue
        if fullname != basename:
            self._imported_module(node, fullname, relative)

</t>
<t tx="ekr.20250131013601.21">    def prepare_checkers(self) -&gt; list[BaseChecker]:
        """Return checkers needed for activated messages and reports."""
        if not self.config.reports:
            self.disable_reporters()
        # get needed checkers
        needed_checkers: list[BaseChecker] = [self]
        for checker in self.get_checkers()[1:]:
            messages = {msg for msg in checker.msgs if self.is_message_enabled(msg)}
            if messages or any(self.report_is_enabled(r[0]) for r in checker.reports):
                needed_checkers.append(checker)
        return needed_checkers

</t>
<t tx="ekr.20250131013601.210">def compute_module(self, context_name: str, mod_path: str) -&gt; bool:
    """Should the module be added to dependencies ?"""
    package_dir = os.path.dirname(self.project.path)
    if context_name == mod_path:
        return False
    # astroid does return a boolean but is not typed correctly yet

    return astroid.modutils.module_in_path(mod_path, (package_dir,))  # type: ignore[no-any-return]

</t>
<t tx="ekr.20250131013601.211">def _imported_module(
    self, node: nodes.Import | nodes.ImportFrom, mod_path: str, relative: bool
) -&gt; None:
    """Notify an imported module, used to analyze dependencies."""
    module = node.root()
    context_name = module.name
    if relative:
        mod_path = f"{'.'.join(context_name.split('.')[:-1])}.{mod_path}"
    if self.compute_module(context_name, mod_path):
        # handle dependencies
        if not hasattr(module, "depends"):
            module.depends = []
        mod_paths = module.depends
        if mod_path not in mod_paths:
            mod_paths.append(mod_path)


</t>
<t tx="ekr.20250131013601.212">@abstractmethod
def set_next(
    self, handler: AssociationHandlerInterface
) -&gt; AssociationHandlerInterface:
    pass

</t>
<t tx="ekr.20250131013601.213">@abstractmethod
def handle(self, node: nodes.AssignAttr, parent: nodes.ClassDef) -&gt; None:
    pass


</t>
<t tx="ekr.20250131013601.214">_next_handler: AssociationHandlerInterface

def set_next(
    self, handler: AssociationHandlerInterface
) -&gt; AssociationHandlerInterface:
    self._next_handler = handler
    return handler

</t>
<t tx="ekr.20250131013601.215">@abstractmethod
def handle(self, node: nodes.AssignAttr, parent: nodes.ClassDef) -&gt; None:
    if self._next_handler:
        self._next_handler.handle(node, parent)


</t>
<t tx="ekr.20250131013601.216">def handle(self, node: nodes.AssignAttr, parent: nodes.ClassDef) -&gt; None:
    if isinstance(node.parent, (nodes.AnnAssign, nodes.Assign)) and isinstance(
        node.parent.value, astroid.node_classes.Name
    ):
        current = set(parent.aggregations_type[node.attrname])
        parent.aggregations_type[node.attrname] = list(
            current | utils.infer_node(node)
        )
    else:
        super().handle(node, parent)


</t>
<t tx="ekr.20250131013601.217">def handle(self, node: nodes.AssignAttr, parent: nodes.ClassDef) -&gt; None:
    current = set(parent.associations_type[node.attrname])
    parent.associations_type[node.attrname] = list(current | utils.infer_node(node))


</t>
<t tx="ekr.20250131013601.218">@path pylint/pyreverse
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Create UML diagrams for classes and modules in &lt;packages&gt;."""

from __future__ import annotations

import sys
from collections.abc import Sequence

from pylint import constants
from pylint.config.arguments_manager import _ArgumentsManager
from pylint.config.arguments_provider import _ArgumentsProvider
from pylint.lint import discover_package_path
from pylint.lint.utils import augmented_sys_path
from pylint.pyreverse import writer
from pylint.pyreverse.diadefslib import DiadefsHandler
from pylint.pyreverse.inspector import Linker, project_from_files
from pylint.pyreverse.utils import (
    check_graphviz_availability,
    check_if_graphviz_supports_format,
    insert_default_options,
)
from pylint.typing import Options

DIRECTLY_SUPPORTED_FORMATS = (
    "dot",
    "puml",
    "plantuml",
    "mmd",
    "html",
)

DEFAULT_COLOR_PALETTE = (
    # colorblind scheme taken from https://personal.sron.nl/~pault/
    "#77AADD",  # light blue
    "#99DDFF",  # light cyan
    "#44BB99",  # mint
    "#BBCC33",  # pear
    "#AAAA00",  # olive
    "#EEDD88",  # light yellow
    "#EE8866",  # orange
    "#FFAABB",  # pink
    "#DDDDDD",  # pale grey
)


OPTIONS_GROUPS = {
    "FILTERING": "Filtering and Scope",
    "DISPLAY": "Display Options",
    "OUTPUT": "Output Control",
    "PROJECT": "Project Configuration",
}


OPTIONS: Options = (
    # Filtering and Scope options
    (
        "filter-mode",
        {
            "short": "f",
            "default": "PUB_ONLY",
            "dest": "mode",
            "type": "string",
            "action": "store",
            "metavar": "&lt;mode&gt;",
            "group": OPTIONS_GROUPS["FILTERING"],
            "help": """Filter attributes and functions according to &lt;mode&gt;. Correct modes are:
'PUB_ONLY' filter all non public attributes [DEFAULT], equivalent to PRIVATE+SPECIAL
'ALL' no filter
'SPECIAL' filter Python special functions except constructor
'OTHER' filter protected and private attributes""",
        },
    ),
    (
        "class",
        {
            "short": "c",
            "action": "extend",
            "metavar": "&lt;class&gt;",
            "type": "csv",
            "dest": "classes",
            "default": None,
            "group": OPTIONS_GROUPS["FILTERING"],
            "help": "Create a class diagram with all classes related to &lt;class&gt;;\
 this uses by default the options -ASmy",
        },
    ),
    (
        "show-ancestors",
        {
            "short": "a",
            "action": "store",
            "metavar": "&lt;ancestor&gt;",
            "type": "int",
            "default": None,
            "group": OPTIONS_GROUPS["FILTERING"],
            "help": "Show &lt;ancestor&gt; generations of ancestor classes not in &lt;projects&gt;.",
        },
    ),
    (
        "all-ancestors",
        {
            "short": "A",
            "default": None,
            "action": "store_true",
            "group": OPTIONS_GROUPS["FILTERING"],
            "help": "Show all ancestors of all classes in &lt;projects&gt;.",
        },
    ),
    (
        "show-associated",
        {
            "short": "s",
            "action": "store",
            "metavar": "&lt;association_level&gt;",
            "type": "int",
            "default": None,
            "group": OPTIONS_GROUPS["FILTERING"],
            "help": "Show &lt;association_level&gt; levels of associated classes not in &lt;projects&gt;.",
        },
    ),
    (
        "all-associated",
        {
            "short": "S",
            "default": None,
            "action": "store_true",
            "group": OPTIONS_GROUPS["FILTERING"],
            "help": "Show all classes associated with the target classes, including indirect associations.",
        },
    ),
    (
        "show-builtin",
        {
            "short": "b",
            "action": "store_true",
            "default": False,
            "group": OPTIONS_GROUPS["FILTERING"],
            "help": "Include builtin objects in representation of classes.",
        },
    ),
    (
        "show-stdlib",
        {
            "short": "L",
            "action": "store_true",
            "default": False,
            "group": OPTIONS_GROUPS["FILTERING"],
            "help": "Include standard library objects in representation of classes.",
        },
    ),
    (
        "max-depth",
        {
            "dest": "max_depth",
            "action": "store",
            "default": None,
            "metavar": "&lt;depth&gt;",
            "type": "int",
            "group": OPTIONS_GROUPS["FILTERING"],
            "help": (
                "Maximum depth in package/module hierarchy to display. A depth of 0 shows only "
                "top-level packages, 1 shows one level of subpackages, etc. If not specified, "
                "all packages/modules are shown."
            ),
        },
    ),
    # Display Options
    (
        "module-names",
        {
            "short": "m",
            "default": None,
            "type": "yn",
            "metavar": "&lt;y or n&gt;",
            "group": OPTIONS_GROUPS["DISPLAY"],
            "help": "Include module name in the representation of classes.",
        },
    ),
    (
        "only-classnames",
        {
            "short": "k",
            "action": "store_true",
            "default": False,
            "group": OPTIONS_GROUPS["DISPLAY"],
            "help": "Don't show attributes and methods in the class boxes; this disables -f values.",
        },
    ),
    (
        "no-standalone",
        {
            "action": "store_true",
            "default": False,
            "group": OPTIONS_GROUPS["DISPLAY"],
            "help": "Only show nodes with connections.",
        },
    ),
    (
        "colorized",
        {
            "dest": "colorized",
            "action": "store_true",
            "default": False,
            "group": OPTIONS_GROUPS["DISPLAY"],
            "help": "Use colored output. Classes/modules of the same package get the same color.",
        },
    ),
    (
        "max-color-depth",
        {
            "dest": "max_color_depth",
            "action": "store",
            "default": 2,
            "metavar": "&lt;depth&gt;",
            "type": "int",
            "group": OPTIONS_GROUPS["DISPLAY"],
            "help": "Use separate colors up to package depth of &lt;depth&gt;. Higher depths will reuse colors.",
        },
    ),
    (
        "color-palette",
        {
            "dest": "color_palette",
            "action": "store",
            "default": DEFAULT_COLOR_PALETTE,
            "metavar": "&lt;color1,color2,...&gt;",
            "type": "csv",
            "group": OPTIONS_GROUPS["DISPLAY"],
            "help": "Comma separated list of colors to use for the package depth coloring.",
        },
    ),
    # Output Control options
    (
        "output",
        {
            "short": "o",
            "dest": "output_format",
            "action": "store",
            "default": "dot",
            "metavar": "&lt;format&gt;",
            "type": "string",
            "group": OPTIONS_GROUPS["OUTPUT"],
            "help": (
                "Create a *.&lt;format&gt; output file if format is available. Available "
                f"formats are: {', '.join('.' + fmt for fmt in DIRECTLY_SUPPORTED_FORMATS)}. Any other "
                "format will be tried to be created by using the 'dot' command line "
                "tool, which requires a graphviz installation. In this case, these additional "
                "formats are available (see `Graphviz output formats &lt;https://graphviz.org/docs/outputs/&gt;`_)."
            ),
        },
    ),
    (
        "output-directory",
        {
            "default": "",
            "type": "path",
            "short": "d",
            "action": "store",
            "metavar": "&lt;output_directory&gt;",
            "group": OPTIONS_GROUPS["OUTPUT"],
            "help": "Set the output directory path.",
        },
    ),
    # Project Configuration options
    (
        "ignore",
        {
            "type": "csv",
            "metavar": "&lt;file[,file...]&gt;",
            "dest": "ignore_list",
            "default": constants.DEFAULT_IGNORE_LIST,
            "group": OPTIONS_GROUPS["PROJECT"],
            "help": "Files or directories to be skipped. They should be base names, not paths.",
        },
    ),
    (
        "project",
        {
            "default": "",
            "type": "string",
            "short": "p",
            "metavar": "&lt;project name&gt;",
            "group": OPTIONS_GROUPS["PROJECT"],
            "help": "Set the project name. This will later be appended to the output file names.",
        },
    ),
    (
        "source-roots",
        {
            "type": "glob_paths_csv",
            "metavar": "&lt;path&gt;[,&lt;path&gt;...]",
            "default": (),
            "group": OPTIONS_GROUPS["PROJECT"],
            "help": "Add paths to the list of the source roots. Supports globbing patterns. The "
            "source root is an absolute path or a path relative to the current working directory "
            "used to determine a package namespace for modules located under the source root.",
        },
    ),
    (
        "verbose",
        {
            "action": "store_true",
            "default": False,
            "group": OPTIONS_GROUPS["PROJECT"],
            "help": "Makes pyreverse more verbose/talkative. Mostly useful for debugging.",
        },
    ),
)


# Base class providing common behaviour for pyreverse commands
@others
if __name__ == "__main__":
    arguments = sys.argv[1:]
    Run(arguments).run()
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.219">class Run(_ArgumentsManager, _ArgumentsProvider):
    @others
</t>
<t tx="ekr.20250131013601.22">    # pylint: disable=unused-argument
    @staticmethod
    def should_analyze_file(modname: str, path: str, is_argument: bool = False) -&gt; bool:
        """Returns whether a module should be checked.

        This implementation returns True for all python source files (.py and .pyi),
        indicating that all files should be linted.

        Subclasses may override this method to indicate that modules satisfying
        certain conditions should not be linted.

        :param str modname: The name of the module to be checked.
        :param str path: The full path to the source code of the module.
        :param bool is_argument: Whether the file is an argument to pylint or not.
                                 Files which respect this property are always
                                 checked, since the user requested it explicitly.
        :returns: True if the module should be checked.
        """
        if is_argument:
            return True
        return path.endswith((".py", ".pyi"))

</t>
<t tx="ekr.20250131013601.220">options = OPTIONS
name = "pyreverse"

def __init__(self, args: Sequence[str]) -&gt; None:
    # Immediately exit if user asks for version
    if "--version" in args:
        print("pyreverse is included in pylint:")
        print(constants.full_version)
        sys.exit(0)

    _ArgumentsManager.__init__(self, prog="pyreverse", description=__doc__)
    _ArgumentsProvider.__init__(self, self)

    # Parse options
    insert_default_options()
    self.args = self._parse_command_line_configuration(args)

    if self.config.output_format not in DIRECTLY_SUPPORTED_FORMATS:
        check_graphviz_availability()
        print(
            f"Format {self.config.output_format} is not supported natively."
            " Pyreverse will try to generate it using Graphviz..."
        )
        check_if_graphviz_supports_format(self.config.output_format)

</t>
<t tx="ekr.20250131013601.221">def run(self) -&gt; int:
    """Checking arguments and run project."""
    if not self.args:
        print(self.help())
        return 1
    extra_packages_paths = list(
        {discover_package_path(arg, self.config.source_roots) for arg in self.args}
    )
    with augmented_sys_path(extra_packages_paths):
        project = project_from_files(
            self.args,
            project_name=self.config.project,
            black_list=self.config.ignore_list,
            verbose=self.config.verbose,
        )
        linker = Linker(project, tag=True)
        handler = DiadefsHandler(self.config)
        diadefs = handler.get_diadefs(project, linker)
    writer.DiagramWriter(self.config).write(diadefs)
    return 0


</t>
<t tx="ekr.20250131013601.222">@path pylint/pyreverse
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Class to generate files in mermaidjs format."""

from __future__ import annotations

from pylint.pyreverse.printer import EdgeType, NodeProperties, NodeType, Printer
from pylint.pyreverse.utils import get_annotation_label


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.223">class MermaidJSPrinter(Printer):
    """Printer for MermaidJS diagrams."""

    @others
</t>
<t tx="ekr.20250131013601.224">class HTMLMermaidJSPrinter(MermaidJSPrinter):
    """Printer for MermaidJS diagrams wrapped in a html boilerplate."""

@others
</t>
<t tx="ekr.20250131013601.225">DEFAULT_COLOR = "black"

NODES: dict[NodeType, str] = {
    NodeType.CLASS: "class",
    NodeType.PACKAGE: "class",
}
ARROWS: dict[EdgeType, str] = {
    EdgeType.INHERITS: "--|&gt;",
    EdgeType.ASSOCIATION: "--*",
    EdgeType.AGGREGATION: "--o",
    EdgeType.USES: "--&gt;",
    EdgeType.TYPE_DEPENDENCY: "..&gt;",
}

def _open_graph(self) -&gt; None:
    """Emit the header lines."""
    self.emit("classDiagram")
    self._inc_indent()

</t>
<t tx="ekr.20250131013601.226">def emit_node(
    self,
    name: str,
    type_: NodeType,
    properties: NodeProperties | None = None,
) -&gt; None:
    """Create a new node.

    Nodes can be classes, packages, participants etc.
    """
    # pylint: disable=duplicate-code
    if properties is None:
        properties = NodeProperties(label=name)
    nodetype = self.NODES[type_]
    body = []
    if properties.attrs:
        body.extend(properties.attrs)
    if properties.methods:
        for func in properties.methods:
            args = self._get_method_arguments(func)
            line = f"{func.name}({', '.join(args)})"
            line += "*" if func.is_abstract() else ""
            if func.returns:
                line += f" {get_annotation_label(func.returns)}"
            body.append(line)
    name = name.split(".")[-1]
    self.emit(f"{nodetype} {name} {{")
    self._inc_indent()
    for line in body:
        self.emit(line)
    self._dec_indent()
    self.emit("}")

</t>
<t tx="ekr.20250131013601.227">def emit_edge(
    self,
    from_node: str,
    to_node: str,
    type_: EdgeType,
    label: str | None = None,
) -&gt; None:
    """Create an edge from one node to another to display relationships."""
    from_node = from_node.split(".")[-1]
    to_node = to_node.split(".")[-1]
    edge = f"{from_node} {self.ARROWS[type_]} {to_node}"
    if label:
        edge += f" : {label}"
    self.emit(edge)

</t>
<t tx="ekr.20250131013601.228">def _close_graph(self) -&gt; None:
    """Emit the lines needed to properly close the graph."""
    self._dec_indent()


</t>
<t tx="ekr.20250131013601.229">    HTML_OPEN_BOILERPLATE = """&lt;html&gt;
  &lt;body&gt;
    &lt;script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"&gt;&lt;/script&gt;
      &lt;div class="mermaid"&gt;
    """
    HTML_CLOSE_BOILERPLATE = """
       &lt;/div&gt;
  &lt;/body&gt;
&lt;/html&gt;
"""
    GRAPH_INDENT_LEVEL = 4

    def _open_graph(self) -&gt; None:
        self.emit(self.HTML_OPEN_BOILERPLATE)
        for _ in range(self.GRAPH_INDENT_LEVEL):
            self._inc_indent()
        super()._open_graph()

</t>
<t tx="ekr.20250131013601.23">    # pylint: enable=unused-argument

    def initialize(self) -&gt; None:
        """Initialize linter for linting.

        This method is called before any linting is done.
        """
        self._ignore_paths = self.config.ignore_paths
        # initialize msgs_state now that all messages have been registered into
        # the store
        for msg in self.msgs_store.messages:
            if not msg.may_be_emitted(self.config.py_version):
                self._msgs_state[msg.msgid] = False

</t>
<t tx="ekr.20250131013601.230">    def _close_graph(self) -&gt; None:
        for _ in range(self.GRAPH_INDENT_LEVEL):
            self._dec_indent()
        self.emit(self.HTML_CLOSE_BOILERPLATE)
</t>
<t tx="ekr.20250131013601.231">@path pylint/pyreverse
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Class to generate files in dot format and image formats supported by Graphviz."""

from __future__ import annotations

from pylint.pyreverse.printer import EdgeType, Layout, NodeProperties, NodeType, Printer
from pylint.pyreverse.utils import get_annotation_label


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.232">class PlantUmlPrinter(Printer):
    """Printer for PlantUML diagrams."""

    @others
</t>
<t tx="ekr.20250131013601.233">DEFAULT_COLOR = "black"

NODES: dict[NodeType, str] = {
    NodeType.CLASS: "class",
    NodeType.PACKAGE: "package",
}
ARROWS: dict[EdgeType, str] = {
    EdgeType.INHERITS: "--|&gt;",
    EdgeType.ASSOCIATION: "--*",
    EdgeType.AGGREGATION: "--o",
    EdgeType.USES: "--&gt;",
    EdgeType.TYPE_DEPENDENCY: "..&gt;",
}

def _open_graph(self) -&gt; None:
    """Emit the header lines."""
    self.emit("@startuml " + self.title)
    if not self.use_automatic_namespace:
        self.emit("set namespaceSeparator none")
    if self.layout:
        if self.layout is Layout.LEFT_TO_RIGHT:
            self.emit("left to right direction")
        elif self.layout is Layout.TOP_TO_BOTTOM:
            self.emit("top to bottom direction")
        else:
            raise ValueError(
                f"Unsupported layout {self.layout}. PlantUmlPrinter only "
                "supports left to right and top to bottom layout."
            )

</t>
<t tx="ekr.20250131013601.234">def emit_node(
    self,
    name: str,
    type_: NodeType,
    properties: NodeProperties | None = None,
) -&gt; None:
    """Create a new node.

    Nodes can be classes, packages, participants etc.
    """
    if properties is None:
        properties = NodeProperties(label=name)
    nodetype = self.NODES[type_]
    if properties.color and properties.color != self.DEFAULT_COLOR:
        color = f" #{properties.color.lstrip('#')}"
    else:
        color = ""
    body = []
    if properties.attrs:
        body.extend(properties.attrs)
    if properties.methods:
        for func in properties.methods:
            args = self._get_method_arguments(func)
            line = "{abstract}" if func.is_abstract() else ""
            line += f"{func.name}({', '.join(args)})"
            if func.returns:
                line += " -&gt; " + get_annotation_label(func.returns)
            body.append(line)
    label = properties.label if properties.label is not None else name
    if properties.fontcolor and properties.fontcolor != self.DEFAULT_COLOR:
        label = f"&lt;color:{properties.fontcolor}&gt;{label}&lt;/color&gt;"
    self.emit(f'{nodetype} "{label}" as {name}{color} {{')
    self._inc_indent()
    for line in body:
        self.emit(line)
    self._dec_indent()
    self.emit("}")

</t>
<t tx="ekr.20250131013601.235">def emit_edge(
    self,
    from_node: str,
    to_node: str,
    type_: EdgeType,
    label: str | None = None,
) -&gt; None:
    """Create an edge from one node to another to display relationships."""
    edge = f"{from_node} {self.ARROWS[type_]} {to_node}"
    if label:
        edge += f" : {label}"
    self.emit(edge)

</t>
<t tx="ekr.20250131013601.236">def _close_graph(self) -&gt; None:
    """Emit the lines needed to properly close the graph."""
    self.emit("@enduml")
</t>
<t tx="ekr.20250131013601.237">@path pylint/pyreverse
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Base class defining the interface for a printer."""

from __future__ import annotations

from abc import ABC, abstractmethod
from enum import Enum
from typing import NamedTuple

from astroid import nodes

from pylint.pyreverse.utils import get_annotation_label


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.238">class NodeType(Enum):
    CLASS = "class"
    PACKAGE = "package"


</t>
<t tx="ekr.20250131013601.239">class EdgeType(Enum):
    INHERITS = "inherits"
    ASSOCIATION = "association"
    AGGREGATION = "aggregation"
    USES = "uses"
    TYPE_DEPENDENCY = "type_dependency"


</t>
<t tx="ekr.20250131013601.24">    def _discover_files(self, files_or_modules: Sequence[str]) -&gt; Iterator[str]:
        """Discover python modules and packages in sub-directory.

        Returns iterator of paths to discovered modules and packages.
        """
        for something in files_or_modules:
            if os.path.isdir(something) and not os.path.isfile(
                os.path.join(something, "__init__.py")
            ):
                skip_subtrees: list[str] = []
                for root, _, files in os.walk(something):
                    if any(root.startswith(s) for s in skip_subtrees):
                        # Skip subtree of already discovered package.
                        continue

                    if _is_ignored_file(
                        root,
                        self.config.ignore,
                        self.config.ignore_patterns,
                        self.config.ignore_paths,
                    ):
                        skip_subtrees.append(root)
                        continue

                    if "__init__.py" in files:
                        skip_subtrees.append(root)
                        yield root
                    else:
                        yield from(
                            os.path.join(root, file)
                            for file in files
                            if file.endswith((".py", ".pyi"))
                        )
            else:
                yield something

</t>
<t tx="ekr.20250131013601.240">class Layout(Enum):
    LEFT_TO_RIGHT = "LR"
    RIGHT_TO_LEFT = "RL"
    TOP_TO_BOTTOM = "TB"
    BOTTOM_TO_TOP = "BT"


</t>
<t tx="ekr.20250131013601.241">class NodeProperties(NamedTuple):
    label: str
    attrs: list[str] | None = None
    methods: list[nodes.FunctionDef] | None = None
    color: str | None = None
    fontcolor: str | None = None


</t>
<t tx="ekr.20250131013601.242">class Printer(ABC):
    """Base class defining the interface for a printer."""

    @others
</t>
<t tx="ekr.20250131013601.243">def __init__(
    self,
    title: str,
    layout: Layout | None = None,
    use_automatic_namespace: bool | None = None,
) -&gt; None:
    self.title: str = title
    self.layout = layout
    self.use_automatic_namespace = use_automatic_namespace
    self.lines: list[str] = []
    self._indent = ""
    self._open_graph()

</t>
<t tx="ekr.20250131013601.244">def _inc_indent(self) -&gt; None:
    """Increment indentation."""
    self._indent += "  "

</t>
<t tx="ekr.20250131013601.245">def _dec_indent(self) -&gt; None:
    """Decrement indentation."""
    self._indent = self._indent[:-2]

</t>
<t tx="ekr.20250131013601.246">@abstractmethod
def _open_graph(self) -&gt; None:
    """Emit the header lines, i.e. all boilerplate code that defines things like
    layout etc.
    """

</t>
<t tx="ekr.20250131013601.247">def emit(self, line: str, force_newline: bool | None = True) -&gt; None:
    if force_newline and not line.endswith("\n"):
        line += "\n"
    self.lines.append(self._indent + line)

</t>
<t tx="ekr.20250131013601.248">@abstractmethod
def emit_node(
    self,
    name: str,
    type_: NodeType,
    properties: NodeProperties | None = None,
) -&gt; None:
    """Create a new node.

    Nodes can be classes, packages, participants etc.
    """

</t>
<t tx="ekr.20250131013601.249">@abstractmethod
def emit_edge(
    self,
    from_node: str,
    to_node: str,
    type_: EdgeType,
    label: str | None = None,
) -&gt; None:
    """Create an edge from one node to another to display relationships."""

</t>
<t tx="ekr.20250131013601.25">    def check(self, files_or_modules: Sequence[str]) -&gt; None:
        """Main checking entry: check a list of files or modules from their name.

        files_or_modules is either a string or list of strings presenting modules to check.
        """
        self.initialize()
        if self.config.recursive:
            files_or_modules = tuple(self._discover_files(files_or_modules))
        if self.config.from_stdin:
            if len(files_or_modules) != 1:
                raise exceptions.InvalidArgsError(
                    "Missing filename required for --from-stdin"
                )

        extra_packages_paths = list(
            dict.fromkeys(
                [
                    discover_package_path(file_or_module, self.config.source_roots)
                    for file_or_module in files_or_modules
                ]
            ).keys()
        )

        # TODO: Move the parallel invocation into step 3 of the checking process
        if not self.config.from_stdin and self.config.jobs &gt; 1:
            original_sys_path = sys.path[:]
            check_parallel(
                self,
                self.config.jobs,
                self._iterate_file_descrs(files_or_modules),
                extra_packages_paths,
            )
            sys.path = original_sys_path
            return

        progress_reporter = ProgressReporter(self.verbose)

        # 1) Get all FileItems
        with augmented_sys_path(extra_packages_paths):
            if self.config.from_stdin:
                fileitems = self._get_file_descr_from_stdin(files_or_modules[0])
                data: str | None = _read_stdin()
            else:
                fileitems = self._iterate_file_descrs(files_or_modules)
                data = None

        # The contextmanager also opens all checkers and sets up the PyLinter class
        with augmented_sys_path(extra_packages_paths):
            with self._astroid_module_checker() as check_astroid_module:
                # 2) Get the AST for each FileItem
                ast_per_fileitem = self._get_asts(fileitems, data, progress_reporter)

                # 3) Lint each ast
                self._lint_files(
                    ast_per_fileitem, check_astroid_module, progress_reporter
                )

</t>
<t tx="ekr.20250131013601.250">@staticmethod
def _get_method_arguments(method: nodes.FunctionDef) -&gt; list[str]:
    if method.args.args is None:
        return []

    first_arg = 0 if method.type in {"function", "staticmethod"} else 1
    arguments: list[nodes.AssignName] = method.args.args[first_arg:]

    annotations = dict(zip(arguments, method.args.annotations[first_arg:]))
    for arg in arguments:
        annotation_label = ""
        ann = annotations.get(arg)
        if ann:
            annotation_label = get_annotation_label(ann)
        annotations[arg] = annotation_label

    return [
        f"{arg.name}: {ann}" if ann else f"{arg.name}"
        for arg, ann in annotations.items()
    ]

</t>
<t tx="ekr.20250131013601.251">def generate(self, outputfile: str) -&gt; None:
    """Generate and save the final outputfile."""
    self._close_graph()
    with open(outputfile, "w", encoding="utf-8") as outfile:
        outfile.writelines(self.lines)

</t>
<t tx="ekr.20250131013601.252">@abstractmethod
def _close_graph(self) -&gt; None:
    """Emit the lines needed to properly close the graph."""
</t>
<t tx="ekr.20250131013601.253">@path pylint/pyreverse
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

from pylint.pyreverse.dot_printer import DotPrinter
from pylint.pyreverse.mermaidjs_printer import HTMLMermaidJSPrinter, MermaidJSPrinter
from pylint.pyreverse.plantuml_printer import PlantUmlPrinter
from pylint.pyreverse.printer import Printer

filetype_to_printer: dict[str, type[Printer]] = {
    "plantuml": PlantUmlPrinter,
    "puml": PlantUmlPrinter,
    "mmd": MermaidJSPrinter,
    "html": HTMLMermaidJSPrinter,
    "dot": DotPrinter,
}


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.254">def get_printer_for_filetype(filetype: str) -&gt; type[Printer]:
    return filetype_to_printer.get(filetype, DotPrinter)
</t>
<t tx="ekr.20250131013601.255">@path pylint/pyreverse
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Generic classes/functions for pyreverse core/extensions."""

from __future__ import annotations

import os
import re
import shutil
import subprocess
import sys
from collections.abc import Callable
from typing import TYPE_CHECKING, Any, Optional, Union

import astroid
from astroid import nodes
from astroid.typing import InferenceResult

if TYPE_CHECKING:
    from pylint.pyreverse.diagrams import ClassDiagram, PackageDiagram

    _CallbackT = Callable[
        [nodes.NodeNG],
        Union[tuple[ClassDiagram], tuple[PackageDiagram, ClassDiagram], None],
    ]
    _CallbackTupleT = tuple[Optional[_CallbackT], Optional[_CallbackT]]


RCFILE = ".pyreverserc"


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.256">def get_default_options() -&gt; list[str]:
    """Read config file and return list of options."""
    options = []
    home = os.environ.get("HOME", "")
    if home:
        rcfile = os.path.join(home, RCFILE)
        try:
            with open(rcfile, encoding="utf-8") as file_handle:
                options = file_handle.read().split()
        except OSError:
            pass  # ignore if no config file found
    return options


</t>
<t tx="ekr.20250131013601.257">def insert_default_options() -&gt; None:
    """Insert default options to sys.argv."""
    options = get_default_options()
    options.reverse()
    for arg in options:
        sys.argv.insert(1, arg)


</t>
<t tx="ekr.20250131013601.258"># astroid utilities ###########################################################
SPECIAL = re.compile(r"^__([^\W_]_*)+__$")
PRIVATE = re.compile(r"^__(_*[^\W_])+_?$")
PROTECTED = re.compile(r"^_\w*$")


def get_visibility(name: str) -&gt; str:
    """Return the visibility from a name: public, protected, private or special."""
    if SPECIAL.match(name):
        visibility = "special"
    elif PRIVATE.match(name):
        visibility = "private"
    elif PROTECTED.match(name):
        visibility = "protected"

    else:
        visibility = "public"
    return visibility


</t>
<t tx="ekr.20250131013601.259">def is_exception(node: nodes.ClassDef) -&gt; bool:
    # bw compatibility
    return node.type == "exception"  # type: ignore[no-any-return]


</t>
<t tx="ekr.20250131013601.26">    def _get_asts(
        self,
        fileitems: Iterator[FileItem],
        data: str | None,
        progress_reporter: ProgressReporter,
    ) -&gt; dict[FileItem, nodes.Module | None]:
        """Get the AST for all given FileItems."""
        ast_per_fileitem: dict[FileItem, nodes.Module | None] = {}

        progress_reporter.start_get_asts()

        for fileitem in fileitems:
            progress_reporter.get_ast_for_file(fileitem.filepath)
            self.set_current_module(fileitem.name, fileitem.filepath)

            try:
                ast_per_fileitem[fileitem] = self.get_ast(
                    fileitem.filepath, fileitem.name, data
                )
            except astroid.AstroidBuildingError as ex:
                template_path = prepare_crash_report(
                    ex, fileitem.filepath, self.crash_file_path
                )
                msg = get_fatal_error_message(fileitem.filepath, template_path)
                self.add_message(
                    "astroid-error",
                    args=(fileitem.filepath, msg),
                    confidence=HIGH,
                )

        return ast_per_fileitem

</t>
<t tx="ekr.20250131013601.260"># Helpers #####################################################################

_SPECIAL = 2
_PROTECTED = 4
_PRIVATE = 8
MODES = {
    "ALL": 0,
    "PUB_ONLY": _SPECIAL + _PROTECTED + _PRIVATE,
    "SPECIAL": _SPECIAL,
    "OTHER": _PROTECTED + _PRIVATE,
}
VIS_MOD = {
    "special": _SPECIAL,
    "protected": _PROTECTED,
    "private": _PRIVATE,
    "public": 0,
}


class FilterMixIn:
    """Filter nodes according to a mode and nodes' visibility."""

    @others
</t>
<t tx="ekr.20250131013601.261">class LocalsVisitor:
    """Visit a project by traversing the locals dictionary.

    * visit_&lt;class name&gt; on entering a node, where class name is the class of
    the node in lower case

    * leave_&lt;class name&gt; on leaving a node, where class name is the class of
    the node in lower case
    """

    @others
</t>
<t tx="ekr.20250131013601.262">def get_annotation_label(ann: nodes.Name | nodes.NodeNG) -&gt; str:
    if isinstance(ann, nodes.Name) and ann.name is not None:
        return ann.name  # type: ignore[no-any-return]
    if isinstance(ann, nodes.NodeNG):
        return ann.as_string()  # type: ignore[no-any-return]
    return ""


</t>
<t tx="ekr.20250131013601.263">def get_annotation(
    node: nodes.AssignAttr | nodes.AssignName,
) -&gt; nodes.Name | nodes.Subscript | None:
    """Return the annotation for `node`."""
    ann = None
    if isinstance(node.parent, nodes.AnnAssign):
        ann = node.parent.annotation
    elif isinstance(node, nodes.AssignAttr):
        init_method = node.parent.parent
        try:
            annotations = dict(zip(init_method.locals, init_method.args.annotations))
            ann = annotations.get(node.parent.value.name)
        except AttributeError:
            pass
    else:
        return ann

    try:
        default, * _ = node.infer()
    except astroid.InferenceError:
        default = ""

    label = get_annotation_label(ann)

    if (
        ann
        and getattr(default, "value", "value") is None
        and not label.startswith("Optional")
        and (
            not isinstance(ann, nodes.BinOp)
            or not any(
                isinstance(child, nodes.Const) and child.value is None
                for child in ann.get_children()
            )
        )
    ):
        label = rf"Optional[{label}]"

    if label and ann:
        ann.name = label
    return ann


</t>
<t tx="ekr.20250131013601.264">def infer_node(node: nodes.AssignAttr | nodes.AssignName) -&gt; set[InferenceResult]:
    """Return a set containing the node annotation if it exists
    otherwise return a set of the inferred types using the NodeNG.infer method.
    """
    ann = get_annotation(node)
    try:
        if ann:
            if isinstance(ann, nodes.Subscript) or (
                isinstance(ann, nodes.BinOp) and ann.op == "|"
            ):
                return {ann}
            return set(ann.infer())
        return set(node.infer())
    except astroid.InferenceError:
        return {ann} if ann else set()


</t>
<t tx="ekr.20250131013601.265">def check_graphviz_availability() -&gt; None:
    """Check if the ``dot`` command is available on the machine.

    This is needed if image output is desired and ``dot`` is used to convert
    from *.dot or *.gv into the final output format.
    """
    if shutil.which("dot") is None:
        print("'Graphviz' needs to be installed for your chosen output format.")
        sys.exit(32)


</t>
<t tx="ekr.20250131013601.266">def check_if_graphviz_supports_format(output_format: str) -&gt; None:
    """Check if the ``dot`` command supports the requested output format.

    This is needed if image output is desired and ``dot`` is used to convert
    from *.gv into the final output format.
    """
    dot_output = subprocess.run(
        ["dot", "-T?"], capture_output=True, check=False, encoding="utf-8"
    )
    match = re.match(
        pattern = r".*Use one of: (?P&lt;formats&gt;(\S*\s?)+)",
        string = dot_output.stderr.strip(),
    )
    if not match:
        print(
            "Unable to determine Graphviz supported output formats. "
            "Pyreverse will continue, but subsequent error messages "
            "regarding the output format may come from Graphviz directly."
        )
        return
    supported_formats = match.group("formats")
    if output_format not in supported_formats.split():
        print(
            f"Format {output_format} is not supported by Graphviz. It supports: {supported_formats}"
        )
        sys.exit(32)
</t>
<t tx="ekr.20250131013601.267">def __init__(self, mode: str) -&gt; None:
    """Init filter modes."""
    __mode = 0
    for nummod in mode.split("+"):
        try:
            __mode += MODES[nummod]
        except KeyError as ex:
            print(f"Unknown filter mode {ex}", file=sys.stderr)
    self.__mode = __mode

</t>
<t tx="ekr.20250131013601.268">def show_attr(self, node: nodes.NodeNG | str) -&gt; bool:
    """Return true if the node should be treated."""
    visibility = get_visibility(getattr(node, "name", node))
    return not self.__mode &amp; VIS_MOD[visibility]


</t>
<t tx="ekr.20250131013601.269">def __init__(self) -&gt; None:
    self._cache: dict[type[nodes.NodeNG], _CallbackTupleT] = {}
    self._visited: set[nodes.NodeNG] = set()

</t>
<t tx="ekr.20250131013601.27">    def check_single_file_item(self, file: FileItem) -&gt; None:
        """Check single file item.

        The arguments are the same that are documented in _check_files

        initialize() should be called before calling this method
        """
        with self._astroid_module_checker() as check_astroid_module:
            self._check_file(self.get_ast, check_astroid_module, file)

</t>
<t tx="ekr.20250131013601.270">def get_callbacks(self, node: nodes.NodeNG) -&gt; _CallbackTupleT:
    """Get callbacks from handler for the visited node."""
    klass = node.__class__
    methods = self._cache.get(klass)
    if methods is None:
        kid = klass.__name__.lower()
        e_method = getattr(
            self, f"visit_{kid}", getattr(self, "visit_default", None)
        )
        l_method = getattr(
            self, f"leave_{kid}", getattr(self, "leave_default", None)
        )
        self._cache[klass] = (e_method, l_method)
    else:
        e_method, l_method = methods
    return e_method, l_method

</t>
<t tx="ekr.20250131013601.271">def visit(self, node: nodes.NodeNG) -&gt; Any:
    """Launch the visit starting from the given node."""
    if node in self._visited:
        return None

    self._visited.add(node)
    methods = self.get_callbacks(node)
    if methods[0] is not None:
        methods[0](node)
    if hasattr(node, "locals"):  # skip Instance and other proxy
        for local_node in node.values():
            self.visit(local_node)
    if methods[1] is not None:
        return methods[1](node)
    return None


</t>
<t tx="ekr.20250131013601.272">@path pylint/pyreverse
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Utilities for creating diagrams."""

from __future__ import annotations

import argparse
import itertools
import os
from collections import defaultdict
from collections.abc import Iterable

from astroid import modutils, nodes

from pylint.pyreverse.diagrams import (
    ClassDiagram,
    ClassEntity,
    DiagramEntity,
    PackageDiagram,
    PackageEntity,
)
from pylint.pyreverse.printer import EdgeType, NodeProperties, NodeType, Printer
from pylint.pyreverse.printer_factory import get_printer_for_filetype
from pylint.pyreverse.utils import is_exception


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.273">class DiagramWriter:
    """Base class for writing project diagrams."""

    @others
</t>
<t tx="ekr.20250131013601.274">def __init__(self, config: argparse.Namespace) -&gt; None:
    self.config = config
    self.printer_class = get_printer_for_filetype(self.config.output_format)
    self.printer: Printer  # defined in set_printer
    self.file_name = ""  # defined in set_printer
    self.depth = self.config.max_color_depth
    self.max_depth = self.config.max_depth
    # default colors are an adaption of the seaborn colorblind palette
    self.available_colors = itertools.cycle(self.config.color_palette)
    self.used_colors: dict[str, str] = {}

</t>
<t tx="ekr.20250131013601.275">def write(self, diadefs: Iterable[ClassDiagram | PackageDiagram]) -&gt; None:
    """Write files for &lt;project&gt; according to &lt;diadefs&gt;."""
    for diagram in diadefs:
        basename = diagram.title.strip().replace("/", "_").replace(" ", "_")
        file_name = f"{basename}.{self.config.output_format}"
        if os.path.exists(self.config.output_directory):
            file_name = os.path.join(self.config.output_directory, file_name)
        self.set_printer(file_name, basename)
        if isinstance(diagram, PackageDiagram):
            self.write_packages(diagram)
        else:
            self.write_classes(diagram)
        self.save()

</t>
<t tx="ekr.20250131013601.276">def should_show_node(self, qualified_name: str, is_class: bool = False) -&gt; bool:
    """Determine if a node should be shown based on depth settings.

    Depth is calculated by counting dots in the qualified name:
    - depth 0: top-level packages (no dots)
    - depth 1: first level sub-packages (one dot)
    - depth 2: second level sub-packages (two dots)

    For classes, depth is measured from their containing module, excluding
    the class name itself from the depth calculation.
    """
    # If no depth limit is set ==&gt; show all nodes
    if self.max_depth is None:
        return True

    # For classes, we want to measure depth from their containing module
    if is_class:
        # Get the module part (everything before the last dot)
        last_dot = qualified_name.rfind(".")
        if last_dot == -1:
            module_path = ""
        else:
            module_path = qualified_name[:last_dot]

        # Count module depth
        module_depth = module_path.count(".")
        return bool(module_depth &lt;= self.max_depth)

    # For packages/modules, count full depth
    node_depth = qualified_name.count(".")
    return bool(node_depth &lt;= self.max_depth)

</t>
<t tx="ekr.20250131013601.277">def write_packages(self, diagram: PackageDiagram) -&gt; None:
    """Write a package diagram."""
    module_info: dict[str, dict[str, int]] = {}

    # sorted to get predictable (hence testable) results
    for module in sorted(diagram.modules(), key=lambda x: x.title):
        module.fig_id = module.node.qname()

        # Filter nodes based on depth
        if not self.should_show_node(module.fig_id):
            continue

        if self.config.no_standalone and not any(
            module in (rel.from_object, rel.to_object)
            for rel in diagram.get_relationships("depends")
        ):
            continue

        self.printer.emit_node(
            module.fig_id,
            type_=NodeType.PACKAGE,
            properties=self.get_package_properties(module),
        )

        module_info[module.fig_id] = {
            "imports": 0,
            "imported": 0,
        }

    # package dependencies
    for rel in diagram.get_relationships("depends"):
        from_id = rel.from_object.fig_id
        to_id = rel.to_object.fig_id

        # Filter nodes based on depth ==&gt; skip if either source or target nodes is beyond the max depth
        if not self.should_show_node(from_id) or not self.should_show_node(to_id):
            continue

        self.printer.emit_edge(
            from_id,
            to_id,
            type_=EdgeType.USES,
        )

        module_info[from_id]["imports"] += 1
        module_info[to_id]["imported"] += 1

    for rel in diagram.get_relationships("type_depends"):
        from_id = rel.from_object.fig_id
        to_id = rel.to_object.fig_id

        # Filter nodes based on depth ==&gt; skip if either source or target nodes is beyond the max depth
        if not self.should_show_node(from_id) or not self.should_show_node(to_id):
            continue

        self.printer.emit_edge(
            from_id,
            to_id,
            type_=EdgeType.TYPE_DEPENDENCY,
        )

        module_info[from_id]["imports"] += 1
        module_info[to_id]["imported"] += 1

    print(
        f"Analysed {len(module_info)} modules with a total "
        f"of {sum(mod['imports'] for mod in module_info.values())} imports"
    )

</t>
<t tx="ekr.20250131013601.278">def write_classes(self, diagram: ClassDiagram) -&gt; None:
    """Write a class diagram."""
    # sorted to get predictable (hence testable) results
    for obj in sorted(diagram.objects, key=lambda x: x.title):
        obj.fig_id = obj.node.qname()

        # Filter class based on depth setting
        if not self.should_show_node(obj.fig_id, is_class=True):
            continue

        if self.config.no_standalone and not any(
            obj in (rel.from_object, rel.to_object)
            for rel_type in ("specialization", "association", "aggregation")
            for rel in diagram.get_relationships(rel_type)
        ):
            continue

        self.printer.emit_node(
            obj.fig_id,
            type_=NodeType.CLASS,
            properties=self.get_class_properties(obj),
        )
    # inheritance links
    for rel in diagram.get_relationships("specialization"):
        # Filter nodes based on depth setting
        if not self.should_show_node(
            rel.from_object.fig_id, is_class=True
        ) or not self.should_show_node(rel.to_object.fig_id, is_class=True):
            continue

        self.printer.emit_edge(
            rel.from_object.fig_id,
            rel.to_object.fig_id,
            type_=EdgeType.INHERITS,
        )
    associations: dict[str, set[str]] = defaultdict(set)
    # generate associations
    for rel in diagram.get_relationships("association"):
        # Filter nodes based on depth setting
        if not self.should_show_node(
            rel.from_object.fig_id, is_class=True
        ) or not self.should_show_node(rel.to_object.fig_id, is_class=True):
            continue

        associations[rel.from_object.fig_id].add(rel.to_object.fig_id)
        self.printer.emit_edge(
            rel.from_object.fig_id,
            rel.to_object.fig_id,
            label=rel.name,
            type_=EdgeType.ASSOCIATION,
        )
    # generate aggregations
    for rel in diagram.get_relationships("aggregation"):
        # Filter nodes based on depth setting
        if not self.should_show_node(
            rel.from_object.fig_id, is_class=True
        ) or not self.should_show_node(rel.to_object.fig_id, is_class=True):
            continue

        if rel.to_object.fig_id in associations[rel.from_object.fig_id]:
            continue
        self.printer.emit_edge(
            rel.from_object.fig_id,
            rel.to_object.fig_id,
            label=rel.name,
            type_=EdgeType.AGGREGATION,
        )

</t>
<t tx="ekr.20250131013601.279">def set_printer(self, file_name: str, basename: str) -&gt; None:
    """Set printer."""
    self.printer = self.printer_class(basename)
    self.file_name = file_name

</t>
<t tx="ekr.20250131013601.28">    def _lint_files(
        self,
        ast_mapping: dict[FileItem, nodes.Module | None],
        check_astroid_module: Callable[[nodes.Module], bool | None],
        progress_reporter: ProgressReporter,
    ) -&gt; None:
        """Lint all AST modules from a mapping.."""
        progress_reporter.start_linting()
        for fileitem, module in ast_mapping.items():
            progress_reporter.lint_file(fileitem.filepath)
            if module is None:
                continue
            try:
                self._lint_file(fileitem, module, check_astroid_module)
            except Exception as ex:  # pylint: disable=broad-except
                template_path = prepare_crash_report(
                    ex, fileitem.filepath, self.crash_file_path
                )
                msg = get_fatal_error_message(fileitem.filepath, template_path)
                if isinstance(ex, astroid.AstroidError):
                    self.add_message(
                        "astroid-error", args=(fileitem.filepath, msg), confidence=HIGH
                    )
                else:
                    self.add_message("fatal", args=msg, confidence=HIGH)

</t>
<t tx="ekr.20250131013601.280">def get_package_properties(self, obj: PackageEntity) -&gt; NodeProperties:
    """Get label and shape for packages."""
    return NodeProperties(
        label=obj.title,
        color=self.get_shape_color(obj) if self.config.colorized else "black",
    )

</t>
<t tx="ekr.20250131013601.281">def get_class_properties(self, obj: ClassEntity) -&gt; NodeProperties:
    """Get label and shape for classes."""
    properties = NodeProperties(
        label=obj.title,
        attrs=obj.attrs if not self.config.only_classnames else None,
        methods=obj.methods if not self.config.only_classnames else None,
        fontcolor="red" if is_exception(obj.node) else "black",
        color=self.get_shape_color(obj) if self.config.colorized else "black",
    )
    return properties

</t>
<t tx="ekr.20250131013601.282">def get_shape_color(self, obj: DiagramEntity) -&gt; str:
    """Get shape color."""
    qualified_name = obj.node.qname()
    if modutils.is_stdlib_module(qualified_name.split(".", maxsplit=1)[0]):
        return "grey"
    if isinstance(obj.node, nodes.ClassDef):
        package = qualified_name.rsplit(".", maxsplit=2)[0]
    elif obj.node.package:
        package = qualified_name
    else:
        package = qualified_name.rsplit(".", maxsplit=1)[0]
    base_name = ".".join(package.split(".", self.depth)[:self.depth])
    if base_name not in self.used_colors:
        self.used_colors[base_name] = next(self.available_colors)
    return self.used_colors[base_name]

</t>
<t tx="ekr.20250131013601.283">def save(self) -&gt; None:
    """Write to disk."""
    self.printer.generate(self.file_name)
</t>
<t tx="ekr.20250131013601.284"></t>
<t tx="ekr.20250131013601.285">@path pylint/reporters
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Utilities methods and classes for reporters."""

from __future__ import annotations

from typing import TYPE_CHECKING

from pylint import utils
from pylint.reporters.base_reporter import BaseReporter
from pylint.reporters.collecting_reporter import CollectingReporter
from pylint.reporters.json_reporter import JSON2Reporter, JSONReporter
from pylint.reporters.multi_reporter import MultiReporter
from pylint.reporters.reports_handler_mix_in import ReportsHandlerMixIn

if TYPE_CHECKING:
    from pylint.lint.pylinter import PyLinter


@others
__all__ = [
    "BaseReporter",
    "CollectingReporter",
    "JSON2Reporter",
    "JSONReporter",
    "MultiReporter",
    "ReportsHandlerMixIn",
]
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.286">def initialize(linter: PyLinter) -&gt; None:
    """Initialize linter with reporters in this package."""
    utils.register_plugins(linter, __path__[0])


</t>
<t tx="ekr.20250131013601.287">@path pylint/reporters
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import os
import sys
from typing import TYPE_CHECKING, TextIO

from pylint.message import Message
from pylint.reporters.ureports.nodes import Text
from pylint.utils import LinterStats

if TYPE_CHECKING:
    from pylint.lint.pylinter import PyLinter
    from pylint.reporters.ureports.nodes import Section


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.288">class BaseReporter:
    """Base class for reporters.

    symbols: show short symbolic names for messages.
    """

    @others
</t>
<t tx="ekr.20250131013601.289">extension = ""

name = "base"
"""Name of the reporter."""

def __init__(self, output: TextIO | None = None) -&gt; None:
    self.linter: PyLinter
    self.section = 0
    self.out: TextIO = output or sys.stdout
    self.messages: list[Message] = []
    # Build the path prefix to strip to get relative paths
    self.path_strip_prefix = os.getcwd() + os.sep

</t>
<t tx="ekr.20250131013601.29">    def _lint_file(
        self,
        file: FileItem,
        module: nodes.Module,
        check_astroid_module: Callable[[nodes.Module], bool | None],
    ) -&gt; None:
        """Lint a file using the passed utility function check_astroid_module).

        :param FileItem file: data about the file
        :param nodes.Module module: the ast module to lint
        :param Callable check_astroid_module: callable checking an AST taking the following
               arguments
        - ast: AST of the module
        :raises AstroidError: for any failures stemming from astroid
        """
        self.set_current_module(file.name, file.filepath)
        self._ignore_file = False
        self.file_state = FileState(file.modpath, self.msgs_store, module)
        # fix the current file (if the source file was not available or
        # if it's actually a c extension)
        self.current_file = module.file

        try:
            check_astroid_module(module)
        except Exception as e:
            raise astroid.AstroidError from e

        # warn about spurious inline messages handling
        spurious_messages = self.file_state.iter_spurious_suppression_messages(
            self.msgs_store
        )
        for msgid, line, args in spurious_messages:
            self.add_message(msgid, line, None, args)

</t>
<t tx="ekr.20250131013601.290">def handle_message(self, msg: Message) -&gt; None:
    """Handle a new message triggered on the current file."""
    self.messages.append(msg)

</t>
<t tx="ekr.20250131013601.291">def writeln(self, string: str = "") -&gt; None:
    """Write a line in the output buffer."""
    print(string, file=self.out)

</t>
<t tx="ekr.20250131013601.292">def display_reports(self, layout: Section) -&gt; None:
    """Display results encapsulated in the layout tree."""
    self.section = 0
    if layout.report_id:
        if isinstance(layout.children[0].children[0], Text):
            layout.children[0].children[0].data += f" ({layout.report_id})"
        else:
            raise ValueError(f"Incorrect child for {layout.children[0].children}")
    self._display(layout)

</t>
<t tx="ekr.20250131013601.293">def _display(self, layout: Section) -&gt; None:
    """Display the layout."""
    raise NotImplementedError()

</t>
<t tx="ekr.20250131013601.294">def display_messages(self, layout: Section | None) -&gt; None:
    """Hook for displaying the messages of the reporter.

    This will be called whenever the underlying messages
    needs to be displayed. For some reporters, it probably
    doesn't make sense to display messages as soon as they
    are available, so some mechanism of storing them could be used.
    This method can be implemented to display them after they've
    been aggregated.
    """

</t>
<t tx="ekr.20250131013601.295"># Event callbacks

def on_set_current_module(self, module: str, filepath: str | None) -&gt; None:
    """Hook called when a module starts to be analysed."""

</t>
<t tx="ekr.20250131013601.296">def on_close(
    self,
    stats: LinterStats,
    previous_stats: LinterStats | None,
) -&gt; None:
    """Hook called when a module finished analyzing."""
</t>
<t tx="ekr.20250131013601.297">@path pylint/reporters
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

from typing import TYPE_CHECKING

from pylint.reporters.base_reporter import BaseReporter

if TYPE_CHECKING:
    from pylint.reporters.ureports.nodes import Section


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.298">class CollectingReporter(BaseReporter):
    """Collects messages."""

    @others
</t>
<t tx="ekr.20250131013601.299">name = "collector"

def __init__(self) -&gt; None:
    super().__init__()
    self.messages = []

</t>
<t tx="ekr.20250131013601.3">def _load_reporter_by_class(reporter_class: str) -&gt; type[BaseReporter]:
    qname = reporter_class
    module_part = astroid.modutils.get_module_part(qname)
    module = astroid.modutils.load_module_from_name(module_part)
    class_name = qname.split(".")[-1]
    klass = getattr(module, class_name)
    assert issubclass(klass, BaseReporter), f"{klass} is not a BaseReporter"
    return klass  # type: ignore[no-any-return]


</t>
<t tx="ekr.20250131013601.30">    def _check_file(
        self,
        get_ast: GetAstProtocol,
        check_astroid_module: Callable[[nodes.Module], bool | None],
        file: FileItem,
    ) -&gt; None:
        """Check a file using the passed utility functions (get_ast and
        check_astroid_module).

        :param callable get_ast: callable returning AST from defined file taking the
                                 following arguments
        - filepath: path to the file to check
        - name: Python module name
        :param callable check_astroid_module: callable checking an AST taking the following
               arguments
        - ast: AST of the module
        :param FileItem file: data about the file
        :raises AstroidError: for any failures stemming from astroid
        """
        self.set_current_module(file.name, file.filepath)
        # get the module representation
        ast_node = get_ast(file.filepath, file.name)
        if ast_node is None:
            return

        self._ignore_file = False

        self.file_state = FileState(file.modpath, self.msgs_store, ast_node)
        # fix the current file (if the source file was not available or
        # if it's actually a c extension)
        self.current_file = ast_node.file
        try:
            check_astroid_module(ast_node)
        except Exception as e:  # pragma: no cover
            raise astroid.AstroidError from e
        # warn about spurious inline messages handling
        spurious_messages = self.file_state.iter_spurious_suppression_messages(
            self.msgs_store
        )
        for msgid, line, args in spurious_messages:
            self.add_message(msgid, line, None, args)

</t>
<t tx="ekr.20250131013601.300">def reset(self) -&gt; None:
    self.messages = []

</t>
<t tx="ekr.20250131013601.301">def _display(self, layout: Section) -&gt; None:
    pass
</t>
<t tx="ekr.20250131013601.302">@path pylint/reporters
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""JSON reporter."""

from __future__ import annotations

import json
from typing import TYPE_CHECKING, Optional, TypedDict

from pylint.interfaces import CONFIDENCE_MAP, UNDEFINED
from pylint.message import Message
from pylint.reporters.base_reporter import BaseReporter
from pylint.typing import MessageLocationTuple

if TYPE_CHECKING:
    from pylint.lint.pylinter import PyLinter
    from pylint.reporters.ureports.nodes import Section

# Since message-id is an invalid name we need to use the alternative syntax
OldJsonExport = TypedDict(
    "OldJsonExport",
    {
        "type": str,
        "module": str,
        "obj": str,
        "line": int,
        "column": int,
        "endLine": Optional[int],
        "endColumn": Optional[int],
        "path": str,
        "symbol": str,
        "message": str,
        "message-id": str,
    },
)


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.303">class JSONReporter(BaseReporter):
    """Report messages and layouts in JSON.

    Consider using JSON2Reporter instead, as it is superior and this reporter
    is no longer maintained.
    """

    @others
</t>
<t tx="ekr.20250131013601.304">class JSONMessage(TypedDict):
    type: str
    message: str
    messageId: str
    symbol: str
    confidence: str
    module: str
    path: str
    absolutePath: str
    line: int
    endLine: int | None
    column: int
    endColumn: int | None
    obj: str


</t>
<t tx="ekr.20250131013601.305">class JSON2Reporter(BaseReporter):
    @others
</t>
<t tx="ekr.20250131013601.306">def register(linter: PyLinter) -&gt; None:
    linter.register_reporter(JSONReporter)
    linter.register_reporter(JSON2Reporter)
</t>
<t tx="ekr.20250131013601.307">name = "json"
extension = "json"

def display_messages(self, layout: Section | None) -&gt; None:
    """Launch layouts display."""
    json_dumpable = [self.serialize(message) for message in self.messages]
    print(json.dumps(json_dumpable, indent=4), file=self.out)

</t>
<t tx="ekr.20250131013601.308">def display_reports(self, layout: Section) -&gt; None:
    """Don't do anything in this reporter."""

</t>
<t tx="ekr.20250131013601.309">def _display(self, layout: Section) -&gt; None:
    """Do nothing."""

</t>
<t tx="ekr.20250131013601.31">    def _get_file_descr_from_stdin(self, filepath: str) -&gt; Iterator[FileItem]:
        """Return file description (tuple of module name, file path, base name) from
        given file path.

        This method is used for creating suitable file description for _check_files when the
        source is standard input.
        """
        if _is_ignored_file(
            filepath,
            self.config.ignore,
            self.config.ignore_patterns,
            self.config.ignore_paths,
        ):
            self.stats.skipped += 1
            return

        try:
            # Note that this function does not really perform an
            # __import__ but may raise an ImportError exception, which
            # we want to catch here.
            modname = ".".join(astroid.modutils.modpath_from_file(filepath))
        except ImportError:
            modname = os.path.splitext(os.path.basename(filepath))[0]

        yield FileItem(modname, filepath, filepath)

</t>
<t tx="ekr.20250131013601.310">@staticmethod
def serialize(message: Message) -&gt; OldJsonExport:
    return {
        "type": message.category,
        "module": message.module,
        "obj": message.obj,
        "line": message.line,
        "column": message.column,
        "endLine": message.end_line,
        "endColumn": message.end_column,
        "path": message.path,
        "symbol": message.symbol,
        "message": message.msg or "",
        "message-id": message.msg_id,
    }

</t>
<t tx="ekr.20250131013601.311">@staticmethod
def deserialize(message_as_json: OldJsonExport) -&gt; Message:
    return Message(
        msg_id=message_as_json["message-id"],
        symbol=message_as_json["symbol"],
        msg=message_as_json["message"],
        location=MessageLocationTuple(
            abspath=message_as_json["path"],
            path=message_as_json["path"],
            module=message_as_json["module"],
            obj=message_as_json["obj"],
            line=message_as_json["line"],
            column=message_as_json["column"],
            end_line=message_as_json["endLine"],
            end_column=message_as_json["endColumn"],
        ),
        confidence=UNDEFINED,
    )


</t>
<t tx="ekr.20250131013601.312">name = "json2"
extension = "json2"

def display_reports(self, layout: Section) -&gt; None:
    """Don't do anything in this reporter."""

</t>
<t tx="ekr.20250131013601.313">def _display(self, layout: Section) -&gt; None:
    """Do nothing."""

</t>
<t tx="ekr.20250131013601.314">def display_messages(self, layout: Section | None) -&gt; None:
    """Launch layouts display."""
    output = {
        "messages": [self.serialize(message) for message in self.messages],
        "statistics": self.serialize_stats(),
    }
    print(json.dumps(output, indent=4), file=self.out)

</t>
<t tx="ekr.20250131013601.315">@staticmethod
def serialize(message: Message) -&gt; JSONMessage:
    return JSONMessage(
        type=message.category,
        symbol=message.symbol,
        message=message.msg or "",
        messageId=message.msg_id,
        confidence=message.confidence.name,
        module=message.module,
        obj=message.obj,
        line=message.line,
        column=message.column,
        endLine=message.end_line,
        endColumn=message.end_column,
        path=message.path,
        absolutePath=message.abspath,
    )

</t>
<t tx="ekr.20250131013601.316">@staticmethod
def deserialize(message_as_json: JSONMessage) -&gt; Message:
    return Message(
        msg_id=message_as_json["messageId"],
        symbol=message_as_json["symbol"],
        msg=message_as_json["message"],
        location=MessageLocationTuple(
            abspath=message_as_json["absolutePath"],
            path=message_as_json["path"],
            module=message_as_json["module"],
            obj=message_as_json["obj"],
            line=message_as_json["line"],
            column=message_as_json["column"],
            end_line=message_as_json["endLine"],
            end_column=message_as_json["endColumn"],
        ),
        confidence=CONFIDENCE_MAP[message_as_json["confidence"]],
    )

</t>
<t tx="ekr.20250131013601.317">def serialize_stats(self) -&gt; dict[str, str | int | dict[str, int]]:
    """Serialize the linter stats into something JSON dumpable."""
    stats = self.linter.stats

    counts_dict = {
        "fatal": stats.fatal,
        "error": stats.error,
        "warning": stats.warning,
        "refactor": stats.refactor,
        "convention": stats.convention,
        "info": stats.info,
    }

    # Calculate score based on the evaluation option
    evaluation = self.linter.config.evaluation
    try:
        note: int = eval(  # pylint: disable=eval-used
            evaluation, {}, {**counts_dict, "statement": stats.statement or 1}
        )
    except Exception as ex:  # pylint: disable=broad-except
        score: str | int = f"An exception occurred while rating: {ex}"
    else:
        score = round(note, 2)

    return {
        "messageTypeCount": counts_dict,
        "modulesLinted": len(stats.by_module),
        "score": score,
    }


</t>
<t tx="ekr.20250131013601.318">@path pylint/reporters
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import os
from collections.abc import Callable
from copy import copy
from typing import TYPE_CHECKING, TextIO

from pylint.message import Message
from pylint.reporters.base_reporter import BaseReporter
from pylint.utils import LinterStats

if TYPE_CHECKING:
    from pylint.lint import PyLinter
    from pylint.reporters.ureports.nodes import Section


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.319">class MultiReporter:
    """Reports messages and layouts in plain text."""

    @others
</t>
<t tx="ekr.20250131013601.32">    def _iterate_file_descrs(
        self, files_or_modules: Sequence[str]
    ) -&gt; Iterator[FileItem]:
        """Return generator yielding file descriptions (tuples of module name, file
        path, base name).

        The returned generator yield one item for each Python module that should be linted.
        """
        for descr in self._expand_files(files_or_modules).values():
            name, filepath, is_arg = descr["name"], descr["path"], descr["isarg"]
            if descr["isignored"]:
                self.stats.skipped += 1
            elif self.should_analyze_file(name, filepath, is_argument=is_arg):
                yield FileItem(name, filepath, descr["basename"])

</t>
<t tx="ekr.20250131013601.320">name = "_internal_multi_reporter"
# Note: do not register this reporter with linter.register_reporter as it is
#       not intended to be used directly like a regular reporter, but is
#       instead used to implement the
#       `--output-format=json:somefile.json,colorized`
#       multiple output formats feature

extension = ""

def __init__(
    self,
    sub_reporters: list[BaseReporter],
    close_output_files: Callable[[], None],
    output: TextIO | None = None,
):
    self._sub_reporters = sub_reporters
    self.close_output_files = close_output_files
    self._path_strip_prefix = os.getcwd() + os.sep
    self._linter: PyLinter | None = None
    self.out = output
    self.messages: list[Message] = []

</t>
<t tx="ekr.20250131013601.321">@property
def out(self) -&gt; TextIO | None:
    return self.__out

</t>
<t tx="ekr.20250131013601.322">@out.setter
def out(self, output: TextIO | None = None) -&gt; None:
    """MultiReporter doesn't have its own output.

    This method is only provided for API parity with BaseReporter
    and should not be called with non-None values for 'output'.
    """
    self.__out = None
    if output is not None:
        raise NotImplementedError("MultiReporter does not support direct output.")

</t>
<t tx="ekr.20250131013601.323">def __del__(self) -&gt; None:
    self.close_output_files()

</t>
<t tx="ekr.20250131013601.324">@property
def path_strip_prefix(self) -&gt; str:
    return self._path_strip_prefix

</t>
<t tx="ekr.20250131013601.325">@property
def linter(self) -&gt; PyLinter | None:
    return self._linter

</t>
<t tx="ekr.20250131013601.326">@linter.setter
def linter(self, value: PyLinter) -&gt; None:
    self._linter = value
    for rep in self._sub_reporters:
        rep.linter = value

</t>
<t tx="ekr.20250131013601.327">def handle_message(self, msg: Message) -&gt; None:
    """Handle a new message triggered on the current file."""
    for rep in self._sub_reporters:
        # We provide a copy so reporters can't modify message for others.
        rep.handle_message(copy(msg))

</t>
<t tx="ekr.20250131013601.328">def writeln(self, string: str = "") -&gt; None:
    """Write a line in the output buffer."""
    for rep in self._sub_reporters:
        rep.writeln(string)

</t>
<t tx="ekr.20250131013601.329">def display_reports(self, layout: Section) -&gt; None:
    """Display results encapsulated in the layout tree."""
    for rep in self._sub_reporters:
        rep.display_reports(layout)

</t>
<t tx="ekr.20250131013601.33">    def _expand_files(
        self, files_or_modules: Sequence[str]
    ) -&gt; dict[str, ModuleDescriptionDict]:
        """Get modules and errors from a list of modules and handle errors."""
        result, errors = expand_modules(
            files_or_modules,
            self.config.source_roots,
            self.config.ignore,
            self.config.ignore_patterns,
            self._ignore_paths,
        )
        for error in errors:
            message = modname = error["mod"]
            key = error["key"]
            self.set_current_module(modname)
            if key == "fatal":
                message = str(error["ex"]).replace(os.getcwd() + os.sep, "")
            self.add_message(key, args=message)
        return result

</t>
<t tx="ekr.20250131013601.330">def display_messages(self, layout: Section | None) -&gt; None:
    """Hook for displaying the messages of the reporter."""
    for rep in self._sub_reporters:
        rep.display_messages(layout)

</t>
<t tx="ekr.20250131013601.331">def on_set_current_module(self, module: str, filepath: str | None) -&gt; None:
    """Hook called when a module starts to be analysed."""
    for rep in self._sub_reporters:
        rep.on_set_current_module(module, filepath)

</t>
<t tx="ekr.20250131013601.332">def on_close(
    self,
    stats: LinterStats,
    previous_stats: LinterStats | None,
) -&gt; None:
    """Hook called when a module finished analyzing."""
    for rep in self._sub_reporters:
        rep.on_close(stats, previous_stats)
</t>
<t tx="ekr.20250131013601.333">@path pylint/reporters
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.334">class ProgressReporter:
    """Progress reporter."""

    @others
</t>
<t tx="ekr.20250131013601.335">def __init__(self, is_verbose: bool = True) -&gt; None:
    self._is_verbose = is_verbose
    self._ast_count = 0
    self._lint_counter = 0

</t>
<t tx="ekr.20250131013601.336">def start_get_asts(self) -&gt; None:
    self._print_message("Get ASTs.")

</t>
<t tx="ekr.20250131013601.337">def get_ast_for_file(self, filename: str) -&gt; None:
    self._ast_count += 1
    self._print_message(f"AST for {filename}")

</t>
<t tx="ekr.20250131013601.338">def start_linting(self) -&gt; None:
    self._print_message(f"Linting {self._ast_count} modules.")

</t>
<t tx="ekr.20250131013601.339">def lint_file(self, filename: str) -&gt; None:
    self._lint_counter += 1
    self._print_message(f"{filename} ({self._lint_counter} of {self._ast_count})")

</t>
<t tx="ekr.20250131013601.34">    def set_current_module(self, modname: str, filepath: str | None = None) -&gt; None:
        """Set the name of the currently analyzed module and
        init statistics for it.
        """
        if not modname and filepath is None:
            return
        self.reporter.on_set_current_module(modname or "", filepath)
        self.current_name = modname
        self.current_file = filepath or modname
        self.stats.init_single_module(modname or "")

        # If there is an actual filepath we might need to update the config attribute
        if filepath:
            namespace = self._get_namespace_for_file(
                Path(filepath), self._directory_namespaces
            )
            if namespace:
                self.config = namespace or self._base_config

</t>
<t tx="ekr.20250131013601.340">def _print_message(self, msg: str) -&gt; None:
    """Display progress message."""
    if self._is_verbose:
        print(msg, flush=True)
</t>
<t tx="ekr.20250131013601.341">@path pylint/reporters
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import collections
from collections.abc import MutableSequence
from typing import TYPE_CHECKING

from pylint.exceptions import EmptyReportError
from pylint.reporters.ureports.nodes import Section
from pylint.typing import ReportsCallable
from pylint.utils import LinterStats

if TYPE_CHECKING:
    from pylint.checkers import BaseChecker
    from pylint.lint.pylinter import PyLinter

ReportsDict = collections.defaultdict[
    "BaseChecker", list[tuple[str, str, ReportsCallable]]
]


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.342">class ReportsHandlerMixIn:
    """A mix-in class containing all the reports and stats manipulation
    related methods for the main lint class.
    """

    @others
</t>
<t tx="ekr.20250131013601.343">def __init__(self) -&gt; None:
    self._reports: ReportsDict = collections.defaultdict(list)
    self._reports_state: dict[str, bool] = {}

</t>
<t tx="ekr.20250131013601.344">def report_order(self) -&gt; MutableSequence[BaseChecker]:
    """Return a list of reporters."""
    return list(self._reports)

</t>
<t tx="ekr.20250131013601.345">def register_report(
    self, reportid: str, r_title: str, r_cb: ReportsCallable, checker: BaseChecker
) -&gt; None:
    """Register a report.

    :param reportid: The unique identifier for the report
    :param r_title: The report's title
    :param r_cb: The method to call to make the report
    :param checker: The checker defining the report
    """
    reportid = reportid.upper()
    self._reports[checker].append((reportid, r_title, r_cb))

</t>
<t tx="ekr.20250131013601.346">def enable_report(self, reportid: str) -&gt; None:
    """Enable the report of the given id."""
    reportid = reportid.upper()
    self._reports_state[reportid] = True

</t>
<t tx="ekr.20250131013601.347">def disable_report(self, reportid: str) -&gt; None:
    """Disable the report of the given id."""
    reportid = reportid.upper()
    self._reports_state[reportid] = False

</t>
<t tx="ekr.20250131013601.348">def report_is_enabled(self, reportid: str) -&gt; bool:
    """Is the report associated to the given identifier enabled ?"""
    return self._reports_state.get(reportid, True)

</t>
<t tx="ekr.20250131013601.349">def make_reports(  # type: ignore[misc] # ReportsHandlerMixIn is always mixed with PyLinter
    self: PyLinter,
    stats: LinterStats,
    old_stats: LinterStats | None,
) -&gt; Section:
    """Render registered reports."""
    sect = Section("Report", f"{self.stats.statement} statements analysed.")
    for checker in self.report_order():
        for reportid, r_title, r_cb in self._reports[checker]:
            if not self.report_is_enabled(reportid):
                continue
            report_sect = Section(r_title)
            try:
                r_cb(report_sect, stats, old_stats)
            except EmptyReportError:
                continue
            report_sect.report_id = reportid
            sect.append(report_sect)
    return sect
</t>
<t tx="ekr.20250131013601.35">    def _get_namespace_for_file(
        self, filepath: Path, namespaces: DirectoryNamespaceDict
    ) -&gt; argparse.Namespace | None:
        for directory in namespaces:
            if Path.is_relative_to(filepath, directory):
                namespace = self._get_namespace_for_file(
                    filepath, namespaces[directory][1]
                )
                if namespace is None:
                    return namespaces[directory][0]
        return None

</t>
<t tx="ekr.20250131013601.350">@path pylint/reporters
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Plain text reporters:.

:text: the default one grouping messages by module
:colorized: an ANSI colorized text reporter
"""

from __future__ import annotations

import os
import re
import sys
import warnings
from dataclasses import asdict, fields
from typing import TYPE_CHECKING, NamedTuple, TextIO

from pylint.message import Message
from pylint.reporters import BaseReporter
from pylint.reporters.ureports.text_writer import TextWriter

if TYPE_CHECKING:
    from pylint.lint import PyLinter
    from pylint.reporters.ureports.nodes import Section


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.351">class MessageStyle(NamedTuple):
    """Styling of a message."""

    @others
</t>
<t tx="ekr.20250131013601.352">ColorMappingDict = dict[str, MessageStyle]

TITLE_UNDERLINES = ["", "=", "-", "."]

ANSI_PREFIX = "\033["
ANSI_END = "m"
ANSI_RESET = "\033[0m"
ANSI_STYLES = {
    "reset": "0",
    "bold": "1",
    "italic": "3",
    "underline": "4",
    "blink": "5",
    "inverse": "7",
    "strike": "9",
}
ANSI_COLORS = {
    "reset": "0",
    "black": "30",
    "red": "31",
    "green": "32",
    "yellow": "33",
    "blue": "34",
    "magenta": "35",
    "cyan": "36",
    "white": "37",
}

MESSAGE_FIELDS = {i.name for i in fields(Message)}
"""All fields of the Message class."""


def colorize_ansi(msg: str, msg_style: MessageStyle) -&gt; str:
    """Colorize message by wrapping it with ANSI escape codes."""
    return msg_style._colorize_ansi(msg)


</t>
<t tx="ekr.20250131013601.353">def make_header(msg: Message) -&gt; str:
    return f"************* Module {msg.module}"


</t>
<t tx="ekr.20250131013601.354">class TextReporter(BaseReporter):
    """Reports messages and layouts in plain text."""

    @others
</t>
<t tx="ekr.20250131013601.355">class NoHeaderReporter(TextReporter):
    """Reports messages and layouts in plain text without a module header."""

    @others
</t>
<t tx="ekr.20250131013601.356">class ParseableTextReporter(TextReporter):
    """A reporter very similar to TextReporter, but display messages in a form
    recognized by most text editors :

    &lt;filename&gt;:&lt;linenum&gt;:&lt;msg&gt;
    """

    @others
</t>
<t tx="ekr.20250131013601.357">class VSTextReporter(ParseableTextReporter):
    """Visual studio text reporter."""

    name = "msvs"
    line_format = "{path}({line}): [{msg_id}({symbol}){obj}] {msg}"


</t>
<t tx="ekr.20250131013601.358">class ColorizedTextReporter(TextReporter):
    """Simple TextReporter that colorizes text output."""

    @others
</t>
<t tx="ekr.20250131013601.359">class GithubReporter(TextReporter):
    """Report messages in GitHub's special format to annotate code in its user
    interface.
    """

    @others
</t>
<t tx="ekr.20250131013601.36">    @contextlib.contextmanager
    def _astroid_module_checker(
        self,
    ) -&gt; Iterator[Callable[[nodes.Module], bool | None]]:
        """Context manager for checking ASTs.

        The value in the context is callable accepting AST as its only argument.
        """
        walker = ASTWalker(self)
        _checkers = self.prepare_checkers()
        tokencheckers = [
            c for c in _checkers if isinstance(c, checkers.BaseTokenChecker)
        ]
        rawcheckers = [
            c for c in _checkers if isinstance(c, checkers.BaseRawFileChecker)
        ]
        for checker in _checkers:
            checker.open()
            walker.add_checker(checker)

        yield functools.partial(
            self.check_astroid_module,
            walker=walker,
            tokencheckers=tokencheckers,
            rawcheckers=rawcheckers,
        )

        # notify global end
        self.stats.statement = walker.nbstatements
        for checker in reversed(_checkers):
            checker.close()

</t>
<t tx="ekr.20250131013601.360">def register(linter: PyLinter) -&gt; None:
    linter.register_reporter(TextReporter)
    linter.register_reporter(NoHeaderReporter)
    linter.register_reporter(ParseableTextReporter)
    linter.register_reporter(VSTextReporter)
    linter.register_reporter(ColorizedTextReporter)
    linter.register_reporter(GithubReporter)
</t>
<t tx="ekr.20250131013601.361">color: str | None
"""The color name (see `ANSI_COLORS` for available values)
or the color number when 256 colors are available.
"""
style: tuple[str, ...] = ()
"""Tuple of style strings (see `ANSI_COLORS` for available values)."""

def __get_ansi_code(self) -&gt; str:
    """Return ANSI escape code corresponding to color and style.

    :raise KeyError: if a nonexistent color or style identifier is given

    :return: the built escape code
    """
    ansi_code = [ANSI_STYLES[effect] for effect in self.style]
    if self.color:
        if self.color.isdigit():
            ansi_code.extend(["38", "5"])
            ansi_code.append(self.color)
        else:
            ansi_code.append(ANSI_COLORS[self.color])
    if ansi_code:
        return ANSI_PREFIX + ";".join(ansi_code) + ANSI_END
    return ""

</t>
<t tx="ekr.20250131013601.362">def _colorize_ansi(self, msg: str) -&gt; str:
    if self.color is None and len(self.style) == 0:
        # If both color and style are not defined, then leave the text as is.
        return msg
    escape_code = self.__get_ansi_code()
    # If invalid (or unknown) color, don't wrap msg with ANSI codes
    if escape_code:
        return f"{escape_code}{msg}{ANSI_RESET}"
    return msg


</t>
<t tx="ekr.20250131013601.363">name = "text"
extension = "txt"
line_format = "{path}:{line}:{column}: {msg_id}: {msg} ({symbol})"

def __init__(self, output: TextIO | None = None) -&gt; None:
    super().__init__(output)
    self._modules: set[str] = set()
    self._template = self.line_format
    self._fixed_template = self.line_format
    """The output format template with any unrecognized arguments removed."""

</t>
<t tx="ekr.20250131013601.364">def on_set_current_module(self, module: str, filepath: str | None) -&gt; None:
    """Set the format template to be used and check for unrecognized arguments."""
    template = str(self.linter.config.msg_template or self._template)

    # Return early if the template is the same as the previous one
    if template == self._template:
        return

    # Set template to the currently selected template
    self._template = template

    # Check to see if all parameters in the template are attributes of the Message
    arguments = re.findall(r"\{(\w+?)(:.*)?\}", template)
    for argument in arguments:
        if argument[0] not in MESSAGE_FIELDS:
            warnings.warn(
                f"Don't recognize the argument '{argument[0]}' in the --msg-template. "
                "Are you sure it is supported on the current version of pylint?",
                stacklevel=2,
            )
            template = re.sub(r"\{" + argument[0] + r"(:.*?)?\}", "", template)
    self._fixed_template = template

</t>
<t tx="ekr.20250131013601.365">def write_message(self, msg: Message) -&gt; None:
    """Convenience method to write a formatted message with class default
    template.
    """
    self_dict = asdict(msg)
    for key in ("end_line", "end_column"):
        self_dict[key] = self_dict[key] or ""

    self.writeln(self._fixed_template.format(**self_dict))

</t>
<t tx="ekr.20250131013601.366">def handle_message(self, msg: Message) -&gt; None:
    """Manage message of different type and in the context of path."""
    if msg.module not in self._modules:
        self.writeln(make_header(msg))
        self._modules.add(msg.module)
    self.write_message(msg)

</t>
<t tx="ekr.20250131013601.367">def _display(self, layout: Section) -&gt; None:
    """Launch layouts display."""
    print(file=self.out)
    TextWriter().format(layout, self.out)


</t>
<t tx="ekr.20250131013601.368">name = "no-header"

def handle_message(self, msg: Message) -&gt; None:
    """Write message(s) without module header."""
    if msg.module not in self._modules:
        self._modules.add(msg.module)
    self.write_message(msg)


</t>
<t tx="ekr.20250131013601.369">name = "parseable"
line_format = "{path}:{line}: [{msg_id}({symbol}), {obj}] {msg}"

def __init__(self, output: TextIO | None = None) -&gt; None:
    warnings.warn(
        f"{self.name} output format is deprecated. This is equivalent to --msg-template={self.line_format}",
        DeprecationWarning,
        stacklevel=2,
    )
    super().__init__(output)


</t>
<t tx="ekr.20250131013601.37">    def get_ast(
        self, filepath: str, modname: str, data: str | None = None
    ) -&gt; nodes.Module | None:
        """Return an ast(roid) representation of a module or a string.

        :param filepath: path to checked file.
        :param str modname: The name of the module to be checked.
        :param str data: optional contents of the checked file.
        :returns: the AST
        :rtype: astroid.nodes.Module
        :raises AstroidBuildingError: Whenever we encounter an unexpected exception
        """
        try:
            if data is None:
                return MANAGER.ast_from_file(filepath, modname, source=True)
            return astroid.builder.AstroidBuilder(MANAGER).string_build(
                data, modname, filepath
            )
        except astroid.AstroidSyntaxError as ex:
            line = getattr(ex.error, "lineno", None)
            if line is None:
                line = 0
            self.add_message(
                "syntax-error",
                line=line,
                col_offset=getattr(ex.error, "offset", None),
                args=f"Parsing failed: '{ex.error}'",
                confidence=HIGH,
            )
        except astroid.AstroidBuildingError as ex:
            self.add_message("parse-error", args=ex)
        except Exception as ex:
            traceback.print_exc()
            # We raise BuildingError here as this is essentially an astroid issue
            # Creating an issue template and adding the 'astroid-error' message is handled
            # by caller: _check_files
            raise astroid.AstroidBuildingError(
                "Building error when trying to create ast representation of module '{modname}'",
                modname=modname,
            ) from ex
        return None

</t>
<t tx="ekr.20250131013601.370">name = "colorized"
COLOR_MAPPING: ColorMappingDict = {
    "I": MessageStyle("green"),
    "C": MessageStyle(None, ("bold",)),
    "R": MessageStyle("magenta", ("bold", "italic")),
    "W": MessageStyle("magenta"),
    "E": MessageStyle("red", ("bold",)),
    "F": MessageStyle("red", ("bold", "underline")),
    "S": MessageStyle("yellow", ("inverse",)),  # S stands for module Separator
}

def __init__(
    self,
    output: TextIO | None = None,
    color_mapping: ColorMappingDict | None = None,
) -&gt; None:
    super().__init__(output)
    self.color_mapping = color_mapping or ColorizedTextReporter.COLOR_MAPPING
    ansi_terms = ["xterm-16color", "xterm-256color"]
    if os.environ.get("TERM") not in ansi_terms:
        if sys.platform == "win32":
            # pylint: disable=import-outside-toplevel
            import colorama

            self.out = colorama.AnsiToWin32(self.out)

</t>
<t tx="ekr.20250131013601.371">def _get_decoration(self, msg_id: str) -&gt; MessageStyle:
    """Returns the message style as defined in self.color_mapping."""
    return self.color_mapping.get(msg_id[0]) or MessageStyle(None)

</t>
<t tx="ekr.20250131013601.372">def handle_message(self, msg: Message) -&gt; None:
    """Manage message of different types, and colorize output
    using ANSI escape codes.
    """
    if msg.module not in self._modules:
        msg_style = self._get_decoration("S")
        modsep = colorize_ansi(make_header(msg), msg_style)
        self.writeln(modsep)
        self._modules.add(msg.module)
    msg_style = self._get_decoration(msg.C)

    msg.msg = colorize_ansi(msg.msg, msg_style)
    msg.symbol = colorize_ansi(msg.symbol, msg_style)
    msg.category = colorize_ansi(msg.category, msg_style)
    msg.C = colorize_ansi(msg.C, msg_style)
    self.write_message(msg)


</t>
<t tx="ekr.20250131013601.373">name = "github"
line_format = "::{category} file={path},line={line},endline={end_line},col={column},title={msg_id}::{msg}"
category_map = {
    "F": "error",
    "E": "error",
    "W": "warning",
    "C": "notice",
    "R": "notice",
    "I": "notice",
}

def write_message(self, msg: Message) -&gt; None:
    self_dict = asdict(msg)
    for key in ("end_line", "end_column"):
        self_dict[key] = self_dict[key] or ""

    self_dict["category"] = self.category_map.get(msg.C) or "error"
    self.writeln(self._fixed_template.format(**self_dict))


</t>
<t tx="ekr.20250131013601.374"></t>
<t tx="ekr.20250131013601.375">@path pylint/reporters/ureports
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

__all__ = ("BaseWriter",)

from pylint.reporters.ureports.base_writer import BaseWriter
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.376">@path pylint/reporters/ureports
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Universal report objects and some formatting drivers.

A way to create simple reports using python objects, primarily designed to be
formatted as text and html.
"""

from __future__ import annotations

import sys
from collections.abc import Iterator
from io import StringIO
from typing import TYPE_CHECKING, TextIO

if TYPE_CHECKING:
    from pylint.reporters.ureports.nodes import (
        BaseLayout,
        EvaluationSection,
        Paragraph,
        Section,
        Table,
    )


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.377">class BaseWriter:
    """Base class for ureport writers."""

    @others
</t>
<t tx="ekr.20250131013601.378">def format(
    self,
    layout: BaseLayout,
    stream: TextIO = sys.stdout,
    encoding: str | None = None,
) -&gt; None:
    """Format and write the given layout into the stream object.

    unicode policy: unicode strings may be found in the layout;
    try to call 'stream.write' with it, but give it back encoded using
    the given encoding if it fails
    """
    if not encoding:
        encoding = getattr(stream, "encoding", "UTF-8")
    self.encoding = encoding or "UTF-8"
    self.out = stream
    self.begin_format()
    layout.accept(self)
    self.end_format()

</t>
<t tx="ekr.20250131013601.379">def format_children(self, layout: EvaluationSection | Paragraph | Section) -&gt; None:
    """Recurse on the layout children and call their accept method
    (see the Visitor pattern).
    """
    for child in getattr(layout, "children", ()):
        child.accept(self)

</t>
<t tx="ekr.20250131013601.38">    def check_astroid_module(
        self,
        ast_node: nodes.Module,
        walker: ASTWalker,
        rawcheckers: list[checkers.BaseRawFileChecker],
        tokencheckers: list[checkers.BaseTokenChecker],
    ) -&gt; bool | None:
        """Check a module from its astroid representation.

        For return value see _check_astroid_module
        """
        before_check_statements = walker.nbstatements

        retval = self._check_astroid_module(
            ast_node, walker, rawcheckers, tokencheckers
        )
        self.stats.by_module[self.current_name]["statement"] = (
            walker.nbstatements - before_check_statements
        )

        return retval

</t>
<t tx="ekr.20250131013601.380">def writeln(self, string: str = "") -&gt; None:
    """Write a line in the output buffer."""
    self.write(string + "\n")

</t>
<t tx="ekr.20250131013601.381">def write(self, string: str) -&gt; None:
    """Write a string in the output buffer."""
    self.out.write(string)

</t>
<t tx="ekr.20250131013601.382">def begin_format(self) -&gt; None:
    """Begin to format a layout."""
    self.section = 0

</t>
<t tx="ekr.20250131013601.383">def end_format(self) -&gt; None:
    """Finished formatting a layout."""

</t>
<t tx="ekr.20250131013601.384">def get_table_content(self, table: Table) -&gt; list[list[str]]:
    """Trick to get table content without actually writing it.

    return an aligned list of lists containing table cells values as string
    """
    result: list[list[str]] = [[]]
    cols = table.cols
    for cell in self.compute_content(table):
        if cols == 0:
            result.append([])
            cols = table.cols
        cols -= 1
        result[-1].append(cell)
    # fill missing cells
    result[-1] += [""] * (cols - len(result[-1]))
    return result

</t>
<t tx="ekr.20250131013601.385">def compute_content(self, layout: BaseLayout) -&gt; Iterator[str]:
    """Trick to compute the formatting of children layout before actually
    writing it.

    return an iterator on strings (one for each child element)
    """
    # Patch the underlying output stream with a fresh-generated stream,
    # which is used to store a temporary representation of a child
    # node.
    out = self.out
    try:
        for child in layout.children:
            stream = StringIO()
            self.out = stream
            child.accept(self)
            yield stream.getvalue()
    finally:
        self.out = out
</t>
<t tx="ekr.20250131013601.386">@path pylint/reporters/ureports
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Micro reports objects.

A micro report is a tree of layout and content objects.
"""

from __future__ import annotations

from collections.abc import Callable, Iterable, Iterator
from typing import Any, TypeVar

from pylint.reporters.ureports.base_writer import BaseWriter

_T = TypeVar("_T")
_VNodeT = TypeVar("_VNodeT", bound="VNode")
VisitLeaveFunction = Callable[[_T, Any, Any], None]


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.387">class VNode:
    @others
</t>
<t tx="ekr.20250131013601.388">class BaseLayout(VNode):
    """Base container node.

    attributes
    * children : components in this table (i.e. the table's cells)
    """

    @others
</t>
<t tx="ekr.20250131013601.389"># non container nodes #########################################################


class Text(VNode):
    """A text portion.

    attributes :
    * data : the text value as an encoded or unicode string
    """

    @others
</t>
<t tx="ekr.20250131013601.39">    def _check_astroid_module(
        self,
        node: nodes.Module,
        walker: ASTWalker,
        rawcheckers: list[checkers.BaseRawFileChecker],
        tokencheckers: list[checkers.BaseTokenChecker],
    ) -&gt; bool | None:
        """Check given AST node with given walker and checkers.

        :param astroid.nodes.Module node: AST node of the module to check
        :param pylint.utils.ast_walker.ASTWalker walker: AST walker
        :param list rawcheckers: List of token checkers to use
        :param list tokencheckers: List of raw checkers to use

        :returns: True if the module was checked, False if ignored,
            None if the module contents could not be parsed
        """
        try:
            tokens = utils.tokenize_module(node)
        except tokenize.TokenError as ex:
            self.add_message(
                "syntax-error",
                line=ex.args[1][0],
                col_offset=ex.args[1][1],
                args=ex.args[0],
                confidence=HIGH,
            )
            return None

        if not node.pure_python:
            self.add_message("raw-checker-failed", args=node.name)
        else:
            # assert astroid.file.endswith('.py')
            # Parse module/block level option pragma's
            self.process_tokens(tokens)
            if self._ignore_file:
                return False
            # run raw and tokens checkers
            for raw_checker in rawcheckers:
                raw_checker.process_module(node)
            for token_checker in tokencheckers:
                token_checker.process_tokens(tokens)
        # generate events to astroid checkers
        walker.walk(node)
        return True

</t>
<t tx="ekr.20250131013601.390">class VerbatimText(Text):
    """A verbatim text, display the raw data.

    attributes :
    * data : the text value as an encoded or unicode string
    """


</t>
<t tx="ekr.20250131013601.391"># container nodes #############################################################


class Section(BaseLayout):
    """A section.

    attributes :
    * BaseLayout attributes

    a title may also be given to the constructor, it'll be added
    as a first element
    a description may also be given to the constructor, it'll be added
    as a first paragraph
    """

    @others
    ) -&gt; None:
        super().__init__(children=children)
        if description:
            self.insert(0, Paragraph([Text(description)]))
        if title:
            self.insert(0, Title(children=(title,)))
        self.report_id: str = ""  # Used in ReportHandlerMixin.make_reports


</t>
<t tx="ekr.20250131013601.392">class EvaluationSection(Section):
    @others
</t>
<t tx="ekr.20250131013601.393">class Title(BaseLayout):
    """A title.

    attributes :
    * BaseLayout attributes

    A title must not contain a section nor a paragraph!
    """


</t>
<t tx="ekr.20250131013601.394">class Paragraph(BaseLayout):
    """A simple text paragraph.

    attributes :
    * BaseLayout attributes

    A paragraph must not contains a section !
    """


</t>
<t tx="ekr.20250131013601.395">class Table(BaseLayout):
    """Some tabular data.

    attributes :
    * BaseLayout attributes
    * cols : the number of columns of the table (REQUIRED)
    * rheaders : the first row's elements are table's header
    * cheaders : the first col's elements are table's header
    * title : the table's optional title
    """

    @others
    ) -&gt; None:
        super().__init__(children=children)
        assert isinstance(cols, int)
        self.cols = cols
        self.title = title
        self.rheaders = rheaders
        self.cheaders = cheaders
</t>
<t tx="ekr.20250131013601.396">def __init__(self) -&gt; None:
    self.parent: BaseLayout | None = None
    self.children: list[VNode] = []
    self.visitor_name: str = self.__class__.__name__.lower()

</t>
<t tx="ekr.20250131013601.397">def __iter__(self) -&gt; Iterator[VNode]:
    return iter(self.children)

</t>
<t tx="ekr.20250131013601.398">def accept(self: _VNodeT, visitor: BaseWriter, *args: Any, **kwargs: Any) -&gt; None:
    func: VisitLeaveFunction[_VNodeT] = getattr(
        visitor, f"visit_{self.visitor_name}"
    )
    return func(self, *args, **kwargs)

</t>
<t tx="ekr.20250131013601.399">def leave(self: _VNodeT, visitor: BaseWriter, *args: Any, **kwargs: Any) -&gt; None:
    func: VisitLeaveFunction[_VNodeT] = getattr(
        visitor, f"leave_{self.visitor_name}"
    )
    return func(self, *args, **kwargs)


</t>
<t tx="ekr.20250131013601.4"># Python Linter class #########################################################

# pylint: disable-next=consider-using-namedtuple-or-dataclass
MSGS: dict[str, MessageDefinitionTuple] = {
    "F0001": (
        "%s",
        "fatal",
        "Used when an error occurred preventing the analysis of a \
              module (unable to find it for instance).",
        {"scope": WarningScope.LINE},
    ),
    "F0002": (
        "%s: %s",
        "astroid-error",
        "Used when an unexpected error occurred while building the "
        "Astroid  representation. This is usually accompanied by a "
        "traceback. Please report such errors !",
        {"scope": WarningScope.LINE},
    ),
    "F0010": (
        "error while code parsing: %s",
        "parse-error",
        "Used when an exception occurred while building the Astroid "
        "representation which could be handled by astroid.",
        {"scope": WarningScope.LINE},
    ),
    "F0011": (
        "error while parsing the configuration: %s",
        "config-parse-error",
        "Used when an exception occurred while parsing a pylint configuration file.",
        {"scope": WarningScope.LINE},
    ),
    "I0001": (
        "Unable to run raw checkers on built-in module %s",
        "raw-checker-failed",
        "Used to inform that a built-in module has not been checked "
        "using the raw checkers.",
        {
            "scope": WarningScope.LINE,
            "default_enabled": False,
        },
    ),
    "I0010": (
        "Unable to consider inline option %r",
        "bad-inline-option",
        "Used when an inline option is either badly formatted or can't "
        "be used inside modules.",
        {
            "scope": WarningScope.LINE,
            "default_enabled": False,
        },
    ),
    "I0011": (
        "Locally disabling %s (%s)",
        "locally-disabled",
        "Used when an inline option disables a message or a messages category.",
        {
            "scope": WarningScope.LINE,
            "default_enabled": False,
        },
    ),
    "I0013": (
        "Ignoring entire file",
        "file-ignored",
        "Used to inform that the file will not be checked",
        {
            "scope": WarningScope.LINE,
            "default_enabled": False,
        },
    ),
    "I0020": (
        "Suppressed %s (from line %d)",
        "suppressed-message",
        "A message was triggered on a line, but suppressed explicitly "
        "by a disable= comment in the file. This message is not "
        "generated for messages that are ignored due to configuration "
        "settings.",
        {
            "scope": WarningScope.LINE,
            "default_enabled": False,
        },
    ),
    "I0021": (
        "Useless suppression of %s",
        "useless-suppression",
        "Reported when a message is explicitly disabled for a line or "
        "a block of code, but never triggered.",
        {
            "scope": WarningScope.LINE,
            "default_enabled": False,
        },
    ),
    "I0022": (
        'Pragma "%s" is deprecated, use "%s" instead',
        "deprecated-pragma",
        "Some inline pylint options have been renamed or reworked, "
        "only the most recent form should be used. "
        "NOTE:skip-all is only available with pylint &gt;= 0.26",
        {
            "old_names": [("I0014", "deprecated-disable-all")],
            "scope": WarningScope.LINE,
            "default_enabled": False,
        },
    ),
    "E0001": (
        "%s",
        "syntax-error",
        "Used when a syntax error is raised for a module.",
        {"scope": WarningScope.LINE},
    ),
    "E0011": (
        "Unrecognized file option %r",
        "unrecognized-inline-option",
        "Used when an unknown inline option is encountered.",
        {"scope": WarningScope.LINE},
    ),
    "W0012": (
        "Unknown option value for '%s', expected a valid pylint message and got '%s'",
        "unknown-option-value",
        "Used when an unknown value is encountered for an option.",
        {
            "scope": WarningScope.LINE,
            "old_names": [("E0012", "bad-option-value")],
        },
    ),
    "R0022": (
        "Useless option value for '%s', %s",
        "useless-option-value",
        "Used when a value for an option that is now deleted from pylint"
        " is encountered.",
        {
            "scope": WarningScope.LINE,
            "old_names": [("E0012", "bad-option-value")],
        },
    ),
    "E0013": (
        "Plugin '%s' is impossible to load, is it installed ? ('%s')",
        "bad-plugin-value",
        "Used when a bad value is used in 'load-plugins'.",
        {"scope": WarningScope.LINE},
    ),
    "E0014": (
        "Out-of-place setting encountered in top level configuration-section '%s' : '%s'",
        "bad-configuration-section",
        "Used when we detect a setting in the top level of a toml configuration that"
        " shouldn't be there.",
        {"scope": WarningScope.LINE},
    ),
    "E0015": (
        "Unrecognized option found: %s",
        "unrecognized-option",
        "Used when we detect an option that we do not recognize.",
        {"scope": WarningScope.LINE},
    ),
}


# pylint: disable=too-many-instance-attributes,too-many-public-methods
class PyLinter(
    _ArgumentsManager,
    _MessageStateHandler,
    reporters.ReportsHandlerMixIn,
    checkers.BaseChecker,
</t>
<t tx="ekr.20250131013601.40">    def open(self) -&gt; None:
        """Initialize counters."""
        MANAGER.always_load_extensions = self.config.unsafe_load_any_extension
        MANAGER.max_inferable_values = self.config.limit_inference_results
        MANAGER.extension_package_whitelist.update(self.config.extension_pkg_allow_list)
        MANAGER.module_denylist.update(self.config.ignored_modules)
        MANAGER.prefer_stubs = self.config.prefer_stubs
        if self.config.extension_pkg_whitelist:
            MANAGER.extension_package_whitelist.update(
                self.config.extension_pkg_whitelist
            )
        self.stats.reset_message_count()

</t>
<t tx="ekr.20250131013601.400">def __init__(self, children: Iterable[Text | str] = ()) -&gt; None:
    super().__init__()
    for child in children:
        if isinstance(child, VNode):
            self.append(child)
        else:
            self.add_text(child)

</t>
<t tx="ekr.20250131013601.401">def append(self, child: VNode) -&gt; None:
    """Add a node to children."""
    assert child not in self.parents()
    self.children.append(child)
    child.parent = self

</t>
<t tx="ekr.20250131013601.402">def insert(self, index: int, child: VNode) -&gt; None:
    """Insert a child node."""
    self.children.insert(index, child)
    child.parent = self

</t>
<t tx="ekr.20250131013601.403">def parents(self) -&gt; list[BaseLayout]:
    """Return the ancestor nodes."""
    assert self.parent is not self
    if self.parent is None:
        return []
    return [self.parent, * self.parent.parents()]

</t>
<t tx="ekr.20250131013601.404">def add_text(self, text: str) -&gt; None:
    """Shortcut to add text data."""
    self.children.append(Text(text))


</t>
<t tx="ekr.20250131013601.405">def __init__(self, data: str, escaped: bool = True) -&gt; None:
    super().__init__()
    self.escaped = escaped
    self.data = data


</t>
<t tx="ekr.20250131013601.406">def __init__(
    self,
    title: str | None = None,
    description: str | None = None,
    children: Iterable[Text | str] = (),
</t>
<t tx="ekr.20250131013601.407">def __init__(self, message: str, children: Iterable[Text | str] = ()) -&gt; None:
    super().__init__(children=children)
    title = Paragraph()
    title.append(Text("-" * len(message)))
    self.append(title)
    message_body = Paragraph()
    message_body.append(Text(message))
    self.append(message_body)


</t>
<t tx="ekr.20250131013601.408">def __init__(
    self,
    cols: int,
    title: str | None = None,
    rheaders: int = 0,
    cheaders: int = 0,
    children: Iterable[Text | str] = (),
</t>
<t tx="ekr.20250131013601.409">@path pylint/reporters/ureports
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Text formatting drivers for ureports."""

from __future__ import annotations

from typing import TYPE_CHECKING

from pylint.reporters.ureports.base_writer import BaseWriter

if TYPE_CHECKING:
    from pylint.reporters.ureports.nodes import (
        EvaluationSection,
        Paragraph,
        Section,
        Table,
        Text,
        Title,
        VerbatimText,
    )

TITLE_UNDERLINES = ["", "=", "-", "`", ".", "~", "^"]
BULLETS = ["*", "-"]


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.41">    def generate_reports(self, verbose: bool = False) -&gt; int | None:
        """Close the whole package /module, it's time to make reports !

        if persistent run, pickle results for later comparison
        """
        # Display whatever messages are left on the reporter.
        self.reporter.display_messages(report_nodes.Section())
        if not self.file_state._is_base_filestate:
            # load previous results if any
            previous_stats = load_results(self.file_state.base_name)
            self.reporter.on_close(self.stats, previous_stats)
            if self.config.reports:
                sect = self.make_reports(self.stats, previous_stats)
            else:
                sect = report_nodes.Section()

            if self.config.reports:
                self.reporter.display_reports(sect)

            score_value = self._report_evaluation(verbose)
            # save results if persistent run
            if self.config.persistent:
                save_results(self.stats, self.file_state.base_name)
        else:
            self.reporter.on_close(self.stats, LinterStats())
            score_value = None
        return score_value

</t>
<t tx="ekr.20250131013601.410">class TextWriter(BaseWriter):
    """Format layouts as text
    (ReStructured inspiration but not totally handled yet).
    """

    @others
</t>
<t tx="ekr.20250131013601.411">def __init__(self) -&gt; None:
    super().__init__()
    self.list_level = 0

</t>
<t tx="ekr.20250131013601.412">def visit_section(self, layout: Section) -&gt; None:
    """Display a section as text."""
    self.section += 1
    self.writeln()
    self.format_children(layout)
    self.section -= 1
    self.writeln()

</t>
<t tx="ekr.20250131013601.413">def visit_evaluationsection(self, layout: EvaluationSection) -&gt; None:
    """Display an evaluation section as a text."""
    self.section += 1
    self.format_children(layout)
    self.section -= 1
    self.writeln()

</t>
<t tx="ekr.20250131013601.414">def visit_title(self, layout: Title) -&gt; None:
    title = "".join(list(self.compute_content(layout)))
    self.writeln(title)
    try:
        self.writeln(TITLE_UNDERLINES[self.section] * len(title))
    except IndexError:
        print("FIXME TITLE TOO DEEP. TURNING TITLE INTO TEXT")

</t>
<t tx="ekr.20250131013601.415">def visit_paragraph(self, layout: Paragraph) -&gt; None:
    """Enter a paragraph."""
    self.format_children(layout)
    self.writeln()

</t>
<t tx="ekr.20250131013601.416">def visit_table(self, layout: Table) -&gt; None:
    """Display a table as text."""
    table_content = self.get_table_content(layout)
    # get columns width
    cols_width = [0] * len(table_content[0])
    for row in table_content:
        for index, col in enumerate(row):
            cols_width[index] = max(cols_width[index], len(col))
    self.default_table(layout, table_content, cols_width)
    self.writeln()

</t>
<t tx="ekr.20250131013601.417">def default_table(
    self, layout: Table, table_content: list[list[str]], cols_width: list[int]
) -&gt; None:
    """Format a table."""
    cols_width = [size + 1 for size in cols_width]
    format_strings = " ".join(["%%-%ss"] * len(cols_width))
    format_strings %= tuple(cols_width)

    table_linesep = "\n+" + "+".join("-" * w for w in cols_width) + "+\n"
    headsep = "\n+" + "+".join("=" * w for w in cols_width) + "+\n"

    self.write(table_linesep)
    split_strings = format_strings.split(" ")
    for index, line in enumerate(table_content):
        self.write("|")
        for line_index, at_index in enumerate(line):
            self.write(split_strings[line_index] % at_index)
            self.write("|")
        if index == 0 and layout.rheaders:
            self.write(headsep)
        else:
            self.write(table_linesep)

</t>
<t tx="ekr.20250131013601.418">def visit_verbatimtext(self, layout: VerbatimText) -&gt; None:
    """Display a verbatim layout as text (so difficult ;)."""
    self.writeln("::\n")
    for line in layout.data.splitlines():
        self.writeln("    " + line)
    self.writeln()

</t>
<t tx="ekr.20250131013601.419">def visit_text(self, layout: Text) -&gt; None:
    """Add some text."""
    self.write(f"{layout.data}")
</t>
<t tx="ekr.20250131013601.42">    def _report_evaluation(self, verbose: bool = False) -&gt; int | None:
        """Make the global evaluation report."""
        # check with at least a statement (usually 0 when there is a
        # syntax error preventing pylint from further processing)
        note = None
        previous_stats = load_results(self.file_state.base_name)
        if self.stats.statement == 0:
            return note

        # get a global note for the code
        evaluation = self.config.evaluation
        try:
            stats_dict = {
                "fatal": self.stats.fatal,
                "error": self.stats.error,
                "warning": self.stats.warning,
                "refactor": self.stats.refactor,
                "convention": self.stats.convention,
                "statement": self.stats.statement,
                "info": self.stats.info,
            }
            note = eval(evaluation, {}, stats_dict)  # pylint: disable=eval-used
        except Exception as ex:  # pylint: disable=broad-except
            msg = f"An exception occurred while rating: {ex}"
        else:
            self.stats.global_note = note
            msg = f"Your code has been rated at {note:.2f}/10"
            if previous_stats:
                pnote = previous_stats.global_note
                if pnote is not None:
                    msg += f" (previous run: {pnote:.2f}/10, {note - pnote:+.2f})"

            if verbose:
                checked_files_count = self.stats.node_count["module"]
                msg += f"\nChecked {checked_files_count} files, skipped {self.stats.skipped} files/modules"

        if self.config.score:
            sect = report_nodes.EvaluationSection(msg)
            self.reporter.display_reports(sect)
        return note

</t>
<t tx="ekr.20250131013601.420"></t>
<t tx="ekr.20250131013601.421">@path pylint/testutils
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Functional/non regression tests for pylint."""

__all__ = [
    "UPDATE_FILE",
    "UPDATE_OPTION",
    "CheckerTestCase",
    "FunctionalTestFile",
    "GenericTestReporter",
    "LintModuleTest",
    "MessageTest",
    "MinimalTestReporter",
    "UnittestLinter",
    "_get_tests_info",
    "_tokenize_str",
    "create_files",
    "linter",
    "set_config",
]

from pylint.testutils.checker_test_case import CheckerTestCase
from pylint.testutils.constants import UPDATE_FILE, UPDATE_OPTION
from pylint.testutils.decorator import set_config
from pylint.testutils.functional import FunctionalTestFile
from pylint.testutils.get_test_info import _get_tests_info
from pylint.testutils.global_test_linter import linter
from pylint.testutils.lint_module_test import LintModuleTest
from pylint.testutils.output_line import MessageTest
from pylint.testutils.reporter_for_tests import GenericTestReporter, MinimalTestReporter
from pylint.testutils.tokenize_str import _tokenize_str
from pylint.testutils.unittest_linter import UnittestLinter
from pylint.testutils.utils import create_files
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.422">@path pylint/testutils
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Classes and functions used to mimic normal pylint runs.

This module is considered private and can change at any time.
"""

from __future__ import annotations

from collections.abc import Sequence

from pylint.lint import Run as LintRun
from pylint.reporters.base_reporter import BaseReporter
from pylint.testutils.lint_module_test import PYLINTRC


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.423">def _add_rcfile_default_pylintrc(args: list[str]) -&gt; list[str]:
    """Add a default pylintrc with the rcfile option in a list of pylint args."""
    if not any("--rcfile" in arg for arg in args):
        args.insert(0, f"--rcfile={PYLINTRC}")
    return args


</t>
<t tx="ekr.20250131013601.424">class _Run(LintRun):
    """Like Run, but we're using an explicitly set empty pylintrc.

    We don't want to use the project's pylintrc during tests, because
    it means that a change in our config could break tests.
    But we want to see if the changes to the default break tests.
    """

    @others
</t>
<t tx="ekr.20250131013601.425">def __init__(
    self,
    args: Sequence[str],
    reporter: BaseReporter | None = None,
    exit: bool = True,  # pylint: disable=redefined-builtin
) -&gt; None:
    args = _add_rcfile_default_pylintrc(list(args))
    super().__init__(args, reporter, exit)
</t>
<t tx="ekr.20250131013601.426">@path pylint/testutils
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import contextlib
from collections.abc import Generator, Iterator
from typing import Any

from astroid import nodes

from pylint.testutils.global_test_linter import linter
from pylint.testutils.output_line import MessageTest
from pylint.testutils.unittest_linter import UnittestLinter
from pylint.utils import ASTWalker


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.427">class CheckerTestCase:
    """A base testcase class for unit testing individual checker classes."""

    @others
</t>
<t tx="ekr.20250131013601.428"># TODO: Figure out way to type this as type[BaseChecker] while also
# setting self.checker correctly.
CHECKER_CLASS: Any
CONFIG: dict[str, Any] = {}

def setup_method(self) -&gt; None:
    self.linter = UnittestLinter()
    self.checker = self.CHECKER_CLASS(self.linter)
    for key, value in self.CONFIG.items():
        setattr(self.checker.linter.config, key, value)
    self.checker.open()

</t>
<t tx="ekr.20250131013601.429">@contextlib.contextmanager
def assertNoMessages(self) -&gt; Iterator[None]:
    """Assert that no messages are added by the given method."""
    with self.assertAddsMessages():
        yield

</t>
<t tx="ekr.20250131013601.43">    def _add_one_message(
        self,
        message_definition: MessageDefinition,
        line: int | None,
        node: nodes.NodeNG | None,
        args: Any | None,
        confidence: interfaces.Confidence | None,
        col_offset: int | None,
        end_lineno: int | None,
        end_col_offset: int | None,
    ) -&gt; None:
        """After various checks have passed a single Message is
        passed to the reporter and added to stats.
        """
        message_definition.check_message_definition(line, node)

        # Look up "location" data of node if not yet supplied
        if node:
            if node.position:
                if not line:
                    line = node.position.lineno
                if not col_offset:
                    col_offset = node.position.col_offset
                if not end_lineno:
                    end_lineno = node.position.end_lineno
                if not end_col_offset:
                    end_col_offset = node.position.end_col_offset
            else:
                if not line:
                    line = node.fromlineno
                if not col_offset:
                    col_offset = node.col_offset
                if not end_lineno:
                    end_lineno = node.end_lineno
                if not end_col_offset:
                    end_col_offset = node.end_col_offset

        # should this message be displayed
        if not self.is_message_enabled(message_definition.msgid, line, confidence):
            self.file_state.handle_ignored_message(
                self._get_message_state_scope(
                    message_definition.msgid, line, confidence
                ),
                message_definition.msgid,
                line,
            )
            return

        # update stats
        msg_cat = MSG_TYPES[message_definition.msgid[0]]
        self.msg_status |= MSG_TYPES_STATUS[message_definition.msgid[0]]
        self.stats.increase_single_message_count(msg_cat, 1)
        self.stats.increase_single_module_message_count(self.current_name, msg_cat, 1)
        try:
            self.stats.by_msg[message_definition.symbol] += 1
        except KeyError:
            self.stats.by_msg[message_definition.symbol] = 1
        # Interpolate arguments into message string
        msg = message_definition.msg
        if args is not None:
            msg %= args
        # get module and object
        if node is None:
            module, obj = self.current_name, ""
            abspath = self.current_file
        else:
            module, obj = utils.get_module_and_frameid(node)
            abspath = node.root().file
        if abspath is not None:
            path = abspath.replace(self.reporter.path_strip_prefix, "", 1)
        else:
            path = "configuration"
        # add the message
        self.reporter.handle_message(
            Message(
                message_definition.msgid,
                message_definition.symbol,
                MessageLocationTuple(
                    abspath or "",
                    path,
                    module or "",
                    obj,
                    line or 1,
                    col_offset or 0,
                    end_lineno,
                    end_col_offset,
                ),
                msg,
                confidence,
            )
        )

</t>
<t tx="ekr.20250131013601.430">@contextlib.contextmanager
def assertAddsMessages(
    self, *messages: MessageTest, ignore_position: bool = False
) -&gt; Generator[None]:
    """Assert that exactly the given method adds the given messages.

    The list of messages must exactly match *all* the messages added by the
    method. Additionally, we check to see whether the args in each message can
    actually be substituted into the message string.

    Using the keyword argument `ignore_position`, all checks for position
    arguments (line, col_offset, ...) will be skipped. This can be used to
    just test messages for the correct node.
    """
    yield
    got = self.linter.release_messages()
    no_msg = "No message."
    expected = "\n".join(repr(m) for m in messages) or no_msg
    got_str = "\n".join(repr(m) for m in got) or no_msg
    msg = (
        "Expected messages did not match actual.\n"
        f"\nExpected:\n{expected}\n\nGot:\n{got_str}\n"
    )

    assert len(messages) == len(got), msg

    for expected_msg, gotten_msg in zip(messages, got):
        assert expected_msg.msg_id == gotten_msg.msg_id, msg
        assert expected_msg.node == gotten_msg.node, msg
        assert expected_msg.args == gotten_msg.args, msg
        assert expected_msg.confidence == gotten_msg.confidence, msg

        if ignore_position:
            # Do not check for line, col_offset etc...
            continue

        assert expected_msg.line == gotten_msg.line, msg
        assert expected_msg.col_offset == gotten_msg.col_offset, msg
        assert expected_msg.end_line == gotten_msg.end_line, msg
        assert expected_msg.end_col_offset == gotten_msg.end_col_offset, msg

</t>
<t tx="ekr.20250131013601.431">def walk(self, node: nodes.NodeNG) -&gt; None:
    """Recursive walk on the given node."""
    walker = ASTWalker(linter)
    walker.add_checker(self.checker)
    walker.walk(node)
</t>
<t tx="ekr.20250131013601.432">@path pylint/testutils
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Utility functions for configuration testing."""

from __future__ import annotations

import copy
import json
import logging
import unittest
from pathlib import Path
from typing import Any

from pylint.lint import Run

# We use Any in this typing because the configuration contains real objects and constants
# that could be a lot of things.
ConfigurationValue = Any
PylintConfiguration = dict[str, ConfigurationValue]


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.433">def get_expected_or_default(
    tested_configuration_file: str | Path,
    suffix: str,
    default: str,
) -&gt; str:
    """Return the expected value from the file if it exists, or the given default."""
    expected = default
    path = Path(tested_configuration_file)
    expected_result_path = path.parent / f"{path.stem}.{suffix}"
    if expected_result_path.exists():
        with open(expected_result_path, encoding="utf8") as f:
            expected = f.read()
        # logging is helpful to realize your file is not taken into
        # account after a misspelling of the file name. The output of the
        # program is checked during the test so printing messes with the result.
        logging.info("%s exists.", expected_result_path)
    else:
        logging.info("%s not found, using '%s'.", expected_result_path, default)
    return expected


</t>
<t tx="ekr.20250131013601.434">EXPECTED_CONF_APPEND_KEY = "functional_append"
EXPECTED_CONF_REMOVE_KEY = "functional_remove"


def get_expected_configuration(
    configuration_path: str, default_configuration: PylintConfiguration
) -&gt; PylintConfiguration:
    """Get the expected parsed configuration of a configuration functional test."""
    result = copy.deepcopy(default_configuration)
    config_as_json = get_expected_or_default(
        configuration_path, suffix="result.json", default="{}"
    )
    to_override = json.loads(config_as_json)
    for key, value in to_override.items():
        if key == EXPECTED_CONF_APPEND_KEY:
            for fkey, fvalue in value.items():
                result[fkey] += fvalue
        elif key == EXPECTED_CONF_REMOVE_KEY:
            for fkey, fvalue in value.items():
                new_value = []
                for old_value in result[fkey]:
                    if old_value not in fvalue:
                        new_value.append(old_value)
                result[fkey] = new_value
        else:
            result[key] = value
    return result


</t>
<t tx="ekr.20250131013601.435">def get_related_files(
    tested_configuration_file: str | Path, suffix_filter: str
) -&gt; list[Path]:
    """Return all the file related to a test conf file ending with a suffix."""
    conf_path = Path(tested_configuration_file)
    return [
        p
        for p in conf_path.parent.iterdir()
        if str(p.stem).startswith(conf_path.stem) and str(p).endswith(suffix_filter)
    ]


</t>
<t tx="ekr.20250131013601.436">def get_expected_output(
    configuration_path: str | Path, user_specific_path: Path
) -&gt; tuple[int, str]:
    """Get the expected output of a functional test."""
    exit_code = 0
    msg = (
        "we expect a single file of the form 'filename.32.out' where 'filename' represents "
        "the name of the configuration file, and '32' the expected error code."
    )
    possible_out_files = get_related_files(configuration_path, suffix_filter="out")
    if len(possible_out_files) &gt; 1:
        logging.error(
            "Too much .out files for %s %s.",
            configuration_path,
            msg,
        )
        return -1, "out file is broken"
    if not possible_out_files:
        # logging is helpful to see what the expected exit code is and why.
        # The output of the program is checked during the test so printing
        # messes with the result.
        logging.info(".out file does not exists, so the expected exit code is 0")
        return 0, ""
    path = possible_out_files[0]
    try:
        exit_code = int(str(path.stem).rsplit(".", maxsplit=1)[-1])
    except Exception as e:  # pylint: disable=broad-except
        logging.error(
            "Wrong format for .out file name for %s %s: %s",
            configuration_path,
            msg,
            e,
        )
        return -1, "out file is broken"

    output = get_expected_or_default(
        configuration_path, suffix=f"{exit_code}.out", default=""
    )
    logging.info(
        "Output exists for %s so the expected exit code is %s",
        configuration_path,
        exit_code,
    )
    return exit_code, output.format(
        abspath=configuration_path,
        relpath=Path(configuration_path).relative_to(user_specific_path),
    )


</t>
<t tx="ekr.20250131013601.437">def run_using_a_configuration_file(
    configuration_path: Path | str, file_to_lint: str = __file__
) -&gt; Run:
    """Simulate a run with a configuration without really launching the checks."""
    configuration_path = str(configuration_path)
    args = ["--rcfile", configuration_path, file_to_lint]
    # Do not actually run checks, that could be slow. We don't mock
    # `PyLinter.check`: it calls `PyLinter.initialize` which is
    # needed to properly set up messages inclusion/exclusion
    # in `_msg_states`, used by `is_message_enabled`.
    check = "pylint.lint.pylinter.check_parallel"
    with unittest.mock.patch(check):
        runner = Run(args, exit=False)
    return runner
</t>
<t tx="ekr.20250131013601.438">@path pylint/testutils
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

import operator
import re
import sys
from pathlib import Path

# This is faster/terser without f-strings:
# '"%d%d%d" % sys.version_info[:3]': (best of 5: 214 nanoseconds per loop)
# '"".join(str(x) for x in sys.version_info[:3])'`: best of 5: 546 nanoseconds per loop
# pylint: disable-next=consider-using-f-string
SYS_VERS_STR = "%d%d%d" % sys.version_info[:3]  # noqa: UP031
TITLE_UNDERLINES = ["", "=", "-", "."]
UPDATE_OPTION = "--update-functional-output"
UPDATE_FILE = Path("pylint-functional-test-update")
# Common sub-expressions.
_MESSAGE = {"msg": r"[a-z][a-z\-]+"}
# Matches a #,
#  - followed by a comparison operator and a Python version (optional),
#  - followed by a line number with a +/- (optional),
#  - followed by a list of bracketed message symbols.
# Used to extract expected messages from testdata files.
_EXPECTED_RE = re.compile(
    r"\s*#\s*(?:(?P&lt;line&gt;[+-]?[0-9]+):)?"  # pylint: disable=consider-using-f-string
    r"(?:(?P&lt;op&gt;[&gt;&lt;=]+) *(?P&lt;version&gt;[0-9.]+):)?"
    r"\s*\[(?P&lt;msgs&gt;{msg}(?:,\s*{msg})*)]".format(**_MESSAGE)
)

_OPERATORS = {"&gt;": operator.gt, "&lt;": operator.lt, "&gt;=": operator.ge, "&lt;=": operator.le}
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.439">@path pylint/testutils
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import functools
from collections.abc import Callable
from typing import Any

from pylint.testutils.checker_test_case import CheckerTestCase


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.44">    def add_message(
        self,
        msgid: str,
        line: int | None = None,
        node: nodes.NodeNG | None = None,
        args: Any | None = None,
        confidence: interfaces.Confidence | None = None,
        col_offset: int | None = None,
        end_lineno: int | None = None,
        end_col_offset: int | None = None,
    ) -&gt; None:
        """Adds a message given by ID or name.

        If provided, the message string is expanded using args.

        AST checkers must provide the node argument (but may optionally
        provide line if the line number is different), raw and token checkers
        must provide the line argument.
        """
        if confidence is None:
            confidence = interfaces.UNDEFINED
        message_definitions = self.msgs_store.get_message_definitions(msgid)
        for message_definition in message_definitions:
            self._add_one_message(
                message_definition,
                line,
                node,
                args,
                confidence,
                col_offset,
                end_lineno,
                end_col_offset,
            )

</t>
<t tx="ekr.20250131013601.440">def set_config(**kwargs: Any) -&gt; Callable[[Callable[..., None]], Callable[..., None]]:
    """Decorator for setting an option on the linter.

    Passing the args and kwargs back to the test function itself
    allows this decorator to be used on parameterized test cases.
    """

    def _wrapper(fun: Callable[..., None]) -&gt; Callable[..., None]:
        @functools.wraps(fun)
        def _forward(
            self: CheckerTestCase, *args: Any, **test_function_kwargs: Any
        ) -&gt; None:
            """Set option via argparse."""
            for key, value in kwargs.items():
                self.linter.set_option(key, value)

            # Reopen checker in case, it may be interested in configuration change
            self.checker.open()

            fun(self, *args, **test_function_kwargs)

        return _forward

    return _wrapper
</t>
<t tx="ekr.20250131013601.441">@path pylint/testutils
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

from glob import glob
from os.path import basename, join, splitext

from pylint.testutils.constants import SYS_VERS_STR


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.442">def _get_tests_info(
    input_dir: str, msg_dir: str, prefix: str, suffix: str
) -&gt; list[tuple[str, str]]:
    """Get python input examples and output messages.

    We use following conventions for input files and messages:
    for different inputs:
        test for python  &gt;= x.y    -&gt;  input   =  &lt;name&gt;_pyxy.py
        test for python  &lt;  x.y    -&gt;  input   =  &lt;name&gt;_py_xy.py
    for one input and different messages:
        message for python &gt;=  x.y -&gt;  message =  &lt;name&gt;_pyxy.txt
        lower versions             -&gt;  message with highest num
    """
    result = []
    for fname in glob(join(input_dir, prefix + "*" + suffix)):
        infile = basename(fname)
        fbase = splitext(infile)[0]
        # filter input files :
        pyrestr = fbase.rsplit("_py", 1)[-1]  # like _26 or 26
        if pyrestr.isdigit():  # '24', '25'...
            if pyrestr.isdigit() and int(SYS_VERS_STR) &lt; int(pyrestr):
                continue
        if pyrestr.startswith("_") and pyrestr[1:].isdigit():
            # skip test for higher python versions
            if pyrestr[1:].isdigit() and int(SYS_VERS_STR) &gt;= int(pyrestr[1:]):
                continue
        messages = glob(join(msg_dir, fbase + "*.txt"))
        # the last one will be without ext, i.e. for all or upper versions:
        if messages:
            for outfile in sorted(messages, reverse=True):
                py_rest = outfile.rsplit("_py", 1)[-1][:-4]
                if py_rest.isdigit() and int(SYS_VERS_STR) &gt;= int(py_rest):
                    break
        else:
            # This will provide an error message indicating the missing filename.
            outfile = join(msg_dir, fbase + ".txt")
        result.append((infile, outfile))
    return result
</t>
<t tx="ekr.20250131013601.443">@path pylint/testutils
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from pylint import checkers
from pylint.lint import PyLinter
from pylint.testutils.reporter_for_tests import GenericTestReporter


@others
# Can't be renamed to a constant (easily), it breaks countless tests
linter = create_test_linter()
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.444">def create_test_linter() -&gt; PyLinter:
    test_reporter = GenericTestReporter()
    linter_ = PyLinter()
    linter_.set_reporter(test_reporter)
    linter_.config.persistent = 0
    checkers.initialize(linter_)
    return linter_


</t>
<t tx="ekr.20250131013601.445">@path pylint/testutils
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import csv
import operator
import platform
import sys
from collections import Counter
from io import StringIO
from pathlib import Path
from typing import TextIO

import pytest
from _pytest.config import Config

from pylint import checkers
from pylint.config.config_initialization import _config_initialization
from pylint.lint import PyLinter
from pylint.message.message import Message
from pylint.testutils.constants import _EXPECTED_RE, _OPERATORS, UPDATE_OPTION

# need to import from functional.test_file to avoid cyclic import
from pylint.testutils.functional.test_file import (
    FunctionalTestFile,
    NoFileError,
    parse_python_version,
)
from pylint.testutils.output_line import OutputLine
from pylint.testutils.reporter_for_tests import FunctionalTestReporter

MessageCounter = Counter[tuple[int, str]]

PYLINTRC = Path(__file__).parent / "testing_pylintrc"


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.446">class LintModuleTest:
    @others
</t>
<t tx="ekr.20250131013601.447">maxDiff = None

def __init__(
    self, test_file: FunctionalTestFile, config: Config | None = None
) -&gt; None:
    _test_reporter = FunctionalTestReporter()
    self._linter = PyLinter()
    self._linter.config.persistent = 0
    checkers.initialize(self._linter)

    # See if test has its own .rc file, if so we use that one
    rc_file: Path | str = PYLINTRC
    try:
        rc_file = test_file.option_file
        self._linter.disable("suppressed-message")
        self._linter.disable("locally-disabled")
        self._linter.disable("useless-suppression")
    except NoFileError:
        pass

    self._test_file = test_file
    try:
        args = [test_file.source]
    except NoFileError:
        # If we're still raising NoFileError the actual source file doesn't exist
        args = [""]
    if config and config.getoption("minimal_messages_config"):
        with self._open_source_file() as f:
            messages_to_enable = {msg[1] for msg in self.get_expected_messages(f)}
            # Always enable fatal errors
            messages_to_enable.add("astroid-error")
            messages_to_enable.add("fatal")
            messages_to_enable.add("syntax-error")
        args.extend(["--disable=all", f"--enable={','.join(messages_to_enable)}"])

    # Add testoptions
    self._linter._arg_parser.add_argument(
        "--min_pyver", type=parse_python_version, default=(2, 5)
    )
    self._linter._arg_parser.add_argument(
        "--max_pyver", type=parse_python_version, default=(4, 0)
    )
    self._linter._arg_parser.add_argument(
        "--min_pyver_end_position", type=parse_python_version, default=(3, 8)
    )
    self._linter._arg_parser.add_argument(
        "--requires", type=lambda s: [i.strip() for i in s.split(",")], default=[]
    )
    self._linter._arg_parser.add_argument(
        "--except_implementations",
        type=lambda s: [i.strip() for i in s.split(",")],
        default=[],
    )
    self._linter._arg_parser.add_argument(
        "--exclude_platforms",
        type=lambda s: [i.strip() for i in s.split(",")],
        default=[],
    )
    self._linter._arg_parser.add_argument(
        "--exclude_from_minimal_messages_config", default=False
    )

    _config_initialization(
        self._linter, args_list=args, config_file=rc_file, reporter=_test_reporter
    )

    self._check_end_position = (
        sys.version_info &gt;= self._linter.config.min_pyver_end_position
    )

    self._config = config

</t>
<t tx="ekr.20250131013601.448">def setUp(self) -&gt; None:
    if self._should_be_skipped_due_to_version():
        pytest.skip(
            f"Test cannot run with Python {sys.version.split(' ', maxsplit=1)[0]}."
        )
    missing = []
    for requirement in self._linter.config.requires:
        try:
            __import__(requirement)
        except ImportError:
            missing.append(requirement)
    if missing:
        pytest.skip(f"Requires {','.join(missing)} to be present.")
    except_implementations = self._linter.config.except_implementations
    if except_implementations:
        if platform.python_implementation() in except_implementations:
            msg = "Test cannot run with Python implementation %r"
            pytest.skip(msg % platform.python_implementation())
    excluded_platforms = self._linter.config.exclude_platforms
    if excluded_platforms:
        if sys.platform.lower() in excluded_platforms:
            pytest.skip(f"Test cannot run on platform {sys.platform!r}")
    if (
        self._config
        and self._config.getoption("minimal_messages_config")
        and self._linter.config.exclude_from_minimal_messages_config
    ):
        pytest.skip("Test excluded from --minimal-messages-config")

</t>
<t tx="ekr.20250131013601.449">def runTest(self) -&gt; None:
    self._runTest()

</t>
<t tx="ekr.20250131013601.45">    def add_ignored_message(
        self,
        msgid: str,
        line: int,
        node: nodes.NodeNG | None = None,
        confidence: interfaces.Confidence | None = interfaces.UNDEFINED,
    ) -&gt; None:
        """Prepares a message to be added to the ignored message storage.

        Some checks return early in special cases and never reach add_message(),
        even though they would normally issue a message.
        This creates false positives for useless-suppression.
        This function avoids this by adding those message to the ignored msgs attribute
        """
        message_definitions = self.msgs_store.get_message_definitions(msgid)
        for message_definition in message_definitions:
            message_definition.check_message_definition(line, node)
            self.file_state.handle_ignored_message(
                self._get_message_state_scope(
                    message_definition.msgid, line, confidence
                ),
                message_definition.msgid,
                line,
            )

</t>
<t tx="ekr.20250131013601.450">def _should_be_skipped_due_to_version(self) -&gt; bool:
    return (  # type: ignore[no-any-return]
        sys.version_info &lt; self._linter.config.min_pyver
        or sys.version_info &gt; self._linter.config.max_pyver
    )

</t>
<t tx="ekr.20250131013601.451">def __str__(self) -&gt; str:
    return f"{self._test_file.base} ({self.__class__.__module__}.{self.__class__.__name__})"

</t>
<t tx="ekr.20250131013601.452">@staticmethod
def get_expected_messages(stream: TextIO) -&gt; MessageCounter:
    """Parses a file and get expected messages.

    :param stream: File-like input stream.
    :type stream: enumerable
    :returns: A dict mapping line,msg-symbol tuples to the count on this line.
    :rtype: dict
    """
    messages: MessageCounter = Counter()
    for i, line in enumerate(stream):
        match = _EXPECTED_RE.search(line)
        if match is None:
            continue
        line = match.group("line")
        if line is None:
            lineno = i + 1
        elif line.startswith(("+", "-")):
            lineno = i + 1 + int(line)
        else:
            lineno = int(line)

        version = match.group("version")
        op = match.group("op")
        if version:
            required = parse_python_version(version)
            if not _OPERATORS[op](sys.version_info, required):
                continue

        for msg_id in match.group("msgs").split(","):
            messages[lineno, msg_id.strip()] += 1
    return messages

</t>
<t tx="ekr.20250131013601.453">@staticmethod
def multiset_difference(
    expected_entries: MessageCounter,
    actual_entries: MessageCounter,
) -&gt; tuple[MessageCounter, dict[tuple[int, str], int]]:
    """Takes two multisets and compares them.

    A multiset is a dict with the cardinality of the key as the value.
    """
    missing = expected_entries.copy()
    missing.subtract(actual_entries)
    unexpected = {}
    for key, value in list(missing.items()):
        if value &lt;= 0:
            missing.pop(key)
            if value &lt; 0:
                unexpected[key] = -value
    return missing, unexpected

</t>
<t tx="ekr.20250131013601.454">def _open_expected_file(self) -&gt; TextIO:
    try:
        return open(self._test_file.expected_output, encoding="utf-8")
    except FileNotFoundError:
        return StringIO("")

</t>
<t tx="ekr.20250131013601.455">def _open_source_file(self) -&gt; TextIO:
    if self._test_file.base == "invalid_encoded_data":
        return open(self._test_file.source, encoding="utf-8")
    if "latin1" in self._test_file.base:
        return open(self._test_file.source, encoding="latin1")
    return open(self._test_file.source, encoding="utf8")

</t>
<t tx="ekr.20250131013601.456">def _get_expected(self) -&gt; tuple[MessageCounter, list[OutputLine]]:
    with self._open_source_file() as f:
        expected_msgs = self.get_expected_messages(f)
    if not expected_msgs:
        expected_msgs = Counter()
    with self._open_expected_file() as f:
        expected_output_lines = [
            OutputLine.from_csv(row, self._check_end_position)
            for row in csv.reader(f, "test")
        ]
    return expected_msgs, expected_output_lines

</t>
<t tx="ekr.20250131013601.457">def _get_actual(self) -&gt; tuple[MessageCounter, list[OutputLine]]:
    messages: list[Message] = self._linter.reporter.messages
    messages.sort(key=lambda m: (m.line, m.symbol, m.msg))
    received_msgs: MessageCounter = Counter()
    received_output_lines = []
    for msg in messages:
        assert(
            msg.symbol != "fatal"
        ), f"Pylint analysis failed because of '{msg.msg}'"
        received_msgs[msg.line, msg.symbol] += 1
        received_output_lines.append(
            OutputLine.from_msg(msg, self._check_end_position)
        )
    return received_msgs, received_output_lines

</t>
<t tx="ekr.20250131013601.458">def _runTest(self) -&gt; None:
    __tracebackhide__ = True  # pylint: disable=unused-variable
    modules_to_check = [self._test_file.source]
    self._linter.check(modules_to_check)
    expected_messages, expected_output = self._get_expected()
    actual_messages, actual_output = self._get_actual()
    assert(
        expected_messages == actual_messages
    ), self.error_msg_for_unequal_messages(
        actual_messages, expected_messages, actual_output
    )
    self._check_output_text(expected_messages, expected_output, actual_output)

</t>
<t tx="ekr.20250131013601.459">def error_msg_for_unequal_messages(
    self,
    actual_messages: MessageCounter,
    expected_messages: MessageCounter,
    actual_output: list[OutputLine],
) -&gt; str:
    msg = [f'Wrong message(s) raised for "{Path(self._test_file.source).name}":']
    missing, unexpected = self.multiset_difference(
        expected_messages, actual_messages
    )
    if missing:
        msg.append("\nExpected in testdata:")
        msg.extend(f" {msg[0]:3}: {msg[1]}" for msg in sorted(missing))
    if unexpected:
        msg.append("\nUnexpected in testdata:")
        msg.extend(f" {msg[0]:3}: {msg[1]}" for msg in sorted(unexpected))
    error_msg = "\n".join(msg)
    if self._config and self._config.getoption("verbose") &gt; 0:
        error_msg += "\n\nActual pylint output for this file:\n"
        error_msg += "\n".join(str(o) for o in actual_output)
    return error_msg

</t>
<t tx="ekr.20250131013601.46">    def _emit_stashed_messages(self) -&gt; None:
        for keys, values in self._stashed_messages.items():
            modname, symbol = keys
            self.linter.set_current_module(modname)
            for args in values:
                self.add_message(
                    symbol,
                    args=args,
                    line=0,
                    confidence=HIGH,
                )
        self._stashed_messages = collections.defaultdict(list)
</t>
<t tx="ekr.20250131013601.460">def error_msg_for_unequal_output(
    self,
    expected_lines: list[OutputLine],
    received_lines: list[OutputLine],
) -&gt; str:
    missing = set(expected_lines) - set(received_lines)
    unexpected = set(received_lines) - set(expected_lines)
    error_msg = f'Wrong output for "{Path(self._test_file.expected_output).name}":'
    sort_by_line_number = operator.attrgetter("lineno")
    if missing:
        error_msg += "\n- Missing lines:\n"
        for line in sorted(missing, key=sort_by_line_number):
            error_msg += f"{line}\n"
    if unexpected:
        error_msg += "\n- Unexpected lines:\n"
        for line in sorted(unexpected, key=sort_by_line_number):
            error_msg += f"{line}\n"
        error_msg += (
            "\nYou can update the expected output automatically with:\n'"
            f"python tests/test_functional.py {UPDATE_OPTION} -k "
            f'"test_functional[{self._test_file.base}]"\'\n\n'
            "Here's the update text in case you can't:\n"
        )
        expected_csv = StringIO()
        writer = csv.writer(expected_csv, dialect="test")
        for line in sorted(received_lines, key=sort_by_line_number):
            writer.writerow(line.to_csv())
        error_msg += expected_csv.getvalue()
    return error_msg

</t>
<t tx="ekr.20250131013601.461">def _check_output_text(
    self,
    _: MessageCounter,
    expected_output: list[OutputLine],
    actual_output: list[OutputLine],
) -&gt; None:
    """This is a function because we want to be able to update the text in
    LintModuleOutputUpdate.
    """
    assert expected_output == actual_output, self.error_msg_for_unequal_output(
        expected_output, actual_output
    )
</t>
<t tx="ekr.20250131013601.462">@path pylint/testutils
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

from collections.abc import Sequence
from typing import Any, NamedTuple, TypeVar

from astroid import nodes

from pylint.interfaces import UNDEFINED, Confidence
from pylint.message.message import Message

_T = TypeVar("_T")


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.463">class MessageTest(NamedTuple):
    msg_id: str
    line: int | None = None
    node: nodes.NodeNG | None = None
    args: Any | None = None
    confidence: Confidence | None = UNDEFINED
    col_offset: int | None = None
    end_line: int | None = None
    end_col_offset: int | None = None
    """Used to test messages produced by pylint.

    Class name cannot start with Test as pytest doesn't allow constructors in test classes.
    """


</t>
<t tx="ekr.20250131013601.464">class OutputLine(NamedTuple):
    @others
</t>
<t tx="ekr.20250131013601.465">symbol: str
lineno: int
column: int
end_lineno: int | None
end_column: int | None
object: str
msg: str
confidence: str

@classmethod
def from_msg(cls, msg: Message, check_endline: bool = True) -&gt; OutputLine:
    """Create an OutputLine from a Pylint Message."""
    column = cls._get_column(msg.column)
    end_line = cls._get_end_line_and_end_col(msg.end_line, check_endline)
    end_column = cls._get_end_line_and_end_col(msg.end_column, check_endline)
    return cls(
        msg.symbol,
        msg.line,
        column,
        end_line,
        end_column,
        msg.obj or "",
        msg.msg.replace("\r\n", "\n"),
        msg.confidence.name,
    )

</t>
<t tx="ekr.20250131013601.466">@staticmethod
def _get_column(column: str | int) -&gt; int:
    """Handle column numbers."""
    return int(column)

</t>
<t tx="ekr.20250131013601.467">@staticmethod
def _get_end_line_and_end_col(value: _T, check_endline: bool) -&gt; _T | None:
    """Used to make end_line and end_column None as indicated by our version
    compared to `min_pyver_end_position`.
    """
    if not check_endline:
        return None  # pragma: no cover
    return value

</t>
<t tx="ekr.20250131013601.468">@classmethod
def from_csv(
    cls, row: Sequence[str] | str, check_endline: bool = True
) -&gt; OutputLine:
    """Create an OutputLine from a comma separated list (the functional tests
    expected output .txt files).
    """
    if isinstance(row, str):
        row = row.split(",")
    try:
        line = int(row[1])
        column = cls._get_column(row[2])
        end_line = cls._value_to_optional_int(
            cls._get_end_line_and_end_col(row[3], check_endline)
        )
        end_column = cls._value_to_optional_int(
            cls._get_end_line_and_end_col(row[4], check_endline)
        )
        # symbol, line, column, end_line, end_column, node, msg, confidences
        assert len(row) == 8
        return cls(
            row[0], line, column, end_line, end_column, row[5], row[6], row[7]
        )
    except Exception:  # pylint: disable=broad-except
        # We need this to not fail for the update script to work.
        return cls("", 0, 0, None, None, "", "", "")

</t>
<t tx="ekr.20250131013601.469">def to_csv(self) -&gt; tuple[str, str, str, str, str, str, str, str]:
    """Convert an OutputLine to a tuple of string to be written by a
    csv-writer.
    """
    return (
        str(self.symbol),
        str(self.lineno),
        str(self.column),
        str(self.end_lineno),
        str(self.end_column),
        str(self.object),
        str(self.msg),
        str(self.confidence),
    )

</t>
<t tx="ekr.20250131013601.47">def __call__(
    self, filepath: str, modname: str, data: str | None = None
) -&gt; nodes.Module: ...


</t>
<t tx="ekr.20250131013601.470">@staticmethod
def _value_to_optional_int(value: str | None) -&gt; int | None:
    """Checks if a (stringified) value should be None or a Python integer."""
    if value == "None" or not value:
        return None
    return int(value)
</t>
<t tx="ekr.20250131013601.471">@path pylint/testutils
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import argparse
import configparser
import shlex
from pathlib import Path
from typing import NamedTuple, TypedDict

from pylint.pyreverse.main import DEFAULT_COLOR_PALETTE


# This class could and should be replaced with a simple dataclass when support for Python &lt; 3.7 is dropped.
# A NamedTuple is not possible as some tests need to modify attributes during the test.
@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.472">class PyreverseConfig(
    argparse.Namespace
</t>
<t tx="ekr.20250131013601.473">):  # pylint: disable=too-many-instance-attributes, too-many-arguments
    """Holds the configuration options for Pyreverse.

    The default values correspond to the defaults of the options' parser.
    """

    # pylint: disable=too-many-locals
    def __init__(
        self,
        *,
        mode: str = "PUB_ONLY",
        classes: list[str] | None = None,
        show_ancestors: int | None = None,
        all_ancestors: bool | None = None,
        show_associated: int | None = None,
        all_associated: bool | None = None,
        no_standalone: bool = False,
        show_builtin: bool = False,
        show_stdlib: bool = False,
        module_names: bool | None = None,
        only_classnames: bool = False,
        output_format: str = "dot",
        colorized: bool = False,
        max_color_depth: int = 2,
        max_depth: int | None = None,
        color_palette: tuple[str, ...] = DEFAULT_COLOR_PALETTE,
        ignore_list: tuple[str, ...] = tuple(),
        project: str = "",
        output_directory: str = "",
</t>
<t tx="ekr.20250131013601.474">    ) -&gt; None:
        super().__init__()
        self.mode = mode
        if classes:
            self.classes = classes
        else:
            self.classes = []
        self.show_ancestors = show_ancestors
        self.all_ancestors = all_ancestors
        self.show_associated = show_associated
        self.all_associated = all_associated
        self.no_standalone = no_standalone
        self.show_builtin = show_builtin
        self.show_stdlib = show_stdlib
        self.module_names = module_names
        self.only_classnames = only_classnames
        self.output_format = output_format
        self.colorized = colorized
        self.max_depth = max_depth
        self.max_color_depth = max_color_depth
        self.color_palette = color_palette
        self.ignore_list = ignore_list
        self.project = project
        self.output_directory = output_directory

    # pylint: enable=too-many-locals


class TestFileOptions(TypedDict):
    source_roots: list[str]
    output_formats: list[str]
    command_line_args: list[str]


</t>
<t tx="ekr.20250131013601.475">class FunctionalPyreverseTestfile(NamedTuple):
    """Named tuple containing the test file and the expected output."""

    source: Path
    options: TestFileOptions


</t>
<t tx="ekr.20250131013601.476">def get_functional_test_files(
    root_directory: Path,
) -&gt; list[FunctionalPyreverseTestfile]:
    """Get all functional test files from the given directory."""
    test_files = []
    for path in root_directory.rglob("*.py"):
        if path.stem.startswith("_"):
            continue
        config_file = path.with_suffix(".rc")
        if config_file.exists():
            test_files.append(
                FunctionalPyreverseTestfile(
                    source=path, options=_read_config(config_file)
                )
            )
        else:
            test_files.append(
                FunctionalPyreverseTestfile(
                    source=path,
                    options={
                        "source_roots": [],
                        "output_formats": ["mmd"],
                        "command_line_args": [],
                    },
                )
            )
    return test_files


</t>
<t tx="ekr.20250131013601.477">def _read_config(config_file: Path) -&gt; TestFileOptions:
    config = configparser.ConfigParser()
    config.read(str(config_file))
    source_roots = config.get("testoptions", "source_roots", fallback=None)
    return {
        "source_roots": source_roots.split(",") if source_roots else [],
        "output_formats": config.get(
            "testoptions", "output_formats", fallback="mmd"
        ).split(","),
        "command_line_args": shlex.split(
            config.get("testoptions", "command_line_args", fallback="")
        ),
    }
</t>
<t tx="ekr.20250131013601.478">@path pylint/testutils
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

from io import StringIO
from os import getcwd, sep
from typing import TYPE_CHECKING

from pylint.message import Message
from pylint.reporters import BaseReporter

if TYPE_CHECKING:
    from pylint.reporters.ureports.nodes import Section


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.479">class GenericTestReporter(BaseReporter):
    """Reporter storing plain text messages."""

    @others
</t>
<t tx="ekr.20250131013601.48">@path pylint/lint
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import collections
from collections import defaultdict
from typing import cast

from pylint import checkers, exceptions
from pylint.reporters.ureports.nodes import Section, Table
from pylint.typing import MessageTypesFullName
from pylint.utils import LinterStats


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.480">class MinimalTestReporter(BaseReporter):
    @others
</t>
<t tx="ekr.20250131013601.481">class FunctionalTestReporter(BaseReporter):
    @others
</t>
<t tx="ekr.20250131013601.482">out: StringIO

def __init__(  # pylint: disable=super-init-not-called # See https://github.com/pylint-dev/pylint/issues/4941
    self,
) -&gt; None:
    self.path_strip_prefix: str = getcwd() + sep
    self.reset()

</t>
<t tx="ekr.20250131013601.483">def reset(self) -&gt; None:
    self.out = StringIO()
    self.messages: list[Message] = []

</t>
<t tx="ekr.20250131013601.484">def handle_message(self, msg: Message) -&gt; None:
    """Append messages to the list of messages of the reporter."""
    self.messages.append(msg)

</t>
<t tx="ekr.20250131013601.485">def finalize(self) -&gt; str:
    """Format and print messages in the context of the path."""
    messages: list[str] = []
    for msg in self.messages:
        obj = ""
        if msg.obj:
            obj = f":{msg.obj}"
        messages.append(f"{msg.msg_id[0]}:{msg.line:&gt;3}{obj}: {msg.msg}")

    messages.sort()
    for message in messages:
        print(message, file=self.out)

    result = self.out.getvalue()
    self.reset()
    return result

</t>
<t tx="ekr.20250131013601.486">def on_set_current_module(self, module: str, filepath: str | None) -&gt; None:
    pass

</t>
<t tx="ekr.20250131013601.487"># pylint: enable=unused-argument

def display_reports(self, layout: Section) -&gt; None:
    """Ignore layouts."""

</t>
<t tx="ekr.20250131013601.488">def _display(self, layout: Section) -&gt; None:
    pass


</t>
<t tx="ekr.20250131013601.489">def on_set_current_module(self, module: str, filepath: str | None) -&gt; None:
    self.messages = []

</t>
<t tx="ekr.20250131013601.49">def report_total_messages_stats(
    sect: Section,
    stats: LinterStats,
    previous_stats: LinterStats | None,
) -&gt; None:
    """Make total errors / warnings report."""
    lines = ["type", "number", "previous", "difference"]
    lines += checkers.table_lines_from_stats(stats, previous_stats, "message_types")
    sect.append(Table(children=lines, cols=4, rheaders=1))


</t>
<t tx="ekr.20250131013601.490">def _display(self, layout: Section) -&gt; None:
    pass


</t>
<t tx="ekr.20250131013601.491">def display_reports(self, layout: Section) -&gt; None:
    """Ignore layouts and don't call self._display()."""

</t>
<t tx="ekr.20250131013601.492">def _display(self, layout: Section) -&gt; None:
    pass
</t>
<t tx="ekr.20250131013601.493">@path pylint/testutils
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import tokenize
from io import StringIO
from tokenize import TokenInfo


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.494">def _tokenize_str(code: str) -&gt; list[TokenInfo]:
    return list(tokenize.generate_tokens(StringIO(code).readline))
</t>
<t tx="ekr.20250131013601.495">@path pylint/testutils
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

# pylint: disable=duplicate-code

from __future__ import annotations

from typing import Any, Literal

from astroid import nodes

from pylint.interfaces import UNDEFINED, Confidence
from pylint.lint import PyLinter
from pylint.testutils.output_line import MessageTest


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.496">class UnittestLinter(PyLinter):
    """A fake linter class to capture checker messages."""

    @others
</t>
<t tx="ekr.20250131013601.497">def __init__(self) -&gt; None:
    self._messages: list[MessageTest] = []
    super().__init__()

</t>
<t tx="ekr.20250131013601.498">def release_messages(self) -&gt; list[MessageTest]:
    try:
        return self._messages
    finally:
        self._messages = []

</t>
<t tx="ekr.20250131013601.499">def add_message(
    self,
    msgid: str,
    line: int | None = None,
    # TODO: Make node non optional
    node: nodes.NodeNG | None = None,
    args: Any = None,
    confidence: Confidence | None = None,
    col_offset: int | None = None,
    end_lineno: int | None = None,
    end_col_offset: int | None = None,
) -&gt; None:
    """Add a MessageTest to the _messages attribute of the linter class."""
    # If confidence is None we set it to UNDEFINED as well in PyLinter
    if confidence is None:
        confidence = UNDEFINED

    # Look up "location" data of node if not yet supplied
    if node:
        if node.position:
            if not line:
                line = node.position.lineno
            if not col_offset:
                col_offset = node.position.col_offset
            if not end_lineno:
                end_lineno = node.position.end_lineno
            if not end_col_offset:
                end_col_offset = node.position.end_col_offset
        else:
            if not line:
                line = node.fromlineno
            if not col_offset:
                col_offset = node.col_offset
            if not end_lineno:
                end_lineno = node.end_lineno
            if not end_col_offset:
                end_col_offset = node.end_col_offset

    self._messages.append(
        MessageTest(
            msgid,
            line,
            node,
            args,
            confidence,
            col_offset,
            end_lineno,
            end_col_offset,
        )
    )

</t>
<t tx="ekr.20250131013601.5">):
    """Lint Python modules using external checkers.

    This is the main checker controlling the other ones and the reports
    generation. It is itself both a raw checker and an astroid checker in order
    to:
    * handle message activation / deactivation at the module level
    * handle some basic but necessary stats' data (number of classes, methods...)

    IDE plugin developers: you may have to call
    `astroid.MANAGER.clear_cache()` across runs if you want
    to ensure the latest code version is actually checked.

    This class needs to support pickling for parallel linting to work. The exception
    is reporter member; see check_parallel function for more details.
    """

    name = MAIN_CHECKER_NAME
    msgs = MSGS
    # Will be used like this : datetime.now().strftime(crash_file_path)
    crash_file_path: str = "pylint-crash-%Y-%m-%d-%H-%M-%S.txt"

    option_groups_descs = {
        "Messages control": "Options controlling analysis messages",
        "Reports": "Options related to output formatting and reporting",
    }

    def __init__(
        self,
        options: Options = (),
        reporter: reporters.BaseReporter | reporters.MultiReporter | None = None,
        option_groups: tuple[tuple[str, str], ...] = (),
        # TODO: Deprecate passing the pylintrc parameter
        pylintrc: str | None = None,  # pylint: disable=unused-argument
</t>
<t tx="ekr.20250131013601.50">def report_messages_stats(
    sect: Section,
    stats: LinterStats,
    _: LinterStats | None,
) -&gt; None:
    """Make messages type report."""
    by_msg_stats = stats.by_msg
    in_order = sorted(
        (value, msg_id)
        for msg_id, value in by_msg_stats.items()
        if not msg_id.startswith("I")
    )
    in_order.reverse()
    lines = ["message id", "occurrences"]
    for value, msg_id in in_order:
        lines += [msg_id, str(value)]
    sect.append(Table(children=lines, cols=2, rheaders=1))


</t>
<t tx="ekr.20250131013601.500">@staticmethod
def is_message_enabled(*unused_args: Any, **unused_kwargs: Any) -&gt; Literal[True]:
    return True
</t>
<t tx="ekr.20250131013601.501">@path pylint/testutils
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import contextlib
import os
import sys
from collections.abc import Generator, Iterator
from copy import copy
from pathlib import Path
from typing import TextIO


@contextlib.contextmanager
@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.502">def _patch_streams(out: TextIO) -&gt; Iterator[None]:
    """Patch and subsequently reset a text stream."""
    sys.stderr = sys.stdout = out
    try:
        yield
    finally:
        sys.stderr = sys.__stderr__
        sys.stdout = sys.__stdout__


</t>
<t tx="ekr.20250131013601.503">@contextlib.contextmanager
def _test_sys_path(
    replacement_sys_path: list[str] | None = None,
) -&gt; Generator[None]:
    original_path = sys.path
    try:
        if replacement_sys_path is not None:
            sys.path = copy(replacement_sys_path)
        yield
    finally:
        sys.path = original_path


</t>
<t tx="ekr.20250131013601.504">@contextlib.contextmanager
def _test_cwd(
    current_working_directory: str | Path | None = None,
) -&gt; Generator[None]:
    original_dir = os.getcwd()
    try:
        if current_working_directory is not None:
            os.chdir(current_working_directory)
        yield
    finally:
        os.chdir(original_dir)


</t>
<t tx="ekr.20250131013601.505">@contextlib.contextmanager
def _test_environ_pythonpath(
    new_pythonpath: str | None = None,
) -&gt; Generator[None]:
    original_pythonpath = os.environ.get("PYTHONPATH")
    if new_pythonpath:
        os.environ["PYTHONPATH"] = new_pythonpath
    elif new_pythonpath is None and original_pythonpath is not None:
        # If new_pythonpath is None, make sure to delete PYTHONPATH if present
        del os.environ["PYTHONPATH"]
    try:
        yield
    finally:
        if original_pythonpath is not None:
            os.environ["PYTHONPATH"] = original_pythonpath
        elif "PYTHONPATH" in os.environ:
            del os.environ["PYTHONPATH"]


</t>
<t tx="ekr.20250131013601.506">def create_files(paths: list[str], chroot: str = ".") -&gt; None:
    """Creates directories and files found in &lt;path&gt;.

    :param list paths: list of relative paths to files or directories
    :param str chroot: the root directory in which paths will be created

    &gt;&gt;&gt; from os.path import isdir, isfile
    &gt;&gt;&gt; isdir('/tmp/a')
    False
    &gt;&gt;&gt; create_files(['a/b/foo.py', 'a/b/c/', 'a/b/c/d/e.py'], '/tmp')
    &gt;&gt;&gt; isdir('/tmp/a')
    True
    &gt;&gt;&gt; isdir('/tmp/a/b/c')
    True
    &gt;&gt;&gt; isfile('/tmp/a/b/c/d/e.py')
    True
    &gt;&gt;&gt; isfile('/tmp/a/b/foo.py')
    True
    """
    dirs, files = set(), set()
    for path in paths:
        path = os.path.join(chroot, path)
        filename = os.path.basename(path)
        # path is a directory path
        if not filename:
            dirs.add(path)
        # path is a filename path
        else:
            dirs.add(os.path.dirname(path))
            files.add(path)
    for dirpath in dirs:
        if not os.path.isdir(dirpath):
            os.makedirs(dirpath)
    for filepath in files:
        with open(filepath, "w", encoding="utf-8"):
            pass
</t>
<t tx="ekr.20250131013601.507"></t>
<t tx="ekr.20250131013601.508">@path pylint/testutils/_primer
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

__all__ = ["PRIMER_DIRECTORY_PATH", "PackageToLint"]

from pylint.testutils._primer.package_to_lint import (
    PRIMER_DIRECTORY_PATH,
    PackageToLint,
)
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.509">@path pylint/testutils/_primer
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import logging
from pathlib import Path
from typing import Literal

from git import GitCommandError
from git.cmd import Git
from git.repo import Repo

PRIMER_DIRECTORY_PATH = Path("tests") / ".pylint_primer_tests"


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.51">def report_messages_by_module_stats(
    sect: Section,
    stats: LinterStats,
    _: LinterStats | None,
) -&gt; None:
    """Make errors / warnings by modules report."""
    module_stats = stats.by_module
    if len(module_stats) == 1:
        # don't print this report when we are analysing a single module
        raise exceptions.EmptyReportError()
    by_mod: defaultdict[str, dict[str, int | float]] = collections.defaultdict(dict)
    for m_type in ("fatal", "error", "warning", "refactor", "convention"):
        m_type = cast(MessageTypesFullName, m_type)
        total = stats.get_global_message_count(m_type)
        for module in module_stats.keys():
            mod_total = stats.get_module_message_count(module, m_type)
            percent = 0 if total == 0 else float(mod_total * 100) / total
            by_mod[module][m_type] = percent
    sorted_result = []
    for module, mod_info in by_mod.items():
        sorted_result.append(
            (
                mod_info["error"],
                mod_info["warning"],
                mod_info["refactor"],
                mod_info["convention"],
                module,
            )
        )
    sorted_result.sort()
    sorted_result.reverse()
    lines = ["module", "error", "warning", "refactor", "convention"]
    for line in sorted_result:
        # Don't report clean modules.
        if all(entry == 0 for entry in line[:-1]):
            continue
        lines.append(line[-1])
        for val in line[:-1]:
            lines.append(f"{val:.2f}")
    if len(lines) == 5:
        raise exceptions.EmptyReportError()
    sect.append(Table(children=lines, cols=5, rheaders=1))
</t>
<t tx="ekr.20250131013601.510">class DirtyPrimerDirectoryException(Exception):
    """We can't pull if there's local changes."""

@others
</t>
<t tx="ekr.20250131013601.511">class PackageToLint:
    """Represents data about a package to be tested during primer tests."""

    @others
</t>
<t tx="ekr.20250131013601.512">    def __init__(self, path: Path | str):
        super().__init__(
            rf"""

/!\ Can't pull /!\

In order for the prepare command to be able to pull please cleanup your local repo:
cd {path}
git diff
"""
        )


</t>
<t tx="ekr.20250131013601.513">url: str
"""URL of the repository to clone."""

branch: str
"""Branch of the repository to clone."""

directories: list[str]
"""Directories within the repository to run pylint over."""

commit: str | None
"""Commit hash to pin the repository on."""

pylint_additional_args: list[str]
"""Arguments to give to pylint."""

pylintrc_relpath: str | None
"""Path relative to project's main directory to the pylintrc if it exists."""

minimum_python: str | None
"""Minimum python version supported by the package."""

def __init__(
    self,
    url: str,
    branch: str,
    directories: list[str],
    commit: str | None = None,
    pylint_additional_args: list[str] | None = None,
    pylintrc_relpath: str | None = None,
    minimum_python: str | None = None,
) -&gt; None:
    self.url = url
    self.branch = branch
    self.directories = directories
    self.commit = commit
    self.pylint_additional_args = pylint_additional_args or []
    self.pylintrc_relpath = pylintrc_relpath
    self.minimum_python = minimum_python

</t>
<t tx="ekr.20250131013601.514">@property
def pylintrc(self) -&gt; Path | Literal[""]:
    if self.pylintrc_relpath is None:
        # Fall back to "" to ensure pylint's own pylintrc is not discovered
        return ""
    return self.clone_directory / self.pylintrc_relpath

</t>
<t tx="ekr.20250131013601.515">@property
def clone_directory(self) -&gt; Path:
    """Directory to clone repository into."""
    clone_name = "/".join(self.url.split("/")[-2:]).replace(".git", "")
    return PRIMER_DIRECTORY_PATH / clone_name

</t>
<t tx="ekr.20250131013601.516">@property
def paths_to_lint(self) -&gt; list[str]:
    """The paths we need to lint."""
    return [str(self.clone_directory / path) for path in self.directories]

</t>
<t tx="ekr.20250131013601.517">@property
def pylint_args(self) -&gt; list[str]:
    options: list[str] = []
    # There is an error if rcfile is given but does not exist
    options += [f"--rcfile={self.pylintrc}"]
    return self.paths_to_lint + options + self.pylint_additional_args

</t>
<t tx="ekr.20250131013601.518">def lazy_clone(self) -&gt; str:  # pragma: no cover
    """Concatenates the target directory and clones the file.

    Not expected to be tested as the primer won't work if it doesn't.
    It's tested in the continuous integration primers, only the coverage
    is not calculated on everything. If lazy clone breaks for local use
    we'll probably notice because we'll have a fatal when launching the
    primer locally.
    """
    logging.info("Lazy cloning %s", self.url)
    if not self.clone_directory.exists():
        return self._clone_repository()
    return self._pull_repository()

</t>
<t tx="ekr.20250131013601.519">def _clone_repository(self) -&gt; str:
    options: dict[str, str | int] = {
        "url": self.url,
        "to_path": str(self.clone_directory),
        "branch": self.branch,
        "depth": 1,
    }
    logging.info("Directory does not exists, cloning: %s", options)
    repo = Repo.clone_from(
        url=self.url, to_path=self.clone_directory, branch=self.branch, depth=1
    )
    return str(repo.head.object.hexsha)

</t>
<t tx="ekr.20250131013601.52">@path pylint/lint
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import os
import sys
import warnings
from collections.abc import Sequence
from pathlib import Path
from typing import ClassVar

from pylint import config
from pylint.checkers.utils import clear_lru_caches
from pylint.config._pylint_config import (
    _handle_pylint_config_commands,
    _register_generate_config_options,
)
from pylint.config.config_initialization import _config_initialization
from pylint.config.exceptions import ArgumentPreprocessingError
from pylint.config.utils import _preprocess_options
from pylint.constants import full_version
from pylint.lint.base_options import _make_run_options
from pylint.lint.pylinter import MANAGER, PyLinter
from pylint.reporters.base_reporter import BaseReporter

try:
    import multiprocessing
    from multiprocessing import synchronize  # noqa pylint: disable=unused-import
except ImportError:
    multiprocessing = None  # type: ignore[assignment]

try:
    from concurrent.futures import ProcessPoolExecutor
except ImportError:
    ProcessPoolExecutor = None  # type: ignore[assignment,misc]


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.520">def _pull_repository(self) -&gt; str:
    remote_sha1_commit = Git().ls_remote(self.url, self.branch).split("\t")[0]
    local_sha1_commit = Repo(self.clone_directory).head.object.hexsha
    if remote_sha1_commit != local_sha1_commit:
        logging.info(
            "Remote sha is '%s' while local sha is '%s': pulling new commits",
            remote_sha1_commit,
            local_sha1_commit,
        )
        try:
            repo = Repo(self.clone_directory)
            if repo.is_dirty():
                raise DirtyPrimerDirectoryException(self.clone_directory)
            origin = repo.remotes.origin
            origin.pull()
        except GitCommandError as e:
            raise SystemError(
                f"Failed to clone repository for {self.clone_directory}"
            ) from e
    else:
        logging.info("Repository already up to date.")
    return str(remote_sha1_commit)
</t>
<t tx="ekr.20250131013601.521">@path pylint/testutils/_primer
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import argparse
import json
import sys
from pathlib import Path

from pylint.testutils._primer import PackageToLint
from pylint.testutils._primer.primer_command import PrimerCommand
from pylint.testutils._primer.primer_compare_command import CompareCommand
from pylint.testutils._primer.primer_prepare_command import PrepareCommand
from pylint.testutils._primer.primer_run_command import RunCommand


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.522">class Primer:
    """Main class to handle priming of packages."""

    @others
</t>
<t tx="ekr.20250131013601.523">def __init__(self, primer_directory: Path, json_path: Path) -&gt; None:
    # Preparing arguments
    self.primer_directory = primer_directory
    self._argument_parser = argparse.ArgumentParser(prog="Pylint Primer")
    self._subparsers = self._argument_parser.add_subparsers(
        dest="command", required=True
    )

    # All arguments for the prepare parser
    prepare_parser = self._subparsers.add_parser("prepare")
    prepare_parser.add_argument(
        "--clone", help="Clone all packages.", action="store_true", default=False
    )
    prepare_parser.add_argument(
        "--check",
        help="Check consistencies and commits of all packages.",
        action="store_true",
        default=False,
    )
    prepare_parser.add_argument(
        "--make-commit-string",
        help="Get latest commit string.",
        action="store_true",
        default=False,
    )
    prepare_parser.add_argument(
        "--read-commit-string",
        help="Print latest commit string.",
        action="store_true",
        default=False,
    )

    # All arguments for the run parser
    run_parser = self._subparsers.add_parser("run")
    run_parser.add_argument(
        "--type", choices=["main", "pr"], required=True, help="Type of primer run."
    )
    run_parser.add_argument(
        "--batches",
        required=False,
        type=int,
        help="Number of batches",
    )
    run_parser.add_argument(
        "--batchIdx",
        required=False,
        type=int,
        help="Portion of primer packages to run.",
    )

    # All arguments for the compare parser
    compare_parser = self._subparsers.add_parser("compare")
    compare_parser.add_argument(
        "--base-file",
        required=True,
        help="Location of output file of the base run.",
    )
    compare_parser.add_argument(
        "--new-file",
        required=True,
        help="Location of output file of the new run.",
    )
    compare_parser.add_argument(
        "--commit",
        required=True,
        help="Commit hash of the PR commit being checked.",
    )
    compare_parser.add_argument(
        "--batches",
        required=False,
        type=int,
        help="Number of batches (filepaths with the placeholder BATCHIDX will be numbered)",
    )

    # Storing arguments
    self.config = self._argument_parser.parse_args()

    self.packages = self._get_packages_to_lint_from_json(json_path)
    """All packages to prime."""

    if self.config.command == "prepare":
        command_class: type[PrimerCommand] = PrepareCommand
    elif self.config.command == "run":
        command_class = RunCommand
    elif self.config.command == "compare":
        command_class = CompareCommand
    # pylint: disable-next=possibly-used-before-assignment
    self.command = command_class(self.primer_directory, self.packages, self.config)

</t>
<t tx="ekr.20250131013601.524">def run(self) -&gt; None:
    self.command.run()

</t>
<t tx="ekr.20250131013601.525">@staticmethod
def _minimum_python_supported(package_data: dict[str, str]) -&gt; bool:
    min_python_str = package_data.get("minimum_python", None)
    if not min_python_str:
        return True
    min_python_tuple = tuple(int(n) for n in min_python_str.split("."))
    return min_python_tuple &lt;= sys.version_info[:2]

</t>
<t tx="ekr.20250131013601.526">@staticmethod
def _get_packages_to_lint_from_json(json_path: Path) -&gt; dict[str, PackageToLint]:
    with open(json_path, encoding="utf8") as f:
        return {
            name: PackageToLint(**package_data)
            for name, package_data in json.load(f).items()
            if Primer._minimum_python_supported(package_data)
        }
</t>
<t tx="ekr.20250131013601.527">@path pylint/testutils/_primer
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import abc
import argparse
from pathlib import Path
from typing import TypedDict

from pylint.reporters.json_reporter import OldJsonExport
from pylint.testutils._primer import PackageToLint


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.528">class PackageData(TypedDict):
    commit: str
    messages: list[OldJsonExport]


</t>
<t tx="ekr.20250131013601.529">PackageMessages = dict[str, PackageData]


class PrimerCommand:
    """Generic primer action with required arguments."""

    @others
</t>
<t tx="ekr.20250131013601.53">def _query_cpu() -&gt; int | None:
    """Try to determine number of CPUs allotted in a docker container.

    This is based on discussion and copied from suggestions in
    https://bugs.python.org/issue36054.
    """
    if Path("/sys/fs/cgroup/cpu.max").is_file():
        avail_cpu = _query_cpu_cgroupv2()
    else:
        avail_cpu = _query_cpu_cgroupsv1()
    return _query_cpu_handle_k8s_pods(avail_cpu)


</t>
<t tx="ekr.20250131013601.530">def __init__(
    self,
    primer_directory: Path,
    packages: dict[str, PackageToLint],
    config: argparse.Namespace,
) -&gt; None:
    self.primer_directory = primer_directory
    self.packages = packages
    self.config = config

</t>
<t tx="ekr.20250131013601.531">@abc.abstractmethod
def run(self) -&gt; None:
    pass
</t>
<t tx="ekr.20250131013601.532">@path pylint/testutils/_primer
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
from __future__ import annotations

import json
from pathlib import Path, PurePosixPath

from pylint.reporters.json_reporter import OldJsonExport
from pylint.testutils._primer.primer_command import (
    PackageData,
    PackageMessages,
    PrimerCommand,
)

MAX_GITHUB_COMMENT_LENGTH = 65536


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.533">class CompareCommand(PrimerCommand):
    @others
</t>
<t tx="ekr.20250131013601.534">def run(self) -&gt; None:
    if self.config.batches is None:
        main_data = self._load_json(self.config.base_file)
        pr_data = self._load_json(self.config.new_file)
    else:
        main_data = {}
        pr_data = {}
        for idx in range(self.config.batches):
            main_data.update(
                self._load_json(
                    self.config.base_file.replace("BATCHIDX", "batch" + str(idx))
                )
            )
            pr_data.update(
                self._load_json(
                    self.config.new_file.replace("BATCHIDX", "batch" + str(idx))
                )
            )

    missing_messages_data, new_messages_data = self._cross_reference(
        main_data, pr_data
    )
    comment = self._create_comment(missing_messages_data, new_messages_data)
    with open(self.primer_directory / "comment.txt", "w", encoding="utf-8") as f:
        f.write(comment)

</t>
<t tx="ekr.20250131013601.535">@staticmethod
def _cross_reference(
    main_data: PackageMessages, pr_data: PackageMessages
) -&gt; tuple[PackageMessages, PackageMessages]:
    missing_messages_data: PackageMessages = {}
    for package, data in main_data.items():
        package_missing_messages: list[OldJsonExport] = []
        for message in data["messages"]:
            try:
                pr_data[package]["messages"].remove(message)
            except ValueError:
                package_missing_messages.append(message)
        missing_messages_data[package] = PackageData(
            commit=pr_data[package]["commit"], messages=package_missing_messages
        )
    return missing_messages_data, pr_data

</t>
<t tx="ekr.20250131013601.536">@staticmethod
def _load_json(file_path: Path | str) -&gt; PackageMessages:
    with open(file_path, encoding="utf-8") as f:
        result: PackageMessages = json.load(f)
    return result

</t>
<t tx="ekr.20250131013601.537">def _create_comment(
    self, all_missing_messages: PackageMessages, all_new_messages: PackageMessages
) -&gt; str:
    comment = ""
    for package, missing_messages in all_missing_messages.items():
        if len(comment) &gt;= MAX_GITHUB_COMMENT_LENGTH:
            break
        new_messages = all_new_messages[package]
        if not missing_messages["messages"] and not new_messages["messages"]:
            continue
        comment += self._create_comment_for_package(
            package, new_messages, missing_messages
        )
    comment = (
        f"🤖 **Effect of this PR on checked open source code:** 🤖\n\n{comment}"
        if comment
        else (
            "🤖 According to the primer, this change has **no effect** on the"
            " checked open source code. 🤖🎉\n\n"
        )
    )
    return self._truncate_comment(comment)

</t>
<t tx="ekr.20250131013601.538">def _create_comment_for_package(
    self, package: str, new_messages: PackageData, missing_messages: PackageData
) -&gt; str:
    comment = f"\n\n**Effect on [{package}]({self.packages[package].url}):**\n"
    # Create comment for new messages
    count = 1
    astroid_errors = 0
    new_non_astroid_messages = ""
    if new_messages["messages"]:
        print("Now emitted:")
    for message in new_messages["messages"]:
        filepath = str(
            PurePosixPath(message["path"]).relative_to(
                self.packages[package].clone_directory
            )
        )
        # Existing astroid errors may still show up as "new" because the timestamp
        # in the message is slightly different.
        if message["symbol"] == "astroid-error":
            astroid_errors += 1
        else:
            new_non_astroid_messages += (
                f"{count}) {message['symbol']}:\n*{message['message']}*\n"
                f"{self.packages[package].url}/blob/{new_messages['commit']}/{filepath}#L{message['line']}\n"
            )
            print(message)
            count += 1

    if astroid_errors:
        comment += (
            f'{astroid_errors} "astroid error(s)" were found. '
            "Please open the GitHub Actions log to see what failed or crashed.\n\n"
        )
    if new_non_astroid_messages:
        comment += (
            "The following messages are now emitted:\n\n&lt;details&gt;\n\n"
            + new_non_astroid_messages
            + "\n&lt;/details&gt;\n\n"
        )

    # Create comment for missing messages
    count = 1
    if missing_messages["messages"]:
        comment += "The following messages are no longer emitted:\n\n&lt;details&gt;\n\n"
        print("No longer emitted:")
    for message in missing_messages["messages"]:
        comment += f"{count}) {message['symbol']}:\n*{message['message']}*\n"
        filepath = str(
            PurePosixPath(message["path"]).relative_to(
                self.packages[package].clone_directory
            )
        )
        assert not self.packages[package].url.endswith(
            ".git"
        ), "You don't need the .git at the end of the github url."
        comment += (
            f"{self.packages[package].url}"
            f"/blob/{new_messages['commit']}/{filepath}#L{message['line']}\n"
        )
        count += 1
        print(message)
    if missing_messages:
        comment += "\n&lt;/details&gt;\n\n"
    return comment

</t>
<t tx="ekr.20250131013601.539">def _truncate_comment(self, comment: str) -&gt; str:
    """GitHub allows only a set number of characters in a comment."""
    hash_information = (
        f"*This comment was generated for commit {self.config.commit}*"
    )
    if len(comment) + len(hash_information) &gt;= MAX_GITHUB_COMMENT_LENGTH:
        truncation_information = (
            f"*This comment was truncated because GitHub allows only"
            f" {MAX_GITHUB_COMMENT_LENGTH} characters in a comment.*"
        )
        max_len = (
            MAX_GITHUB_COMMENT_LENGTH
            - len(hash_information)
            - len(truncation_information)
        )
        comment = f"{comment[:max_len - 10]}...\n\n{truncation_information}\n\n"
    comment += hash_information
    return comment
</t>
<t tx="ekr.20250131013601.54">def _query_cpu_cgroupv2() -&gt; int | None:
    avail_cpu = None
    with open("/sys/fs/cgroup/cpu.max", encoding="utf-8") as file:
        line = file.read().rstrip()
        fields = line.split()
        if len(fields) == 2:
            str_cpu_quota = fields[0]
            cpu_period = int(fields[1])
            # Make sure this is not in an unconstrained cgroup
            if str_cpu_quota != "max":
                cpu_quota = int(str_cpu_quota)
                avail_cpu = int(cpu_quota / cpu_period)
    return avail_cpu


</t>
<t tx="ekr.20250131013601.540">@path pylint/testutils/_primer
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
from __future__ import annotations

import sys

from git.cmd import Git
from git.repo import Repo

from pylint.testutils._primer.primer_command import PrimerCommand


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.541">class PrepareCommand(PrimerCommand):
    @others
</t>
<t tx="ekr.20250131013601.542">def run(self) -&gt; None:
    commit_string = ""
    version_string = ".".join(str(x) for x in sys.version_info[:2])
    # Shorten the SHA to avoid exceeding GitHub's 512 char ceiling
    if self.config.clone:
        for package, data in self.packages.items():
            local_commit = data.lazy_clone()
            print(f"Cloned '{package}' at commit '{local_commit}'.")
            commit_string += local_commit[:8] + "_"
    elif self.config.check:
        for package, data in self.packages.items():
            local_commit = Repo(data.clone_directory).head.object.hexsha
            print(f"Found '{package}' at commit '{local_commit}'.")
            commit_string += local_commit[:8] + "_"
    elif self.config.make_commit_string:
        for package, data in self.packages.items():
            remote_sha1_commit = (
                Git().ls_remote(data.url, data.branch).split("\t")[0][:8]
            )
            print(f"'{package}' remote is at commit '{remote_sha1_commit}'.")
            commit_string += remote_sha1_commit + "_"
    elif self.config.read_commit_string:
        with open(
            self.primer_directory / f"commit_string_{version_string}.txt",
            encoding="utf-8",
        ) as f:
            print(f.read())
    if commit_string:
        with open(
            self.primer_directory / f"commit_string_{version_string}.txt",
            "w",
            encoding="utf-8",
        ) as f:
            f.write(commit_string)
</t>
<t tx="ekr.20250131013601.543">@path pylint/testutils/_primer
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import json
import sys
import warnings
from io import StringIO

from git.repo import Repo

from pylint.lint import Run
from pylint.message import Message
from pylint.reporters.json_reporter import JSONReporter, OldJsonExport
from pylint.testutils._primer.package_to_lint import PackageToLint
from pylint.testutils._primer.primer_command import (
    PackageData,
    PackageMessages,
    PrimerCommand,
)

GITHUB_CRASH_TEMPLATE_LOCATION = "/home/runner/.cache"
CRASH_TEMPLATE_INTRO = "There is a pre-filled template"


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.544">class RunCommand(PrimerCommand):
    @others
</t>
<t tx="ekr.20250131013601.545">def run(self) -&gt; None:
    packages: PackageMessages = {}
    fatal_msgs: list[Message] = []
    package_data_iter = (
        self.packages.items()
        if self.config.batches is None
        else list(self.packages.items())[
            self.config.batchIdx::self.config.batches
        ]
    )
    for package, data in package_data_iter:
        messages, p_fatal_msgs = self._lint_package(package, data)
        fatal_msgs += p_fatal_msgs
        local_commit = Repo(data.clone_directory).head.object.hexsha
        packages[package] = PackageData(commit=local_commit, messages=messages)
    path = self.primer_directory / (
        f"output_{'.'.join(str(i) for i in sys.version_info[:2])}_{self.config.type}"
        + (f"_batch{self.config.batchIdx}.txt" if self.config.batches else "")
    )
    print(f"Writing result in {path}")
    with open(path, "w", encoding="utf-8") as f:
        json.dump(packages, f)
    # Assert that a PR run does not introduce new fatal errors
    if self.config.type == "pr":
        plural = "s" if len(fatal_msgs) &gt; 1 else ""
        assert(
            not fatal_msgs
        ), f"We encountered {len(fatal_msgs)} fatal error message{plural} (see log)."

</t>
<t tx="ekr.20250131013601.546">@staticmethod
def _filter_fatal_errors(
    messages: list[OldJsonExport],
) -&gt; list[Message]:
    """Separate fatal errors so we can report them independently."""
    fatal_msgs: list[Message] = []
    for raw_message in messages:
        message = JSONReporter.deserialize(raw_message)
        if message.category == "fatal":
            if GITHUB_CRASH_TEMPLATE_LOCATION in message.msg:
                # Remove the crash template location if we're running on GitHub.
                # We were falsely getting "new" errors when the timestamp changed.
                message.msg = message.msg.rsplit(CRASH_TEMPLATE_INTRO)[0]
            fatal_msgs.append(message)
    return fatal_msgs

</t>
<t tx="ekr.20250131013601.547">@staticmethod
def _print_msgs(msgs: list[Message]) -&gt; str:
    return "\n".join(f"- {JSONReporter.serialize(m)}" for m in msgs)

</t>
<t tx="ekr.20250131013601.548">def _lint_package(
    self, package_name: str, data: PackageToLint
) -&gt; tuple[list[OldJsonExport], list[Message]]:
    # We want to test all the code we can
    enables = ["--enable-all-extensions", "--enable=all"]
    # Duplicate code takes too long and is relatively safe
    # TODO: Find a way to allow cyclic-import and compare output correctly
    disables = ["--disable=duplicate-code,cyclic-import"]
    additional = ["--clear-cache-post-run=y"]
    arguments = data.pylint_args + enables + disables + additional
    output = StringIO()
    reporter = JSONReporter(output)
    print(f"Running 'pylint {', '.join(arguments)}'")
    pylint_exit_code = -1
    try:
        Run(arguments, reporter=reporter)
    except SystemExit as e:
        pylint_exit_code = int(e.code)  # type: ignore[arg-type]
    readable_messages: str = output.getvalue()
    messages: list[OldJsonExport] = json.loads(readable_messages)
    fatal_msgs: list[Message] = []
    if pylint_exit_code % 2 == 0:
        print(f"Successfully primed {package_name}.")
    else:
        fatal_msgs = self._filter_fatal_errors(messages)
        if fatal_msgs:
            warnings.warn(
                f"Encountered fatal errors while priming {package_name} !\n"
                f"{self._print_msgs(fatal_msgs)}\n\n",
                stacklevel=2,
            )
    return messages, fatal_msgs
</t>
<t tx="ekr.20250131013601.549"></t>
<t tx="ekr.20250131013601.55">def _query_cpu_cgroupsv1() -&gt; int | None:
    cpu_quota, avail_cpu = None, None
    if Path("/sys/fs/cgroup/cpu/cpu.cfs_quota_us").is_file():
        with open("/sys/fs/cgroup/cpu/cpu.cfs_quota_us", encoding="utf-8") as file:
            # Not useful for AWS Batch based jobs as result is -1, but works on local linux systems
            cpu_quota = int(file.read().rstrip())

    if (
        cpu_quota
        and cpu_quota != -1
        and Path("/sys/fs/cgroup/cpu/cpu.cfs_period_us").is_file()
    ):
        with open("/sys/fs/cgroup/cpu/cpu.cfs_period_us", encoding="utf-8") as file:
            cpu_period = int(file.read().rstrip())
        # Divide quota by period and you should get num of allotted CPU to the container,
        # rounded down if fractional.
        avail_cpu = int(cpu_quota / cpu_period)
    elif Path("/sys/fs/cgroup/cpu/cpu.shares").is_file():
        with open("/sys/fs/cgroup/cpu/cpu.shares", encoding="utf-8") as file:
            cpu_shares = int(file.read().rstrip())
        # For AWS, gives correct value * 1024.
        avail_cpu = int(cpu_shares / 1024)
    return avail_cpu


</t>
<t tx="ekr.20250131013601.550">@path pylint/testutils/functional
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

__all__ = [
    "REASONABLY_DISPLAYABLE_VERTICALLY",
    "FunctionalTestFile",
    "LintModuleOutputUpdate",
    "NoFileError",
    "get_functional_test_files_from_directory",
    "parse_python_version",
]

from pylint.testutils.functional.find_functional_tests import (
    REASONABLY_DISPLAYABLE_VERTICALLY,
    get_functional_test_files_from_directory,
)
from pylint.testutils.functional.lint_module_output_update import LintModuleOutputUpdate
from pylint.testutils.functional.test_file import (
    FunctionalTestFile,
    NoFileError,
    parse_python_version,
)
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.551">@path pylint/testutils/functional
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import os
from collections.abc import Iterator
from pathlib import Path

from pylint.testutils.functional.test_file import FunctionalTestFile

REASONABLY_DISPLAYABLE_VERTICALLY = 49
"""'Wet finger' number of files that are reasonable to display by an IDE.

'Wet finger' as in 'in my settings there are precisely this many'.
"""

IGNORED_PARENT_DIRS = {
    "deprecated_relative_import",
    "ext",
    "regression",
    "regression_02",
}
"""Direct parent directories that should be ignored."""

IGNORED_PARENT_PARENT_DIRS = {
    "docparams",
    "deprecated_relative_import",
    "ext",
}
"""Parents of direct parent directories that should be ignored."""


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.552">def get_functional_test_files_from_directory(
    input_dir: Path | str,
    max_file_per_directory: int = REASONABLY_DISPLAYABLE_VERTICALLY,
) -&gt; list[FunctionalTestFile]:
    """Get all functional tests in the input_dir."""
    suite = []

    _check_functional_tests_structure(Path(input_dir), max_file_per_directory)

    for dirpath, dirnames, filenames in os.walk(input_dir):
        if dirpath.endswith("__pycache__"):
            continue
        dirnames.sort()
        filenames.sort()
        for filename in filenames:
            if filename != "__init__.py" and filename.endswith(".py"):
                suite.append(FunctionalTestFile(dirpath, filename))
    return suite


</t>
<t tx="ekr.20250131013601.553">def _check_functional_tests_structure(
    directory: Path, max_file_per_directory: int
) -&gt; None:
    """Check if test directories follow correct file/folder structure.

    Ignore underscored directories or files.
    """
    if Path(directory).stem.startswith("_"):
        return

    files: set[Path] = set()
    dirs: set[Path] = set()

    def _get_files_from_dir(
        path: Path, violations: list[tuple[Path, int]]
    ) -&gt; list[Path]:
        """Return directories and files from a directory and handles violations."""
        files_without_leading_underscore = list(
            p for p in path.iterdir() if not p.stem.startswith("_")
        )
        if len(files_without_leading_underscore) &gt; max_file_per_directory:
            violations.append((path, len(files_without_leading_underscore)))
        return files_without_leading_underscore

    def walk(path: Path) -&gt; Iterator[Path]:
        violations: list[tuple[Path, int]] = []
        violations_msgs: set[str] = set()
        parent_dir_files = _get_files_from_dir(path, violations)
        error_msg = (
            "The following directory contains too many functional tests files:\n"
        )
        for _file_or_dir in parent_dir_files:
            if _file_or_dir.is_dir():
                _files = _get_files_from_dir(_file_or_dir, violations)
                yield _file_or_dir.resolve()
                try:
                    yield from walk(_file_or_dir)
                except AssertionError as e:
                    violations_msgs.add(str(e).replace(error_msg, ""))
            else:
                yield _file_or_dir.resolve()
        if violations or violations_msgs:
            _msg = error_msg
            for offending_file, number in violations:
                _msg += f"- {offending_file}: {number} when the max is {max_file_per_directory}\n"
            for error_msg in violations_msgs:
                _msg += error_msg
            raise AssertionError(_msg)

    # Collect all sub-directories and files in directory
    for file_or_dir in walk(directory):
        if file_or_dir.is_dir():
            dirs.add(file_or_dir)
        elif file_or_dir.suffix == ".py":
            files.add(file_or_dir)

    directory_does_not_exists: list[tuple[Path, Path]] = []
    misplaced_file: list[Path] = []
    for file in files:
        possible_dir = file.parent / file.stem.split("_")[0]
        if possible_dir.exists():
            directory_does_not_exists.append((file, possible_dir))
        # Exclude some directories as they follow a different structure
        if (
            not len(file.parent.stem) == 1  # First letter sub-directories
            and file.parent.stem not in IGNORED_PARENT_DIRS
            and file.parent.parent.stem not in IGNORED_PARENT_PARENT_DIRS
        ):
            if not file.stem.startswith(file.parent.stem):
                misplaced_file.append(file)

    if directory_does_not_exists or misplaced_file:
        msg = "The following functional tests are disorganized:\n"
        for file, possible_dir in directory_does_not_exists:
            msg += (
                f"- In '{directory}', '{file.relative_to(directory)}' "
                f"should go in '{possible_dir.relative_to(directory)}'\n"
            )
        for file in misplaced_file:
            msg += (
                f"- In '{directory}', {file.relative_to(directory)} should go in a directory"
                f" that starts with the first letters"
                f" of '{file.stem}' (not '{file.parent.stem}')\n"
            )
        raise AssertionError(msg)
</t>
<t tx="ekr.20250131013601.554">@path pylint/testutils/functional
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import csv
import os

from pylint.testutils.lint_module_test import LintModuleTest, MessageCounter
from pylint.testutils.output_line import OutputLine


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.555">class LintModuleOutputUpdate(LintModuleTest):
    """Class to be used if expected output files should be updated instead of
    checked.
    """

    @others
</t>
<t tx="ekr.20250131013601.556">class TestDialect(csv.excel):
    """Dialect used by the csv writer."""

    delimiter = ":"
    lineterminator = "\n"

</t>
<t tx="ekr.20250131013601.557"># TestDialect inherit from csv.excel, which inherit from Dialect
# probably something wrong in csv typing
csv.register_dialect("test", TestDialect)  # type: ignore[arg-type]

def _check_output_text(
    self,
    _: MessageCounter,
    expected_output: list[OutputLine],
    actual_output: list[OutputLine],
) -&gt; None:
    """Overwrite or remove the expected output file based on actual output."""
    # Remove the expected file if no output is actually emitted and a file exists
    if not actual_output:
        if os.path.exists(self._test_file.expected_output):
            os.remove(self._test_file.expected_output)
        return
    # Write file with expected output
    with open(self._test_file.expected_output, "w", encoding="utf-8") as f:
        writer = csv.writer(f, dialect="test")
        for line in actual_output:
            writer.writerow(line.to_csv())
</t>
<t tx="ekr.20250131013601.558">@path pylint/testutils/functional
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import configparser
from collections.abc import Callable
from os.path import basename, exists, join
from typing import TypedDict


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.559">def parse_python_version(ver_str: str) -&gt; tuple[int, ...]:
    """Convert python version to a tuple of integers for easy comparison."""
    return tuple(int(digit) for digit in ver_str.split("."))


</t>
<t tx="ekr.20250131013601.56">def _query_cpu_handle_k8s_pods(avail_cpu: int | None) -&gt; int | None:
    # In K8s Pods also a fraction of a single core could be available
    # As multiprocessing is not able to run only a "fraction" of process
    # assume we have 1 CPU available
    if avail_cpu == 0:
        avail_cpu = 1

    return avail_cpu


</t>
<t tx="ekr.20250131013601.560">class NoFileError(Exception):
    pass


</t>
<t tx="ekr.20250131013601.561">class TestFileOptions(TypedDict):
    min_pyver: tuple[int, ...]
    max_pyver: tuple[int, ...]
    min_pyver_end_position: tuple[int, ...]
    requires: list[str]
    except_implementations: list[str]
    exclude_platforms: list[str]
    exclude_from_minimal_messages_config: bool


</t>
<t tx="ekr.20250131013601.562"># mypy need something literal, we can't create this dynamically from TestFileOptions
POSSIBLE_TEST_OPTIONS = {
    "min_pyver",
    "max_pyver",
    "min_pyver_end_position",
    "requires",
    "except_implementations",
    "exclude_platforms",
    "exclude_from_minimal_messages_config",
}


class FunctionalTestFile:
    """A single functional test case file with options."""

    @others
</t>
<t tx="ekr.20250131013601.563">_CONVERTERS: dict[str, Callable[[str], tuple[int, ...] | list[str]]] = {
    "min_pyver": parse_python_version,
    "max_pyver": parse_python_version,
    "min_pyver_end_position": parse_python_version,
    "requires": lambda s: [i.strip() for i in s.split(",")],
    "except_implementations": lambda s: [i.strip() for i in s.split(",")],
    "exclude_platforms": lambda s: [i.strip() for i in s.split(",")],
}

def __init__(self, directory: str, filename: str) -&gt; None:
    self._directory = directory
    self.base = filename.replace(".py", "")
    # TODO:4.0: Deprecate FunctionalTestFile.options and related code
    # We should just parse these options like a normal configuration file.
    self.options: TestFileOptions = {
        "min_pyver": (2, 5),
        "max_pyver": (4, 0),
        "min_pyver_end_position": (3, 8),
        "requires": [],
        "except_implementations": [],
        "exclude_platforms": [],
        "exclude_from_minimal_messages_config": False,
    }
    self._parse_options()

</t>
<t tx="ekr.20250131013601.564">def __repr__(self) -&gt; str:
    return f"FunctionalTest:{self.base}"

</t>
<t tx="ekr.20250131013601.565">def _parse_options(self) -&gt; None:
    cp = configparser.ConfigParser()
    cp.add_section("testoptions")
    try:
        cp.read(self.option_file)
    except NoFileError:
        pass

    for name, value in cp.items("testoptions"):
        conv = self._CONVERTERS.get(name, lambda v: v)

        assert(
            name in POSSIBLE_TEST_OPTIONS
        ), f"[testoptions]' can only contains one of {POSSIBLE_TEST_OPTIONS} and had '{name}'"
        self.options[name] = conv(value)  # type: ignore[literal-required]

</t>
<t tx="ekr.20250131013601.566">@property
def option_file(self) -&gt; str:
    return self._file_type(".rc")

</t>
<t tx="ekr.20250131013601.567">@property
def module(self) -&gt; str:
    package = basename(self._directory)
    return ".".join([package, self.base])

</t>
<t tx="ekr.20250131013601.568">@property
def expected_output(self) -&gt; str:
    return self._file_type(".txt", check_exists=False)

</t>
<t tx="ekr.20250131013601.569">@property
def source(self) -&gt; str:
    return self._file_type(".py")

</t>
<t tx="ekr.20250131013601.57">def _cpu_count() -&gt; int:
    """Use sched_affinity if available for virtualized or containerized
    environments.
    """
    cpu_share = _query_cpu()
    cpu_count = None
    sched_getaffinity = getattr(os, "sched_getaffinity", None)
    # pylint: disable=not-callable,using-constant-test,useless-suppression
    if sched_getaffinity:
        cpu_count = len(sched_getaffinity(0))
    elif multiprocessing:
        cpu_count = multiprocessing.cpu_count()
    else:
        cpu_count = 1
    if sys.platform == "win32":
        # See also https://github.com/python/cpython/issues/94242
        cpu_count = min(cpu_count, 56)  # pragma: no cover
    if cpu_share is not None:
        return min(cpu_share, cpu_count)
    return cpu_count


</t>
<t tx="ekr.20250131013601.570">def _file_type(self, ext: str, check_exists: bool = True) -&gt; str:
    name = join(self._directory, self.base + ext)
    if not check_exists or exists(name):
        return name
    raise NoFileError(f"Cannot find '{name}'.")
</t>
<t tx="ekr.20250131013601.571"></t>
<t tx="ekr.20250131013601.572">@path pylint/utils
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Some various utilities and helper classes, most of them used in the
main pylint class.
"""

from pylint.utils.ast_walker import ASTWalker
from pylint.utils.docs import print_full_documentation
from pylint.utils.file_state import FileState
from pylint.utils.linterstats import LinterStats, ModuleStats, merge_stats
from pylint.utils.utils import (
    HAS_ISORT_5,
    IsortDriver,
    _check_csv,
    _check_regexp_csv,
    _splitstrip,
    _unquote,
    decoding_stream,
    diff_string,
    format_section,
    get_module_and_frameid,
    get_rst_section,
    get_rst_title,
    normalize_text,
    register_plugins,
    tokenize_module,
)

__all__ = [
    "HAS_ISORT_5",
    "ASTWalker",
    "FileState",
    "IsortDriver",
    "LinterStats",
    "ModuleStats",
    "_check_csv",
    "_check_regexp_csv",
    "_splitstrip",
    "_unquote",
    "decoding_stream",
    "diff_string",
    "format_section",
    "get_module_and_frameid",
    "get_rst_section",
    "get_rst_title",
    "merge_stats",
    "normalize_text",
    "print_full_documentation",
    "register_plugins",
    "tokenize_module",
]
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.573">@path pylint/utils
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import sys
import traceback
from collections import defaultdict
from collections.abc import Callable
from typing import TYPE_CHECKING

from astroid import nodes

if TYPE_CHECKING:
    from pylint.checkers.base_checker import BaseChecker
    from pylint.lint import PyLinter

# Callable parameter type NodeNG not completely correct.
# Due to contravariance of Callable parameter types,
# it should be a Union of all NodeNG subclasses.
# However, since the methods are only retrieved with
# getattr(checker, member) and thus are inferred as Any,
# NodeNG will work too.
AstCallback = Callable[[nodes.NodeNG], None]


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.574">class ASTWalker:
    @others
</t>
<t tx="ekr.20250131013601.575">def __init__(self, linter: PyLinter) -&gt; None:
    # callbacks per node types
    self.nbstatements = 0
    self.visit_events: defaultdict[str, list[AstCallback]] = defaultdict(list)
    self.leave_events: defaultdict[str, list[AstCallback]] = defaultdict(list)
    self.linter = linter
    self.exception_msg = False

</t>
<t tx="ekr.20250131013601.576">def _is_method_enabled(self, method: AstCallback) -&gt; bool:
    if not hasattr(method, "checks_msgs"):
        return True
    return any(self.linter.is_message_enabled(m) for m in method.checks_msgs)

</t>
<t tx="ekr.20250131013601.577">def add_checker(self, checker: BaseChecker) -&gt; None:
    """Walk to the checker's dir and collect visit and leave methods."""
    vcids: set[str] = set()
    lcids: set[str] = set()
    visits = self.visit_events
    leaves = self.leave_events
    for member in dir(checker):
        cid = member[6:]
        if cid == "default":
            continue
        if member.startswith("visit_"):
            v_meth = getattr(checker, member)
            # don't use visit_methods with no activated message:
            if self._is_method_enabled(v_meth):
                visits[cid].append(v_meth)
                vcids.add(cid)
        elif member.startswith("leave_"):
            l_meth = getattr(checker, member)
            # don't use leave_methods with no activated message:
            if self._is_method_enabled(l_meth):
                leaves[cid].append(l_meth)
                lcids.add(cid)
    visit_default = getattr(checker, "visit_default", None)
    if visit_default:
        for cls in nodes.ALL_NODE_CLASSES:
            cid = cls.__name__.lower()
            if cid not in vcids:
                visits[cid].append(visit_default)
</t>
<t tx="ekr.20250131013601.578">    # For now, we have no "leave_default" method in Pylint

def walk(self, astroid: nodes.NodeNG) -&gt; None:
    """Call visit events of astroid checkers for the given node, recurse on
    its children, then leave events.
    """
    cid = astroid.__class__.__name__.lower()

    visit_events = self.visit_events[cid]
    leave_events = self.leave_events[cid]

    # pylint: disable = too-many-try-statements
    try:
        if astroid.is_statement:
            self.nbstatements += 1
        # generate events for this node on each checker
        for callback in visit_events:
            callback(astroid)
        # recurse on children
        for child in astroid.get_children():
            self.walk(child)
        for callback in leave_events:
            callback(astroid)
    except Exception:
        if self.exception_msg is False:
            file = getattr(astroid.root(), "file", None)
            print(
                f"Exception on node {astroid!r} in file '{file}'",
                file=sys.stderr,
            )
            traceback.print_exc()
            self.exception_msg = True
        raise
</t>
<t tx="ekr.20250131013601.579">@path pylint/utils
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""Various helper functions to create the docs of a linter object."""

from __future__ import annotations

import sys
from typing import TYPE_CHECKING, Any, TextIO

from pylint.constants import MAIN_CHECKER_NAME
from pylint.utils.utils import get_rst_section, get_rst_title

if TYPE_CHECKING:
    from pylint.lint.pylinter import PyLinter


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.58">class Run:
    """Helper class to use as main for pylint with 'run(*sys.argv[1:])'."""

@others
</t>
<t tx="ekr.20250131013601.580">def _get_checkers_infos(linter: PyLinter) -&gt; dict[str, dict[str, Any]]:
    """Get info from a checker and handle KeyError."""
    by_checker: dict[str, dict[str, Any]] = {}
    for checker in linter.get_checkers():
        name = checker.name
        if name != MAIN_CHECKER_NAME:
            try:
                by_checker[name]["checker"] = checker
                by_checker[name]["options"] += checker._options_and_values()
                by_checker[name]["msgs"].update(checker.msgs)
                by_checker[name]["reports"] += checker.reports
            except KeyError:
                by_checker[name] = {
                    "checker": checker,
                    "options": list(checker._options_and_values()),
                    "msgs": dict(checker.msgs),
                    "reports": list(checker.reports),
                }
    return by_checker


</t>
<t tx="ekr.20250131013601.581">def _get_global_options_documentation(linter: PyLinter) -&gt; str:
    """Get documentation for the main checker."""
    result = get_rst_title("Pylint global options and switches", "-")
    result += """
Pylint provides global options and switches.

"""
    for checker in linter.get_checkers():
        if checker.name == MAIN_CHECKER_NAME and checker.options:
            for section, options in checker._options_by_section():
                if section is None:
                    title = "General options"
                else:
                    title = f"{section.capitalize()} options"
                result += get_rst_title(title, "~")
                assert isinstance(options, list)
                result += f"{get_rst_section(None, options)}\n"
    return result


</t>
<t tx="ekr.20250131013601.582">def _get_checkers_documentation(linter: PyLinter, show_options: bool = True) -&gt; str:
    """Get documentation for individual checkers."""
    if show_options:
        result = _get_global_options_documentation(linter)
    else:
        result = ""

    result += get_rst_title("Pylint checkers' options and switches", "-")
    result += """\

Pylint checkers can provide three set of features:

* options that control their execution,
* messages that they can raise,
* reports that they can generate.

Below is a list of all checkers and their features.

"""
    by_checker = _get_checkers_infos(linter)
    for checker_name in sorted(by_checker):
        information = by_checker[checker_name]
        checker = information["checker"]
        del information["checker"]
        result += checker.get_full_documentation(
            **information, show_options=show_options
        )
    return result


</t>
<t tx="ekr.20250131013601.583">def print_full_documentation(
    linter: PyLinter, stream: TextIO = sys.stdout, show_options: bool = True
) -&gt; None:
    """Output a full documentation in ReST format."""
    print(
        _get_checkers_documentation(linter, show_options=show_options)[:-3], file=stream
    )
</t>
<t tx="ekr.20250131013601.584">@path pylint/utils
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import collections
from collections import defaultdict
from collections.abc import Iterator
from typing import TYPE_CHECKING, Literal

from astroid import nodes

from pylint.constants import (
    INCOMPATIBLE_WITH_USELESS_SUPPRESSION,
    MSG_STATE_SCOPE_MODULE,
    WarningScope,
)

if TYPE_CHECKING:
    from pylint.message import MessageDefinition, MessageDefinitionStore


MessageStateDict = dict[str, dict[int, bool]]


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.585">class FileState:
    """Hold internal state specific to the currently analyzed file."""

    @others
</t>
<t tx="ekr.20250131013601.586">def __init__(
    self,
    modname: str,
    msg_store: MessageDefinitionStore,
    node: nodes.Module | None = None,
    *,
    is_base_filestate: bool = False,
) -&gt; None:
    self.base_name = modname
    self._module_msgs_state: MessageStateDict = {}
    self._raw_module_msgs_state: MessageStateDict = {}
    self._ignored_msgs: defaultdict[tuple[str, int], set[int]] = (
        collections.defaultdict(set)
    )
    self._suppression_mapping: dict[tuple[str, int], int] = {}
    self._module = node
    if node:
        self._effective_max_line_number = node.tolineno
    else:
        self._effective_max_line_number = None
    self._msgs_store = msg_store
    self._is_base_filestate = is_base_filestate
    """If this FileState is the base state made during initialization of
    PyLinter.
    """

</t>
<t tx="ekr.20250131013601.587">def _set_state_on_block_lines(
    self,
    msgs_store: MessageDefinitionStore,
    node: nodes.NodeNG,
    msg: MessageDefinition,
    msg_state: dict[int, bool],
) -&gt; None:
    """Recursively walk (depth first) AST to collect block level options
    line numbers and set the state correctly.
    """
    for child in node.get_children():
        self._set_state_on_block_lines(msgs_store, child, msg, msg_state)
    # first child line number used to distinguish between disable
    # which are the first child of scoped node with those defined later.
    # For instance in the code below:
    #
    # 1.   def meth8(self):
    # 2.        """test late disabling"""
    # 3.        pylint: disable=not-callable, useless-suppression
    # 4.        print(self.blip)
    # 5.        pylint: disable=no-member, useless-suppression
    # 6.        print(self.bla)
    #
    # E1102 should be disabled from line 1 to 6 while E1101 from line 5 to 6
    #
    # this is necessary to disable locally messages applying to class /
    # function using their fromlineno
    if (
        isinstance(node, (nodes.Module, nodes.ClassDef, nodes.FunctionDef))
        and node.body
    ):
        firstchildlineno = node.body[0].fromlineno
    else:
        firstchildlineno = node.tolineno
    self._set_message_state_in_block(msg, msg_state, node, firstchildlineno)

</t>
<t tx="ekr.20250131013601.588">def _set_message_state_in_block(
    self,
    msg: MessageDefinition,
    lines: dict[int, bool],
    node: nodes.NodeNG,
    firstchildlineno: int,
) -&gt; None:
    """Set the state of a message in a block of lines."""
    first = node.fromlineno
    last = node.tolineno
    for lineno, state in list(lines.items()):
        original_lineno = lineno
        if first &gt; lineno or last &lt; lineno:
            continue
        # Set state for all lines for this block, if the
        # warning is applied to nodes.
        if msg.scope == WarningScope.NODE:
            if lineno &gt; firstchildlineno:
                state = True
            first_, last_ = node.block_range(lineno)
            # pylint: disable=useless-suppression
            # For block nodes first_ is their definition line. For example, we
            # set the state of line zero for a module to allow disabling
            # invalid-name for the module. For example:
            # 1. # pylint: disable=invalid-name
            # 2. ...
            # OR
            # 1. """Module docstring"""
            # 2. # pylint: disable=invalid-name
            # 3. ...
            #
            # But if we already visited line 0 we don't need to set its state again
            # 1. # pylint: disable=invalid-name
            # 2. # pylint: enable=invalid-name
            # 3. ...
            # The state should come from line 1, not from line 2
            # Therefore, if the 'fromlineno' is already in the states we just start
            # with the lineno we were originally visiting.
            # pylint: enable=useless-suppression
            if (
                first_ == node.fromlineno
                and first_ &gt;= firstchildlineno
                and node.fromlineno in self._module_msgs_state.get(msg.msgid, ())
            ):
                first_ = lineno

        else:
            first_ = lineno
            last_ = last
        for line in range(first_, last_ + 1):
            # Do not override existing entries. This is especially important
            # when parsing the states for a scoped node where some line-disables
            # have already been parsed.
            if (
                (
                    isinstance(node, nodes.Module)
                    and node.fromlineno &lt;= line &lt; lineno
                )
                or (
                    not isinstance(node, nodes.Module)
                    and node.fromlineno &lt; line &lt; lineno
                )
            ) and line in self._module_msgs_state.get(msg.msgid, ()):
                continue
            if line in lines:  # state change in the same block
                state = lines[line]
                original_lineno = line

            self._set_message_state_on_line(msg, line, state, original_lineno)

        del lines[lineno]

</t>
<t tx="ekr.20250131013601.589">def _set_message_state_on_line(
    self,
    msg: MessageDefinition,
    line: int,
    state: bool,
    original_lineno: int,
) -&gt; None:
    """Set the state of a message on a line."""
    # Update suppression mapping
    if not state:
        self._suppression_mapping[(msg.msgid, line)] = original_lineno
    else:
        self._suppression_mapping.pop((msg.msgid, line), None)

    # Update message state for respective line
    try:
        self._module_msgs_state[msg.msgid][line] = state
    except KeyError:
        self._module_msgs_state[msg.msgid] = {line: state}

</t>
<t tx="ekr.20250131013601.59">class _PylintConfigRun(Run):
    """A private wrapper for the 'pylint-config' command."""

    _is_pylint_config: ClassVar[bool] = True
    """Boolean whether or not this is a 'pylint-config' run.

    Used by _PylintConfigRun to make the 'pylint-config' command work.
    """
</t>
<t tx="ekr.20250131013601.590">def set_msg_status(
    self,
    msg: MessageDefinition,
    line: int,
    status: bool,
    scope: str = "package",
) -&gt; None:
    """Set status (enabled/disable) for a given message at a given line."""
    assert line &gt; 0
    if scope != "line":
        # Expand the status to cover all relevant block lines
        self._set_state_on_block_lines(
            self._msgs_store, self._module, msg, {line: status}
        )
    else:
        self._set_message_state_on_line(msg, line, status, line)

    # Store the raw value
    try:
        self._raw_module_msgs_state[msg.msgid][line] = status
    except KeyError:
        self._raw_module_msgs_state[msg.msgid] = {line: status}

</t>
<t tx="ekr.20250131013601.591">def handle_ignored_message(
    self, state_scope: Literal[0, 1, 2] | None, msgid: str, line: int | None
) -&gt; None:
    """Report an ignored message.

    state_scope is either MSG_STATE_SCOPE_MODULE or MSG_STATE_SCOPE_CONFIG,
    depending on whether the message was disabled locally in the module,
    or globally.
    """
    if state_scope == MSG_STATE_SCOPE_MODULE:
        assert isinstance(line, int)  # should always be int inside module scope

        try:
            orig_line = self._suppression_mapping[(msgid, line)]
            self._ignored_msgs[(msgid, orig_line)].add(line)
        except KeyError:
            pass

</t>
<t tx="ekr.20250131013601.592">def iter_spurious_suppression_messages(
    self,
    msgs_store: MessageDefinitionStore,
) -&gt; Iterator[
    tuple[
        Literal["useless-suppression", "suppressed-message"],
        int,
        tuple[str] | tuple[str, int],
    ]
</t>
<t tx="ekr.20250131013601.593">]:
    for warning, lines in self._raw_module_msgs_state.items():
        for line, enable in lines.items():
            if (
                not enable
                and (warning, line) not in self._ignored_msgs
                and warning not in INCOMPATIBLE_WITH_USELESS_SUPPRESSION
            ):
                yield "useless-suppression", line, (
                    msgs_store.get_msg_display_string(warning),
                )
    # don't use iteritems here, _ignored_msgs may be modified by add_message
    for (warning, from_), ignored_lines in list(self._ignored_msgs.items()):
        for line in ignored_lines:
            yield "suppressed-message", line, (
                msgs_store.get_msg_display_string(warning),
                from_,
            )

def get_effective_max_line_number(self) -&gt; int | None:
    return self._effective_max_line_number  # type: ignore[no-any-return]
</t>
<t tx="ekr.20250131013601.594">@path pylint/utils
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

from typing import Literal, TypedDict, cast

from pylint.typing import MessageTypesFullName


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.595">class BadNames(TypedDict):
    """TypedDict to store counts of node types with bad names."""

    argument: int
    attr: int
    klass: int
    class_attribute: int
    class_const: int
    const: int
    inlinevar: int
    function: int
    method: int
    module: int
    variable: int
    typevar: int
    typealias: int


</t>
<t tx="ekr.20250131013601.596">class CodeTypeCount(TypedDict):
    """TypedDict to store counts of lines of code types."""

    code: int
    comment: int
    docstring: int
    empty: int
    total: int


</t>
<t tx="ekr.20250131013601.597">class DuplicatedLines(TypedDict):
    """TypedDict to store counts of lines of duplicated code."""

    nb_duplicated_lines: int
    percent_duplicated_lines: float


</t>
<t tx="ekr.20250131013601.598">class NodeCount(TypedDict):
    """TypedDict to store counts of different types of nodes."""

    function: int
    klass: int
    method: int
    module: int


</t>
<t tx="ekr.20250131013601.599">class UndocumentedNodes(TypedDict):
    """TypedDict to store counts of undocumented node types."""

    function: int
    klass: int
    method: int
    module: int


</t>
<t tx="ekr.20250131013601.6">    ) -&gt; None:
        _ArgumentsManager.__init__(self, prog="pylint")
        _MessageStateHandler.__init__(self, self)

        # Some stuff has to be done before initialization of other ancestors...
        # messages store / checkers / reporter / astroid manager

        # Attributes for reporters
        self.reporter: reporters.BaseReporter | reporters.MultiReporter
        if reporter:
            self.set_reporter(reporter)
        else:
            self.set_reporter(TextReporter())
        self._reporters: dict[str, type[reporters.BaseReporter]] = {}
        """Dictionary of possible but non-initialized reporters."""

        # Attributes for checkers and plugins
        self._checkers: defaultdict[str, list[checkers.BaseChecker]] = (
            collections.defaultdict(list)
        )
        """Dictionary of registered and initialized checkers."""
        self._dynamic_plugins: dict[str, ModuleType | ModuleNotFoundError | bool] = {}
        """Set of loaded plugin names."""

        # Attributes related to stats
        self.stats = LinterStats()

        # Attributes related to (command-line) options and their parsing
        self.options: Options = options + _make_linter_options(self)
        for opt_group in option_groups:
            self.option_groups_descs[opt_group[0]] = opt_group[1]
        self._option_groups: tuple[tuple[str, str], ...] = (
            * option_groups,
            * PyLinter.option_groups_descs.items(),
        )
        self.fail_on_symbols: list[str] = []
        """List of message symbols on which pylint should fail, set by --fail-on."""
        self._error_mode = False

        reporters.ReportsHandlerMixIn.__init__(self)
        checkers.BaseChecker.__init__(self, self)
        # provided reports
        self.reports = (
            ("RP0001", "Messages by category", report_total_messages_stats),
            (
                "RP0002",
                "% errors / warnings by module",
                report_messages_by_module_stats,
            ),
            ("RP0003", "Messages", report_messages_stats),
        )

        # Attributes related to registering messages and their handling
        self.msgs_store = MessageDefinitionStore(self.config.py_version)
        self.msg_status = 0
        self._by_id_managed_msgs: list[ManagedMessage] = []

        # Attributes related to visiting files
        self.file_state = FileState("", self.msgs_store, is_base_filestate=True)
        self.current_name: str = ""
        self.current_file: str | None = None
        self._ignore_file = False
        self._ignore_paths: list[Pattern[str]] = []
        self.verbose = False

        self.register_checker(self)

    def load_default_plugins(self) -&gt; None:
        checkers.initialize(self)
        reporters.initialize(self)

</t>
<t tx="ekr.20250131013601.60">    LinterClass = PyLinter
    option_groups = (
        (
            "Commands",
            "Options which are actually commands. Options in this \
group are mutually exclusive.",
        ),
    )
    _is_pylint_config: ClassVar[bool] = False
    """Boolean whether or not this is a 'pylint-config' run.

    Used by _PylintConfigRun to make the 'pylint-config' command work.
    """

    # pylint: disable = too-many-statements, too-many-branches
    def __init__(
        self,
        args: Sequence[str],
        reporter: BaseReporter | None = None,
        exit: bool = True,  # pylint: disable=redefined-builtin
    ) -&gt; None:
        # Immediately exit if user asks for version
        if "--version" in args:
            print(full_version)
            sys.exit(0)

        self._rcfile: str | None = None
        self._output: str | None = None
        self._plugins: list[str] = []
        self.verbose: bool = False

        # Pre-process certain options and remove them from args list
        try:
            args = _preprocess_options(self, args)
        except ArgumentPreprocessingError as ex:
            print(ex, file=sys.stderr)
            sys.exit(32)

        # Determine configuration file
        if self._rcfile is None:
            default_file = next(config.find_default_config_files(), None)
            if default_file:
                self._rcfile = str(default_file)

        self.linter = linter = self.LinterClass(
            _make_run_options(self),
            option_groups=self.option_groups,
            pylintrc=self._rcfile,
        )
        # register standard checkers
        linter.load_default_plugins()
        # load command line plugins
        linter.load_plugin_modules(self._plugins)

        # Register the options needed for 'pylint-config'
        # By not registering them by default they don't show up in the normal usage message
        if self._is_pylint_config:
            _register_generate_config_options(linter._arg_parser)

        args = _config_initialization(
            linter, args, reporter, config_file=self._rcfile, verbose_mode=self.verbose
        )

        # Handle the 'pylint-config' command
        if self._is_pylint_config:
            warnings.warn(
                "NOTE: The 'pylint-config' command is experimental and usage can change",
                UserWarning,
                stacklevel=2,
            )
            code = _handle_pylint_config_commands(linter)
            if exit:
                sys.exit(code)
            return

        # Display help if there are no files to lint or only internal checks enabled (`--disable=all`)
        disable_all_msg_set = set(
            msg.symbol for msg in linter.msgs_store.messages
        ) - set(msg[1] for msg in linter.default_enabled_messages.values())
        if not args or (
            len(linter.config.enable) == 0
            and set(linter.config.disable) == disable_all_msg_set
        ):
            print("No files to lint: exiting.")
            sys.exit(32)

        if linter.config.jobs &lt; 0:
            print(
                f"Jobs number ({linter.config.jobs}) should be greater than or equal to 0",
                file=sys.stderr,
            )
            sys.exit(32)
        if linter.config.jobs &gt; 1 or linter.config.jobs == 0:
            if ProcessPoolExecutor is None:
                print(
                    "concurrent.futures module is missing, fallback to single process",
                    file=sys.stderr,
                )
                linter.set_option("jobs", 1)
            elif linter.config.jobs == 0:
                linter.config.jobs = _cpu_count()

        if self._output:
            try:
                with open(self._output, "w", encoding="utf-8") as output:
                    linter.reporter.out = output
                    linter.check(args)
                    score_value = linter.generate_reports(verbose=self.verbose)
            except OSError as ex:
                print(ex, file=sys.stderr)
                sys.exit(32)
        else:
            linter.check(args)
            score_value = linter.generate_reports(verbose=self.verbose)
        if linter.config.clear_cache_post_run:
            clear_lru_caches()
            MANAGER.clear_cache()

        if exit:
            if linter.config.exit_zero:
                sys.exit(0)
            elif linter.any_fail_on_issues():
                # We need to make sure we return a failing exit code in this case.
                # So we use self.linter.msg_status if that is non-zero, otherwise we just return 1.
                sys.exit(self.linter.msg_status or 1)
            elif score_value is not None:
                if score_value &gt;= linter.config.fail_under:
                    sys.exit(0)
                else:
                    # We need to make sure we return a failing exit code in this case.
                    # So we use self.linter.msg_status if that is non-zero, otherwise we just return 1.
                    sys.exit(self.linter.msg_status or 1)
            else:
                sys.exit(self.linter.msg_status)


</t>
<t tx="ekr.20250131013601.600">class ModuleStats(TypedDict):
    """TypedDict to store counts of types of messages and statements."""

    convention: int
    error: int
    fatal: int
    info: int
    refactor: int
    statement: int
    warning: int


</t>
<t tx="ekr.20250131013601.601"># pylint: disable-next=too-many-instance-attributes
class LinterStats:
    """Class used to linter stats."""

    @others
</t>
<t tx="ekr.20250131013601.602">def merge_stats(stats: list[LinterStats]) -&gt; LinterStats:
    """Used to merge multiple stats objects into a new one when pylint is run in
    parallel mode.
    """
    merged = LinterStats()
    for stat in stats:
        merged.bad_names["argument"] += stat.bad_names["argument"]
        merged.bad_names["attr"] += stat.bad_names["attr"]
        merged.bad_names["klass"] += stat.bad_names["klass"]
        merged.bad_names["class_attribute"] += stat.bad_names["class_attribute"]
        merged.bad_names["class_const"] += stat.bad_names["class_const"]
        merged.bad_names["const"] += stat.bad_names["const"]
        merged.bad_names["inlinevar"] += stat.bad_names["inlinevar"]
        merged.bad_names["function"] += stat.bad_names["function"]
        merged.bad_names["method"] += stat.bad_names["method"]
        merged.bad_names["module"] += stat.bad_names["module"]
        merged.bad_names["variable"] += stat.bad_names["variable"]
        merged.bad_names["typevar"] += stat.bad_names["typevar"]
        merged.bad_names["typealias"] += stat.bad_names["typealias"]

        for mod_key, mod_value in stat.by_module.items():
            merged.by_module[mod_key] = mod_value

        for msg_key, msg_value in stat.by_msg.items():
            try:
                merged.by_msg[msg_key] += msg_value
            except KeyError:
                merged.by_msg[msg_key] = msg_value

        merged.code_type_count["code"] += stat.code_type_count["code"]
        merged.code_type_count["comment"] += stat.code_type_count["comment"]
        merged.code_type_count["docstring"] += stat.code_type_count["docstring"]
        merged.code_type_count["empty"] += stat.code_type_count["empty"]
        merged.code_type_count["total"] += stat.code_type_count["total"]

        for dep_key, dep_value in stat.dependencies.items():
            try:
                merged.dependencies[dep_key].update(dep_value)
            except KeyError:
                merged.dependencies[dep_key] = dep_value

        merged.duplicated_lines["nb_duplicated_lines"] += stat.duplicated_lines[
            "nb_duplicated_lines"
        ]
        merged.duplicated_lines["percent_duplicated_lines"] += stat.duplicated_lines[
            "percent_duplicated_lines"
        ]

        merged.node_count["function"] += stat.node_count["function"]
        merged.node_count["klass"] += stat.node_count["klass"]
        merged.node_count["method"] += stat.node_count["method"]
        merged.node_count["module"] += stat.node_count["module"]

        merged.undocumented["function"] += stat.undocumented["function"]
        merged.undocumented["klass"] += stat.undocumented["klass"]
        merged.undocumented["method"] += stat.undocumented["method"]
        merged.undocumented["module"] += stat.undocumented["module"]

        merged.convention += stat.convention
        merged.error += stat.error
        merged.fatal += stat.fatal
        merged.info += stat.info
        merged.refactor += stat.refactor
        merged.statement += stat.statement
        merged.warning += stat.warning
        merged.skipped += stat.skipped

        merged.global_note += stat.global_note
    return merged
</t>
<t tx="ekr.20250131013601.603">def __init__(
    self,
    bad_names: BadNames | None = None,
    by_module: dict[str, ModuleStats] | None = None,
    by_msg: dict[str, int] | None = None,
    code_type_count: CodeTypeCount | None = None,
    dependencies: dict[str, set[str]] | None = None,
    duplicated_lines: DuplicatedLines | None = None,
    node_count: NodeCount | None = None,
    undocumented: UndocumentedNodes | None = None,
) -&gt; None:
    self.bad_names = bad_names or BadNames(
        argument=0,
        attr=0,
        klass=0,
        class_attribute=0,
        class_const=0,
        const=0,
        inlinevar=0,
        function=0,
        method=0,
        module=0,
        variable=0,
        typevar=0,
        typealias=0,
    )
    self.by_module: dict[str, ModuleStats] = by_module or {}
    self.by_msg: dict[str, int] = by_msg or {}
    self.code_type_count = code_type_count or CodeTypeCount(
        code=0, comment=0, docstring=0, empty=0, total=0
    )

    self.dependencies: dict[str, set[str]] = dependencies or {}
    self.duplicated_lines = duplicated_lines or DuplicatedLines(
        nb_duplicated_lines=0, percent_duplicated_lines=0.0
    )
    self.node_count = node_count or NodeCount(
        function=0, klass=0, method=0, module=0
    )
    self.undocumented = undocumented or UndocumentedNodes(
        function=0, klass=0, method=0, module=0
    )

    self.convention = 0
    self.error = 0
    self.fatal = 0
    self.info = 0
    self.refactor = 0
    self.statement = 0
    self.warning = 0
    self.skipped = 0

    self.global_note = 0
    self.nb_duplicated_lines = 0
    self.percent_duplicated_lines = 0.0

</t>
<t tx="ekr.20250131013601.604">def __repr__(self) -&gt; str:
    return str(self)

</t>
<t tx="ekr.20250131013601.605">def __str__(self) -&gt; str:
    return f"""{self.bad_names}
    {sorted(self.by_module.items())}
    {sorted(self.by_msg.items())}
    {self.code_type_count}
    {sorted(self.dependencies.items())}
    {self.duplicated_lines}
    {self.undocumented}
    {self.convention}
    {self.error}
    {self.fatal}
    {self.info}
    {self.refactor}
    {self.statement}
    {self.warning}
    {self.skipped}
    {self.global_note}
    {self.nb_duplicated_lines}
    {self.percent_duplicated_lines}"""

</t>
<t tx="ekr.20250131013601.606">def init_single_module(self, module_name: str) -&gt; None:
    """Use through PyLinter.set_current_module so PyLinter.current_name is
    consistent.
    """
    self.by_module[module_name] = ModuleStats(
        convention=0, error=0, fatal=0, info=0, refactor=0, statement=0, warning=0
    )

</t>
<t tx="ekr.20250131013601.607">def get_bad_names(
    self,
    node_name: Literal[
        "argument",
        "attr",
        "class",
        "class_attribute",
        "class_const",
        "const",
        "inlinevar",
        "function",
        "method",
        "module",
        "variable",
        "typevar",
        "typealias",
    ],
) -&gt; int:
    """Get a bad names node count."""
    if node_name == "class":
        return self.bad_names.get("klass", 0)
    return self.bad_names.get(node_name, 0)

</t>
<t tx="ekr.20250131013601.608">def increase_bad_name(self, node_name: str, increase: int) -&gt; None:
    """Increase a bad names node count."""
    if node_name not in {
        "argument",
        "attr",
        "class",
        "class_attribute",
        "class_const",
        "const",
        "inlinevar",
        "function",
        "method",
        "module",
        "variable",
        "typevar",
        "typealias",
    }:
        raise ValueError("Node type not part of the bad_names stat")

    node_name = cast(
        Literal[
            "argument",
            "attr",
            "class",
            "class_attribute",
            "class_const",
            "const",
            "inlinevar",
            "function",
            "method",
            "module",
            "variable",
            "typevar",
            "typealias",
        ],
        node_name,
    )
    if node_name == "class":
        self.bad_names["klass"] += increase
    else:
        self.bad_names[node_name] += increase

</t>
<t tx="ekr.20250131013601.609">def reset_bad_names(self) -&gt; None:
    """Resets the bad_names attribute."""
    self.bad_names = BadNames(
        argument=0,
        attr=0,
        klass=0,
        class_attribute=0,
        class_const=0,
        const=0,
        inlinevar=0,
        function=0,
        method=0,
        module=0,
        variable=0,
        typevar=0,
        typealias=0,
    )

</t>
<t tx="ekr.20250131013601.61">@path pylint/lint
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import contextlib
import platform
import sys
import traceback
from collections.abc import Iterator, Sequence
from datetime import datetime
from pathlib import Path

from pylint.constants import PYLINT_HOME, full_version


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.610">def get_code_count(
    self, type_name: Literal["code", "comment", "docstring", "empty", "total"]
) -&gt; int:
    """Get a code type count."""
    return self.code_type_count.get(type_name, 0)

</t>
<t tx="ekr.20250131013601.611">def reset_code_count(self) -&gt; None:
    """Resets the code_type_count attribute."""
    self.code_type_count = CodeTypeCount(
        code=0, comment=0, docstring=0, empty=0, total=0
    )

</t>
<t tx="ekr.20250131013601.612">def reset_duplicated_lines(self) -&gt; None:
    """Resets the duplicated_lines attribute."""
    self.duplicated_lines = DuplicatedLines(
        nb_duplicated_lines=0, percent_duplicated_lines=0.0
    )

</t>
<t tx="ekr.20250131013601.613">def get_node_count(
    self, node_name: Literal["function", "class", "method", "module"]
) -&gt; int:
    """Get a node count while handling some extra conditions."""
    if node_name == "class":
        return self.node_count.get("klass", 0)
    return self.node_count.get(node_name, 0)

</t>
<t tx="ekr.20250131013601.614">def reset_node_count(self) -&gt; None:
    """Resets the node count attribute."""
    self.node_count = NodeCount(function=0, klass=0, method=0, module=0)

</t>
<t tx="ekr.20250131013601.615">def get_undocumented(
    self, node_name: Literal["function", "class", "method", "module"]
) -&gt; float:
    """Get a undocumented node count."""
    if node_name == "class":
        return self.undocumented["klass"]
    return self.undocumented[node_name]

</t>
<t tx="ekr.20250131013601.616">def reset_undocumented(self) -&gt; None:
    """Resets the undocumented attribute."""
    self.undocumented = UndocumentedNodes(function=0, klass=0, method=0, module=0)

</t>
<t tx="ekr.20250131013601.617">def get_global_message_count(self, type_name: str) -&gt; int:
    """Get a global message count."""
    return getattr(self, type_name, 0)

</t>
<t tx="ekr.20250131013601.618">def get_module_message_count(
    self, modname: str, type_name: MessageTypesFullName
) -&gt; int:
    """Get a module message count."""
    return self.by_module[modname].get(type_name, 0)

</t>
<t tx="ekr.20250131013601.619">def increase_single_message_count(self, type_name: str, increase: int) -&gt; None:
    """Increase the message type count of an individual message type."""
    setattr(self, type_name, getattr(self, type_name) + increase)

</t>
<t tx="ekr.20250131013601.62">def prepare_crash_report(ex: Exception, filepath: str, crash_file_path: str) -&gt; Path:
    issue_template_path = (
        Path(PYLINT_HOME) / datetime.now().strftime(str(crash_file_path))
    ).resolve()
    with open(filepath, encoding="utf8") as f:
        file_content = f.read()
    template = ""
    if not issue_template_path.exists():
        template = """\
First, please verify that the bug is not already filled:
https://github.com/pylint-dev/pylint/issues/

Then create a new issue:
https://github.com/pylint-dev/pylint/issues/new?labels=Crash 💥%2CNeeds triage 📥


"""
    template += f"""
Issue title:
Crash ``{ex}`` (if possible, be more specific about what made pylint crash)

### Bug description

When parsing the following ``a.py``:

&lt;!--
 If sharing the code is not an option, please state so,
 but providing only the stacktrace would still be helpful.
 --&gt;

```python
{file_content}
```

### Command used

```shell
pylint a.py
```

### Pylint output

&lt;details open&gt;
    &lt;summary&gt;
        pylint crashed with a ``{ex.__class__.__name__}`` and with the following stacktrace:
    &lt;/summary&gt;

```python
"""
    template += traceback.format_exc()
    template += f"""
```


&lt;/details&gt;

### Expected behavior

No crash.

### Pylint version

```shell
{full_version}
```

### OS / Environment

{sys.platform} ({platform.system()})

### Additional dependencies

&lt;!--
Please remove this part if you're not using any of
your dependencies in the example.
 --&gt;
"""
    try:
        with open(issue_template_path, "a", encoding="utf8") as f:
            f.write(template)
    except Exception as exc:  # pylint: disable=broad-except
        print(
            f"Can't write the issue template for the crash in {issue_template_path} "
            f"because of: '{exc}'\nHere's the content anyway:\n{template}.",
            file=sys.stderr,
        )
    return issue_template_path


</t>
<t tx="ekr.20250131013601.620">def increase_single_module_message_count(
    self, modname: str, type_name: MessageTypesFullName, increase: int
) -&gt; None:
    """Increase the message type count of an individual message type of a
    module.
    """
    self.by_module[modname][type_name] += increase

</t>
<t tx="ekr.20250131013601.621">def reset_message_count(self) -&gt; None:
    """Resets the message type count of the stats object."""
    self.convention = 0
    self.error = 0
    self.fatal = 0
    self.info = 0
    self.refactor = 0
    self.warning = 0


</t>
<t tx="ekr.20250131013601.622">@path pylint/utils
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import re
from collections.abc import Generator
from typing import NamedTuple

# Allow stopping after the first semicolon/hash encountered,
# so that an option can be continued with the reasons
# why it is active or disabled.
OPTION_RGX = r"""
    (?:^\s*\#.*|\s*|               # Comment line, or whitespaces,
       \s*\#.*(?=\#.*?\bpylint:))  # or a beginning of an inline comment
                                   # followed by "pylint:" pragma
    (\#                            # Beginning of comment
    .*?                            # Anything (as little as possible)
    \bpylint:                      # pylint word and column
    \s*                            # Any number of whitespaces
    ([^;#\n]+))                    # Anything except semicolon or hash or
                                   # newline (it is the second matched group)
                                   # and end of the first matched group
    [;#]{0,1}                      # From 0 to 1 repetition of semicolon or hash
"""
OPTION_PO = re.compile(OPTION_RGX, re.VERBOSE)


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.623">class PragmaRepresenter(NamedTuple):
    action: str
    messages: list[str]


</t>
<t tx="ekr.20250131013601.624">ATOMIC_KEYWORDS = frozenset(("disable-all", "skip-file"))
MESSAGE_KEYWORDS = frozenset(
    ("disable-next", "disable-msg", "enable-msg", "disable", "enable")
)
# sorted is necessary because sets are unordered collections and ALL_KEYWORDS
# string should not vary between executions
# reverse is necessary in order to have the longest keywords first, so that, for example,
# 'disable' string should not be matched instead of 'disable-all'
ALL_KEYWORDS = "|".join(
    sorted(ATOMIC_KEYWORDS | MESSAGE_KEYWORDS, key=len, reverse=True)
)


TOKEN_SPECIFICATION = [
    ("KEYWORD", rf"\b({ALL_KEYWORDS:s})\b"),
    ("MESSAGE_STRING", r"[0-9A-Za-z\-\_]{2,}"),  # Identifiers
    ("ASSIGN", r"="),  # Assignment operator
    ("MESSAGE_NUMBER", r"[CREIWF]{1}\d*"),
]

TOK_REGEX = "|".join(
    f"(?P&lt;{token_name:s}&gt;{token_rgx:s})"
    for token_name, token_rgx in TOKEN_SPECIFICATION
)


def emit_pragma_representer(action: str, messages: list[str]) -&gt; PragmaRepresenter:
    if not messages and action in MESSAGE_KEYWORDS:
        raise InvalidPragmaError(
            "The keyword is not followed by message identifier", action
        )
    return PragmaRepresenter(action, messages)


</t>
<t tx="ekr.20250131013601.625">class PragmaParserError(Exception):
    """A class for exceptions thrown by pragma_parser module."""

    @others
</t>
<t tx="ekr.20250131013601.626">class UnRecognizedOptionError(PragmaParserError):
    """Thrown in case the of a valid but unrecognized option."""


</t>
<t tx="ekr.20250131013601.627">class InvalidPragmaError(PragmaParserError):
    """Thrown in case the pragma is invalid."""


</t>
<t tx="ekr.20250131013601.628">def parse_pragma(pylint_pragma: str) -&gt; Generator[PragmaRepresenter]:
    action: str | None = None
    messages: list[str] = []
    assignment_required = False
    previous_token = ""

    for mo in re.finditer(TOK_REGEX, pylint_pragma):
        kind = mo.lastgroup
        value = mo.group()

        if kind == "ASSIGN":
            if not assignment_required:
                if action:
                    # A keyword has been found previously but doesn't support assignment
                    raise UnRecognizedOptionError(
                        "The keyword doesn't support assignment", action
                    )
                if previous_token:
                    # Something found previously but not a known keyword
                    raise UnRecognizedOptionError(
                        "The keyword is unknown", previous_token
                    )
                # Nothing at all detected before this assignment
                raise InvalidPragmaError("Missing keyword before assignment", "")
            assignment_required = False
        elif assignment_required:
            raise InvalidPragmaError(
                "The = sign is missing after the keyword", action or ""
            )
        elif kind == "KEYWORD":
            if action:
                yield emit_pragma_representer(action, messages)
            action = value
            messages = []
            assignment_required = action in MESSAGE_KEYWORDS
        elif kind in {"MESSAGE_STRING", "MESSAGE_NUMBER"}:
            messages.append(value)
            assignment_required = False
        else:
            raise RuntimeError("Token not recognized")

        previous_token = value

    if action:
        yield emit_pragma_representer(action, messages)
    else:
        raise UnRecognizedOptionError("The keyword is unknown", previous_token)
</t>
<t tx="ekr.20250131013601.629">def __init__(self, message: str, token: str) -&gt; None:
    """:args message: explain the reason why the exception has been thrown
    :args token: token concerned by the exception.
    """
    self.message = message
    self.token = token
    super().__init__(self.message)


</t>
<t tx="ekr.20250131013601.63">def get_fatal_error_message(filepath: str, issue_template_path: Path) -&gt; str:
    return (
        f"Fatal error while checking '{filepath}'. "
        f"Please open an issue in our bug tracker so we address this. "
        f"There is a pre-filled template that you can use in '{issue_template_path}'."
    )


</t>
<t tx="ekr.20250131013601.630">@path pylint/utils
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

try:
    import isort.api
    import isort.settings

    HAS_ISORT_5 = True
except ImportError:  # isort &lt; 5
    import isort

    HAS_ISORT_5 = False

import argparse
import codecs
import os
import re
import sys
import textwrap
import tokenize
import warnings
from collections import deque
from collections.abc import Iterable, Sequence
from io import BufferedReader, BytesIO
from re import Pattern
from typing import TYPE_CHECKING, Any, Literal, TextIO, TypeVar, Union

from astroid import Module, modutils, nodes

from pylint.constants import PY_EXTS
from pylint.typing import OptionDict

if TYPE_CHECKING:
    from pylint.lint import PyLinter

DEFAULT_LINE_LENGTH = 79

# These are types used to overload get_global_option() and refer to the options type
GLOBAL_OPTION_BOOL = Literal[
    "suggestion-mode",
    "analyse-fallback-blocks",
    "allow-global-unused-variables",
    "prefer-stubs",
]
GLOBAL_OPTION_INT = Literal["max-line-length", "docstring-min-length"]
GLOBAL_OPTION_LIST = Literal["ignored-modules"]
GLOBAL_OPTION_PATTERN = Literal[
    "no-docstring-rgx",
    "dummy-variables-rgx",
    "ignored-argument-names",
    "mixin-class-rgx",
]
GLOBAL_OPTION_PATTERN_LIST = Literal["exclude-too-few-public-methods", "ignore-paths"]
GLOBAL_OPTION_TUPLE_INT = Literal["py-version"]
GLOBAL_OPTION_NAMES = Union[
    GLOBAL_OPTION_BOOL,
    GLOBAL_OPTION_INT,
    GLOBAL_OPTION_LIST,
    GLOBAL_OPTION_PATTERN,
    GLOBAL_OPTION_PATTERN_LIST,
    GLOBAL_OPTION_TUPLE_INT,
]
T_GlobalOptionReturnTypes = TypeVar(
    "T_GlobalOptionReturnTypes",
    bool,
    int,
    list[str],
    Pattern[str],
    list[Pattern[str]],
    tuple[int, ...],
)


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.631">def normalize_text(
    text: str, line_len: int = DEFAULT_LINE_LENGTH, indent: str = ""
) -&gt; str:
    """Wrap the text on the given line length."""
    return "\n".join(
        textwrap.wrap(
            text, width=line_len, initial_indent=indent, subsequent_indent=indent
        )
    )


</t>
<t tx="ekr.20250131013601.632">CMPS = ["=", "-", "+"]


# py3k has no more cmp builtin
def cmp(a: float, b: float) -&gt; int:
    return (a &gt; b) - (a &lt; b)


</t>
<t tx="ekr.20250131013601.633">def diff_string(old: float, new: float) -&gt; str:
    """Given an old and new value, return a string representing the difference."""
    diff = abs(old - new)
    diff_str = f"{CMPS[cmp(old, new)]}{(diff and f'{diff:.2f}') or ''}"
    return diff_str


</t>
<t tx="ekr.20250131013601.634">def get_module_and_frameid(node: nodes.NodeNG) -&gt; tuple[str, str]:
    """Return the module name and the frame id in the module."""
    frame = node.frame()
    module, obj = "", []
    while frame:
        if isinstance(frame, Module):
            module = frame.name
        else:
            obj.append(getattr(frame, "name", "&lt;lambda&gt;"))
        try:
            frame = frame.parent.frame()
        except AttributeError:
            break
    obj.reverse()
    return module, ".".join(obj)


</t>
<t tx="ekr.20250131013601.635">def get_rst_title(title: str, character: str) -&gt; str:
    """Permit to get a title formatted as ReStructuredText test (underlined with a
    chosen character).
    """
    return f"{title}\n{character * len(title)}\n"


</t>
<t tx="ekr.20250131013601.636">def get_rst_section(
    section: str | None,
    options: list[tuple[str, OptionDict, Any]],
    doc: str | None = None,
) -&gt; str:
    """Format an option's section using as a ReStructuredText formatted output."""
    result = ""
    if section:
        result += get_rst_title(section, "'")
    if doc:
        formatted_doc = normalize_text(doc)
        result += f"{formatted_doc}\n\n"
    for optname, optdict, value in options:
        help_opt = optdict.get("help")
        result += f":{optname}:\n"
        if help_opt:
            assert isinstance(help_opt, str)
            formatted_help = normalize_text(help_opt, indent="  ")
            result += f"{formatted_help}\n"
        if value and optname != "py-version":
            value = str(_format_option_value(optdict, value))
            result += f"\n  Default: ``{value.replace('`` ', '```` ``')}``\n"
    return result


</t>
<t tx="ekr.20250131013601.637">def decoding_stream(
    stream: BufferedReader | BytesIO,
    encoding: str,
    errors: Literal["strict"] = "strict",
) -&gt; codecs.StreamReader:
    try:
        reader_cls = codecs.getreader(encoding or sys.getdefaultencoding())
    except LookupError:
        reader_cls = codecs.getreader(sys.getdefaultencoding())
    return reader_cls(stream, errors)


</t>
<t tx="ekr.20250131013601.638">def tokenize_module(node: nodes.Module) -&gt; list[tokenize.TokenInfo]:
    with node.stream() as stream:
        readline = stream.readline
        return list(tokenize.tokenize(readline))


</t>
<t tx="ekr.20250131013601.639">def register_plugins(linter: PyLinter, directory: str) -&gt; None:
    """Load all module and package in the given directory, looking for a
    'register' function in each one, used to register pylint checkers.
    """
    imported = {}
    for filename in os.listdir(directory):
        base, extension = os.path.splitext(filename)
        if base in imported or base == "__pycache__":
            continue
        if (extension in PY_EXTS and base != "__init__") or (
            not extension
            and os.path.isdir(os.path.join(directory, base))
            and not filename.startswith(".")
        ):
            try:
                module = modutils.load_module_from_file(
                    os.path.join(directory, filename)
                )
            except ValueError:
                # empty module name (usually Emacs auto-save files)
                continue
            except ImportError as exc:
                print(f"Problem importing module {filename}: {exc}", file=sys.stderr)
            else:
                if hasattr(module, "register"):
                    module.register(linter)
                    imported[base] = 1


</t>
<t tx="ekr.20250131013601.64">def _augment_sys_path(additional_paths: Sequence[str]) -&gt; list[str]:
    original = list(sys.path)
    changes = []
    seen = set()
    for additional_path in additional_paths:
        if additional_path not in seen:
            changes.append(additional_path)
            seen.add(additional_path)

    sys.path[:] = changes + sys.path
    return original


</t>
<t tx="ekr.20250131013601.640">def _splitstrip(string: str, sep: str = ",") -&gt; list[str]:
    r"""Return a list of stripped string by splitting the string given as
    argument on `sep` (',' by default), empty strings are discarded.

    &gt;&gt;&gt; _splitstrip('a, b, c   ,  4,,')
    ['a', 'b', 'c', '4']
    &gt;&gt;&gt; _splitstrip('a')
    ['a']
    &gt;&gt;&gt; _splitstrip('a,\nb,\nc,')
    ['a', 'b', 'c']

    :type string: str or unicode
    :param string: a csv line

    :type sep: str or unicode
    :param sep: field separator, default to the comma (',')

    :rtype: str or unicode
    :return: the unquoted string (or the input string if it wasn't quoted)
    """
    return [word.strip() for word in string.split(sep) if word.strip()]


</t>
<t tx="ekr.20250131013601.641">def _unquote(string: str) -&gt; str:
    """Remove optional quotes (simple or double) from the string.

    :param string: an optionally quoted string
    :return: the unquoted string (or the input string if it wasn't quoted)
    """
    if not string:
        return string
    if string[0] in "\"'":
        string = string[1:]
    if string[-1] in "\"'":
        string = string[:-1]
    return string


</t>
<t tx="ekr.20250131013601.642">def _check_csv(value: list[str] | tuple[str] | str) -&gt; Sequence[str]:
    if isinstance(value, (list, tuple)):
        return value
    return _splitstrip(value)


</t>
<t tx="ekr.20250131013601.643">def _check_regexp_csv(value: list[str] | tuple[str] | str) -&gt; Iterable[str]:
    r"""Split a comma-separated list of regexps, taking care to avoid splitting
    a regex employing a comma as quantifier, as in `\d{1,2}`.
    """
    if isinstance(value, (list, tuple)):
        yield from value
    else:
        # None is a sentinel value here
        regexps: deque[deque[str] | None] = deque([None])
        open_braces = False
        for char in value:
            if char == "{":
                open_braces = True
            elif char == "}" and open_braces:
                open_braces = False

            if char == "," and not open_braces:
                regexps.append(None)
            elif regexps[-1] is None:
                regexps.pop()
                regexps.append(deque([char]))
            else:
                regexps[-1].append(char)
        yield from ("".join(regexp).strip() for regexp in regexps if regexp is not None)


</t>
<t tx="ekr.20250131013601.644">def _comment(string: str) -&gt; str:
    """Return string as a comment."""
    lines = [line.strip() for line in string.splitlines()]
    sep = "\n"
    return "# " + f"{sep}# ".join(lines)


</t>
<t tx="ekr.20250131013601.645">def _format_option_value(optdict: OptionDict, value: Any) -&gt; str:
    """Return the user input's value from a 'compiled' value.

    TODO: Refactor the code to not use this deprecated function
    """
    if optdict.get("type", None) == "py_version":
        value = ".".join(str(item) for item in value)
    elif isinstance(value, (list, tuple)):
        value = ",".join(_format_option_value(optdict, item) for item in value)
    elif isinstance(value, dict):
        value = ",".join(f"{k}:{v}" for k, v in value.items())
    elif hasattr(value, "match"):  # optdict.get('type') == 'regexp'
        # compiled regexp
        value = value.pattern
    elif optdict.get("type") == "yn":
        value = "yes" if value else "no"
    elif isinstance(value, str) and value.isspace():
        value = f"'{value}'"
    return str(value)


</t>
<t tx="ekr.20250131013601.646">def format_section(
    stream: TextIO,
    section: str,
    options: list[tuple[str, OptionDict, Any]],
    doc: str | None = None,
) -&gt; None:
    """Format an option's section using the INI format."""
    warnings.warn(
        "format_section has been deprecated. It will be removed in pylint 4.0.",
        DeprecationWarning,
        stacklevel=2,
    )
    if doc:
        print(_comment(doc), file=stream)
    print(f"[{section}]", file=stream)
    with warnings.catch_warnings():
        warnings.filterwarnings("ignore", category=DeprecationWarning)
        _ini_format(stream, options)


</t>
<t tx="ekr.20250131013601.647">def _ini_format(stream: TextIO, options: list[tuple[str, OptionDict, Any]]) -&gt; None:
    """Format options using the INI format."""
    warnings.warn(
        "_ini_format has been deprecated. It will be removed in pylint 4.0.",
        DeprecationWarning,
        stacklevel=2,
    )
    for optname, optdict, value in options:
        # Skip deprecated option
        if "kwargs" in optdict:
            assert isinstance(optdict["kwargs"], dict)
            if "new_names" in optdict["kwargs"]:
                continue
        value = _format_option_value(optdict, value)
        help_opt = optdict.get("help")
        if help_opt:
            assert isinstance(help_opt, str)
            help_opt = normalize_text(help_opt, indent="# ")
            print(file=stream)
            print(help_opt, file=stream)
        else:
            print(file=stream)
        if value in {"None", "False"}:
            print(f"#{optname}=", file=stream)
        else:
            value = str(value).strip()
            if re.match(r"^([\w-]+,)+[\w-]+$", str(value)):
                separator = "\n " + " " * len(optname)
                value = separator.join(x + "," for x in str(value).split(","))
                # remove trailing ',' from last element of the list
                value = value[:-1]
            print(f"{optname}={value}", file=stream)


</t>
<t tx="ekr.20250131013601.648">class IsortDriver:
    """A wrapper around isort API that changed between versions 4 and 5."""

    @others
</t>
<t tx="ekr.20250131013601.649">def __init__(self, config: argparse.Namespace) -&gt; None:
    if HAS_ISORT_5:
        self.isort5_config = isort.settings.Config(
            # There is no typo here. EXTRA_standard_library is
            # what most users want. The option has been named
            # KNOWN_standard_library for ages in pylint, and we
            # don't want to break compatibility.
            extra_standard_library=config.known_standard_library,
            known_third_party=config.known_third_party,
        )
    else:
        # pylint: disable-next=no-member
        self.isort4_obj = isort.SortImports(  # type: ignore[attr-defined]
            file_contents="",
            known_standard_library=config.known_standard_library,
            known_third_party=config.known_third_party,
        )

</t>
<t tx="ekr.20250131013601.65">@contextlib.contextmanager
def augmented_sys_path(additional_paths: Sequence[str]) -&gt; Iterator[None]:
    """Augment 'sys.path' by adding non-existent entries from additional_paths."""
    original = _augment_sys_path(additional_paths)
    try:
        yield
    finally:
        sys.path[:] = original
</t>
<t tx="ekr.20250131013601.650">def place_module(self, package: str) -&gt; str:
    if HAS_ISORT_5:
        return isort.api.place_module(package, self.isort5_config)
    return self.isort4_obj.place_module(package)  # type: ignore[no-any-return]
</t>
<t tx="ekr.20250131013601.66"></t>
<t tx="ekr.20250131013601.67">@path pylint/message
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

"""All the classes related to Message handling."""

from pylint.message.message import Message
from pylint.message.message_definition import MessageDefinition
from pylint.message.message_definition_store import MessageDefinitionStore
from pylint.message.message_id_store import MessageIdStore

__all__ = [
    "Message",
    "MessageDefinition",
    "MessageDefinitionStore",
    "MessageIdStore",
]
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.68">@path pylint/message
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

from functools import cache
from typing import NamedTuple


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.69">class DeletedMessage(NamedTuple):
    msgid: str
    symbol: str
    old_names: list[tuple[str, str]] = []


</t>
<t tx="ekr.20250131013601.7">    def load_plugin_modules(self, modnames: Iterable[str], force: bool = False) -&gt; None:
        """Check a list of pylint plugins modules, load and register them.

        If a module cannot be loaded, never try to load it again and instead
        store the error message for later use in ``load_plugin_configuration``
        below.

        If `force` is True (useful when multiprocessing), then the plugin is
        reloaded regardless if an entry exists in self._dynamic_plugins.
        """
        for modname in modnames:
            if modname in self._dynamic_plugins and not force:
                continue
            try:
                module = astroid.modutils.load_module_from_name(modname)
                module.register(self)
                self._dynamic_plugins[modname] = module
            except ModuleNotFoundError as mnf_e:
                self._dynamic_plugins[modname] = mnf_e

</t>
<t tx="ekr.20250131013601.70">DELETED_MSGID_PREFIXES: list[int] = []

DELETED_MESSAGES_IDS = {
    # Everything until the next comment is from the PY3K+ checker
    "https://github.com/pylint-dev/pylint/pull/4942": [
        DeletedMessage("W1601", "apply-builtin"),
        DeletedMessage("E1601", "print-statement"),
        DeletedMessage("E1602", "parameter-unpacking"),
        DeletedMessage(
            "E1603", "unpacking-in-except", [("W0712", "old-unpacking-in-except")]
        ),
        DeletedMessage(
            "E1604", "old-raise-syntax", [("W0121", "old-old-raise-syntax")]
        ),
        DeletedMessage("E1605", "backtick", [("W0333", "old-backtick")]),
        DeletedMessage("E1609", "import-star-module-level"),
        DeletedMessage("W1601", "apply-builtin"),
        DeletedMessage("W1602", "basestring-builtin"),
        DeletedMessage("W1603", "buffer-builtin"),
        DeletedMessage("W1604", "cmp-builtin"),
        DeletedMessage("W1605", "coerce-builtin"),
        DeletedMessage("W1606", "execfile-builtin"),
        DeletedMessage("W1607", "file-builtin"),
        DeletedMessage("W1608", "long-builtin"),
        DeletedMessage("W1609", "raw_input-builtin"),
        DeletedMessage("W1610", "reduce-builtin"),
        DeletedMessage("W1611", "standarderror-builtin"),
        DeletedMessage("W1612", "unicode-builtin"),
        DeletedMessage("W1613", "xrange-builtin"),
        DeletedMessage("W1614", "coerce-method"),
        DeletedMessage("W1615", "delslice-method"),
        DeletedMessage("W1616", "getslice-method"),
        DeletedMessage("W1617", "setslice-method"),
        DeletedMessage("W1618", "no-absolute-import"),
        DeletedMessage("W1619", "old-division"),
        DeletedMessage("W1620", "dict-iter-method"),
        DeletedMessage("W1621", "dict-view-method"),
        DeletedMessage("W1622", "next-method-called"),
        DeletedMessage("W1623", "metaclass-assignment"),
        DeletedMessage(
            "W1624", "indexing-exception", [("W0713", "old-indexing-exception")]
        ),
        DeletedMessage("W1625", "raising-string", [("W0701", "old-raising-string")]),
        DeletedMessage("W1626", "reload-builtin"),
        DeletedMessage("W1627", "oct-method"),
        DeletedMessage("W1628", "hex-method"),
        DeletedMessage("W1629", "nonzero-method"),
        DeletedMessage("W1630", "cmp-method"),
        DeletedMessage("W1632", "input-builtin"),
        DeletedMessage("W1633", "round-builtin"),
        DeletedMessage("W1634", "intern-builtin"),
        DeletedMessage("W1635", "unichr-builtin"),
        DeletedMessage(
            "W1636", "map-builtin-not-iterating", [("W1631", "implicit-map-evaluation")]
        ),
        DeletedMessage("W1637", "zip-builtin-not-iterating"),
        DeletedMessage("W1638", "range-builtin-not-iterating"),
        DeletedMessage("W1639", "filter-builtin-not-iterating"),
        DeletedMessage("W1640", "using-cmp-argument"),
        DeletedMessage("W1642", "div-method"),
        DeletedMessage("W1643", "idiv-method"),
        DeletedMessage("W1644", "rdiv-method"),
        DeletedMessage("W1645", "exception-message-attribute"),
        DeletedMessage("W1646", "invalid-str-codec"),
        DeletedMessage("W1647", "sys-max-int"),
        DeletedMessage("W1648", "bad-python3-import"),
        DeletedMessage("W1649", "deprecated-string-function"),
        DeletedMessage("W1650", "deprecated-str-translate-call"),
        DeletedMessage("W1651", "deprecated-itertools-function"),
        DeletedMessage("W1652", "deprecated-types-field"),
        DeletedMessage("W1653", "next-method-defined"),
        DeletedMessage("W1654", "dict-items-not-iterating"),
        DeletedMessage("W1655", "dict-keys-not-iterating"),
        DeletedMessage("W1656", "dict-values-not-iterating"),
        DeletedMessage("W1657", "deprecated-operator-function"),
        DeletedMessage("W1658", "deprecated-urllib-function"),
        DeletedMessage("W1659", "xreadlines-attribute"),
        DeletedMessage("W1660", "deprecated-sys-function"),
        DeletedMessage("W1661", "exception-escape"),
        DeletedMessage("W1662", "comprehension-escape"),
    ],
    "https://github.com/pylint-dev/pylint/pull/3578": [
        DeletedMessage("W0312", "mixed-indentation"),
    ],
    "https://github.com/pylint-dev/pylint/pull/3577": [
        DeletedMessage(
            "C0326",
            "bad-whitespace",
            [
                ("C0323", "no-space-after-operator"),
                ("C0324", "no-space-after-comma"),
                ("C0322", "no-space-before-operator"),
            ],
        ),
    ],
    "https://github.com/pylint-dev/pylint/pull/3571": [
        DeletedMessage("C0330", "bad-continuation")
    ],
    "https://pylint.readthedocs.io/en/latest/whatsnew/1/1.4.html#what-s-new-in-pylint-1-4-3": [
        DeletedMessage("R0921", "abstract-class-not-used"),
        DeletedMessage("R0922", "abstract-class-little-used"),
        DeletedMessage("W0142", "star-args"),
    ],
    "https://github.com/pylint-dev/pylint/issues/2409": [
        DeletedMessage("W0232", "no-init"),
    ],
    "https://github.com/pylint-dev/pylint/pull/6421": [
        DeletedMessage("W0111", "assign-to-new-keyword"),
    ],
}
MOVED_TO_EXTENSIONS = {
    "https://pylint.readthedocs.io/en/latest/whatsnew/2/2.14/summary.html#removed-checkers": [
        DeletedMessage("R0201", "no-self-use")
    ],
}


@cache
def is_deleted_symbol(symbol: str) -&gt; str | None:
    """Return the explanation for removal if the message was removed."""
    for explanation, deleted_messages in DELETED_MESSAGES_IDS.items():
        for deleted_message in deleted_messages:
            if symbol == deleted_message.symbol or any(
                symbol == m[1] for m in deleted_message.old_names
            ):
                return explanation
    return None


</t>
<t tx="ekr.20250131013601.71">@cache
def is_deleted_msgid(msgid: str) -&gt; str | None:
    """Return the explanation for removal if the message was removed."""
    for explanation, deleted_messages in DELETED_MESSAGES_IDS.items():
        for deleted_message in deleted_messages:
            if msgid == deleted_message.msgid or any(
                msgid == m[0] for m in deleted_message.old_names
            ):
                return explanation
    return None


</t>
<t tx="ekr.20250131013601.72">@cache
def is_moved_symbol(symbol: str) -&gt; str | None:
    """Return the explanation for moving if the message was moved to extensions."""
    for explanation, moved_messages in MOVED_TO_EXTENSIONS.items():
        for moved_message in moved_messages:
            if symbol == moved_message.symbol or any(
                symbol == m[1] for m in moved_message.old_names
            ):
                return explanation
    return None


</t>
<t tx="ekr.20250131013601.73">@cache
def is_moved_msgid(msgid: str) -&gt; str | None:
    """Return the explanation for moving if the message was moved to extensions."""
    for explanation, moved_messages in MOVED_TO_EXTENSIONS.items():
        for moved_message in moved_messages:
            if msgid == moved_message.msgid or any(
                msgid == m[0] for m in moved_message.old_names
            ):
                return explanation
    return None
</t>
<t tx="ekr.20250131013601.74">@path pylint/message
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

from dataclasses import asdict, dataclass

from pylint.constants import MSG_TYPES
from pylint.interfaces import UNDEFINED, Confidence
from pylint.typing import MessageLocationTuple


@dataclass(unsafe_hash=True)
@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.75">class Message:  # pylint: disable=too-many-instance-attributes
    """This class represent a message to be issued by the reporters."""

    @others
</t>
<t tx="ekr.20250131013601.76">msg_id: str
symbol: str
msg: str
C: str
category: str
confidence: Confidence
abspath: str
path: str
module: str
obj: str
line: int
column: int
end_line: int | None
end_column: int | None

def __init__(
    self,
    msg_id: str,
    symbol: str,
    location: MessageLocationTuple,
    msg: str,
    confidence: Confidence | None,
) -&gt; None:
    self.msg_id = msg_id
    self.symbol = symbol
    self.msg = msg
    self.C = msg_id[0]
    self.category = MSG_TYPES[msg_id[0]]
    self.confidence = confidence or UNDEFINED
    self.abspath = location.abspath
    self.path = location.path
    self.module = location.module
    self.obj = location.obj
    self.line = location.line
    self.column = location.column
    self.end_line = location.end_line
    self.end_column = location.end_column

</t>
<t tx="ekr.20250131013601.77">def format(self, template: str) -&gt; str:
    """Format the message according to the given template.

    The template format is the one of the format method :
    cf. https://docs.python.org/2/library/string.html#formatstrings
    """
    return template.format(**asdict(self))

</t>
<t tx="ekr.20250131013601.78">@property
def location(self) -&gt; MessageLocationTuple:
    return MessageLocationTuple(
        self.abspath,
        self.path,
        self.module,
        self.obj,
        self.line,
        self.column,
        self.end_line,
        self.end_column,
    )
</t>
<t tx="ekr.20250131013601.79">@path pylint/message
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import sys
from typing import TYPE_CHECKING

from astroid import nodes

from pylint.constants import _SCOPE_EXEMPT, MSG_TYPES, WarningScope
from pylint.exceptions import InvalidMessageError
from pylint.utils import normalize_text

if TYPE_CHECKING:
    from pylint.checkers import BaseChecker


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.8">    def load_plugin_configuration(self) -&gt; None:
        """Call the configuration hook for plugins.

        This walks through the list of plugins, grabs the "load_configuration"
        hook, if exposed, and calls it to allow plugins to configure specific
        settings.

        The result of attempting to load the plugin of the given name
        is stored in the dynamic plugins dictionary in ``load_plugin_modules`` above.

        ..note::
            This function previously always tried to load modules again, which
            led to some confusion and silent failure conditions as described
            in GitHub issue #7264. Making it use the stored result is more efficient, and
            means that we avoid the ``init-hook`` problems from before.
        """
        for modname, module_or_error in self._dynamic_plugins.items():
            if isinstance(module_or_error, ModuleNotFoundError):
                self.add_message(
                    "bad-plugin-value", args=(modname, module_or_error), line=0
                )
            elif hasattr(module_or_error, "load_configuration"):
                module_or_error.load_configuration(self)

        # We re-set all the dictionary values to True here to make sure the dict
        # is pickle-able. This is only a problem in multiprocessing/parallel mode.
        # (e.g. invoking pylint -j 2)
        self._dynamic_plugins = {
            modname: not isinstance(val, ModuleNotFoundError)
            for modname, val in self._dynamic_plugins.items()
        }

</t>
<t tx="ekr.20250131013601.80">class MessageDefinition:
    @others
</t>
<t tx="ekr.20250131013601.81"># pylint: disable-next=too-many-arguments
def __init__(
    self,
    checker: BaseChecker,
    msgid: str,
    msg: str,
    description: str,
    symbol: str,
    scope: str,
    minversion: tuple[int, int] | None = None,
    maxversion: tuple[int, int] | None = None,
    old_names: list[tuple[str, str]] | None = None,
    shared: bool = False,
    default_enabled: bool = True,
) -&gt; None:
    self.checker_name = checker.name
    self.check_msgid(msgid)
    self.msgid = msgid
    self.symbol = symbol
    self.msg = msg
    self.description = description
    self.scope = scope
    self.minversion = minversion
    self.maxversion = maxversion
    self.shared = shared
    self.default_enabled = default_enabled
    self.old_names: list[tuple[str, str]] = []
    if old_names:
        for old_msgid, old_symbol in old_names:
            self.check_msgid(old_msgid)
            self.old_names.append(
                (old_msgid, old_symbol),
            )

</t>
<t tx="ekr.20250131013601.82">@staticmethod
def check_msgid(msgid: str) -&gt; None:
    if len(msgid) != 5:
        raise InvalidMessageError(f"Invalid message id {msgid!r}")
    if msgid[0] not in MSG_TYPES:
        raise InvalidMessageError(f"Bad message type {msgid[0]} in {msgid!r}")

</t>
<t tx="ekr.20250131013601.83">def __eq__(self, other: object) -&gt; bool:
    return (
        isinstance(other, MessageDefinition)
        and self.msgid == other.msgid
        and self.symbol == other.symbol
    )

</t>
<t tx="ekr.20250131013601.84">def __repr__(self) -&gt; str:
    return f"MessageDefinition:{self.symbol} ({self.msgid})"

</t>
<t tx="ekr.20250131013601.85">def __str__(self) -&gt; str:
    return f"{self!r}:\n{self.msg} {self.description}"

</t>
<t tx="ekr.20250131013601.86">def may_be_emitted(self, py_version: tuple[int, ...] | sys._version_info) -&gt; bool:
    """May the message be emitted using the configured py_version?"""
    if self.minversion is not None and self.minversion &gt; py_version:
        return False
    if self.maxversion is not None and self.maxversion &lt;= py_version:
        return False
    return True

</t>
<t tx="ekr.20250131013601.87">def format_help(self, checkerref: bool = False) -&gt; str:
    """Return the help string for the given message id."""
    desc = self.description
    if checkerref:
        desc += f" This message belongs to the {self.checker_name} checker."
    title = self.msg
    if self.minversion or self.maxversion:
        restr = []
        if self.minversion:
            restr.append(f"&lt; {'.'.join(str(n) for n in self.minversion)}")
        if self.maxversion:
            restr.append(f"&gt;= {'.'.join(str(n) for n in self.maxversion)}")
        restriction = " or ".join(restr)
        if checkerref:
            desc += f" It can't be emitted when using Python {restriction}."
        else:
            desc += (
                f" This message can't be emitted when using Python {restriction}."
            )
    msg_help = normalize_text(" ".join(desc.split()), indent="  ")
    message_id = f"{self.symbol} ({self.msgid})"
    if title != "%s":
        title = title.splitlines()[0]
        return f":{message_id}: *{title.rstrip(' ')}*\n{msg_help}"
    return f":{message_id}:\n{msg_help}"

</t>
<t tx="ekr.20250131013601.88">def check_message_definition(
    self, line: int | None, node: nodes.NodeNG | None
) -&gt; None:
    """Check MessageDefinition for possible errors."""
    if self.msgid[0] not in _SCOPE_EXEMPT:
        # Fatal messages and reports are special, the node/scope distinction
        # does not apply to them.
        if self.scope == WarningScope.LINE:
            if line is None:
                raise InvalidMessageError(
                    f"Message {self.msgid} must provide line, got None"
                )
            if node is not None:
                raise InvalidMessageError(
                    f"Message {self.msgid} must only provide line, "
                    f"got line={line}, node={node}"
                )
        elif self.scope == WarningScope.NODE:
            # Node-based warnings may provide an override line.
            if node is None:
                raise InvalidMessageError(
                    f"Message {self.msgid} must provide Node, got None"
                )
</t>
<t tx="ekr.20250131013601.89">@path pylint/message
# Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt

from __future__ import annotations

import collections
import sys
from collections.abc import Sequence, ValuesView
from functools import cache
from typing import TYPE_CHECKING

from pylint.exceptions import UnknownMessageError
from pylint.message.message_definition import MessageDefinition
from pylint.message.message_id_store import MessageIdStore

if TYPE_CHECKING:
    from pylint.checkers import BaseChecker


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20250131013601.9">    def _load_reporters(self, reporter_names: str) -&gt; None:
        """Load the reporters if they are available on _reporters."""
        if not self._reporters:
            return
        sub_reporters = []
        output_files = []
        with contextlib.ExitStack() as stack:
            for reporter_name in reporter_names.split(","):
                reporter_name, * reporter_output = reporter_name.split(":", 1)

                reporter = self._load_reporter_by_name(reporter_name)
                sub_reporters.append(reporter)
                if reporter_output:
                    output_file = stack.enter_context(
                        open(reporter_output[0], "w", encoding="utf-8")
                    )
                    reporter.out = output_file
                    output_files.append(output_file)

            # Extend the lifetime of all opened output files
            close_output_files = stack.pop_all().close

        if len(sub_reporters) &gt; 1 or output_files:
            self.set_reporter(
                reporters.MultiReporter(
                    sub_reporters,
                    close_output_files,
                )
            )
        else:
            self.set_reporter(sub_reporters[0])

</t>
<t tx="ekr.20250131013601.90">class MessageDefinitionStore:
    """The messages store knows information about every possible message definition but
    has no particular state during analysis.
    """

    @others
</t>
<t tx="ekr.20250131013601.91">def __init__(
    self, py_version: tuple[int, ...] | sys._version_info = sys.version_info
) -&gt; None:
    self.message_id_store: MessageIdStore = MessageIdStore()
    # Primary registry for all active messages definitions.
    # It contains the 1:1 mapping from msgid to MessageDefinition.
    # Keys are msgid, values are MessageDefinition
    self._messages_definitions: dict[str, MessageDefinition] = {}
    # MessageDefinition kept by category
    self._msgs_by_category: dict[str, list[str]] = collections.defaultdict(list)
    self.py_version = py_version

</t>
<t tx="ekr.20250131013601.92">@property
def messages(self) -&gt; ValuesView[MessageDefinition]:
    """The list of all active messages."""
    return self._messages_definitions.values()

</t>
<t tx="ekr.20250131013601.93">def register_messages_from_checker(self, checker: BaseChecker) -&gt; None:
    """Register all messages definitions from a checker."""
    checker.check_consistency()
    for message in checker.messages:
        self.register_message(message)

</t>
<t tx="ekr.20250131013601.94">def register_message(self, message: MessageDefinition) -&gt; None:
    """Register a MessageDefinition with consistency in mind."""
    self.message_id_store.register_message_definition(
        message.msgid, message.symbol, message.old_names
    )
    self._messages_definitions[message.msgid] = message
    self._msgs_by_category[message.msgid[0]].append(message.msgid)

</t>
<t tx="ekr.20250131013601.95"># Since MessageDefinitionStore is only initialized once
# and the arguments are relatively small we do not run the
# risk of creating a large memory leak.
# See discussion in: https://github.com/pylint-dev/pylint/pull/5673
@cache  # pylint: disable=method-cache-max-size-none # noqa: B019
def get_message_definitions(self, msgid_or_symbol: str) -&gt; list[MessageDefinition]:
    """Returns the Message definition for either a numeric or symbolic id.

    The cache has no limit as its size will likely stay minimal. For each message we store
    about 1000 characters, so even if we would have 1000 messages the cache would only
    take up ~= 1 Mb.
    """
    return [
        self._messages_definitions[m]
        for m in self.message_id_store.get_active_msgids(msgid_or_symbol)
    ]

</t>
<t tx="ekr.20250131013601.96">def get_msg_display_string(self, msgid_or_symbol: str) -&gt; str:
    """Generates a user-consumable representation of a message."""
    message_definitions = self.get_message_definitions(msgid_or_symbol)
    if len(message_definitions) == 1:
        return repr(message_definitions[0].symbol)
    return repr([md.symbol for md in message_definitions])

</t>
<t tx="ekr.20250131013601.97">def help_message(self, msgids_or_symbols: Sequence[str]) -&gt; None:
    """Display help messages for the given message identifiers."""
    for msgids_or_symbol in msgids_or_symbols:
        try:
            for message_definition in self.get_message_definitions(
                msgids_or_symbol
            ):
                print(message_definition.format_help(checkerref=True))
                print("")
        except UnknownMessageError as ex:
            print(ex)
            print("")
            continue

</t>
<t tx="ekr.20250131013601.98">def list_messages(self) -&gt; None:
    """Output full messages list documentation in ReST format."""
    emittable, non_emittable = self.find_emittable_messages()
    print("Emittable messages with current interpreter:")
    for msg in emittable:
        print(msg.format_help(checkerref=False))
    print("\nNon-emittable messages with current interpreter:")
    for msg in non_emittable:
        print(msg.format_help(checkerref=False))
    print("")

</t>
<t tx="ekr.20250131013601.99">def find_emittable_messages(
    self,
) -&gt; tuple[list[MessageDefinition], list[MessageDefinition]]:
    """Finds all emittable and non-emittable messages."""
    messages = sorted(self._messages_definitions.values(), key=lambda m: m.msgid)
    emittable = []
    non_emittable = []
    for message in messages:
        if message.may_be_emitted(self.py_version):
            emittable.append(message)
        else:
            non_emittable.append(message)
    return emittable, non_emittable
</t>
<t tx="ekr.20250131014444.1">tbo: beautified: test_file.py

Traceback (most recent call last):

  File "C:\Repos\leo-editor\leo\core\leoAtFile.py", line 2347, in runTokenBasedBeautifier
    changed = beautify_file(filename)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Repos\leo-editor\leo\core\leoTokens.py", line 109, in beautify_file
    return tbo.beautify_file(filename)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Repos\leo-editor\leo\core\leoTokens.py", line 833, in beautify_file
    results = self.beautify(contents, filename, tokens)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Repos\leo-editor\leo\core\leoTokens.py", line 807, in beautify
    print(self.internal_error_message(repr(e)))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Repos\leo-editor\leo\core\leoTokens.py", line 681, in internal_error_message
    line_number = self.input_token.line_number
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^

AttributeError: 'NoneType' object has no attribute 'line_number</t>
<t tx="ekr.20250131014711.1"></t>
</tnodes>
</leo_file>
